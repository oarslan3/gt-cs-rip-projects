@Comment(BIBTEMPLATE .)
@Comment(BIBREFERENCES stdalphabetic)
@Comment{BIBSEPARATORS ",;&"}
		  
% BibTeX bibliography string definitions of the ABBREVIATED titles of
% IEEE journals and magazines taken from IEEEabrv.bib

@STRING{AES   = "{IEEE} Trans. Aerosp. Electron. Syst."}
@STRING{AS    = "{IEEE} Trans. Aerosp."}
@STRING{IP    = "{IEEE} Trans. Image Processing"}
@STRING{ITAC  = "{IEEE} Trans. Automat. Contr."}
@STRING{PAMI  = "{IEEE} Trans. Pattern Anal. Machine Intell."}
@string{SMC   = "{IEEE} Trans. Syst., Man, Cybern."}
@string{SP    = "{IEEE} Trans. Signal Processing"}
@string{TRA   = "{IEEE} Trans. Robot. Automat."}
@string{TRO   = "{IEEE} Trans. Robotics"}
@string{ASSP  = "{IEEE} Trans. Acoust., Speech, Signal Processing"}
@STRING{IT    = "{IEEE} Trans. Inform. Theory"}
@STRING{COMP  = "{IEEE} Trans. Computers"}

% Other Journals
@string{AI    = "Artificial Intelligence"}
@string{JAIR  = "Journal of Artificial Intelligence Research"}
@string{CVIU  = "Computer Vision and Image Understanding"}
@string{GMIP  = "CVGIP:Graphical Models and Image Processing"}
@string{IJCV  = "Intl. J. of Computer Vision"}
@string{IJRR  = "Intl. J. of Robotics Research"}
@string{IVC   = "Image and Vision Computing"}
@string{JMLR  = "J. of Machine Learning Research"}
@string{JVCIR = "J. of Visual Communication and Image Representation"}
@string{ML    = "Machine learning"}
@string{PR    = "Pattern Recognition"}
@string{PRL   = "Pattern Recognition Letters"}
@string{RAS   = "Journal of Robotics and Autonomous Systems"}
@string{JFR   = "J. of Field Robotics"}
@string{RoyalP = "Proceedings of Royal Society of London"}
@string{josaa = "J. of the Optical Society of America A"}
@string{tcs   = "Theoretical Computer Science"}
@string{AR    = "Autonomous Robots"}
@string{JEPLMC= "Journal of Experimental Psychology: Learning,Memory, \& Cognition"}
@string{JASA  = "Journal of the American Statistical Association"}

% Image processing conferences
@string{ICIP = "Intl. Conf. on Image Processing (ICIP)"}
@string{IAPR = "Intl. Conf. on Image Processing A"}
@string{ICASSP = "Intl. Conf. Acoust., Speech, and Signal Proc. (ICASSP)"}

% Vision Conferences
@string{BMVC = "British Machine Vision Conf. (BMVC)"}
@string{CVPR = "IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)"}
@string{ACCV = "Asian Conf. on Computer Vision (ACCV)"}
@string{ECCV = "Eur. Conf. on Computer Vision (ECCV)"}
@string{ICCV = "Intl. Conf. on Computer Vision (ICCV)"}
@string{ICPR = "Intl. Conf. on Pattern Recognition (ICPR)"}
@string{RVS95 = "Representation of Visual Scenes"}
@string{SPIE = "Intl. Soc. Opt. Eng. (SPIE)"}
@string{SIGGRAPH = "SIGGRAPH"}
@string{AICV94 = "Application of Invariance in Computer Vision"}
@string{FG = "Intl. Conf. on Automatic Face and Gesture Recognition"}
@string{PVT = "3D Data Processing Visualization and Transmission (3DPVT)"}

% Robotics Conferences
@string{ICRA = "IEEE Intl. Conf. on Robotics and Automation (ICRA)"}
@string{IROS = "IEEE/RSJ Intl. Conf. on Intelligent Robots and Systems (IROS)"}
@string{FSR = "Field and Service Robotics (FSR)"}
@string{RSS = "Robotics: Science and Systems (RSS)"}
@string{CIRA = "IEEE Intl. Symp. on Computational Intelligence in Robotics and Automation (CIRA)"}
@string{ISRR = "Proc. of the Intl. Symp. of Robotics Research (ISRR)"}
@string{AAMAS = "Proc. of the Intl. Conf. on Autonomous Agents and Multiagent Systems (AAMAS)"}

% Augmented Reality Conferences
@string{ISMAR = "IEEE and ACM Intl. Sym. on Mixed and Augmented Reality (ISMAR)"}
@string{ISAR = "IEEE and ACM Intl. Sym. on Augmented Reality (ISAR)"}
@string{ISMR = "Intl. Sym. on Mixed Reality (ISMR)"}
@string{CVE = "ACM Intl. Conf. on Collaborative Virtual Environments (CVE)"}
@string{ISWC = "IEEE Intl. Sym. on Wearable Computers (ISWC)"}
@string{HRI = "Conf. on Human-Robot Interaction (HRI)"}

%AI Conferences
@string{AAAI = "Nat. Conf. on Artificial Intelligence (AAAI)"}
@string{IJCAI = "Intl. Joint Conf. on AI (IJCAI)"}
@string{NIPS = "Advances in Neural Information Processing Systems (NIPS)"}
@string{ICML = "Intl. Conf. on Machine Learning (ICML)"}
@string{UAI = "Conf. on Uncertainty in Artificial Intelligence (UAI)"}
@string{

%Multimedia Conference
@string{ICME = "IEEE Intl. Conf. on Multimedia and Expo(ICME)"}

%DataMining Conferences
@string{KDD = "Intl. Conf. Knowledge Discovery and Data Mining (KDD)"}

%Graphics Conferences
@string{_3DIM = "Intl. Conf. on 3D Digital Imaging and Modeling"}
@string{IVIS = "IEEE Visualization"}

%Architecture Conferences
@string{EPB = "Environment and Planning B: Planning and Design"}

% Theory Conferences
@string{STOC  ="ACM Symp. on Theory of Computing (STOC)"}
@string{ICFP = "Intl. Conf. on Functional Programming (ICFP)"}

% Control Conferences
@string{CDC = "IEEE Conference on Decision and Control"}
@string{ACC = "American Control Conference"}

% Aerospace Conferences
@string{GNC = "AIAA Guidance, Navigation, and Control Conference"}
@string{AC = "IEEE Aerospace Conference"}

% Information Retrieval Conferences
@string{SIGIR = "ACM Special Interest Group on Information Retrieval"}

% Workshops
@string{IUW  = "DARPA Image Understanding Workshop (IUW)"}
@string{WACV = "IEEE Workshop on Applications of Computer Vision (WACV)"}
@string{ISER = "Intl. Sym. on Experimental Robotics (ISER)"}
@string{IPSN = "Intl. Sym. on Information Processing in Sensor Networks (IPSN)"}

% Publishers
@string{kluwer = "Kluwer"}
@string{springer = "Springer Verlag"}
@string{ieeepress = "IEEE Computer Society Press"}
@string{addison = "Addison-Wesley Publishing"}
@string{ap = "Academic Press"}
@string{chap = "Chapman and Hall"}
@string{MIT = "The MIT press, Cambridge, MA"}
@string{Wiley = "John Wiley \& Sons, New York, NY"}

% Institutions
@string{CoC = "College of Computing, Georgia Institute of Technology"}

@InProceedings{Aboutalib07aamas,
  AUTHOR =	 {S. Aboutalib and M. Veloso},
  TITLE =	 {Towards Using Multiple Cues for Robust Object Detection},
  Booktitle =	 AAMAS,
  YEAR =	 { 2007 },
  added-by =     {Alex}
}

@misc{ACFR,
  author =	 {ACFR},
  title =	 {{Experimental} outdoor dataset},
  url =
                  {http://www.acfr.usyd.edu.au/homepages/academic/enebot/dataset.htm}
}

@TECHREPORT{Adams07,
  AUTHOR =	 {R.P. Adams and D.J.C. MacKay},
  TITLE =	 "{B}ayesian Online Changepoint Detection",
  INSTITUTION =	 "University of Cambridge",
  ADDRESS =	 "Cambridge, UK",
  YEAR =	 2007,
  NOTE =	 "arXiv:0710.3742v1 [stat.ML]"
}

@article{Adelson85,
  author =	 "E.H. Adelson and J.R. Bergen",
  fullauthor =	 "Edward H. Adelson and James R. Bergen",
  title =	 "Spatiotemporal energy models for the perception of
                  motion",
  journal =	 "Journal of the Optical Society of America A",
  volume =	 2,
  year =	 1985,
  number =	 2,
  pages =	 "284-299"
}

@InCollection{Adelson91,
  author =	 {E.H. Adelson and J.R. Bergen},
  title =	 {The plenoptic function and elements of early vision},
  booktitle =	 {Computational Models of Visual Processing},
  pages =	 {3--20},
  publisher =	 {MIT Press},
  year =	 1991,
  editor =	 {M. Landy and J. Anthony Movshon},
}

@article{Adler81,
  author =	 "S. L. Adler",
  title =	 "Over-relaxation method for the Monte Carlo
                  evaluation of the partition function for
                  multiquadratic actions",
  journal =	 "Physical Review D",
  volume =	 23,
  pages =	 "2901-2904",
  year =	 1981
}

@Article{Agarwal00,
  author =	 {M. Agarwal, J. Cagan and G. Stiny},
  title =	 {A micro language: generating MEMS resonators by
                  using a coupled form-function shape grammar},
  journal =	 {Environment and Planning B: Planning and Design},
  year =	 2000,
  volume =	 27,
  pages =	 {615-626 },
}

@Article{Agarwal98,
  author =	 {M. Agarwal and J. Cagan},
  title =	 {A Blend of Different Tastes: The Language of Coffee
                  Makers},
  journal =	 {Environment and Planning B: Planning and Design},
  year =	 1998,
  volume =	 {25(2)},
  pages =	 {205-226 },
}

@Article{Agarwal99cviu,
  author =	 {J.K. Agarwal and Q.Cai},
  title =	 {{Human Motion Analysis : A Review}},
  journal =	 CVIU,
  month =	 {March},
  year =	 1999,
  volume =	 73,
  number =	 3,
  pages =	 {428--440},
}

@article{Aggarwal81,
  author =	 "J. Aggarwal and L. Davis and W. Martin",
  title =	 "Correspondence processes in dynamic scene analysis",
  journal =	 "Proceedings of IEEE",
  volume =	 69,
  number =	 5,
  pages =	 "562--572",
  month =	 "May",
  year =	 1981
}

@inproceedings{Agrawal06iros,
  author =	 {M. Agrawal},
  title =	 {A {L}ie Algebraic Approach for Consistent Pose
                  Registration for Motion Estimation},
  booktitle =	 IROS,
  year =	 2006,
}

@article {Agrawal08tro,
  title =	 {{FrameSLAM}: From Bundle Adjustment to Real-Time
                  Visual Mapping},
  journal =	 TRO,
  pages =	 {1066-1077},
  volume =	 {24},
  number =	 {5},
  year =	 {2008},
  month =	 {October},
  author =	 {M. Agrawal and K. Konolige}
}

@InProceedings{Ahmadzadeh06auvsi,
  AUTHOR =	 {A. Ahmadzadeh and G. Buchman and P. Cheng and
                  A. Jadbabaie and J. Keller and V. Kumar and
                  G. Pappas },
  TITLE =	 {Cooperative control of UAVs for Search and Coverage},
  Booktitle =	 { Proceedings of the AUVSI Conference on Unmanned
                  Systems },
  YEAR =	 { 2006 },
}

@InProceedings{Ahn06iros,
  author =	 {Sunghwan Ahn and Minyong Choi and Jinwoo Choi and
                  Wang Kyun Chung},
  title =	 {Data Association using Visual Object Recognition for
                  {EKF-SLAM} in Home Environment},
  booktitle =	 IROS,
  year =	 {2006},
  added-by =	 {Alireza}
}

@InProceedings{Ahn07icra,
  author =	 {Sunghwan Ahn and Kyongmin Lee and Wang Kyun Chung
                  and Sang-Rok oh},
  title =	 {{SLAM} with Visual Plane: Extracting Vertical Plane by
                  Fusing Stereo Vision and Ultrasonic Sensor for
                  Indoor Environment},
  booktitle =	 ICRA,
  year =	 {2007},
  added-by =	 {Alireza}
}

@InProceedings{Ahn07iros,
  author =	 {Sunghwan Ahn and Wang Kyun Chung and Sang-Rok oh},
  title =	 {Construction of Hybrid Visual Map for Indoor {SLAM}},
  booktitle =	 IROS,
  year =	 {2007},
  added-by =	 {Alireza}
}

@Book{Aho88,
  author =	 {A. Aho and R. Sethi and J. Ullman},
  title =	 {Compilers, principles, techniques and tools},
  publisher =	 {Addison-Wesley},
  year =	 1988,
  address =	 {Reading, MA},
}

@Book{AhoUllman72,
  author =	 {A.V. Aho and J.D. Ullman},
  title =	 {The Theory of Parsing, Translation and Compiling,
                  Vol. 1: Parsing},
  publisher =	 {Prentice-Hall},
  year =	 1972,
  fulladdress =	 {Englewood Cliffs, NJ},
}

@Article{Aji00it,
  author =	 {S.M. Aji and R.J. McEliece},
  fullauthor =	 {Srinivas M. Aji and Robert J. McEliece},
  title =	 {The Generalized Distributive Law},
  journal =	 IT,
  year =	 2000,
  volume =	 46,
  number =	 2,
  pages =	 325,
  month =	 {March},
  abstract =	 {We discuss a general message passing algorithm,
                  which we call the generalized distributive law
                  (GDL). The GDL is a synthesis of the work of many
                  authors in information theory, digital
                  communications, signal processing, statistics and
                  artificial intelligence. It includes as special
                  cases the Baum-Welch algorithm, the fast Fourier
                  transform (FFT) on any finite Abelian group, the
                  Gallager-Tanner-Wiberg decoding algorithm, Viterbi's
                  algorithm, the BCJR algorithm, Pearl's "belief
                  propagation" algorithm, the Shafer-Shenoy
                  probability propagation algorithm, and the turbo
                  decoding algorithm. Although this algorithm is
                  guaranteed to give exact answers only in certain
                  cases (the "junction tree" condition), unfortunately
                  not including the cases of GTW with cycles or turbo
                  decoding, there is much experimental evidence, and a
                  few theorems, suggesting that it often works
                  approximately even when it is not supposed to.},
  quotes =	 {The relevant research in the artificial intelligence
                  (AI) community began relatively late, but it has
                  evolved quickly. [plus nice history]},
  r-Kschischang01it ={variables are arguments of which local
                  functions. In a landmark paper \cite{Aji00it}, Aji
                  and McEliece develop a "generalized distributive
                  law" (GDL) that in some cases solves the MPF problem
                  using a "junction tree" representation of the global
                  function. Factor graphs may be viewed as an
                  alternative approach with closer ties to Tanner
                  graphs and previously developed graphical
                  representations for codes. Es- sentially, every
                  result developed in the junction tree/GDL set- ting
                  may be translated into an equivalent result in the
                  factor graph/sum-product algorithm setting, and vice
                  versa.},
  r-Loeliger04spm ={It was therefore exciting when, in the wake of
                  turbo coding, probability propagation and the
                  sum-product algorithm were found to be the same
                  thing \citep{Frey96ccc,Aji00it}. In particular, the
                  example of iterative decoding proved that
                  probability propagation, which had been used only
                  for cycle-free graphs, could be used also for graphs
                  with cycles. },
  c-dellaert =	 {Originator of name "factor graphs" ?},
}

@Article{Akaike74,
  author =	 {H. Akaike},
  title =	 {A new look at statistical model identification},
  journal =	 {IEEE Transactions on Automatic Control},
  year =	 1974,
  volume =	 19,
  pages =	 {716--723},
}

@Article{Akaike74,
  author =	 {H. Akaike},
  title =	 {A new look at statistical model identification},
  journal =	 {IEEE Transactions on Automatic Control},
  year =	 1974,
  volume =	 19,
  pages =	 {716--723},
}

@Article{Akashi77,
  author =	 {Hajime Akashi and Hiromitsu Kumamoto},
  title =	 {Random {S}ampling {A}pproach to State Estimation in
                  Switching Environments},
  journal =	 {Automatica},
  year =	 {1977},
  volume =	 {13},
  pages =	 {429-434},
}

@InProceedings{Akbarally96,
  author =	 {H. Akbarally and L. Kleeman},
  title =	 {{3D} Robot Sensing from Sonar and Vision},
  booktitle =	 ICRA,
  year =	 1996,
  pages =	 {686-691},
}

@InProceedings{Akbarzadeh06_3dpvt,
  author =	 {A. Akbarzadeh and J.-M. Frahm and P. Mordohai and
                  B. Clipp and C. Engels and D. Gallup and P. Merrell
                  and M. Phelps and S. Sinha and B. Talton and L. Wang
                  and Q. Yang and H. Stew\'eius and R. Yang and
                  G. Welch and H. Towles and D. Nist\'er and
                  M. Pollefeys},
  title =	 {Towards Urban {3D} Reconstruction From Video},
  booktitle =	 PVT,
  year =	 2006,
}

@Unpublished{Aksoy05,
  author =	 "Selim Aksoy",
  title =	 "Parametric Models",
  institution =	 {Department of Computer Engineering, Bilkent
                  University},
  year =	 2005,
  note =	 {CS551 slides}
}

@InProceedings{Alegre04cipa,
  title =	 "A Probabilistic Approach to the Semantic
                  Interpretation of Building Facades",
  author =	 "F. Alegre and F. Dellaert",
  fullauthor =	 "Fernando Alegre and Frank Dellaert",
  booktitle =	 "International Workshop on Vision Techniques Applied
                  to the Rehabilitation of City Centres",
  organization = "International Committee for Architectural
                  Photogrammetry; (CIPA); Lisbon",
  month =	 "October",
  year =	 2004,
  url =
                  {http://www.cc.gatech.edu/~dellaert/pubs/Alegre04cipa.pdf}
}

@article{Allen83acm,
  author =	 {J. F. Allen},
  fullauthor =	 {James F. Allen},
  title =	 {Maintaining knowledge about temporal intervals},
  journal =	 {Commun. ACM},
  volume =	 26,
  number =	 11,
  year =	 1983,
  issn =	 {0001-0782},
  pages =	 {832--843},
  doi =		 {http://doi.acm.org/10.1145/182.358434},
  publisher =	 {ACM Press},
  address =	 {New York, NY, USA},
}

@article{Aloimonos88ijcv,
  title =	 {Active vision},
  journal =	 IJCV,
  Volume =	 1,
  Number =	 4,
  Month =	 {January},
  year =	 1988,
  author =	 {Y. Aloimonos and I. Weiss and A. Bandyopadhyay},
  fullauthor =	 {John (Yiannis) Aloimonos and Isaac Weiss and Amit
                  Bandyopadhyay},
  Abstract =	 {We investigate several basic problems in vision
                  under the assumption that the observer is active. An
                  observer is called active when engaged in some kind
                  of activity whose purpose is to control the
                  geometric parameters of the sensory apparatus. The
                  purpose of the activity is to manipulate the
                  constraints underlying the observed phenomena in
                  order to improve the quality of the perceptual
                  results. For example a monocular observer that moves
                  with a known or unknown motion or a binocular
                  observer that can rotate his eyes and track
                  environmental objects are just two examples of an
                  observer that we call active. We prove that an
                  active observer can solve basic vision problems in a
                  much more efficient way than a passive one. Problems
                  that are ill-posed and nonlinear for a passive
                  observer become well-posed and linear for an active
                  observer. In particular, the problems of shape from
                  shading and depth computation, shape from contour,
                  shape from texture, and structure from motion are
                  shown to be much easier for an active observer than
                  for a passive one. It has to be emphasized that
                  correspondence is not used in our approach, i.e.,
                  active vision is not correspondence of features from
                  multiple viewpoints. Finally, active vision here
                  does not mean active sensing, and this paper
                  introduces a general methodology, a general
                  framework in which we believe low-level vision
                  problems should be addressed.},
  r-Clark92chapter ={Aloimonos et al showed that camera motion can be
                  used to make a vision problem that is ill-posed in
                  the single image case into a well posed one},
  r-Edelman08chapter ={Both the feasibility of and the need for an
                  explicit and sweeping reconstruction of the geometry
                  of the visual world have been subsequently
                  questioned (Aloimonos et al., 1988; Bajcsy,
                  1988). Noting that biological vision is purposive
                  and active, researchers proposed that computer
                  vision too should aim at serving certain well-dened
                  goals such as navigation or recognition rather than
                  at constructing a general-purpose representation of
                  the world.},
  c-dellaert =	 {Camera motion makes some problems easier.}
}

@techreport{Amestoy94tr,
  author =	 "P. R. Amestoy and I.S. Duff and C. Puglisi",
  title =	 "Multifrontal {QR} factorization in a multiprocessor
                  environment",
  number =	 "TR/PA/94/09",
  institution =	 {ENSEEIHT},
  address =	 "Toulouse, France",
  year =	 "1994",
}

@Article{Amestoy96siam,
  author =	 {P.R. Amestoy and T. Davis and I.S. Duff},
  title =	 {An approximate minimum degree ordering algorithm},
  journal =	 {SIAM Journal on Matrix Analysis and Applications},
  year =	 1996,
  volume =	 17,
  number =	 4,
  pages =	 {886-905},
  abstract =	 {An approximate minimum degree (AMD) ordering
                  algorithm for preordering a symmetric sparse matrix
                  prior to numerical factorization is presented. We
                  use techniques based on the quotient graph for
                  matrix factorization that allow us to obtain
                  computationally cheap bounds for the minimum
                  degree. We show that these bounds are often equal to
                  the actual degree. The resulting algorithm is
                  typically much faster than previous minimum degree
                  ordering algorithms and produces results that are
                  comparable in quality with the best orderings from
                  other minimum degree algorithms.},
}

@book{Amestoy99,
  author =	 {P. R. Amestoy },
  title =	 {Parallel multifrontal sparse direct methods},
  year =	 1999,
  month =	 {May},
}

@Article{Amit91,
  author =	 "Y. Amit and U. Grenander and M. Piccioni",
  title =	 "Structural Image Restoration through Derormable
                  Templates",
  journal =	 {Journal of the American Statistical Association},
  volume =	 86,
  pages =	 {376--387},
  year =	 1991
}

@article{Andersen06vc,
  Author =	 {Andersen, G.J. and Enriquez, A.},
  fullAuthor =	 {Andersen, George J. and Enriquez, AnnJudel},
  Journal =	 {Visual Cognition},
  Number =	 1,
  Pages =	 {p119 - 128},
  Title =	 {Use of landmarks and allocentric reference frames
                  for the control of locomotion.},
  Volume =	 13,
  Year =	 2006,
  Abstract =	 {In the present study we assessed the use of
                  landmarks and scene layout information for the
                  control of locomotion. Observers were presented
                  displays simulating forward locomotion through a
                  random dot field with the horizontal position
                  perturbed by a sum-of-sines function and were asked
                  to steer and null out the horizontal disturbance of
                  the path of locomotion. The results indicate greater
                  control gain and accuracy when presented with a
                  repeating layout of landmarks as compared to a
                  changing layout of landmarks. Debriefing responses
                  suggest that observers may have implicitly learned
                  the layout of the repeating pattern. These results
                  suggest that observers use an allocentric
                  representation of the scene for steering control. A
                  model for the control of locomotion is discussed
                  that utilizes both scene-based information and optic
                  flow.},
  quotes =	 {Both flow and scene are used to drive. Scene =
                  high-level, flow = control.}
}

@InProceedings{Anderson02kdd,
  author =	 {C. Anderson and P. Domingos and D. Weld},
  title =	 {{Relational Markov Models and their Application to
                  Adaptive Web Navigation}},
  BOOKTITLE =	 KDD,
  pages =	 {143-152},
  year =	 2002,
  keywords =	 {relational model, hierarchical model, abstraction,
                  web navigation},
  c-sangmin =	 {Authors introduce relational markov
                  model(RMM).Different from Markov models which evolve
                  over a set of states under one category(relation),
                  RMM generalizes the behavior so that the system can
                  iterate over distinct sets of relations consisted of
                  several domain entities which correspond to
                  attributes. One nicer fact is that there are states
                  with abstract domain attributes which correspond to
                  the middle nodes of a hierarchical tree rather than
                  the leaves(which are specific instances). Hence, RMM
                  provides improved learning/inference results given a
                  small amount of training dataset over a large state
                  space via the use of higher level knowledge between
                  abstract states.},
}

@Book{Anderson93book,
  author =	 {J.R. Anderson},
  title =	 {Rules of the Mind},
  publisher =	 {Lawrence Erlbaum Associates},
  year =	 1993,
  address =	 {Hillsdale, NJ},
}

@Book{Andreson99book,
  author =	 {E. Anderson and Z. Bai and J. Bishop and J. Demmel
                  and J. Du Croz and A. Greenbaum and S. Hammarling
                  and A. McKenney and S. Ostrouchov and D. Sorensen},
  title =	 {{LAPACK} User's Guide},
  publisher =	 {SIAM},
  year =	 1999,
  address =	 {Philadelphia},
  edition =	 3,
}

@INPROCEEDINGS{Andrieu01nips,
  AUTHOR =	 {C. Andrieu and N. {de Freitas} and A. Doucet},
  FULLAUTHOR =	 {Christophe Andrieu and Nando {de Freitas} and Arnaud
                  Doucet},
  TITLE =	 {Rao-Blackwellised Particle filtering via Data
                  Augmentation},
  BOOKTITLE =	 NIPS,
  YEAR =	 2001,
}

@Article{Andrieu03,
  title =	 {An Introduction to {MCMC} for machine learning.},
  author =	 {C. Andrieu and N. de Freitas and A. Doucet and
                  M. I. Jordan},
  journal =	 ML,
  volume =	 50,
  pages =	 {5--43},
  year =	 2003,
}

@Article{Andrieu03b,
  author =	 "C. Andrieu and M. Davy and A. Doucet",
  title =	 "Efficient Particle Filtering for Jump {M}arkov
                  Systems",
  journal =	 SP,
  volume =	 51,
  number =	 7,
  pages =	 {1762--1769},
  month =	 "July",
  year =	 2003,
}

@InProceedings{Andrieu99,
  author =	 {C. Andrieu and M. Davy and A. Doucet},
  title =	 {Sequential {MCMC} for {B}ayesian Model Selection},
  booktitle =	 {{IEEE} Signal Processing Workshop on Higher Order
                  Statistics},
  address =	 {Ceasarea, Israel},
  year =	 1999,
}

@Article{Angluin83,
  author =	 {D. Angluin and C.H. Smith},
  title =	 {Introductory inference, theory and methods},
  journal =	 {ACM Computing Surveys},
  year =	 1983,
  volume =	 15,
  pages =	 {741-765 },
}

@INPROCEEDINGS{Anguelov02uai,
  AUTHOR =	 {Anguelov, D. and Biswas, R. and Koller, D. and
                  Limketkai, B. and Sanner, S. and Thrun, S.},
  TITLE =	 {Learning Hierarchical Object Maps Of Non-Stationary
                  Environments With Mobile Robots},
  crossref =	 {_UAI02},
}

@InProceedings{Anguelov04icra,
  author =	 { D. Anguelov and D. Koller and E. Parker and
                  S. Thrun },
  title =	 {Detecting and modeling doors with mobile robots},
  booktitle =	 ICRA,
  year =	 2004,
  volume =	 4,
  pages =	 {3777--3784},
  abstract =	 {We describe a probabilistic framework for detection
                  and modeling of doors from sensor data acquired in
                  corridor environments with mobile robots. The
                  framework captures shape, color, and motion
                  properties of door and wall objects. The
                  probabilistic model is optimized with a version of
                  the expectation maximization algorithm, which
                  segments the environment into door and wall objects
                  and learns their properties. The framework allows
                  the robot to generalize the properties of detected
                  object instances to new object instances. We
                  demonstrate the algorithm on real-world data
                  acquired by a Pioneer robot equipped with a laser
                  range finder and an omni-directional camera. Our
                  results show that our algorithm reliably segments
                  the environment into walls and doors, finding both
                  doors that move and doors that do not move. We show
                  that our approach achieves better results than
                  models that only capture behavior, or only capture
                  appearance.},
}

@article{Anonymous,
  author =	 "Anonymous Reference",
  title =	 "For {B}lind {R}eview",
}

@article{Anonymous2,
  author =	 "Anonymous Reference",
  title =	 "For Blind Review",
  year =	 { },
  volume =	 { },
  pages =	 { },
}

@TechReport{Antone00,
  author =	 {M. Antone and S. Teller},
  title =	 {Automatic Recovery of camera Position in Urban
                  Scenes},
  institution =	 {MIT},
  year =	 2000,
  number =	 {LCS TR-814},
  month =	 {December}
}

@InProceedings{Antone00cvpr,
  author =	 {M. Antone and S. Teller},
  title =	 {Automatic Recovery of Relative Camera Rotations in
                  Urban Scenes},
  crossref =	 {_CVPR00},
  pages =	 {282-289},
}

@article{Antoniak74aos,
  author =	 {C. E. Antoniak},
  year =	 1974,
  title =	 "Mixtures of {Dirichlet} processes with applications
                  to {Bayesian} nonparametric problems",
  journal =	 {Annals of Statistics},
  volume =	 2,
  pages =	 {1152-1174}
}

@inproceedings{Archer00nips,
  author =	 "Cynthia Archer and Todd K. Leen",
  title =	 "From Mixtures of Mixtures to Adaptive Transform
                  Coding",
  booktitle =	 NIPS,
  pages =	 "925-931",
  year =	 2000,
  url =		 "citeseer.nj.nec.com/456647.html"
}

@InProceedings{Argyros01cvpr,
  author =	 {A.A. Argyros and C. Bekris and S. Orphanoudakis},
  title =	 {Robot Homing based on Corner Tracking in a Sequence
                  of Panoramic Images},
  crossref =	 {_CVPR01},
  pages =	 {3-10},
}

@Article{Argyros05ar,
  author =	 {A.A. Argyros and C. Bekris and S.C. Orphanoudakis
                  and L.E. Kavraki},
  title =	 {Robot Homing by Exploiting Panoramic Vision},
  journal =	 AR,
  year =	 2005,
  volume =	 19,
  number =	 1,
  pages =	 {7-25},
  month =	 {July},
}

@InProceedings{Argyros99cvpr,
  title =	 {Combining central and peripheral vision for reactive
                  robot navigation},
  author =	 {Argyros, A.A. and Bergholm, F.},
  booktitle =	 CVPR,
  year =	 1999,
  volume =	 2,
  pages =	 {651 Vol. 2},
  abstract =	 {In this paper we present a new method for
                  vision-based, reactive robot navigation that enables
                  a robot to move in the middle of the free space by
                  exploiting both central and peripheral vision. The
                  robot employs a forward-looking camera for central
                  vision and two side-looking cameras for sensing the
                  periphery of its visual field. The developed method
                  combines the information acquired by this trinocular
                  vision system and produces low-level motor commands
                  that keep the robot in the middle of the free
                  space. The approach follows the purposive vision
                  paradigm in the sense that vision is not studied in
                  isolation but in the context of the behaviors that
                  the system is engaged as well as the environment and
                  the robot's motor capabilities. It is demonstrated
                  that by taking into account these issues, vision
                  processing can be drastically simplified still
                  giving rise to quite complex behaviors. The proposed
                  method does not make strict assumptions about the
                  environment, requires very low level information to
                  be extracted from the images, produces a robust
                  robot behavior and is computationally
                  efficient. Results obtained by bath simulations and
                  from a prototype on-line implementation demonstrate
                  the effectiveness of the method},
  c-dellaert =	 {Flow based, fairly forgettable}
}

@Book{Arkin98book,
  author =	 "R.C. Arkin",
  title =	 "Behavior-based Robotics",
  publisher =	 MIT,
  year =	 1998,
}

@Article{Arnborg85bit,
  author =	 "S. Arnborg",
  fullauthor =	 "Stefan Arnborg",
  title =	 "Efficient algorithms for combinatorial problems on
                  graphs with bounded decomposability --- a survey",
  journal =	 "BIT",
  volume =	 25,
  number =	 1,
  pages =	 "2--23",
  year =	 1985,
  r-Dechter92chapter ={Finding the smallest induced width of a graph
                  and its corresponding ordering is an NP-complete
                  problem \cite{Arnborg85bit}.},
  r-Kask05ai =	 { the notion of tree-width, as a means for capturing
                  the decomposition of a hyper-graph into a
                  hyper-tree, is well known in the area of theoretical
                  computer science for quite some time
                  \cite{Arnborg85bit,Robertson85sc}.},
}

@InProceedings{Arras02icra,
  author =	 {K.O. Arras and J.A. Castellanos and R. Siegwart},
  title =	 {Feature-Based Multi-Hypothesis Localization and
                  Tracking for Mobile Robots Using Geometric
                  Constraints},
  booktitle =	 ICRA,
  pages =	 {1371--1377},
  year =	 2002,
  month =	 {May},
}

@article{Arulampalam02,
  author =	 "S. Arulampalam and S. Maskell and N. Gordon and
                  T. Clapp",
  title =	 "A Tutorial on Particle Filters for On-line
                  Non-linear/Non-{Gaussian} {Bayesian} Tracking",
  journal =	 SP,
  volume =	 50,
  number =	 2,
  pages =	 "174--188",
  month =	 feb,
  year =	 2002,
}

@Article{Arya98acm,
  author =	 {S. Arya and D.M. Mount and N.S. Netanyahu and
                  R. Silverman and A. Wu},
  title =	 {An optimal algorithm for approximate nearest
                  neighbor searching},
  journal =	 {Journal of the ACM},
  year =	 1998,
  volume =	 45,
  number =	 6,
  pages =	 {891-923},
}

@InProceedings{Asada88icpr,
  author =	 {M. Asada and Y. Fukul and S. Tsuji},
  title =	 {Representing a Global Map for a Mobile Robot with
                  Relational Local Maps from Sensory Data},
  booktitle =	 ICPR,
  pages =	 {520-524},
  year =	 1988,
}

@Article{Ashbrook03,
  author =	 {Ashbrook, D. and T. Starner},
  title =	 {Using GPS to Learn Significant Locations and Predict
                  Movement Across Multiple Users},
  journal =	 {Personal and ubiquitous Computing},
  year =	 2003,
  volume =	 7,
  number =	 1,
}

@InProceedings{Ashida01ca,
  author =	 {K. Ashida and S-J. Lee and J. Allbeck and H. Sun
                  N. I. Badler and D. Metaxas},
  title =	 {{Pedestrians: Creating Agent Behaviors through
                  Statistical Analysis of Observation Data}},
  booktitle =	 {Conference on Computer Animation},
  pages =	 {84--92},
  year =	 2001,
  keywords =	 {crowd simulation},
  c-sangmin =	 {mostly about realistic humman upper body animation
                  for pedestrians. To obtain realistic distribution
                  and behavior classes for subconcious behaviors such
                  as skin itch, body touches, body scratches, yawning,
                  looking around, the authors video-taped 33 human
                  subjects, and *manually* counted them.},
}

@Article{Atiya93,
  author =	 {S. Atiya and G. Hager},
  title =	 {Real-time vision-based robot localization},
  journal =	 TRA,
  year =	 1993,
  volume =	 9,
  number =	 6,
  pages =	 {785-800},
}

@InProceedings{Attias00nips,
  author =	 {H. Attias},
  title =	 {A Variational Bayesian Framework for Graphical
                  Models},
  booktitle =	 NIPS,
  year =	 2000,
}

@InProceedings{Attias03ais,
  author =	 {H. Attias},
  title =	 {Planning by probabilistic inference},
  booktitle =	 "{Proceedings of the 9th International Conference on
                  Artificial Intelligence and Statistics}",
  year =	 2003,
}

@INPROCEEDINGS{Aucouturier02icme,
  AUTHOR =	 "Aucouturier, J.J. and Pachet, F.",
  BOOKTITLE =	 "Proceedings of IEEE International Conference on
                  Multimedia and Expo (ICME)",
  MONTH =	 "August",
  ORGANIZATION = "Lausanne, Switzerland",
  TITLE =	 "Scaling up Music Playlist Generation",
  YEAR =	 2002
}

@Article{Avidan01pami,
  author =	 {S. Avidan and A. Shashua},
  title =	 {Threading Fundamental Matrices},
  journal =	 PAMI,
  year =	 2001,
  volume =	 23,
  number =	 1,
  pages =	 {73--77},
}

@Article{Avitzour92,
  author =	 {Avitzour, D},
  title =	 {A maximum likelihood approach to data association},
  journal =	 AES,
  year =	 1992,
  volume =	 28,
  number =	 2,
  pages =	 {560-566},
  month =	 {April},
}

@Article{Avitzour95,
  author =	 {Avitzour, D},
  title =	 {Stochastic simulation {B}ayesian approach to
                  multitarget tracking},
  journal =	 {IEE Proceedings - Radar, Sonar and Navigation},
  year =	 1995,
  volume =	 142,
  number =	 2,
  pages =	 {41-44},
  month =	 {April},
}

@INPROCEEDINGS{Avot02iros,
  AUTHOR =	 {D. Avots and E. Lim and R. Thibaux and S. Thrun},
  BOOKTITLE =	 IROS,
  TITLE =	 {A probabilistic technique for simultaneous
                  localization and door state estimation with mobile
                  robots in dynamic environments},
  YEAR =	 {2002},
  pages =	 {521--526},
}

@article{Ayache86pami,
  author =	 "N. Ayache and O. Faugeras",
  title =	 "HYPER: A new approach for the representation and
                  positioning of two-dimensional objects",
  journal =	 PAMI,
  volume =	 8,
  number =	 1,
  pages =	 "44-54",
  year =	 1986,
}

@Article{Ayache88,
  author =	 {N. Ayache and O.D. Faugeras},
  title =	 {Building, registering and fusing noisy visual maps},
  journal =	 IJRR,
  volume =	 7,
  number =	 6,
  pages =	 {45-65},
  year =	 1988,
  r-Smith06bmvc ={In perhaps the earliest work in visual SLAM using
                  lines, Ayache and Faugeras [this] used a stereo pair
                  of calibrated cameras to directly extract the
                  three-dimensional location of line segments and
                  filtered these within an EKF SLAM framework.},
  c-dellaert =	 {Is seminal work. It is line-segment-based and works
                  with calibrated binocular or trinocular stereo on
                  robots.},
}

@Article{Ayache88ijrr,
  author =	 {N. Ayache and O.D. Faugeras},
  title =	 {Building, registering and fusing noisy visual maps},
  journal =	 IJRR,
  year =	 1988,
}

@Article{Ayache89tra,
  author =	 {N. Ayache and O.D. Faugeras},
  title =	 {Maintaining representations of the environment of a
                  mobile robot},
  journal =	 TRA,
  year =	 1989,
  volume =	 5,
  number =	 6,
  pages =	 {804-819},
}

@Book{Ayache91,
  author =	 {N. Ayache},
  title =	 {Artificial Vision for Mobile Robots: Stereo Vision
                  and Multisensory Perception},
  publisher =	 MIT,
  year =	 1991,
}

@inproceedings{Aycard97,
  author =	 {O. Aycard and F. Charpillet and D. Fohr and
                  JF. Mari},
  title =	 {Place Learning and Recognition using Hidden Markov
                  Models},
  booktitle =	 IROS,
  pages =	 {1741-1746},
  year =	 1997,
  c-ananth =	 {Other examples of HMM-based work include
                  [Kaelbling96][Gutierrez-Osuna96] and [Aycard97]
                  where a second order HMM is used to model the
                  environment.},
}

@INPROCEEDINGS{Ayer95,
  AUTHOR =	 "Ayer, S. and Sawhney, H.S.",
  TITLE =	 "Layered Representation of Motion Video using Robust
                  Maximum-Likelihood Estimation of Mixture Models and
                  {MDL} Encoding",
  BOOKTITLE =	 ICCV,
  MONTH =	 "June",
  YEAR =	 1995,
  PAGES =	 "777--784",
  KEYWORDS =	 {motion analysis, mosaicking, video indexing, motion
                  segmentation, motion estimation}
}

@Book{Ayers00,
  author =	 {Ayers, Edward L. and Anne S. Rubin},
  title =	 {The Valley of the Shadow: Two Communities in the
                  American Civil War - The Eve of War},
  publisher =	 {W.W. Norton},
  year =	 2000,
  address =	 {New York},
}

@Article{Ayers01ivc,
  author =	 {D. Ayers and M. Shah},
  fullauthor =	 {Douglas Ayers and Mubarak Shah},
  title =	 {{Monitoring Human Behavior from Video Taken in an
                  Office Environment}},
  journal =	 IVC,
  year =	 2001,
  volume =	 19,
  number =	 12,
  pages =	 {833-846},
  keywords =	 {activity recognition, surveillance},
  c-sangmin =	 {hand code important regions, and associated
                  activities very specifically. then use FSM to
                  interpret the activities.},
}

@Article{Aysche90,
  author =	 {N.Aysche and O.D. Faugeras},
  title =	 {Maintaining Representation of the Enviroment of a
                  Mobile Robot},
  journal =	 {Autonomous Robot Vehicles},
  year =	 1990,
  pages =	 205
}

@Article{Azarbayejani95pami,
  author =	 "Ali Azarbayejani and Alex P Pentland",
  title =	 "Recursive Estimation of Motion, Structure, and Focal
                  Length",
  journal =	 PAMI,
  year =	 1995,
  volume =	 17,
  number =	 6,
  month =	 "June",
  pages =	 562,
}

@Article{Azuma01,
  author =	 {R. Azuma and B. Yohan and R. Behringer and S. Feiner
                  and S. Juierand B.MacIntyre},
  title =	 {Recent Advances in Augmented Reality},
  journal =	 {Computers and Graphics},
  year =	 2001,
  month =	 {November}
}

@inproceedings{Bacchus93uai,
  author =	 "F. Bacchus",
  fullauthor =	 "Fahiem Bacchus",
  title =	 {Using First-Order Probability Logic for the
                  Construction of Bayesian Networks},
  booktitle =	 UAI,
  pages =	 "219--226",
  year =	 1993,
}

@inproceedings{Bach01nips,
  author =	 "F.R. Bach and M.I. Jordan",
  fullauthor =	 "Francis R. Bach and Michael I. Jordan",
  title =	 "Thin junction trees",
  booktitle =	 NIPS,
  year =	 2001,
  c-dellaert =	 {A generalizion of \citep{Chow68it}, very confusing
                  paper}
}


@article{Bachelder95ras,
  author =	 {Bachelder, I.A. and Waxman, A.M.},
  year =	 1995,
  title =	 {A view-based neurocomputational system for
                  relational map-making and navigation in visual
                  environments},
  journal =	 {Robotics and Autonomous Systems},
  volume =	 16,
  pages =	 {267--289},
  Abstract =	 {Artificial navigation systems stand to benefit
                  greatly from learning maps of visual environments,
                  but traditional map-making techniques are inadequate
                  in several respects. This paper describes an
                  adaptive, view-based, relational map-making system
                  for navigating within a 3D environment defined by a
                  spatially distributed set of visual
                  landmarks. Inspired by an analogy to learning aspect
                  graphs of 3D objects, the system comprises two
                  neurocomputational architectures that emulate
                  cognitive mapping in the rat hippocampus. The first
                  architecture performs unsupervised place learning by
                  combining the ?hat?with the ?here? namely through
                  conjunctions of landmark identity, pose, and
                  egocentric gaze direction within a local, restricted
                  sensory view of the environment. The second
                  associatively learns action consequences by
                  incorporating the ?hen? namely through conjunctions
                  of learned places and coarsely coded robot
                  motions. Together, these networks form a map
                  reminiscent of a partially observable Markov
                  decision process, and consequently provide an ideal
                  neural substrate for prediction, environment
                  recognition, route planning, and
                  exploration. Preliminary results from real-time
                  implementations on a mobile robot called MAVIN (the
                  Mobile Adaptive VIsual Navigator) demonstrate the
                  potential for these capabilities.},
  quotes =	 {The system comprises two interacting architectures:
                  the place learning architecture (PLA), and the
                  action consequence learning architecture (ACLA).},
  r-Franz98ar =	 {Bachelder and Waxman (1995) have reported results on
                  a vision-based topological system which uses a
                  neural control architecture and object recognition
                  techniques for landmark detection. In their current
                  implementation, however, the system has to rely on
                  artificially illuminated landmarks and a
                  pre-programmed path during exploration of the
                  environment.},
  c-dellaert =	 {MAVIN robot, Touretzky-style hippocampus
                  bio-mumbo-jumbo.},
}

@article{Badaloni04aicomm,
  author =	 {S. Badaloni and M. Falda and M. Giacomin},
  title =	 {Integrating quantitative and qualitative fuzzy
                  temporal constraints},
  journal =	 {AI Commun.},
  volume =	 {17},
  number =	 {4},
  year =	 {2004},
  issn =	 {0921-7126},
  pages =	 {187--200},
  publisher =	 {IOS Press},
  address =	 {Amsterdam, The Netherlands, The Netherlands},
  c-schindler =	 {Trapezoidal fuzzy algebra.}
}

@Article{Bailey06ram,
  author =	 {T. Bailey and H.F. Durrant-Whyte},
  fullauthor =	 {Tim Bailey and Hugh F. Durrant-Whyte},
  title =	 {Simultaneous Localisation and Mapping ({SLAM}): Part
                  {II} State of the Art},
  journal =	 {Robotics \& Automation Magazine},
  month =	 {Sep},
  year =	 2006,
  abstract =	 {This tutorial provides an introduction to the
                  Simultaneous Localisation and Mapping (SLAM) method
                  and the extensive research on SLAM that has been
                  undertaken. Part I of this tutorial described the
                  essential SLAM problem. Part II of this tutorial
                  (this paper) is concerned with recent advances in
                  computational methods and in new formulations of the
                  SLAM problem for large scale and complex
                  environments.},
  quotes =	 {SLAM methods have now reached a state of
                  considerable maturity. Future challenges will centre
                  on methods enabling large scale implementations in
                  increasingly unstructured environments and
                  especially in situations where GPS-like solutions
                  are unavailable or unreliable; in urban canyons,
                  under foliage, underwater or on remote planets.},
  c-kaess =	 {Good SLAM overview, history and related work; see
                  DurrantWhyte06ram for the first part; good source
                  for open SLAM problems},
}

@inproceedings{Bailey95ml,
  Title =	 {Unsupervised Learning of Multiple Motifs in
                  Biopolymers Using Expectation Maximization},
  Author =	 {Timothy L. Bailey and Charles Elkan},
  Journal =	 ML,
  Month =	 {October},
  Number =	 {1-2},
  Pages =	 {51-80},
  Volume =	 {21},
  Year =	 {1995},
  Keywords =	 {em, biology, discovery},
  c-sangmin =	 {Use of EM to find multiple occurences of multiple
                  patterns from DNA sequence data. Influential early
                  work, the MEME algorithm is still being used.},
}

@InProceedings{Baillard00,
  author =	 "Baillard, C. and Zisserman, A.",
  title =	 "A Plane-Sweep Strategy for the {3D} Reconstruction
                  of Buildings from Multiple Images",
  booktitle =	 "19th ISPRS Congress and Exhibition",
  year =	 2000,
  address =	 {Amsterdam},
  month =	 jul,
  url =		 "http://www.robots.ox.ac.uk/~vgg"
}

@inproceedings{Baillard99,
  author =	 "Baillard, C. and Schmid, C. and Zisserman, A. and
                  Fitzgibbon, A.",
  title =	 "Automatic line matching and {3D} reconstruction of
                  buildings from multiple views",
  booktitle =	 "ISPRS Conference on Automatic Extraction of GIS
                  Objects from Digital Imagery, IAPRS Vol.32, Part
                  3-2W5",
  year =	 1999,
  pages =	 "69--80",
  month =	 "September",
  url =
                  "http://imogen.robots.ox.ac.uk:20000/~vgg/vggpapers/Baillard99a.ps.gz"
}

@Book{Baird84,
  author =	 {H.S. Baird},
  title =	 {Model based image matching using location},
  publisher =	 MIT,
  year =	 1984,
}

@book{Baird85,
  author =	 "H. Baird",
  title =	 "Model-Based Image Matching Using Location",
  publisher =	 MIT,
  year =	 1985
}

@InProceedings{Bajaj94,
  author =	 "Chandrajit Bajaj and Guoliang Xu",
  title =	 "Data Fitting with Cubic {A}-Splines",
  booktitle =	 "Comp. Graph. Int.",
  month =	 "27~--1~",
  year =	 1994,
  url =		 "citeseer.nj.nec.com/bajaj96data.html"
}

@article{Bajcsy88ieee,
  title =	 {Active perception},
  author =	 {R. Bajcsy},
  journal =	 {Proceedings of the IEEE},
  year =	 1988,
  volume =	 76,
  number =	 8,
  pages =	 {996--1005},
  abstract =	 {Active Perception (Active Vision specifically) is
                  defined as a study of Modeling and Control
                  strategies for perception. By modeling we mean
                  models of sensors, processing modules and their
                  interaction. We distinguish local models from global
                  models by their extent of application in space and
                  time. The local models represent procedures and
                  parameters such as optical distortions of the lens,
                  focal lens, spatial resolution, band-pass filter,
                  etc. The global models on the other hand
                  characterize the overall performance and make
                  predictions on how the individual modules
                  interact. The control strategies are formulated as a
                  search of such sequence of steps that would minimize
                  a loss function while one is seeking the most
                  information. Examples are shown as the existence
                  proof of the proposed theory on obtaining range from
                  focus and sterolvergence on 2-D segmentation of an
                  image and 3-D shape parametrization.},
  quotes =	 {Perceptual activity is exploratory, probing,
                  searching; percepts do not simply fall onto sensors
                  as rain falls onto ground. We do not just see, we
                  look. .. [The] problem of Active Sensing can be
                  stated as a problem of controlling strategies
                  applied to the data acquisition process. .. We
                  [differ] with Aloimonos and Bandyopadhyay in the
                  emphasis of the Active Vision (or perception in
                  general) as a scientific paradigm. For us the
                  emphasis is in the study of modeling and control
                  strategies for perception, i.e., modeling of the
                  sensors, the objects, the environment, and the
                  interaction between them for a given purpose, which
                  can be manipulation, mobility, and recognition.},
  r-Edelman08chapter ={Both the feasibility of and the need for an
                  explicit and sweeping reconstruction of the geometry
                  of the visual world have been subsequently
                  questioned (Aloimonos et al., 1988; Bajcsy,
                  1988). Noting that biological vision is purposive
                  and active, researchers proposed that computer
                  vision too should aim at serving certain
                  well-defined goals such as navigation or recognition
                  rather than at constructing a general-purpose
                  representation of the world.},
  c-dellaert =	 {Seminal Active vision paper, focuses on modeling and
                  control of sensor.},
}

@InProceedings{Baker01cvpr,
  author =	 {Baker, P. and Ferm{\"u}ller, C. and Aloimonos,
                  Y. and R. Pless},
  title =	 {A spherical eye from multiple cameras (makes better
                  models of the world)},
  crossref =	 {_CVPR01},
  pages =	 {567-583},
  volume =	 {1},
}

@techreport{Baker01tr,
  author =	 "S. Baker and F. Dellaert and I. Matthews",
  fullauthor =	 "Simon Baker and Frank Dellaert and Iain Matthews",
  title =	 "Aligning Images Incrementally Backwards",
  institution =	 "CMU Robotics Institute",
  month =	 "Feb.",
  year =	 2001,
  number =	 "CMU-RI-TR-01-03",
  address =	 "Pittsburgh, PA"
}

@InProceedings{Baker03iros,
  author =	 {Baker, P. and Ogale, A.S. and Ferm{\"u}ller, C. and
                  Aloimonos, Y.},
  title =	 {New eyes for robotics},
  booktitle =	 IROS,
  pages =	 {1018 - 1023},
  year =	 2003,
  volume =	 1,
}

@InProceedings{Baker03ominivis,
  author =	 {P.T. Baker and Y. Aloimonos},
  title =	 {Calibration of a Multicamera Network},
  booktitle =	 {Omnivis: Omnidirectional Vision and Camera Networks},
  year =	 2003,
}

@Article{Baker04ijcv,
  author =	 "S. Baker and I. Matthews",
  title =	 "Lucas-Kanade 20 Years On: A Unifying Framework",
  journal =	 IJCV,
  year =	 2004,
  volume =	 56,
  number =	 3,
  pages =	 "221-255",
}

@inproceedings{Baker98iccv,
  author =	 "S. Baker and S.K. Nayar",
  fullauthor =	 "Simon Baker and Shree K. Nayar",
  title =	 "A Theory of Catadioptric Image Formation",
  booktitle =	 ICCV,
  pages =	 "35-42",
  year =	 1998,
}

@INPROCEEDINGS{Balch01,
  AUTHOR =	 {Balch, T. and Khan, Z. and Veloso, M.},
  TITLE =	 {Automatically Tracking and Analyzing the Behavior of
                  Live Insect Colonies},
  BOOKTITLE =	 {Proc. Autonomous Agents 2001},
  YEAR =	 2001,
  pages =	 {521-528},
  ADDRESS =	 {Montreal}
}

@Book{Balch02book,
  author =	 "T. Balch and L. Parker",
  title =	 "Robot Teams: From Diversity to Polymorphism",
  publisher =	 "AK Peters",
  year =	 2002,
}

@article{Balch05ieee,
  author =	 "T. Balch and F. Dellaert and A. Feldman and
                  A. Guillory and C. Isbell and Z. Khan and A. Stein
                  and H. Wilde",
  title =	 " How {A}.{I}. and multi-robot systems research will
                  accelerate our understanding of social animal
                  behavior",
  journal =	 "Proceedings of IEEE",
  volume =	 94,
  number =	 7,
  pages =	 "1145-1463",
  month =	 "July",
  year =	 2006
}

@Article{Balch94,
  author =	 "T. Balch and R.C. Arkin",
  title =	 "Communication in Reactive Multiagent Systems",
  journal =	 AR,
  year =	 1994,
  volume =	 1,
  number =	 1,
  pages =	 "27-52",
}

@PhdThesis{Balch98,
  author =	 "Balch, T.",
  title =	 "Behavioral Diversity in Learning Robot Teams",
  school =	 "College of Computing, Georgia Institute of
                  Technology",
  year =	 1998
}

@article{Ballard02jov,
  author =	 {Ballard, D. and Sprague, N.},
  title =	 {{Attentional resource allocation in extended natural
                  tasks}},
  journal =	 {J. Vision},
  ISSN =	 {1534-7362},
  volume =	 2,
  number =	 7,
  pages =	 {568-568},
  year =	 2002,
  month =	 11,
  abstract =	 {To ambulate in an urban environment, we face the
                  management of many simultaneous tasks, such as
                  walking on a sidewalk, avoiding pedestrians, and
                  crossing busy streets. The management of
                  simultaneous tasks has been studied extensively, but
                  those studies tend to focus on attentional loading
                  in reaction time experiments that use stimulus
                  presentations of less than one second. As a result,
                  little is known about how attention is managed in
                  extended natural tasks that take on the order of
                  many minutes. The current study addresses the
                  extended allocation of visual attention. We study
                  the gaze control and locomotion control for a
                  virtual humanoid agent walking in a realistic
                  simulated urban world. The agent? behaviors are
                  directed by visuo-motor routines that each handle a
                  single well-defined task, such as staying on the
                  sidewalk or avoiding an obstacle. The key element in
                  our model is that behaviors ask for and are given
                  access to the body on a probabilistic basis. The
                  probabilities are continually adjusted to reflect
                  the contingencies produced by the environment. The
                  gaze access period is adjusted to reflect the modal
                  time of human fixations in similar tasks. The
                  locomotion access period is adjusted to fit human
                  performance data. Such a model can explain how
                  different behaviors can compete for both eye gaze
                  resources in addition to locomotion resources of the
                  body in a seamless manner. In our simulation, the
                  humanoid walks along a crowded sidewalk and crosses
                  streets. During this time the instantaneous
                  allocation of resources to gaze and ambulation are
                  recorded. To test our model, we have human subjects
                  doing the same task. Humans wear head-mounted
                  displays that allow them to navigate in the same
                  virtual environment. Six-dof head-tracking as well
                  as eye-tracking in the HMD allows us to compare the
                  use of gaze and locomotion by the human subjects
                  with our model. Our initial results suggest that the
                  probabilistic allocation of resources is a good fit
                  to the human data.},
  URL =		 {http://journalofvision.org/2/7/568/},
  c-dellaert =	 {Abstract. Validate RL model of gaze allocation with
                  human subjects.}
}

@article{Ballard91ai,
  author =	 {Ballard, D.H.},
  title =	 {Animate Vision},
  journal =	 AI,
  volume =	 48,
  pages =	 {57--86},
  year =	 1991,
  abstract =	 {Animate vision systems have gaze control mechanisms
                  that can actively position the camera coordinate
                  systemin response to physical stimuli. Compared to
                  passive systems, animate systems show that visual
                  computation can be vastly less expensive when
                  considered in the larger context of behavior. The
                  most important visual behavior is the ability to
                  control the direction of gaze. This allows the use
                  of very low resolution imaging that has a high
                  virtual resolution. Using such a system in a
                  controlled way provides additional constraints that
                  dramatically simplify the computations of early
                  vision. Another important behavior is the way the
                  environment "behaves." Animate systems under
                  real-time constraints can further reduce their
                  computational burden by using environmental cues
                  that are perspicuous in the local context. A third
                  source of economy is introduced when behaviors are
                  learned. Because errors are rarely fatal, systems
                  using learning algorithms can amortize computational
                  cost over extended periods. Further economies can be
                  achieved when the learning system uses indexical
                  reference, which is a form of dynamic variable
                  binding. Animate vision is a natural way of
                  implementing this dynamic binding.},
  quotes =	 {The most important visual behavior is the ability to
                  control the direction of gaze. ..[Animate vision]
                  argues that vision is more readily understood in the
                  context of the visual behaviors that the system is
                  engaged in, and that these behaviors may not require
                  elaborate categorical representations of the 3-D
                  world. .. The human eye is distinguished from
                  current electronic cameras by virtue of having much
                  better resolution in a small region near the optical
                  axis. .. With the small fovea at a premium in a
                  large visual field, it is not surprising that the
                  human visual system has special behaviors (saccades)
                  for quickly moving the fovea to different spatial
                  targets. .. Furthermore most of the brain structures
                  that represent visual information are retinally
                  indexed. This means that their state is changed with
                  each eye movement This raises a technical puzzle for
                  human visual perception: How can the world appear to
                  be stable when the data collecting process is so
                  dynamic? We believe that this is a profound question
                  with a surprising answer: The visual system provides
                  the illusion of three-dimensional stability by
                  virtue of being able to execute fast
                  behaviors. .. The central asset of animate vision is
                  gaze control. Gaze control is the collection of
                  different mechanisms for keeping the fovea over a
                  given spatial target. The single most distinguishing
                  feature of the human visual system is its high-speed
                  gaze control mechanisms. .. Gaze control mechanisms
                  fundamentally change computational models of
                  vision. [] With them a new paradigm emerges in which
                  the visual calculations are embedded in a
                  sensory-motor behavioral repertoire. .. This
                  viewpoint has many different kinds of advantages. 1)
                  Animate vision systems can use physical
                  search. []. 2) Animate vision can make
                  (approximately) known camera movements. []. 3)
                  Animate vision can use exocentric coordinate
                  frames. [] 4) Animate vision can use relative (or
                  qualitative) algorithms. [] 5) Gaze control can
                  segment areas of interest in the image
                  pre-categorically. [] 6) Animate systems can exploit
                  environmental context. [] 7) Animate vision is
                  tailor-made/or learning algorithms that use
                  indexical reference. .. We further suggest that very
                  different algorithms are used depending on the task
                  of the moment. A gross distinction that can be made
                  is between identification algorithms that analyze
                  the foveated area during fixation and location
                  algorithms that direct the eyes to new
                  targets. .. Why should the primate brain be
                  specialized into two separate areas that are crucial
                  for different functions? If we think generally about
                  the problem of relating internal models to objects
                  in the world, then one way to interpret this
                  dichotomy is as a suggestion that the general
                  problem of associating many models to many parts of
                  the image simultaneously is too difficult. In order
                  to make it computationally tractable within a single
                  fixation, it has to be simplified, either into one
                  of location (one internal model) or identification
                  (one world object).},
  c-dellaert =	 {Seminal paper, gaze as central asset, 7 advantages
                  of animate vision, distinction between recognition
                  and location algorithms, very cool rationale for
                  what/where pathway that so vibes with my own. },
}

@InProceedings{Baltzakis02icra,
  author =	 {H. Baltzakis and P. Trahanias},
  title =	 {Hybrid mobile robot localization using switching
                  state-space models},
  booktitle =	 ICRA,
  year =	 2002,
  pages =	 {366-373}
}

@InProceedings{Baltzakis02iros,
  author =	 {H. Baltzakis and P. Trahanias},
  title =	 {An Iterative Approach for Building Feature Maps in
                  Cyclic Environments},
  booktitle =	 IROS,
  year =	 2002,
  pages =	 {576-581}
}

@InProceedings{Baltzakis03iros,
  author =	 {H. Baltzakis and P. Trahanias},
  title =	 {Closing Multiple Loops while Mapping Features in
                  Cyclic Environments},
  booktitle =	 IROS,
  year =	 2003,
  pages =	 {717-722}
}

@article{BarShalom00spie,
  author =	 {Y. Bar-Shalom},
  title =	 "{Update with out-of-sequence measurements in
                  tracking: Exact solution}",
  journal =	 "{Signal and Data Processing of Small Targets 2000,
                  Proceedings of SPIE}",
  volume =	 4080,
  pages =	 {541--556},
  year =	 2000,
}

@Article{BarShalom75,
  author =	 {Y. Bar-Shalom and E. Tse},
  title =	 {Tracking in a cluttered environment with
                  probabilistic data-association},
  journal =	 {Automatica},
  year =	 1975,
  volume =	 11,
  pages =	 {451-460},
}

@InProceedings{BarShalom80,
  author =	 {Y. Bar-Shalom and T.E. Fortmann and M. Scheffe},
  title =	 {Joint probabilistic data association for multiple
                  targets in clutter},
  booktitle =	 {Conf. on Information Sciences and Systems},
  year =	 1980,
}

@InProceedings{BarShalom84itac,
  author =	 {Y.C. Chang and Y. Bar-Shalom },
  title =	 {Joint probabilistic data association for multitarget
                  tracking with possibly unresolved measurements and
                  maneuvers},
  booktitle =	 ITAC,
  volume =	 29,
  issue =	 7,
  year =	 1984,
  pages =	 {585-594},
}

@Book{BarShalom88,
  author =	 {Y. Bar-Shalom and T.E. Fortmann},
  title =	 {Tracking and data association},
  publisher =	 {Academic Press},
  address =	 {New York},
  year =	 1988,
}

@Book{BarShalom92,
  author =	 {Y. Bar-Shalom},
  title =	 {Multitarget multisensor tracking: {A}dvanced
                  applications},
  publisher =	 {Artech House},
  address =	 {Norwood, MA},
  year =	 1992,
}

@Book{BarShalom93,
  author =	 {Y. Bar-Shalom and X. Li},
  title =	 {Estimation and Tracking: principles, techniques and
                  software},
  publisher =	 {Artech House},
  address =	 "Boston, London",
  year =	 1993,
}

@Book{BarShalom95,
  author =	 {Y. Bar-Shalom and X. Li},
  title =	 {Multitarget-multisensor tracking: principles and
                  techniques},
  publisher =	 {YBS Publishing},
  year =	 1995,
}

@inproceedings{Barbu03iccv,
  title =	 {Graph Partition by {Swendsen-Wang} Cuts},
  author =	 {A. Barbu and S.-C. Zhu},
  fullauthor =	 {Adrian Barbu and Song-Chun Zhu},
  pages =	 {320--327},
  booktitle =	 ICCV,
  address =	 {Nice, France},
  year =	 2003
}

@article{Barbu05pami,
  title =	 {Generalizing {Swendsen-Wang} to Sampling Arbitrary
                  Posterior Probabilities},
  author =	 {A. Barbu and S.-C. Zhu},
  fullauthor =	 {Adrian Barbu and Song-Chun Zhu},
  pages =	 {1239-1253},
  journal =	 PAMI,
  volume =	 27,
  number =	 8,
  month =	 "August",
  year =	 2005,
}

@InProceedings{Barfoot05iros,
  author =	 {T.D. Barfoot},
  fullauthor =	 {Timothy D. Barfoot},
  title =	 {Online Visual Motion Estimation using {FastSLAM} with
                  SIFT Features},
  booktitle =	 IROS,
  location =	 {Edmonton, Canada},
  pages =	 {579-585},
  month =	 {Aug},
  year =	 2005,
  abstract =	 {This paper describes a technique to estimate the 3D
                  motion of a vehicle using odometric sensors and a
                  stereo camera. The algorithm falls into the category
                  of simultaneous localization and mapping as a large
                  database of visual landmarks is created. The
                  algorithm has been eld tested online on a rover
                  traversing loose terrain in the presence of
                  obstacles. The resulting position estimation errors
                  are between 0.5\% and 4\% of distance travelled, a
                  significant improvement over odometry alone.},
}

@article{Barnard89,
  author =	 "Stephan T. Barnard",
  title =	 "Stochastic Stereo Matching Over Scale",
  journal =	 IJCV,
  volume =	 3,
  number =	 1,
  pages =	 "17--32",
  year =	 1989
}

@Article{Barron94,
  author =	 "J L Barron and D J Fleet and S S Beuachemin",
  title =	 "Performance of Optical Flow Techniques",
  journal =	 IJCV,
  year =	 1994,
  volume =	 12,
  number =	 1,
  pages =	 "43-77",
}

@InProceedings{Barrow77ijcai,
  author =	 "H. Barrow and J. Tenenbaum and R. Bolles and
                  H. Wolf",
  title =	 "Parametric Correspondence and Chamfer Matching: Two
                  New Techniques for Image Matching",
  booktitle =	 IJCAI,
  pages =	 "659--663",
  year =	 1977
}

@InProceedings{Bartels06uai,
  author =	 {C.D. Bartels and J.A. Bilmes},
  fullauthor =	 {Chris D. Bartels and Jeff A. Bilmes},
  title =	 {Non-Minimal Triangulations for Mixed
                  Stochastic/Deterministic Graphical Models},
  crossref =	 {_UAI06},
}

@Book{Bartholomew87,
  author =	 {D. J. Bartholomew},
  title =	 {Latent Variable Models and Factor Analysis},
  publisher =	 {Oxford University Press},
  year =	 1987,
  address =	 {New York},
}

@article{Barto81bc,
  title =	 {Landmark Learning: An Illustration of Associative
                  Search},
  author =	 {A.G. Barto and R.S. Sutton},
  fullauthor =	 {Andrew G. Barto and Richard S. Sutton},
  journal =	 {Biological Cybernetics},
  year =	 1981,
  volume =	 42,
  pages =	 {1--8},
  abstract =	 {In a previous paper we defined the associative
                  search problem and presented a system capable of
                  solving it under certain conditions. In this paper
                  we interpret a spatial learning problem as an
                  associative search task and describe the behavior of
                  an adaptive network capable of solving it. This
                  example shows how naturally the associative search
                  problem can arise and permits the search,
                  association, and generalization properties of the
                  adaptive network to be clearly illustrated.},
  r-Gillner98jcn ={Recognizing and approaching views (local landmarks)
                  requires a long-term memory of the view or some of
                  its features. A strictly associative mechanism for
                  this task has been proposed by Barto and Sutton
                  (1981). It actually stores the required approach
                  direction for every position identified by its local
                  position information.},
  c-dellaert =	 {Very early reinforcement learning paper, applied to
                  view-action associations.},
}

@Article{Bartoli05,
  author =	 {A. Bartoli and P. Sturm},
  title =	 {Structure-From-Motion Using Lines: Representation,
                  Triangulation and Bundle Adjustment},
  journal =	 CVIU,
  year =	 2005,
  volume =	 100,
  number =	 3,
  pages =	 {416-441},
}

@InProceedings{Bascle96,
  author =	 {B.~Bascle and A.~Blake and A.~Zisserman},
  title =	 {Motion Deblurring and Super-Resolution from an Image
                  Sequence},
  booktitle =	 ECCV,
  year =	 1996,
  address =	 {Cambridge, England},
  month =	 {April},
  pages =	 {573--581}
}

@inproceedings{Basri01cvpr,
  author =	 "R. Basri and D. Jacobs",
  title =	 "Photometric Stereo with General, Unknown Lighting",
  pages =	 {374--381},
  crossref =	 {_CVPR01},
}

@Article{Basri95,
  author =	 {R. Basri and E. Rivlin},
  title =	 {Localization and Homing Using Combinations of Model
                  Views},
  journal =	 AI,
  year =	 1995,
}

@Article{Basri96,
  author =	 {R. Basri and D. Jacobs},
  title =	 {Recognition using region correspondences},
  journal =	 IJCV,
  year =	 1996,
  volume =	 25,
  number =	 2,
  pages =	 {141-162},
}

@article{Basri98,
  AUTHOR =	 "Basri, R. and Grove, A.J. and Jacobs, D.W.",
  TITLE =	 "Efficient determination of shape from multiple
                  images containing partial information",
  JOURNAL =	 PR,
  VOLUME =	 31,
  YEAR =	 1998,
  NUMBER =	 11,
  MONTH =	 "November",
  PAGES =	 "1691-1703"
}

@InProceedings{Basso01,
  author =	 {A.Basso and H.Graf and D.Gibbon and E.Cosatto and
                  S.Liu},
  title =	 {Virtual light: digitally-generated lighting for
                  video conferencingapplications},
  booktitle =	 ICIP,
  year =	 2001,
}

@inproceedings{Basu87,
  author =	 "A. Basu and J. Aloimonos",
  title =	 "A robust algorithm for determining the translation
                  of a rigidly moving surface without correspondence
                  for robotics applications",
  booktitle =	 IJCAI,
  pages =	 "815-818",
  year =	 1987
}

@article{Batalin04icra,
  author =	 {M. Batalin and G. S. Sukhatme and M. Hattig},
  title =	 {Mobile Robot Navigation using a Sensor Network},
  journal =	 ICRA,
  month =	 {April},
  year =	 {2004},
  pages =	 {636--642},
  Abstract =	 {We describe an algorithm for robot navigation using
                  a Sensor network embedded in the environment. Sensor
                  nodes act as signposts for the robot to follow, thus
                  obviating the need for a map or localization on the
                  part of the robot Navigation directions are computed
                  within the network (not on the robot) using value
                  iteration. Using small low-power radios, the robot
                  communicates with nodes in the network locally, and
                  makes navigation decisions based on which node it is
                  near. An algorithm based on processing of radio
                  signal strength data was developed so the robot
                  could succcessfully decide which node neighborhood
                  it belonged to. Extensive experiments with a robot
                  and a sensor network confirm the validity of the
                  approach.}
}

@inproceedings{Baumberg00cvpr,
  author =	 "A. Baumberg",
  title =	 "Reliable Feature Matching across Widely Separated
                  Views",
  pages =	 "774--781",
  crossref =	 {_CVPR00},
}

@InProceedings{Baumberg94,
  author =	 "A Baumberg and D Hogg",
  title =	 "Learning flexible models from image sequences",
  booktitle =	 ECCV,
  year =	 1994,
}

@Book{Bazaraa77,
  author =	 "M.S. Bazaraa and J.J. Jarvis",
  title =	 "Linear programming and network flow",
  publisher =	 "John Wiley \& Sons",
  year =	 1977,
}

@InProceedings{Beal03bs,
  author =	 {M.J. Beal and Z. Ghahramani},
  title =	 {The Variational Bayesian EM Algorithm for Incomplete
                  Data: with Applilcation to Scoring Graphical Model
                  Structures},
  booktitle =	 {Bayesian Statistics},
  year =	 2003,
}

@PhdThesis{Beal03thesis,
  author =	 "M.J. Beal",
  title =	 "Variational algorithms for approximate Bayesian
                  inference",
  school =	 "Gatsby Computational Neuroscience Unit, University
                  College London",
  year =	 2003
}

@inproceedings{Beardsley95iccv,
  title =	 {Active visual navigation using non-metric structure},
  author =	 {Beardsley, P.A. and Reid, I.D. and Zisserman, A. and
                  Murray, D.W.},
  booktitle =	 ICCV,
  year =	 1995,
  month =	 {Jun},
  pages =	 {58-64},
  abstract =	 {Demonstrates a method of using non-metric visual
                  information derived from an uncalibrated active
                  vision system to navigate an autonomous vehicle
                  through free-space regions detected in a cluttered
                  environment. The structure of 3-space is recovered
                  modulo an affine transformation using an
                  uncalibrated active stereo head carried by the
                  vehicle. The plane at infinity, necessary for
                  recovering affine structure from projective
                  structure, is found in a novel manner by making
                  controlled rotations of the head. The structure is
                  composed of 3D points obtained by detecting and
                  matching image corners through the stereo image
                  sequence. Considerable care has been taken to ensure
                  that the processing is reliable, robust and
                  automatic. Driveable regions are determined from the
                  projection of the affine structure onto a plane
                  parallel to the ground determined using projective
                  constructs. Two methods of negotiating the regions
                  are explored. The first introduces metric
                  information to allow control of a Euclidean
                  vehicle. The second uses visual servoing of the
                  active head to navigate in the affinely described
                  free-space regions},
  r-Davison98thesis ={\citet{Beardsley95iccv} used precisely
                  controlled motions of an active head to determine
                  the affine structure of a dense point set of
                  features in front of a robot, and then showed that
                  it was possible to initiate obstacle avoidance
                  behaviours based on the limits of free-space regions
                  detected. This work was impressive, particularly as
                  it operated without needing knowledge of camera
                  calibrations. It implemented in short demonstrations
                  which worked well, but consideration was not given
                  to the long-term goals of navigation and how the
                  active head could be used in many aspects.},
  c-dellaert =	 {Cool trick for establishing plane at infinity using
                  two head rotations, although algebraic and not
                  intuitive. Then some navigation without calibration
                  - did not read in detail.},
}

@inproceedings{Beardsley96,
  AUTHOR =	 "Beardsley, P.A. and Torr, P.H.S. and Zisserman, A.",
  TITLE =	 "{3D} Model Acquisition from Extended Image
                  Sequences",
  BOOKTITLE =	 ECCV,
  YEAR =	 "1996",
  PAGES =	 "II:683-695"
}

@Article{Beardsley97ijcv,
  author =	 "Beardsley, P.~A. and Zisserman, A. and Murray,
                  D.~W.",
  title =	 "Sequential update of projective and affine structure
                  from motion",
  journal =	 IJCV,
  year =	 1997,
  volume =	 23,
  number =	 3,
  pages =	 "235--259",
  url =		 "http://www.robots.ox.ac.uk/~vgg"
}

@inproceedings{Bedekar96,
  AUTHOR =	 "Bedekar, A.S. and Haralick, R.M.",
  TITLE =	 "Finding Correspondence Points Based on {B}ayesian
                  Triangulation",
  BOOKTITLE =	 CVPR,
  YEAR =	 1996,
  PAGES =	 "61-66"
}

@inproceedings{Beeri81stoc,
  author =	 {C. Beeri and R. Fagin and D. Maier and A. Mendelzon
                  and J. Ullman and M. Yannakakis},
  fullauthor =	 {Catriel Beeri and Ronald Fagin and David Maier and
                  Alberto Mendelzon and Jeffrey Ullman and Mihalis
                  Yannakakis},
  title =	 {Properties of acyclic database schemes},
  booktitle =	 STOC,
  year =	 1981,
  pages =	 {355--362},
  location =	 {Milwaukee, Wisconsin, United States},
  doi =		 {http://doi.acm.org/10.1145/800076.802489},
  publisher =	 {ACM Press},
  address =	 {New York, NY, USA},
  abstract =	 {There is a class of database descriptions, involving
                  one "acyclic" join dependency and a collection of
                  functional dependencies, and nothing else, that
                  appears powerful enough to describe most any
                  real-world body of data in relational database
                  terms. Further, this class has many desirable
                  properties. Some properties make operations like
                  updates and the selection of joins to implement a
                  query over a universal relation especially
                  easy. Other properties of interest were studied by
                  other researchers who described the same class in
                  radically different terms, and found desirable
                  properties in their own contexts. It is the purpose
                  of this paper to define the class formally, to give
                  its important properties and the equivalences with
                  the other classes mentioned, and to explain the
                  importance of each property. This paper is intended
                  to summarize the results that will appear in more
                  detail in \cite{FMU} and \cite{Beeri83jacm}. },
  r-Beeri83jacm ={Beeri et al. \cite{Beeri81stoc} introduced a special
                  class of database schemes, called acyclic. Fagin et
                  al. \cite{Fagin82tods} have shown that this class
                  enjoys a certain desirable property.},
}

@Article{Beeri83jacm,
  author =	 {C. Beeri and R. Fagin and D. Maier and
                  M. Yannakakis},
  fullauthor =	 {Catriel Beeri and Ronald Fagin and David Maier and
                  Mihalis Yannakakis},
  title =	 {On the desirability of acyclic database schemes},
  journal =	 {J. ACM},
  year =	 {1983},
  volume =	 {30},
  number =	 {3},
  pages =	 {479--513},
  abstract =	 {A class of database schemes, called acyclic, was
                  recently introduced. It is shown that this class has
                  a number of desirable properties. In particular,
                  several desirable properties that have been studied
                  by other researchers in very different terms are all
                  shown to be eqmvalent to acyclicity. In addition,
                  several equivalent characterizations of the class in
                  terms of graphs and hypergraphs are given, and a
                  sample algorithm for determining acyclicty is
                  presented. Also given are several equivalent
                  characterizations of those sets M of multivalued
                  dependencies such that M is the set of multivalued
                  dependencies that are the consequences of a given
                  join dependency. Several characterizations for a
                  conflict-free (in the sense of Lien) set of
                  multivalued dependencies are provided. },
  quotes =	 {For acyclic schemes there are efficient
                  (polynomial-time) algorithms for solving problems
                  that are NP-complete in the unrestricted
                  case. ... \cite{A} collection of sets can be viewed
                  as being a hypergraph.},
  r-Dechter92chapter ={Acyclic constraint networks (ACNs) ... were
                  first characterized and evaluated in the relational
                  database literature \cite{Beeri83jacm}. ... Several
                  efficient procedures for identifying and finding a
                  representative join tree have been described
                  \cite{Maier83book}. One scheme that proved
                  particularly useful is based on the observation that
                  a CN is acyclic if, and only if, its primal graph is
                  both chordal and conformal \cite{Beeri83jacm}. ... A
                  graph is conformal if each of its maximal cliques
                  corresponds to a constraint in the original CN.},
  r-Kask05ai =	 {Many of the important properties of tree-based
                  processing were discussed and proved within the
                  database community \cite{this,Tarjan84siam}.},
  c-dellaert =	 {Database scheme = factor graph = hypergraph, join
                  tree = junction tree ? Acyclic database scheme =
                  acyclic hyper graph = chordal conformal hypergraph =
                  Graham's algorithm succeeds = R has a join tree = R
                  has running intersection property},
}

@InProceedings{Beeson05icra,
  author =	 {P. Beeson and N. K. Jong and B. Kuipers},
  year =	 2005,
  title =	 {Towards autonomous topological place detection using
                  the {E}xtended {V}oronoi {G}raph},
  booktitle =	 ICRA,
}

@PhdThesis{Beeson08thesis,
  author =	 {P. Beeson},
  fullauthor =	 {Patrick Beeson},
  year =	 2008,
  title =	 {Creating and Utilizing Symbolic Representations of
                  Spatial Knowledge using Mobile Robots},
  school =	 {University of Texas at Austin},
  abstract =	 {A map is a description of an environment allowing an
                  agent---a human, or in our case a mobile robot---to
                  plan and perform effective actions. From a single
                  location, an agent's sensors can not observe the
                  whole structure of a complex, large environment. For
                  this reason, the agent must build a map from
                  observations gathered over time and space. We
                  distinguish between large-scale space, with spatial
                  structure larger than the agent's sensory horizon,
                  and small-scale space, with structure within the
                  sensory horizon. We propose a factored approach to
                  mobile robot map-building that handles qualitatively
                  different types of uncertainty by combining the
                  strengths of topological and metrical
                  approaches. Our framework is based on a
                  computational model of the human cognitive map; thus
                  it allows robust navigation and communication within
                  several different spatial ontologies. Our approach
                  factors the mapping problem into natural sub-goals:
                  building a metrical representation for local
                  small-scale spaces; finding a topological map that
                  represents the qualitative structure of large-scale
                  space; and (when necessary) constructing a metrical
                  representation for large-scale space using the
                  skeleton provided by the topological map. The core
                  contributions of this thesis are a formal
                  description of the Hybrid Spatial Semantic Hierarchy
                  (HSSH), a framework for both small-scale and
                  large-scale representations of space, and an
                  implementation of the HSSH that allows a robot to
                  ground the large-scale concepts of place and path in
                  a metrical model of the local surround. Given
                  metrical models of the robot's local surround, we
                  argue that places at decision points in the world
                  can be grounded by the use of a primitive called a
                  gateway. Gateways separate different regions in
                  space and have a natural description at
                  intersections and in doorways. We provide an
                  algorithmic definition of gateways, a theory of how
                  they contribute to the description of paths and
                  places, and practical uses of gateways in spatial
                  mapping and learning. },
  c-dellaert =	 {Hybrid SSH in depth, lots of voronoi graphs at lower
                  levels. ICRA paper seems nicer.}
}

@InProceedings{Behringer92,
  author =	 "R Behringer and V Holt and E D Dickmanns",
  title =	 "Road and relative ego-state recognition",
  booktitle =	 "Proceedings of the Intelligent Vehicles '92
                  Symposium",
  year =	 "1992",
}

@InProceedings{Behringer94,
  author =	 "R Behringer and S Holtz",
  title =	 "Simultaneous estimation of pitch angle and lane
                  width from the video image of a marked road",
  booktitle =	 IROS,
  year =	 1994,
}

@InProceedings{Behringer99,
  author =	 {R. Behringer},
  title =	 {Registration for Outdoor Augmented Reality
                  Applications using Computer Vision Techniques and
                  Hybrid Sensors},
  booktitle =	 {Proceedings of IEEE Virtual Reality},
  pages =	 {244-251},
  year =	 1999,
  month =	 {March}
}

@Article{Beichl00cse,
  author =	 {Beichl, I. and Sullivan, F.},
  title =	 {The Metropolis Algorithm},
  pages =	 {65-69},
  crossref =	 {_CSE00Jan},
  journal =	 {Computing in Science \& Engineering},
  volume =	 2,
  number =	 1,
  month =	 {Jan.-Feb.},
  year =	 2000,
  note =	 {Special issue on the Top 10 Algorithms in {Science}
                  \& {Engineering}},
}

@InProceedings{Belhumeur96,
  author =	 {P. N Belhumeur and J P Hespanha and David J
                  Kriegman},
  title =	 {Eigenfaces vs. Fisherfaces: Recognition Using Class
                  Specific Linear Projection},
  booktitle =	 CVPR,
  year =	 1996,
}

@Article{Belhumeur98,
  author =	 {P. Belhumeur and D. Kriegman},
  title =	 {What Is the Set of Images of an Object Under All
                  Possible Illumination Conditions?},
  journal =	 IJCV,
  volume =	 28,
  number =	 3,
  year =	 1998,
  pages =	 {245--260}
}

@Article{Bell95,
  author =	 "A.J. Bell and T.J. Sejnowski",
  title =	 "An information-maximisation approach to blind
                  separation and blind deconvolution",
  journal =	 "Neural Computation",
  volume =	 7,
  number =	 6,
  pages =	 "1004-1034",
  year =	 1995,
}

@Book{Bellman62book,
  author =	 {R.E. Bellman and S.E. Dreyfus},
  title =	 {Applied Dynamic Programming},
  publisher =	 {Princeton University Press},
  year =	 1962,
  r-Helman89jacm ={Examples of computationally feasible dominance
                  relations include comparability relations based on
                  Bellman's principle of optimality
                  \cite{Bellman62book}}
}

@InProceedings{Belluta89,
  author =	 {P. Belluta and G. Collini and V. Verri and V. Torre},
  title =	 {{3D} visual information from vanishing points},
  booktitle =	 {IEEE Workshop on interpretation of {3D} scenes},
  pages =	 {41-49},
  year =	 1989,
}

@InProceedings{Belongie05mb,
  author =	 {S. Belongie, K. Branson, P. Doll\'{a}r and
                  V. Rabaud},
  title =	 {Monitoring {A}nimal {B}ehavior in the {S}mart
                  {V}ivarium},
  booktitle =	 {International Conference on Methods and Techniques
                  in Behavioral Research},
  year =	 2005,
  pages =	 "70-72",
}

@article{Benhamou98ac,
  author =	 {S. Benhamou},
  title =	 {Place navigation in mammals: a configuration-based
                  model},
  journal =	 {Animal {C}ognition},
  publisher =	 {Springer {B}erlin},
  volume =	 1,
  number =	 1,
  month =	 {July},
  year =	 1998,
  pages =	 {55--63},
}

@InProceedings{Benoit03iccv,
  author =	 {S. Benoit and F.P. Ferrie},
  title =	 {Towards Direct Recovery of Shape and Motion
                  Parameters from Image Sequences},
  booktitle =	 ICCV,
  year =	 2003,
}

@InProceedings{Benosman00omnivis,
  author =	 {Benosman, R. and Deforas, E. and Devars, J.},
  title =	 {A new catadioptric sensor for the panoramic vision
                  of mobile robots},
  booktitle =	 {Proceedings. IEEE Workshop on Omnidirectional
                  Vision},
  pages =	 {112-116},
  year =	 2000,
  month =	 {June},
}

@Book{Benosman01,
  editor =	 {R. Benosman and S.-B. Kang},
  fulleditor =	 {Ryad Benosman and Sing Bing Kang},
  title =	 {Panoramic Vision: Sensors, Theory, and Applications},
  publisher =	 {Springer-Verlag},
  address =	 {New York},
  year =	 2001,
  month =	 {Feb},
}

@Article{Bentley75,
  author =	 {J. L. Bentley},
  title =	 {Multidimensional binary search trees used for
                  associative searching},
  journal =	 {Communications of the ACM},
  year =	 1975,
  volume =	 18,
  pages =	 {509--517},
}

@inproceedings{Berg94acc,
  Author =	 {Berg, T. M. and Durrant-Whyte, H. F.},
  booktitle =	 ACC,
  Journal =	 {American Control Conference, 1994},
  Pages =	 {2273--2274},
  volume =	 2,
  Title =	 {General decentralized Kalman filters},
  Volume =	 2,
  Year =	 1994,
  Abstract =	 {This paper considers a general decentralised Kalman
                  filter, unique because it: requires no fusion center
                  yet allows the different estimators to employ
                  distributed models; minimizes communication with
                  respect to message size and topology; requires no
                  explicit knowledge of the transformations between
                  the estimators; and reduces to previous results when
                  appropriately constrained.},
  c-dellaert =	 {I cannot see why this is not the same as
                  \cite{DurrantWhyte90icra} and later HDW papers, and
                  it does not reference any of them.},
}

@InProceedings{Bergen92,
  author =	 "J. R Bergen and P Anandan and Keith J Hanna and
                  Rajesh Hingorani",
  title =	 "Hierarchical Model-Based Motion Estimation",
  booktitle =	 ECCV,
  editor =	 "G Sandini",
  year =	 1992,
  publisher =	 "Springer-Verlag",
}

@InProceedings{Berger08iros,
  author =	 {Cyrille Berger and Simon Lacroix},
  title =	 {Using Planar Facets for Stereovision {SLAM}},
  booktitle =	 IROS,
  year =	 {2008}
}

@InProceedings{Bergman00,
  author =	 {N. Bergman and A. Doucet},
  title =	 {Markov Chain {Monte Carlo} Data Association for
                  Target Tracking},
  booktitle =	 ICASSP,
  year =	 2000,
}

@PhdThesis{Bergman99,
  author =	 "N. Bergman",
  title =	 "Recursive Bayesian Estimation: Navigation and
                  Tracking Applications",
  school =	 "Linkoping University",
  year =	 1999
}

@InProceedings{Berrou93icc,
  author =	 {C. Berrou and A. Glavieux and P. Thitimajshima},
  title =	 {Near {Shannon} limit error-correcting coding and
                  decoding: {Turbo} codes},
  booktitle =	 {ICC93},
  pages =	 {1064--1070},
  year =	 1993,
  address =	 {Geneva, Switzerland},
  r-Wiberg96thesis ={Undoubtedly, the invention of turbo codes
                  \cite{Berrou93icc} is a milestone in the development
                  of communication theory. ... As it turned out, turbo
                  codes and their decoding algorithm fit directly into
                  our general framework for codes and decoding based
                  on graphs. ... The turbo codes of Berrou et
                  al. \cite{Berrou93icc} are famous for their amazing
                  performance, which beats anything else that has been
                  presented so far. Unfortunately, the performance has
                  only been demonstrated by simulations, and not by
                  theoretical results. }
}

@Article{Berry99algorithmica,
  author =	 {A. Berry and J.R.S. Blair and P. Heggernes and
                  B.W. Peyton},
  title =	 {Maximum Cardinality Search for Computing Minimal
                  Triangulations of Graphs},
  journal =	 {Algorithmica},
  year =	 2004,
  volume =	 39,
  number =	 4,
  pages =	 {287-298},
}

@Book{Bertele72book,
  author =	 {U. Bertele and F. Brioschi},
  title =	 {Nonserial Dynamic Programming},
  publisher =	 {Academic Press},
  year =	 1972,
  r-MathSciNet = {Dynamic programming involves the decomposition of an
                  optimization problem into a sequence of smaller
                  subproblems. For classical problems, there is a
                  logical order to this sequence, and each subproblem
                  involves only two variables. Nonserial dynamic
                  programming is a generalization of this; typically
                  the decomposition yields subproblems involving three
                  or more variables and there is no logical order to
                  the sequence of these subproblems, but the principle
                  of optimality can still be applied to yield
                  computational savings. This book is a comprehensive
                  study of discrete deterministic nonserial dynamic
                  programming. The emphasis is on the secondary
                  optimization problem of how to decompose a problem
                  and order the sequence of subproblems so as to
                  minimize the computational effort. Throughout,
                  extensive use is made of graph theory.},
  r-Dechter99ai ={dynamic programming for combinatorial optimization},
  r-Rosenthal77stoc ={The general problem we will consider is taken
                  from \cite{Bertele72book}: minimize the objective
                  function f(x_1,...,x_m) where f is given as the sum
                  of terms f_j(.) which are functions of only a subset
                  of the variables. We will assume that all variables
                  x_i take on values from the same finite set
                  {1...M}. The terms fj (.) are given by tables, and
                  have no special properties assumed. Example:
                  f(xl,x2,xS,x4)=f1(x1,x2,x3)+f2(x2,x4)+f3(xl,x4).}
}

@Article{Bertele72jmaa,
  author =	 {U. Bertele and F. Brioschi},
  title =	 {On the theory of the elimination process},
  journal =	 {J. Math. Anal. Appl.},
  year =	 1972,
  volume =	 {35},
  number =	 {1},
  month =	 {July},
  pages =	 {48--57},
  abstract =	 {In this paper a general theory of the elimination
                  process (vertex elimination on a graph) is
                  developed. The connections between this theory and
                  the secondary optimization problem of nonserial
                  dynamic programming and the numerical solution of
                  systems of linear equations by Gaussian elimination
                  are pointed out.},
}

@Article{Bertele73jct,
  author =	 {U. Bertele and F. Brioschi},
  title =	 {On Nonserial Dynamic Programming},
  journal =	 {J. Combinatorial Theory},
  year =	 1973,
  volume =	 14,
  pages =	 {137--148},
  r-MathSciNet = {Consider an optimization problem without the special
                  serial structure that allows the use of dynamic
                  programming technique. Decomposition can be
                  tried. The optimization problem obtained is called a
                  secondary optimization problem. Let $G=(X,E)$ be an
                  undirected graph without self-loops and parallel
                  edges. Given $x\in X$, the set $T(x)$ is the set of
                  vertices adjacent to $x$. Consider a vertex $y\in
                  X$. The graph obtained from $G$ by (1) deleting $y$
                  and all edges emanating from it and (2) putting an
                  edge between all the pairs of vertices not adjacent
                  in $G$ is called the $y$-elimination graph of $G$
                  and denoted by $G_y$. The operation is called the
                  elimination of the vertex $y$. Call the degree of an
                  eliminated vertex $y_i$ in a given order of
                  elimination $y_1,y_2,\cdots,y_M$ the dimension
                  associated with the elimination of the vertex
                  $y_i$. The largest degree of the eliminated vertices
                  for an order of elimination $y_1,y_2,\cdots,y_M$ is
                  called the dimension of the order and denoted by
                  $D(y_1,y_2,\cdots,y_M)$. The minimal dimension for
                  all possible orders is called the dimension of the
                  graph $G$ and denoted by $D(G)$. The following
                  problem is discussed: Find an ordering of
                  $y_1,y_2,\cdots,y_M$ of $X$ which minimizes
                  $D(y_1,y_2,\cdots,y_M)$. This is exactly the
                  secondary optimization problem which can be solved
                  considering only the interaction graph of the
                  non-serial problem. There are two algorithms known
                  to solve the secondary optimization problem but they
                  are restricted to problems with 15--20 variables
                  only. Based on two theorems proved in this paper,
                  further computational possibilities are presented,
                  although no formal algorithm is given. The
                  computational significance of the theorems is
                  discussed and demonstrated by some simple
                  examples. Reviewed by D. Hochstadter},
}

@InProceedings{Berthilsson99,
  author =	 {R. Berthilsson and K. {\AA}str\"{o}m and A. Heyden},
  title =	 {Reconstruction of Curves in ${R}^3$, using
                  Factorization and Bundle Adjustment},
  booktitle =	 "ICCV",
  pages =	 {674-679},
  volume =	 {1},
  year =	 1999,
}

@Book{Bertsekas91,
  author =	 "D.P. Bertsekas",
  title =	 "Linear Network Optimization: Algorithms and Codes",
  publisher =	 MIT,
  year =	 1991,
}

@InCollection{Berzuini01smc,
  author =	 {C. Berzuini and W. Gilks},
  title =	 {{RESAMPLE-MOVE} Filtering with Cross-Model Jumps},
  booktitle =	 {Sequential {M}onte {C}arlo Methods in Practice},
  publisher =	 {Springer-Verlag},
  year =	 2001,
  editor =	 {Arnaud Doucet and Nando de Freitas and Neil Gordon},
  address =	 {New York}
}

@Article{Berzuini96,
  author =	 {C. Berzuini and N. G. Best and W.R. Gilks and
                  C. Larizza},
  title =	 {Dynamic conditional independence models and {Markov}
                  chain {Monte Carlo} methods},
  journal =	 {Journal of the American Statistical Association},
  volume =	 92,
  pages =	 {1403--1412},
  year =	 1996
}

@article{Besl92,
  author =	 "P.J. Besl and N.D. McKay",
  title =	 "A method for registration of {3-D} shapes",
  journal =	 PAMI,
  volume =	 14,
  number =	 2,
  year =	 1992,
}

@TechReport{Betke96,
  type =	 "Technical Report",
  number =	 "CS-TR-3667",
  institution =	 "University of Maryland, College Park",
  title =	 "Multiple Vehicle Detection and Tracking in Hard Real
                  Time",
  year =	 1996,
  month =	 jul,
  author =	 "Margrit Betke and Esin Haritaoglu and Larry
                  S. Davis",
}

@article{Betke97tra,
  journal =	 TRA,
  volume =	 13,
  number =	 2,
  Month =	 {April},
  year =	 1997,
  pages =	 {251--263},
  title =	 {Mobile Robot Localization Using Landmarks},
  author =	 {M. Betke and L. Gurvits},
  fullauthor =	 {Margrit Betke and Leonid Gurvits},
  Abstract =	 {We describe an efficient method for localizing a
                  mobile robot in an environment with landmarks. We
                  assume that the robot can identify these landmarks
                  and measure their bearings relative to each
                  other. Given such noisy input, the algorithm
                  estimates the robot? position and orientation with
                  respect to the map of the environment. The algorithm
                  makes efficient use of our representation of the
                  landmarks by complex numbers. The algorithm runs in
                  time linear in the number of landmarks. We present
                  results of simulations and propose how to use our
                  method for robot navigation.},
  c-dellaert =	 {Just some math to localize a robot via
                  triangulation},
}

@Article{Beymer96,
  author =	 {David Beymer and Tomaso Poggio},
  title =	 {Image Representations for Visual Learning},
  journal =	 {Science},
  year =	 1996,
  month =	 {June},
}

@InProceedings{Beymer96b,
  author =	 {David Beymer},
  title =	 {Feature Correspondence by Interleaving Shape and
                  Texture Computations},
  booktitle =	 CVPR,
  year =	 1996,
  pages =	 {921-928},
}

@Unpublished{Bezakova04,
  author =	 {I. Bezakova and D. Stefankovic and V. Vazirani and
                  E. Vigoda},
  title =	 {Approximing the Permanent in ${O}^{*}(n^{7})$ Time},
  year =	 2004,
  month =	 {November},
}

@InProceedings{Bhukhanwala04,
  author =	 "S. A. Bhukhanwala and T. V. Ramabadram",
  title =	 "Automated global enhancement of digitized
                  photographs",
  booktitle =	 "IEEE Transactions on Consumer Electronics",
  volume =	 40,
  issue =	 1,
  pages =	 {1-10},
  year =	 1994,
}

@InProceedings{Bhukhanwala04,
  author =	 "S. A. Bhukhanwala and T. V. Ramabadram",
  title =	 "Automated global enhancement of digitized
                  photographs",
  booktitle =	 "IEEE Transactions on Consumer Electronics",
  volume =	 40,
  issue =	 1,
  pages =	 {1-10},
  year =	 1994,
}

@InProceedings{Biber05,
  author =	 {Biber, P. and Duckett, T.},
  title =	 {Dynamic Maps for Long-Term Operation of Mobile
                  Service Robots},
  booktitle =	 RSS,
  year =	 2005,
}

@Book{Bierman77book,
  author =	 {G.J. Bierman},
  fullauthor =	 {Gerald J. Bierman},
  title =	 {Factorization methods for discrete sequential
                  estimation},
  publisher =	 {Academic Press},
  year =	 1977,
  series =	 {Mathematics in Science and Engineering},
  volume =	 128,
  address =	 {New York},
}

@Article{Bierman78itac,
  author =	 {G.J. Bierman},
  fullauthor =	 {Gerald J. Bierman},
  title =	 {An application of the Square-Root Information Filter
                  to Large Scale Linear Interconnected Systems},
  journal =	 ITAC,
  year =	 1978,
  volume =	 23,
  number =	 1,
  pages =	 {91-93},
  month =	 {February},
}

@inproceedings{Bignone96eccv,
  author =	 "F. Bignone and . Henricsson and P. Fua and
                  M.A. Stricker",
  fullauthor =	 "Frank Bignone and Olof Henricsson and Pascal Fua and
                  Markus A. Stricker",
  title =	 "Automatic Extraction of Generic House Roofs from
                  High Resolution Aerial Imagery",
  booktitle =	 ECCV,
  pages =	 "85-96",
  year =	 1996,
  url =		 "citeseer.nj.nec.com/bignone96automatic.html"
}

@phdthesis{Bileschi06thesis,
  author =	 {S. M. Bileschi},
  title =	 {StreetScenes: Towards Scene Understanding in Still
                  Images},
  year =	 2006,
  month =	 {May},
  school =	 {Massachusetts Institute of Technology}
}

@TechReport{Bilmes98,
  type =	 "Technical Report",
  number =	 "TR-97-021",
  institution =	 "International Computer Science Institute, Berkeley",
  title =	 "A Gentle Tutorial of the EM Algorithm and its
                  Application to Parameter Estimation for Gaussian
                  Mixture and Hidden Markov Models",
  year =	 1998,
  month =	 {April},
  author =	 "Jeff A. Bilmes",
}

@Article{Binford82,
  author =	 {T. Binford},
  title =	 {Survey of Model-Based Image Analysis},
  journal =	 IJRR,
  year =	 1982,
  volume =	 1,
  number =	 1,
  pages =	 {18-64},
}

@InProceedings{Birchfield98,
  author =	 {S.Birchfield},
  title =	 {Elliptical Head Tracking Using Intensity Gradients
                  and Color Histograms},
  booktitle =	 CVPR,
  year =	 1998,
}

@InProceedings{Bishop04,
  author =	 {C. M. Bishop and M. Svensen},
  title =	 {Robust {Bayesian} mixture modelling},
  booktitle =	 {Proceedings of the European Symposium on Artificial
                  Neural Networks},
  year =	 2004
}

@Book{Bishop06book,
  fullauthor =	 "Christopher M. Bishop",
  title =	 "Pattern Recognition and Machine Learning",
  year =	 2006,
  author =	 {C.M. Bishop},
  series =	 {Information Science and Statistics},
  isbn =	 {0387310738},
  publisher =	 {Springer-Verlag},
  address =	 {Secaucus, NJ, USA},
}

@Book{Bishop95,
  author =	 "Christopher M. Bishop",
  title =	 "Neural Networks and Pattern Recognition",
  publisher =	 "Oxford",
  year =	 1995,
}

@inproceedings{Biswas02,
  author =	 {R. Biswas and B. Limketkai and S. Sanner and
                  S. Thrun},
  title =	 {Towards object mapping in non-stationary
                  environments with mobile robots},
  year =	 2002,
  pages =	 "1014--1019",
  booktitle =	 IROS,
}

@inproceedings{Bittner01,
  title =	 "Visibility Preprocessing for Urban Scenes using Line
                  Space Subdivision",
  author =	 "Bittner and Peter Wonka and Michael Wimmer",
  year =	 2001,
  pages =	 "276--284",
  editor =	 "Bob Werner",
  isbn =	 "0-7695-1227-5",
  booktitle =	 "Proceedings of Pacific Graphics 2001 (Ninth Pacific
                  Conference on Computer Graphics and Applications)",
  address =	 "Los Alamitos, CA",
  month =	 oct,
  location =	 "Tokyo, Japan",
  publisher =	 "IEEE Computer Society Press",
  URL =
                  "http://www.cg.tuwien.ac.at/research/publications/2001/Bittner-2001-Vis",
}

@InProceedings{Black95,
  author =	 "M.J. Black and Y. Yacoob",
  title =	 "Tracking and recognizing rigid and non-rigid facial
                  motions using local parametric models of image
                  motion",
  pages =	 "374-381",
  booktitle =	 ICCV,
  year =	 1995,
}

@InProceedings{Black96,
  author =	 "M.J. Black and A.D. Jepson",
  title =	 "EigenTracking: Robust Matching and Tracking of
                  Articulated Objects Using a View-Based
                  Representation",
  booktitle =	 ECCV,
  year =	 1996,
}

@article{Black98,
  AUTHOR =	 "Black, M.J. and Jepson, A.D.",
  TITLE =	 "EigenTracking: Robust Matching and Tracking of
                  Articulated Objects Using a View-Based
                  Representation",
  JOURNAL =	 IJCV,
  VOLUME =	 26,
  YEAR =	 1998,
  NUMBER =	 1,
  MONTH =	 "January",
  PAGES =	 "63-84"
}

@book{Blackman86,
  author =	 "S. Blackman",
  title =	 "Multiple-Target Tracking with Radar Applications",
  publisher =	 "Artech House",
  address =	 "Norwood, MA",
  year =	 1986
}

@article{Blackwell73aos1,
  author =	 "D. Blackwell and J.B. MacQueen",
  title =	 "Ferguson distributions via Polya urn schemes",
  journal =	 "Annals of Statistics",
  volume =	 1,
  pages =	 "353-355",
  year =	 1973,
}

@article{Blackwell73aos2,
  author =	 "D. Blackwell",
  year =	 1973,
  title =	 {Discreteness of {Ferguson} selections},
  journal =	 "Annals of Statistics",
  volume =	 1,
  pages =	 "356-358"
}

@InCollection{Blair93chapter,
  author =	 {J.R.S. Blair and B.W. Peyton},
  fullauthor =	 {Jean R S Blair and Barry W. Peyton},
  title =	 {An Introduction to Chordal Graphs and Clique Trees},
  pages =	 {1-27},
  year =	 1993,
  crossref =	 {_George93edited},
  abstract =	 {Clique trees and chordal graphs have carved out a
                  niche for themselves in recent work on sparse matrix
                  algorithms, due primarily to research questions
                  associated with advanced computer
                  architectures. This paper is a unified and
                  elementary introduction to the standard
                  characterizations of chordal graphs and clique
                  trees. The pace is leisurely, as detailed proofs of
                  all results are included. We also briefly discuss
                  applications of chordal graphs and clique trees in
                  sparse matrix computations.},
  quotes =	 {This paper is intended as an update to the graph
                  theoretical results presented and proved in Rose
                  \cite{Rose72chapter}, which predated the
                  introduction of clique trees. Our goal is to provide
                  a unified introduction to chordal graphs and clique
                  trees for those interested in sparse matrix
                  computations, though we hope it will be of use to
                  those in other application areas in which these
                  graphs play a major role.},
  r-Heggernes06dm ={Chordal graphs are exactly the intersection graphs
                  of subtrees of a tree
                  \cite{Buneman74dm,Gavril74jct,Walter72thesis}: A
                  graph G is chordal if and only if there exists a
                  tree T whose vertex set is the set of maximal
                  cliques of G and that satisfies the following
                  property: for every vertex v in G, the set of
                  maximal cliques containing v induces a connected
                  subtree of T. Such a tree is called a clique tree,
                  and it can be computed in linear time
                  \cite{Blair93chapter}.},
  c-dellaert =	 {Great paper}
}

@Book{Blake92,
  editor =	 "A. Blake and A. Yuille",
  title =	 "Active Vision",
  publisher =	 MIT,
  year =	 1992,
}

@article{Blake93,
  author =	 "A. Blake and R. Curwen and R. Zisserman",
  title =	 "A Framework for Spatiotemporal control in the
                  tracking of visual contours",
  journal =	 IJCV,
  volume =	 11,
  year =	 1993,
  pages =	 "127:145",
  bibdate =	 "Tue Sep 23 21:43:12 1997"
}

@InProceedings{Blake98,
  author =	 "A. Blake and B. North and M. Isard",
  title =	 "Learning multi-class dynamics",
  booktitle =	 NIPS,
  year =	 1998,
}

@Article{Blake98a,
  author =	 "A. Blake and B. Bascle and M. Isard and
                  J. MacCormick",
  title =	 "Statistical models of visual shape and motion",
  journal =	 "Roy. Soc. Lond.",
  year =	 1998,
  volume =	 356,
  pages =	 {1283-1302}
}

@InProceedings{Blatt96b,
  author =	 "M. Blatt and S. Wiseman and E. Domany",
  title =	 "Clustering data through an analogy to the {P}otts
                  model",
  booktitle =	 NIPS,
  year =	 1996,
}

@Article{Blei03jmlr,
  author =	 "David M. Blei and Andrew Y. Ng and Michael
                  I. Jordan",
  title =	 "Latent {D}irichlet allocation",
  journal =	 JMLR,
  year =	 2003,
  volume =	 3,
  pages =	 {993-1022}
}

@PhdThesis{Blythe98thesis,
  author =	 {J. Blythe},
  title =	 {Planning under uncertainty in dynamic domains},
  school =	 {School of Computer Science, Carnegie Mellon},
  year =	 1998,
  c-dellaert =	 {Jim was my neighbor in Pittsburgh}
}

@Article{Board00cse,
  author =	 {Board, J. and Schulten, L.},
  title =	 {The fast multipole algorithm},
  pages =	 {76-79},
  crossref =	 {_CSE00Jan},
  journal =	 {Computing in Science \& Engineering},
  volume =	 2,
  number =	 1,
  month =	 {Jan.-Feb.},
  year =	 2000,
  note =	 {Special issue on the Top 10 Algorithms in {Science}
                  \& {Engineering}},
}

@article{Bobick01pami,
  author =	 "A. F. Bobick and J. Davis",
  title =	 "The Recognition of Human Movement Using Temporal
                  Templates",
  journal =	 PAMI,
  volume =	 23,
  number =	 3,
  pages =	 "257-267",
  year =	 2001,
}

@article{Bobick97pami,
  author =	 "A. F. Bobick and A. D. Wilson",
  fullauthor =	 "Aaron F. Bobick and Andrew D. Wilson",
  title =	 {{A State-Based Approach to the Representation and
                  Recognition of Gesture}},
  journal =	 PAMI,
  volume =	 19,
  number =	 12,
  pages =	 {1325--1337},
  month =	 {December},
  year =	 1997,
}

@InProceedings{Bobick98cvpr,
  author =	 "A. Bobick and Y. Ivanov",
  title =	 "Action Recognition Using Probabilistic Parsing",
  booktitle =	 CVPR,
  year =	 1998,
  pages =	 "196-202",
}

@article{Bobick99IJCV,
  author =	 "A. F. Bobick and S. S. Intille",
  title =	 "Large occlusion stereo",
  journal =	 IJCV,
  volume =	 33,
  number =	 3,
  pages =	 "181-200",
  year =	 1999,
}

@InProceedings{Bolles81,
  author =	 "R. Bolles and M. Fischler",
  title =	 "A {RANSAC}-based approach to model fitting and its
                  application to finding cylinders in range data",
  booktitle =	 IJCAI,
  address =	 "Vancouver, BC, Canada",
  pages =	 "637-643",
  year =	 1981
}

@article{Bolles82,
  author =	 "R. Bolles and R. Cain",
  title =	 "Recognizing and locating partially visible objects:
                  the local feature-focus method",
  journal =	 IJRR,
  year =	 1982,
  volume =	 1,
  number =	 3,
  pages =	 "57--82",
}

@Article{Boo97,
  author =	 {K.J. Boo and N.K. Bose},
  title =	 {Multispectral Image restoration with Multisensors},
  journal =	 {IEEE Trans. on Geoscience and Remote Sensing},
  year =	 1997,
  volume =	 35,
  number =	 5,
  pages =	 {1160-1170},
}

@PhdThesis{Borenstein87,
  author =	 {Borenstein, J.},
  title =	 {The nursing robot system},
  school =	 {Technion, Haifa, Israel},
  year =	 1987,
}

@BOOK{Borenstein96,
  AUTHOR =	 {Borenstein, J. and Everett, B. and Feng, L.},
  TITLE =	 {Navigating Mobile Robots: Systems and Techniques},
  PUBLISHER =	 {A. K. Peters, Ltd.},
  YEAR =	 1996,
  ADDRESS =	 {Wellesley, MA}
}

@InProceedings{Borges01,
  author =	 {G.A. Borges and M.J.Aldon},
  title =	 {An Optimal Pose Estimator for Map-Based Mobile Robot
                  Dynamixc Localization: Experimental Comparison with
                  the {EKF}},
  booktitle =	 {IEEE International Conference on Robotics and
                  Automation (ICRA)},
  year =	 2001,
  month =	 {May}
}

@InProceedings{Bosse03icra,
  author =	 {M. Bosse and P. Newman and J. Leonard and M. Soika
                  and W. Feiten and S. Teller},
  title =	 {An {Atlas} Framework for Scalable Mapping},
  booktitle =	 ICRA,
  pages =	 {1899-1906},
  location =	 {Taipei, Taiwan},
  month =	 {Sep},
  year =	 2003,
  abstract =	 {This paper describes Atlas, a hybrid metrical/
                  topological approach to SLAM that achieves efficient
                  mapping of large-scale environments. The
                  representation is a graph of coordinate frames, with
                  each vertex in the graph representing a local frame,
                  and each edge representing the transformation
                  between adjacent frames. In each frame, we build a
                  map that captures the local environment and the
                  current robot pose along with the uncertainties of
                  each. Each map? uncertainties are modeled with
                  respect to its own frame. Probabilities of entities
                  with respect to arbitrary frames are generated by
                  following a path formed by the edges between
                  adjacent frames, computed via Dijkstra? shortest
                  path algorithm. Loop closing is achieved via an
                  efficient map matching algorithm. We demonstrate the
                  technique running in real-time in a large indoor
                  structured environment (2.2 km path length) with
                  multiple nested loops using laser or ultrasonic
                  ranging sensors. |D? },
  r-Stasse06iros ={Bosse et al. [this] used omni-directional vision in
                  combination with other sensors in their ATLAS
                  mapping framework, making particular use of lines in
                  a man-made environment as consistent bearing
                  references.},
}

@Article{Bosse04ijrr,
  author =	 {M.C. Bosse and P.M. Newman and J.J. Leonard and
                  S. Teller},
  title =	 {Simultaneous Localization and Map Building in
                  Large-scale Cyclic Environments using the {Atlas}
                  Framework},
  journal =	 IJRR,
  volume =	 23,
  number =	 12,
  pages =	 {1113-1139},
  month =	 {Dec},
  year =	 2004,
  abstract =	 {In this paper we describe Atlas, a hybrid
                  metrical/topological approach to simultaneous
                  localization and mapping (SLAM) that achieves
                  efficient mapping of large-scale environments. The
                  representation is a graph of coordinate frames, with
                  each vertex in the graph representing a local frame
                  and each edge representing the transformation
                  between adjacent frames. In each frame, we build a
                  map that captures the local environment and the
                  current robot pose along with the uncertainties of
                  each. Each map? uncertainties are modeled with
                  respect to its own frame. Probabilities of entities
                  with respect to arbitrary frames are generated by
                  following a path formed by the edges between
                  adjacent frames, computed using either the Dijkstra
                  shortest path algorithm or breath-first search. Loop
                  closing is achieved via an efficient map-matching
                  algorithm coupled with a cycle verification step.We
                  demonstrate the performance of the technique for
                  post-processing large data sets, including an indoor
                  structured environment (2.2 km path length) with
                  multiple nested loops using laser or ultrasonic
                  ranging sensors. },
  c-dellaert =	 {Hybrid metric-topological, do not maintain a global
                  coordinatre frame but rather an interconnected set
                  of local coordinate frames. He says The strategy
                  of partitioning a large map into multiple smaller
                  maps is intuitively appealing for both computational
                  efficiency and robustness. Mentions this is same
                  strategy as in [Chong97fsr].},
  quotes =	 {More: The hybrid metrical/topological approach
                  allows us to restrict the representation of errors
                  via Gaussian distributions to local regions where
                  linearization works well, rather than representing
                  the entire environment with one Gaussian
                  distribution. The large-scale linearization inherent
                  in methods that use a single global coordinate
                  system for error representation, such as SEIFs or
                  DSM, will fail when closing large loops with
                  unbounded linearization errors.},
}

@InProceedings{Bouget95,
  author =	 {J.Bouguet and P.Perona},
  fullauthor =	 {Jean-Yves Bouguet and Pietro Perona},
  title =	 {Visual Navigation using a Single Camera},
  booktitle =	 ICCV,
  year =	 1995
}

@InProceedings{Bouget98iccv,
  author =	 {J. Bouguet and P. Perona},
  fullauthor =	 {Jean-Yves Bouguet and Pietro Perona},
  title =	 {3D Photography on Your Desk},
  booktitle =	 ICCV,
  year =	 1998
}

@Article{Boult93,
  author =	 {T.E.~Boult and G.~Wolberg},
  title =	 {Local Image Reconstruction and Subpixel Restoration
                  Algorithms},
  journal =	 GMIP,
  year =	 1993,
  volume =	 55,
  number =	 1,
  month =	 {January},
  pages =	 {63--77}
}

@Article{Bouman93,
  author =	 {Charles Bouman and Ken Sauer},
  title =	 {A Generalized Gaussian Image Model for
                  Edge-Preserving {MAP} Estimation},
  journal =	 IP,
  year =	 1993,
  volume =	 2,
  number =	 3,
  pages =	 {296-310},
}

@Article{Bouman96,
  author =	 {Charles Bouman and Ken Sauer},
  title =	 {A Unified Approach to Statistical Tomography Using
                  Coordinate Descent Optimization},
  journal =	 IP,
  year =	 1996,
  volume =	 5,
  number =	 3,
  pages =	 {480-492},
}

@Article{Bourque00,
  author =	 {E. Bourque and G. Dudek},
  title =	 {Automated Image-Based Mapping},
  journal =	 {Autonomous Robots},
  volume =	 8,
  number =	 2,
  year =	 2000,
  pages =	 {173--192},
}

@Article{Boutilier99jair,
  fullauthor =	 "Craig Boutilier and Thomas Dean and Steve Hanks",
  author =	 "C. Boutilier and T. Dean and S. Hanks",
  title =	 "Decision-Theoretic Planning: Structural Assumptions
                  and Computational Leverage",
  journal =	 JAIR,
  year =	 1999,
  volume =	 11,
  pages =	 "1-94",
}

@inproceedings{Boyen98uai,
  author =	 "X. Boyen and D. Koller",
  title =	 "Tractable Inference for Complex Stochastic
                  Processes",
  crossref =	 {_UAI98},
  pages =	 "33--42",
}

@InProceedings{Boykov99,
  AUTHOR =	 "Boykov, Y. and Huttenlocher, D.P.",
  TITLE =	 "A New {B}ayesian Approach to Object Recognition",
  BOOKTITLE =	 CVPR,
  YEAR =	 1999,
  PAGES =	 "II:517-523"
}

@Article{Brand00pami,
  author =	 "M. Brand and V. Kettnaker",
  fullauthor =	 "Mattew Brand and Vera Kettnaker",
  title =	 {{Discovery and Segmentation of Activities in Video}},
  journal =	 PAMI,
  year =	 2000,
  volume =	 22,
  number =	 8,
  pages =	 "844-851",
}

@inproceedings{Brand00siggraph,
  author =	 "M. Brand and A. Hertzmann",
  fullauthor =	 "Matthew Brand and Aaron Hertzmann",
  title =	 "Style Machines",
  booktitle =	 SIGGRAPH,
  pages =	 "183--192",
  year =	 2000,
  url =		 "citeseer.ist.psu.edu/brand00style.html"
}

@InProceedings{Brand96,
  author =	 "M. Brand",
  title =	 "Understanding manipulation in video",
  pages =	 "94--99",
  booktitle =	 "2nd International Workshop on Automatic Face and
                  Gesture Recognition",
  year =	 1996,
}

@InProceedings{Brand99iccv,
  author =	 "M. Brand",
  fullauthor =	 "Mathew Brand",
  title =	 "Shadow puppetry",
  pages =	 "1237-1244",
  vol =		 2,
  booktitle =	 ICCV,
  year =	 1999,
}

@INPROCEEDINGS{Brandou07oceans,
  title =	 {{3D} Reconstruction of Natural Underwater Scenes
                  Using the Stereovision System IRIS},
  author =	 {Brandou, V. and Allais, A.G. and Perrier, M. and
                  Malis, E. and Rives, P. and Sarrazin, J. and
                  Sarradin, P.M.},
  crossref =	 {_Oceans07Aberdeen},
  pages =	 {1-6},
  abstract =	 {The aim of this study is to propose a 3-dimension
                  reconstruction method of small-scale scenes improved
                  by a new image acquisition method for quantitative
                  measurements. A stereovision system is used to
                  acquire images in order to obtain several shots of
                  an object, at regular intervals according to a
                  predefined trajectory. A complete methodology of 3D
                  reconstruction is exposed to perform a dense 3D
                  model with texture mapping. A first result on
                  natural images collected with the stereovision
                  system during sea trials has been obtained.},
}

@Article{Brandt77,
  author =	 {A. Brandt},
  title =	 {Multi-level adaptive solutions to boundary value
                  problems},
  journal =	 {Mathematics of Computation},
  year =	 1977,
  volume =	 31,
  pages =	 {333-390},
}

@InProceedings{Branson05,
  author =	 {K. Branson and S. Belongie},
  title =	 {Tracking Multiple Mouse Contours (without Too Many
                  Samples)},
  booktitle =	 CVPR,
  pages =	 {1039--1046},
  year =	 2005,
  volume =	 1,
}

@Article{Braunstein05rsa,
  author =	 {Braunstein, A. and Mzard, M. and Zecchina, R.},
  title =	 {Survey propagation: an algorithm for satisfiability},
  journal =	 {Random Structures Algorithms},
  year =	 2005,
  volume =	 27,
  number =	 2,
  pages =	 {201--226},
  abstract =	 {We study the satisfiability of randomly generated
                  formulas formed by $M$ clauses of exactly $K$
                  literals over $N$ Boolean variables. For a given
                  value of $N$ the problem is known to be most
                  difficult when $\alpha=M/N$ is close to the
                  experimental threshold $\alpha_c$ separating the
                  region where almost all formulas are SAT from the
                  region where all formulas are UNSAT. Recent results
                  from a statistical physics analysis suggest that the
                  difficulty is related to the existence of a
                  clustering phenomenon of the solutions when $\alpha$
                  is close to (but smaller than) $\alpha_c$. We
                  introduce a new type of message-passing algorithm
                  which can be used to find efficiently a satisfying
                  assignment of the variables in this difficult
                  region. This algorithm is iterative and composed of
                  two main parts. The first is a message-passing
                  procedure which generalizes the usual methods like
                  sum-product and belief propagation: It passes
                  messages that may be thought of as surveys over
                  clusters of ordinary messages. The second part uses
                  the detailed probabilistic information obtained from
                  the surveys in order to fix variables and simplify
                  the problem. Eventually, the simplified problem that
                  remains is solved by a conventional heuristic.},
  c-dellaert =	 {Got here via Mao's homepage},
}

@TechReport{Brayer75,
  author =	 {J.M. Brayer and K.S. Fu},
  title =	 {Web grammars and their application to pattern
                  recognition},
  institution =	 {Purdue University},
  year =	 1975,
  number =	 {TR-EE 75-1},
}

@InProceedings{Brayer77,
  author =	 {J.M. Brayer},
  title =	 {Parsing of Web grammars},
  booktitle =	 {{IEEE} Workshop on data description and management},
  address =	 {Long Beach, CA},
  year =	 1977,
}

@Article{Breese92ci,
  title =	 "Construction of belief and decision networks",
  author =	 "John S. Breese",
  journal =	 {Computational Intelligence},
  pages =	 "624-647",
  volume =	 8,
  number =	 4,
  year =	 1992,
}

@InProceedings{Bregler94,
  author =	 "C Bregler and S M Omohundro",
  title =	 "Surface Learning with Applications to Lip Reading",
  booktitle =	 "NIPS-6",
  year =	 1994,
}

@InProceedings{Bregler94b,
  author =	 "C Bregler and Y Konig",
  title =	 "'Eigenlips' for Robust Speech Recognition",
  booktitle =	 "Proceedings of the IEEE International Conference on
                  Acoustics, Speech and Signal Processing, Adelaide,
                  Australia",
  year =	 1994,
}

@inproceedings{Bregler97cvpr,
  author =	 "C. Bregler",
  fullauthor =	 "Christoph Bregler",
  title =	 "Learning and {R}ecognizing {H}uman {D}ynamics in
                  {V}ideo {S}equences",
  booktitle =	 CVPR,
  pages =	 "568-574",
  year =	 1997,
}

@Book{Breiman84,
  author =	 {L. Breiman and J. H. Friedman and R. A. Olshen and
                  C. J. Stone},
  title =	 {Classification and Regression Trees},
  publisher =	 {Wadsworth Inc.},
  year =	 1984,
}

@Article{Bresler89pami,
  title =	 "A {Bayesian} approach to reconstruction from
                  incomplete projections of a multiple object {3D}
                  domain",
  author =	 "Y. Bresler and J.A. Fessler and A. Macovski",
  journal =	 PAMI,
  pages =	 "840-858",
  volume =	 11,
  number =	 8,
  year =	 1989,
  month =	 August
}

@InProceedings{Briegel00,
  author =	 {T. Briegel and V. Tresp},
  title =	 {Robust Neural Network Regression for Offline and
                  Online Learning},
  booktitle =	 NIPS,
  year =	 2000
}

@inproceedings{Briers03,
  author =	 {M. Briers and S. Maskell and M. Philpott},
  title =	 {Two-dimensional Assignment with Merged Measurements
                  using {Lagrangian} Relaxation},
  booktitle =	 {Proceedings of {SPIE} Conference on Signal
                  Processing of Small Targets},
  pages =	 {283--292},
  year =	 2003,
}

@Book{Briggs87,
  author =	 {W.L. Briggs},
  title =	 {A Multigrid Tutorial},
  publisher =	 {SIAM},
  year =	 1987,
}

@InProceedings{Broder86,
  title =	 {How hard is it to marry at random? ({On} the
                  approximation of the permanent)},
  author =	 {Broder, A.Z.},
  fullauthor =	 {Broder, Andrei Z.},
  pages =	 {50--58},
  booktitle =	 {Proceedings of the Eighteenth Annual ACM Symposium
                  on Theory of Computing},
  month =	 {May},
  year =	 1986,
  address =	 {Berkeley, California},
}

@Article{Broida90aes,
  author =	 {T.J. Broida and S. Chandrashekhar and R. Chellappa},
  title =	 {Recursive {3-D} Motion Estimation from a Monocular
                  Image Sequence},
  journal =	 AES,
  volume =	 26,
  number =	 4,
  pages =	 {639-656},
  month =	 {Jul},
  year =	 1990,
  bstract =	 {Consideration is given to the design and application
                  of a recursive algorithm to a sequence of images of
                  a moving object to estimate both its structure and
                  kinematics. The object is assumed to be rigid, and
                  its motion is assumed to be smooth in the sense that
                  it can be modeled by retaining an arbitrary number
                  of terms in the appropriate Taylor series
                  expansions. Translational motion involves a standard
                  rectilinear model, while rotational motion is
                  described with quaternions. Neglected terms of the
                  Taylor series are modeled as process noise. A
                  state-space model is constructed, incorporating both
                  kinematic and structural states, and recursive
                  techniques are used to estimate the state vector as
                  a function of time. A set of object match points is
                  assumed to be available. The problem is formulated
                  as a parameter estimation and tracking problem which
                  can use an arbitrarily large number of images in a
                  sequence. The recursive estimation is done using an
                  iterated extended Kalman filter (IEKF), initialized
                  with the output of a batch algorithm run on the
                  first few frames. Approximate Cramer-Rao lower
                  bounds on the error covariance of the batch estimate
                  are used as the initial state estimate error
                  covariance of the IEKF. The performance of the
                  recursive estimator is illustrated using both real
                  and synthetic image sequences},
  c-dellaert =	 {Seminal reference which uses an IEKF for the motion
                  and all the features, and hence is a true SLAM
                  approach. It seems to be not well-known as evidenced
                  by later work.},
  r-Azarbayejani95pami ={The computational framework we use for
                  recursive estimation is the EKF, which has been the
                  subject of much recent work on image sequences
                  [...], including the seminal work by Broida,
                  Chandrashekhar, and Chellappa on structure and
                  motion estimation [5].}
}

@article{Broida91pami,
  author =	 {T. Broida and R. Chellappa},
  title =	 {Estimating the Kinematics and Structure of a Rigid
                  Object from a Sequence of Monocular Images},
  journal =	 PAMI,
  volume =	 13,
  number =	 6,
  pages =	 {497-513},
  month =	 {Jun},
  year =	 1991,
  c-dellaert =	 {see Broida90},
  abstract =	 {The problem considered involves the use of a
                  sequence of noisy monocular images of a
                  three-dimensional moving object to estimate both its
                  structure and kinematics. The object is assumed to
                  be rigid, and its motion is assumed to be smooth. A
                  set of object match points is assumed to be
                  available, consisting of fixed features on the
                  object, the image plane coordinates of which have
                  been extracted from successive images in the
                  sequence. Structure is defined as the 3-D positions
                  of these object feature points, relative to each
                  other. Rotational motion occurs about the origin of
                  an object-centered coordinate system, while
                  translational motion is that of the origin of this
                  coordinate system. In this work, which is a
                  continuation of the research done by the authors and
                  reported previously (ibid., vol.PAMI-8, p.90-9,
                  Jan. 1986), results of an experiment with real
                  imagery are presented, involving estimation of 28
                  unknown translational, rotational, and structural
                  parameters, based on 12 images with seven feature
                  points.}
}

@InProceedings{Broll00,
  author =	 {W.Broll and E.Meier and T.Schardt},
  title =	 {The Virtual Round Table - A Collaborative Augmented
                  Multi-User Environment},
  booktitle =	 {CVE},
  year =	 2000,
  pages =	 {39-- 45},
}

@Book{Brookes04,
  author =	 {M. Brookes},
  title =	 {Matrix Reference Manual},
  publisher =	 {http://www.ee.ic.ac.uk/hp/staff/dmb/matrix/},
  year =	 {Accessed March 2004},
}

@Article{Brooks81,
  author =	 {R.A. Brooks},
  title =	 {Symbolic Reasoning Among {3-D} Models and {2-D}
                  Images},
  journal =	 AI,
  year =	 1981,
  volume =	 17,
  pages =	 {285-349},
}

@InProceedings{Brooks85,
  author =	 {R.A. Brooks},
  title =	 {Aspects of mobile robot visual map making},
  booktitle =	 {Second. Int. Symp. Robotics Research},
  year =	 1984,
  publisher =	 MIT,
}

@InProceedings{Brooks85icra,
  author =	 {R.A. Brooks},
  title =	 {Visual map making for a mobile robot},
  booktitle =	 ICRA,
  pages =	 {824 - 829 },
  year =	 1985,
  volume =	 2,
  month =	 {March},
}

@Article{Brooks86,
  author =	 "R. Brooks",
  title =	 "A Robust Layered Control System for a Mobile Robot",
  journal =	 "Journal of Robotics and Automation",
  year =	 1986,
  volume =	 "RA-2",
  number =	 1,
  pages =	 "14-23",
}

@Article{Brooks98,
  author =	 {Stephen Brooks and Andrew Gelman},
  title =	 {General methods for monitoring convergence of
                  iterative simulations},
  journal =	 {Journal of Computational and Graphical Statistics},
  year =	 1998,
}

@InProceedings{Brooks98b,
  author =	 {Stephen Brooks and Andrew Gelman},
  title =	 {Some issues in monitoring convergence of iterative
                  simulations},
  booktitle =	 {Computing Science and Statistics},
  year =	 1998,
}

@Article{Brown76iap,
  author =	 {Duane C. Brown},
  title =	 {The bundle adjustment - progress and prospects},
  journal =	 {Int. Archives Photogrammetry},
  year =	 1976,
  volume =	 21,
  number =	 3,
}

@InProceedings{Bruce00,
  author =	 {J. Bruce and T. Balch and M. Veloso},
  title =	 {Fast and inexpensive color image segmentation for
                  interactive robots},
  booktitle =	 IROS,
  year =	 2000
}

@InProceedings{Bruce02iros,
  author =	 "J. Bruce and M. Veloso",
  fullauthor =	 "James Bruce and Manuela Veloso",
  title =	 "Real-Time Randomized Path Planning for Robot
                  Navigation",
  booktitle =	 IROS,
  year =	 2002,
}

@article{Brunelli93,
  author =	 "R. Brunelli and T. Poggio",
  fullauthor =	 "Roberto Brunelli and Tomaso Poggio",
  title =	 "Face Recognition: Features versus Templates",
  journal =	 "PAMI",
  volume =	 15,
  number =	 10,
  pages =	 "1042-1052",
  year =	 1993,
}

@InProceedings{Buchanan05cvpr,
  author =	 {A. Buchanan and A.W. Fitzgibbon},
  title =	 {Damped {Newton} algorithms for matrix factorization
                  with missing data},
  booktitle =	 CVPR,
  month =	 {June},
  year =	 2005,
}

@Article{Bucy69,
  author =	 {R. S. Bucy},
  title =	 {theorem Bayes and digital realisation for nonlinear
                  filters},
  journal =	 {J. of Astronautical Science},
  year =	 1969,
  volume =	 17,
  pages =	 {80-94},
}

@inproceedings{Buehler01siggraph,
  author =	 "C. Buehler and M. Bosse and L. McMillan and
                  S. Gortler and M. Cohen",
  fullauthor =	 "Chris Buehler and Michael Bosse and Leonard McMillan
                  and Steven Gortler and Michael Cohen",
  title =	 "Unstructured lumigraph rendering",
  booktitle =	 SIGGRAPH,
  month =	 "August",
  year =	 2001,
}

@InProceedings{Bui00aaai,
  author =	 {H.H Bui, and S. Venkatesh and G. West},
  title =	 {{The recognition of abstract Markov policies}},
  crossref =	 {_AAAI00},
  keywords =	 {HMM, hierarchical model, activity recognition},
  c-sangmin =	 {see the expanded journal version : Bui02jair},
}

@Misc{Bui01ijprai,
  test =	 {Bui, H. H. and Venkatesh S. and West, G. (2001)
                  Tracking and surveillance in wide-area spatial
                  environments using the Abstract Hidden {Markov}
                  Model. International Journal of Pattern Recognition
                  and Artificial Intelligence (Special issue on Hidden
                  Markov Models in Vision), 15(1): 177-195.},
}

@Article{Bui02jair,
  author =	 {H.H. Bui and S. Venkatesh and G. West},
  title =	 {{Policy recognition in the Abstract Hidden Markov
                  Model}},
  journal =	 JAIR,
  year =	 2002,
  volume =	 17,
  pages =	 {451-499},
  keywords =	 {HMM, hierarchical model, activity recognition},
  c-sangmin =	 {The authors build a hierarchical DBN where all he
                  bottom nodes correspond to the states (e.g.,2D grid
                  cells), and the nodes in the hierarchies above are
                  plans the agent is performing. Each plan has
                  pre-defined starting and ending states, and more
                  abstract plans (higher plan) executes lower-level
                  abstract plans until the bottom plans (which are
                  simple motion) are executed. Exact inference is
                  intractable, but they can reduce the sampling space
                  through RB and provide RB-particle filtering. They
                  hand-crafted the model and only provide inference
                  method, not learning.},
}

@InProceedings{Bui03ijcai,
  author =	 {H. H. Bui},
  fullauthor =	 {Hung H. Bui},
  title =	 {{A General Model for Online Probabilistic Plan
                  Recognition}},
  booktitle =	 IJCAI,
  year =	 2003,
  keywords =	 {hierarchical model, activity recognition},
  c-sangmin =	 {Introduce AHMEM which extends AHMM in Bui02jair to
                  allow sequence of lower-level policy given the
                  higher level policy. In previous AHMM, abstract
                  policy chooses the next sub-policy based on current
                  state only. Howver, in AHMEM, the next sub-policy is
                  chosen given (1) current state and (2) previous
                  policy at the same level represented by the memory
                  variable},
}

@InProceedings{Bui04aaai,
  author =	 {H.H Bui and D. Q. Phung and S. Venkatesh},
  title =	 {Hierarchical Hidden Markov Models with general state
                  hierarchy},
  crossref =	 {_AAAI04},
  keywords =	 {HMM, hierarchical model, activity recognition},
}

@Article{Buneman74dm,
  author =	 {P. Buneman},
  title =	 {A characterization of rigid circuit graphs},
  journal =	 {Discrete Math.},
  year =	 1974,
  volume =	 9,
  pages =	 {205-212},
  r-Blair93chapter ={The notion of clique trees was introduced
                  independently by Buneman \cite{Buneman74dm},
                  Gavril\cite{Gavril74jct}, and Walter
                  \cite{Walter72thesis}},
  r-Heggernes06dm ={Chordal graphs are exactly the intersection graphs
                  of subtrees of a tree
                  \cite{Buneman74dm,Gavril74jct,Walter72thesis}: A
                  graph G is chordal if and only if there exists a
                  tree T whose vertex set is the set of maximal
                  cliques of G and that satisfies the following
                  property: for every vertex v in G, the set of
                  maximal cliques containing v induces a connected
                  subtree of T. Such a tree is called a clique tree,
                  and it can be computed in linear time
                  \cite{Blair93chapter}.},
  c-dellaert =	 {Several theorems regarding chordal graphs and
                  separators, but to say this paper introduces clique
                  trees is a bit of an overstatement, IMHO.},
}

@Article{Bunke84,
  author =	 {H. Bunke and K. Grebner and G. Sagarer},
  title =	 {Syntactic analysis of noisy input strings with an
                  application to the analysis of heart-volume curves},
  journal =	 ICPR,
  year =	 {1984},
  pages =	 {1145-1147},
}

@Article{Bunke88,
  author =	 {H. Bunke and D. Pasche},
  title =	 {A new syntactic parsing method and its application
                  to the tracking of noisy contours in images},
  journal =	 {Signal Processing IV : Theories and Applications},
  year =	 1988,
  pages =	 {1201-1204},
}

@Book{BunkeSanfeliu90,
  author =	 {H. Bunke and A. Sanfeliu},
  title =	 {Syntactic and Structural Pattern Recognition :
                  Theory and Applications},
  publisher =	 {World Scientific},
  year =	 1990,
}

@InProceedings{Bunschoten03icra,
  author =	 {Bunschoten, R. and Kr{\"o}se, B.},
  title =	 {Visual odometry from an omnidirectional vision
                  system},
  booktitle =	 ICRA,
  pages =	 {577-583},
  year =	 2003,
  volume =	 1,
}

@Article{Bunschoten03tra,
  author =	 {Bunschoten, R. and Kr{\"o}se, B.},
  title =	 {Robust scene reconstruction from an omnidirectional
                  vision system},
  journal =	 TRA,
  year =	 2003,
  volume =	 19,
  number =	 2,
  pages =	 {351-357},
  month =	 {April},
}

@InProceedings{Burgard00icra,
  author =	 "Burgard, W. and M. Moors and Fox, D. and R. Simmons
                  and S. Thrun",
  title =	 "Collaborative Robot Exploration",
  booktitle =	 ICRA,
  year =	 2000,
  abstract =	 {In this paper we consider the problem of exploring
                  an unknown environment by a team of robots. As in
                  single-robot exploration the goal is to minimize the
                  overall exploration time. The key problem to be
                  solved therefore is to choose appropriate target
                  points for the individual robots so that they
                  simultaneously explore different regions of their
                  environment. We present a probabilistic approach for
                  the coordination of multiple robots which, in
                  contrast to previous approaches, simultaneously
                  takes into account the costs of reaching a target
                  point and the utility of target points. The utility
                  of target points is given by the size of the
                  unexplored area that a robot can cover with its
                  sensors upon reaching a target position. Whenever a
                  target point is assigned to a specific robot, the
                  utility of the unexplored area visible from this
                  target position is reduced for the other
                  robots. This way, a team of multiple robots assigns
                  different target points to the individual
                  robots. The technique has been implemented and
                  tested extensively in real-world experiments and
                  simulation runs. The results given in this paper
                  demonstrate that our coordination technique
                  significantly reduces the exploration time compared
                  to previous approaches.},
}

@Article{Burgard05tro,
  author =	 "W. Burgard and M. Moors and C. Stachniss and
                  F. Schneider",
  title =	 "Coordinated multi-robot exploration",
  journal =	 TRO,
  year =	 2005,
  abstract =	 {In this paper, we consider the problem of exploring
                  an unknown environment with a team of robots. As in
                  singlerobot exploration the goal is to minimize the
                  overall exploration time. The key problem to be
                  solved in the context of multiple robots is to
                  choose appropriate target points for the individual
                  robots so that they simultaneously explore different
                  regions of the environment. We present an approach
                  for the coordination of multiple robots, which
                  simultaneously takes into account the cost of
                  reaching a target point and its utility. Whenever a
                  target point is assigned to a specic robot, the
                  utility of the unexplored area visible from this
                  target position is reduced. In this way, different
                  target locations are assigned to the individual
                  robots. We furthermore describe how our algorithm
                  can be extended to situations in which the
                  communication range of the robots is limited. Our
                  technique has been implemented and tested
                  extensively in real-world experiments and simulation
                  runs. The results demonstrate that our technique
                  effectively distributes the robots over the
                  environment and allows them to quickly accomplish
                  their mission.},
  r-Fox06iee =	 {If the robots know their relative locations and
                  share a map of the area they explored so far, then
                  effective coordination can be achieved by guiding
                  the robots into different, non-overlapping areas of
                  the environment},
}

@InProceedings{Burgard96aaai,
  author =	 "Burgard, W. and Fox, D. and Hennig, D. and Schmidt,
                  T.",
  title =	 "Estimating the Absolute Position of a Mobile Robot
                  Using Position Probability Grids",
  crossref =	 {_AAAI96},
  pages =	 "896-901"
}

@InProceedings{Burgard98,
  author =	 {W. Burgard and A. Derr and D. Fox and A.B. Cremers},
  title =	 {Integrating global position estimation and position
                  tracking for mobile robots: the {D}ynamic {M}arkov
                  {L}ocalization approach},
  booktitle =	 IROS,
  year =	 1998,
}

@INPROCEEDINGS{Burgard99a,
  AUTHOR =	 {Burgard, W. and Fox, D. and Jans, H. and Matenar,
                  C. and Thrun, S.},
  TITLE =	 {Sonar-Based Mapping of Large-Scale Mobile Robot
                  Environments Using {EM}},
  YEAR =	 1999,
  BOOKTITLE =	 ICML,
  pages =	 {67-76},
  ADDRESS =	 {Bled, Slovenia},
}

@Book{Burke85book,
  author =	 {W.L. Burke},
  title =	 {Applied Differential Geometry},
  publisher =	 {Cambridge University Press},
  year =	 {1985},
  c-dellaert =	 {The book recommended to me by Pai in Brazil},
}

@article{Burl98,
  author =	 "M.C. Burl and M. Weber and P. Perona",
  fullauthor =	 "Michael C. Burl and Markus Weber and Pietro Perona",
  title =	 "A probabilistic approach to object recognition using
                  local photometry and global geometry",
  journal =	 "Lecture Notes in CS",
  volume =	 1407,
  pages =	 628,
  year =	 1998,
  url =		 "citeseer.nj.nec.com/burl98probabilistic.html"
}

@InProceedings{Burschka04icra,
  author =	 {D. Burschka and G.D. Hager},
  fullauthor =	 {Darius Burschka and Gregory D. Hager},
  title =	 {{V-GPS(SLAM)}: Vision-based Inertial System for
                  Mobile Robots},
  booktitle =	 ICRA,
  pages =	 {409-415},
  location =	 {New Orleans, LA},
  month =	 {Apr},
  year =	 2004,
  abstract =	 {We present a novel vision-based approach to
                  simultaneous localization and mapping (SLAM). We
                  discuss it in the context of estimating the 6 DoF
                  pose of a mobile robot from the perception of a
                  monocular camera using a minimum set of three
                  natural landmarks. In contrast to our previously
                  presented V-GPS system, which navigates based on a
                  set of known landmarks, the current approach allows
                  to estimate the required information about the
                  landmarks on-the-fly during the exploration of an
                  unknown environment The method is applicable to
                  indoor and outdoor environments. The calculation is
                  done from the image position of a set of natural
                  landmarks that are tracked in a continuous video
                  stream at frame-rate. An automatic hand-off process
                  allows an update of the set to compensate for
                  occlusions and decreasing reconstruction accuracies
                  with the distance to an imaged landmark. A generic
                  sensor model allows a system configuration with a
                  variety of physical sensors including: monocular
                  perspective cameras, omni-directional cameras and
                  laser range finders.},
  r-Davison07pami ={Burschka and Hager [this] demonstrated a
                  small-scale visual localization and mapping system,
                  though by separating the localization and mapping
                  steps they neglect estimate correlations and the
                  ability of this method to function over long time
                  periods is doubtful.},
}

@Article{Burt83,
  author =	 {P.J. Burt and E.H. Adelson},
  title =	 {A multiresolution spline with application to image
                  mosaics},
  journal =	 {ACM Transactions on Graphics},
  year =	 1983,
  volume =	 2,
  number =	 4,
  pages =	 {217-236},
}

@article{Burt88ieee,
  title =	 {Smart sensing within a pyramid vision machine},
  author =	 {Burt, P.J.},
  journal =	 {Proceedings of the IEEE},
  Volume =	 76,
  number =	 8,
  month =	 {Aug},
  year =	 1988,
  Pages =	 {1006--1015},
  abstract =	 {In human vision, sensing is a distinctly dynamic
                  process: the eyes move through an evolving sequence
                  of fixations to explore the visual world, and to
                  selectively gather information critical to the task
                  at hand. Computer vision systems must follow similar
                  smart sensing strategies if they are to perform
                  useful tasks in real time. Through intelligent
                  selection of data at an early analysis stage,
                  systems can reduce the overall computational cost by
                  orders of magnitude. Through smart sensing a vision
                  system makes efficient use of limited computing
                  resources. We have built a machine, based on a
                  pyramid architecture, that supports smart sensing
                  and related highly efficient processing. Key
                  elements of the design are a) hierarchical data
                  structures for image representation, b)
                  fine-to-coarse algorithms for the fast generation of
                  image measures, c) coarse-tofine search strategies
                  that rapidly locate objects or events within a
                  scene, and d) high level control mechanisms that
                  guide data gathering even as visual information is
                  being interpreted. This system, known as the Pyramid
                  Vision Machine, achieves high performance at modest
                  cost. Design considerations and several applications
                  are described here.},
  quotes =	 {Many aspects of smart sensing are familiar from our
                  own visual experience. Imagine, for example, the
                  driver of a car traveling on a country road. His
                  visual task is to locate and follow the road,
                  observe oncoming traffic, read appropriate road
                  signs, and avoid any objects in the road. To perform
                  this task he does not examine the world in uniform
                  detail. Rather he moves his eyes to fixate in turn
                  certain critical points in the visual field, the
                  road, an oncoming car, a sign. Two or three such
                  fixations per second suffice to drive the car, yet
                  he ?ees?only a minute fraction of the world before
                  his eyes.},
  r-Clark92chapter ={ Burt describes active sensing, or "smart
                  sensing" as the selective "task oriented gathering
                  of information". In this form of active vision one
                  focusses the "attention" of the visual system on a
                  portion of the scene that is important to the task
                  at hand.}
}

@InProceedings{Burt94,
  author =	 {P.J. Burt and P. Anandan},
  title =	 {Image stabilization by registration to a reference
                  mosaic},
  booktitle =	 IUW,
  pages =	 {457-465},
  year =	 1994,
}

@InProceedings{Cain96,
  author =	 "S. Cain and R.C. Hardie and E. Armstrong",
  title =	 "Restoration of aliased video sequences via a
                  maximum-likelihood approach",
  booktitle =	 "Proc. Nat. Infrared Information Symposium on Passive
                  Sensors",
  year =	 1996,
}

@InProceedings{Campbell05,
  author =	 "Jason Campbell and Rahul Sukthankar and Illah
                  Nourbakhsh and Aroon Pahwa",
  title =	 "A Robust Visual Odometry and Precipice Detection
                  System Using Consumer-grade Monocular Vision",
  booktitle =	 ICRA,
  year =	 2005,
}

@InProceedings{CampbellIROS05,
  author =	 "Jason Campbell and Rahul Sukthankar and Illah
                  Nourbakhsh",
  title =	 "Techniques for Evaluating Optical Flow for Visual
                  Odometry in Extreme Terrain",
  booktitle =	 IROS,
  year =	 2005,
}

@Article{Cannings78aap,
  author =	 {C. Cannings and E.A. Thompson and M.H. Skolnick},
  title =	 {Probability functions on complex pedigrees},
  journal =	 {Advances in Applied Probability},
  year =	 1978,
  pages =	 {26--61},
  volume =	 10,
  month =	 {March},
  abstract =	 {The calculation of probabilities on pedigrees of
                  arbitrary complexity is discussed for a basic model
                  of transmission and penetrance (encompassing
                  Mendelian inheritance, and certain environmental
                  influences). The structure of pedigrees, and the
                  types of loops occurring, is discussed. Some results
                  in graph theory are obtained and, using these, a
                  recurrence relation derived for certain
                  probabilities. The recursive procedure enables the
                  successive peeling off of certain members of the
                  pedigree, and the condensation of the information on
                  those individuals into a function on a subset of
                  those remaining. The underlying theory is set out,
                  and examples given of the utilization of the
                  resulting algorithm.},
  r-Shafer90amai ={The basic algorithms we describe in sections 7 and
                  8 do not go beyond the algorithms of Kelly and
                  Barclay \cite{Kelly73obhp}, Cannings, Thompson and
                  Skolnick \cite{Cannings78aap}, Pearl
                  \cite{Pearl86ai}, and Lauritzen and Spiegelhalter
                  \cite{Lauritzen88jrssb} in what they accomplish, but
                  they do show that the accomplishment is simpler than
                  sometimes thought.},
  c-dellaert =	 {Peeling algorithm, as first mentioned to me by Geman
                  at snowbird},
}

@Article{Canny86pami,
  author =	 "J. Canny",
  title =	 "A Computational Approach to Edge Detection",
  journal =	 PAMI,
  year =	 1986,
  month =	 "November",
  volume =	 8,
  number =	 6,
  pages =	 "679-698",
}

@InProceedings{Cantzler02bmvc,
  author =	 {H. Cantzler and R.B. Fisher and M. Devy},
  title =	 {Improving architectural {3D} reconstruction by plane
                  and edge constraining},
  booktitle =	 BMVC,
  year =	 2002,
}

@inproceedings{Cao07iccv,
  author =	 {L. Cao and L. Fei-Fei},
  title =	 {Spatially coherent latent topic model for concurrent
                  object segmentation and classification},
  booktitle =	 ICCV,
  year =	 2007,
}

@Article{Caprile90ijcv,
  author =	 {B. Caprile and V. Torre},
  title =	 {Using Vanishing Points for Camera Calibration},
  journal =	 IJCV,
  year =	 1990,
  volume =	 4,
  pages =	 {127-140},
}

@Book{Carlin96,
  author =	 "B.P. Carlin and T.A. Louis",
  title =	 "Bayes and empirical {B}ayes methods for data
                  analysis",
  publisher =	 chap,
  year =	 1996,
}

@InProceedings{Carneiro05cvpr,
  author =	 {G. Carneiro and A. Jepson},
  title =	 {The Distinctiveness, Detectability, and Robustness
                  of Local Image Features},
  booktitle =	 CVPR,
  year =	 2005,
}

@article{Caron07tsp,
  author =	 {F. Caron and M. Davy and E. Duflos and P. Vanheeghe},
  title =	 {Particle Filtering for Multisensor Data Fusion with
                  Switching Observation Models. Application to Land
                  Vehicle Positioning},
  journal =	 {{IEEE} {T}ransactions on {S}ignal {P}rocessing},
  year =	 2007,
}

@TechReport{Carpenter97,
  author =	 {J. Carpenter and P. Clifford and P. Fernhead},
  title =	 {An improved particle filter for non-linear problems},
  institution =	 {Department of Statistics, University of Oxford},
  year =	 1997,
}

@Article{Carre71jima,
  author =	 {Carr\'{e}, B. A.},
  title =	 {An algebra for network routing problems},
  journal =	 {J. Inst. Math. Appl.},
  year =	 1971,
  volume =	 7,
  pages =	 {273--294},
  r-MathSciNet = {The author formulates the shortest path problem and
                  several variations of it as the solution of the
                  matrix equation $Y=AY\oplus B$ for $Y$ where $A$ and
                  $B$ are specified and all operations are in terms of
                  a semiring $(S,\oplus,\otimes)$. He then shows that
                  a number of known shortest path algorithms are the
                  same as specific solution methods for the above
                  equation. In particular, methods of Bellman and Ford
                  \& Fulkerson [Flows in networks], correspond to
                  variations of the Jacobi and Gauss-Seidel methods,
                  respectively; Floyd's method corresponds to a
                  variant of Jordan elimination and Dantzig's method
                  is a variant of the escalator method of inverting
                  matrices. The author gives a variant of Gauss
                  elimination which yields an apparently new method
                  for finding shortest paths.},
}

@Article{Carter96,
  author =	 {C. Carter and R. Kohn},
  title =	 {Markov chain {M}onte {C}arlo in {C}onditionally
                  {G}aussian {S}tate {S}paece {M}odels},
  journal =	 {Biometrika},
  year =	 1996,
  volume =	 83,
  pages =	 {589-601}
}

@article{Cartwright87bc,
  author =	 {B.A. Cartwright and T.S. Collet},
  title =	 {Landmark maps for honeybees},
  Journal =	 {Biological Cybernetics},
  Volume =	 57,
  Number =	 {1-2},
  month =	 {August},
  year =	 1987,
  abstract =	 {Experiments by Fabre (1915), Thorpe (1950),
                  Chmurzynski (1964), and most recently Gould (1986)
                  suggest that insects have maps of their terrain
                  which enable them to find their way directly to a
                  goal when they are displaced several hundred metres
                  from it. This paper discusses what might constitute
                  an insect's map in terms of a two-part computational
                  model. The first part describes how an insect
                  reaches a goal when the insect is sufficiently close
                  that it can see some of the landmarks which are
                  visible from the goal. The second part considers the
                  problem of navigating when there is no similarity
                  between the view from the release-site and the view
                  from the goal. We start from a model designed to
                  explain how a bee might return to a goal using a
                  two-dimensional snapshot of the landscape seen from
                  the goal (Collett and Cartwright 1983). To guide its
                  return, the model bee continuously compares its
                  snapshot with its current retinal image and moves so
                  as to reduce the discrepancy between the two. Bees
                  can only be guided in the right direction by the
                  difference between current retinal image and
                  snapshot when there is some resemblance between the
                  two. In a realistically cluttered world, snapshot
                  and retinal image become very dissimilar only a
                  short distance from the goal. To increase the
                  distance from which a model bee can return, the bee
                  takes two snapshots at the goal. The first snapshot
                  excludes landmarks near to the goal and the second
                  snapshot includes them. With close landmarks
                  filtered from both snapshot and retinal image, the
                  match between the two deteriorates gradually as the
                  bee moves away from the goal. A model bee using a
                  filtered snapshot and image finds its way back to
                  the neighbourhood of the goal from a relatively long
                  distance (Fig. 2). The bee then switches to the
                  second snapshot and is guided to the precise spot by
                  its memory of the close landmarks. For longer range
                  guidance, the model bee is equipped with an album of
                  snapshots, each taken at a different location within
                  the terrain. Linked to each snapshot is a vector
                  encoding the distance and direction from the place
                  where the snapshot was taken to the hive. When the
                  bee is displaced to a new position, it selects the
                  snapshot which best matches its current image and
                  follows the associated home-vector back to the hive
                  (Fig. 3). Such a hive-centred map can also be used
                  to devise novel routes to places other than the
                  hive. For instance, a bee can reach a foraging site
                  from anywhere in its terrain by adding the
                  home-vector recalled at the starting position to a
                  vector specifying the distance and direction of the
                  foraging site from the hive. The sum of these two
                  vectors defines a direct trajectory to the foraging
                  site.},
  c-dellaert =	 {Often referenced as seminal on view-based homing in
                  bees. Seems speculative.}
}

@TechReport{Casella00tr,
  author =	 {Casella, G. and Robert, C.P. and Wells, M.T.},
  title =	 {Rao-{B}lackwellization of Generalized Accept-Reject
                  Schemes},
  institution =	 {Dept. of Statistics, University of Florida},
  year =	 {2000},
}

@Article{Casella96biometrika,
  author =	 {Casella, G. and Robert, C.P.},
  title =	 {Rao-{B}lackwellisation of Sampling Schemes},
  journal =	 {Biometrika},
  year =	 1996,
  volume =	 83,
  number =	 1,
  pages =	 {81-94},
  month =	 {March},
}

@BOOK{Castellanos00,
  AUTHOR =	 {Castellanos, J.A. and Tards, J.D.},
  TITLE =	 {Mobile Robot Localization and Map Building: A
                  Multisensor Fusion Approach},
  PUBLISHER =	 {Kluwer Academic Publishers},
  YEAR =	 2000,
  ADDRESS =	 {Boston, MA}
}

@InProceedings{Castellanos04,
  author =	 {J.A. Castellanos and J. Neira and J.D. Tards},
  title =	 {Limits to the consistency of {EKF}-based {SLAM}},
  booktitle =	 {5th IFAC Symp. on Intelligent Autonomous Vehicles,
                  IAV'04},
  year =	 2004,
  month =	 {July},
  Abstract =	 {This paper analyzes the consistency of the classical
                  extended Kalman filter (EKF) solution to the
                  simultaneous localization and map building (SLAM)
                  problem. Our results show that in large environments
                  the map quickly becomes inconsistent due to
                  linearization errors. We propose a new EKF-based
                  SLAM algorithm, robocentric mapping, that greatly
                  reduces linearization errors, improving map
                  consistency. We also present results showing that
                  large-scale mapping methods based on building local
                  maps with a local uncertainty representation
                  (Tardos et al., 2002) have better consistency
                  than methods that work with global uncertainties.},
  c-Alireza =	 {The paper has a very nice introduction (previous
                  work) section, which can be used to write papers. In
                  this paper they show that linearization of SLAM can
                  cause the problem to diverge. However, in methods in
                  which joining of local maps is used for building the
                  global map, the linearization works better since it
                  is local. They also suggest an alternative for the
                  computation of SLAM problem using EKF, in which the
                  observation is used to get a better estimation of
                  odometry. The method is called ROBOCENTRIC
                  MAPPING.},
  c-dellaert =	 {Robocentric mapping is not very clearly explained},
}

@Article{Castellanos07ras,
  author =	 {Castellanos, J.A. and Martnez-Cantn, R. and
                  Tards, J.D and Neira J.},
  title =	 {Robocentric Map Joining: Improving the Consistency
                  of {EKF-SLAM} },
  journal =	 RAS,
  year =	 {2007},
  volume =	 {55},
  number =	 {1},
  pages =	 {21-29},
  month =	 {January},
  abstract =	 {In this paper we study the Extended Kalman Filter
                  approach to the simultaneous localization and
                  mapping (EKF-SLAM), describing its known properties
                  and limi- tations, and concentrate on the filter
                  consistency issue. We show that linearization of the
                  inherent nonlinearities of both the vehicle motion
                  and the sensor models fre- quently drives the
                  solution of the EKF-SLAM out of consistency,
                  specially in those situations where uncertainty
                  surpasses a certain threshold. We propose a mapping
                  algorithm, Robocentric Map Joining, which improves
                  consistency of the EKF-SLAM algorithm by limiting
                  the level of uncertainty in the continuous evolution
                  of the sto- chastic map: (1) by building a sequence
                  of independent local maps, and (2) by using a robot
                  centered representation of each local
                  map. Simulations and a large-scale in- door/outdoor
                  experiment validate the proposed approach.},
}

@InProceedings{Castellanos97,
  author =	 {J.A. Castellanos and J.D. Tards and G. Schmidt},
  title =	 {Building a global map of the environment of a mobile
                  robot: {T}he importance of correlations},
  booktitle =	 ICRA,
  pages =	 {1053-1059},
  year =	 1997,
}

@ARTICLE{Castellanos99a,
  AUTHOR =	 {J.A. Castellanos and J.M.M. Montiel and J. Neira and
                  J.D. Tards},
  TITLE =	 {The {SP}map: {A} Probabilistic Framework for
                  Simultaneous Localization and Map Building},
  JOURNAL =	 TRA,
  YEAR =	 1999,
  VOLUME =	 15,
  NUMBER =	 5,
  PAGES =	 {948--953}
}

@InProceedings{Castle07icra,
  Author =	 {R. O. Castle and D. J. Gawley and G. Klein and
                  D. W. Murray},
  Title =	 {Towards simultaneous recognition, localization and
                  mapping for hand-held and wearable cameras},
  BookTitle =	 icra,
  Pages =	 {4102--4107},
  Address =	 {Rome, Italy},
  day =		 {10-14},
  month =	 apr,
  year =	 2007
}

@InCollection{Cela99,
  author =	 {E. Cela and R. E. Burkard},
  editor =	 {P. M. Pardalos and D. Z. Du},
  booktitle =	 {Handbook of Combinatorial Optimization - Supplement
                  Volume A},
  title =	 {Linear Assignment Problems and Extensions},
  publisher =	 {Kluwer Academic Publishers,},
  year =	 1999,
  pages =	 {75-149},
}

@InProceedings{Chahl97,
  author =	 {Chahl, J.S. and Srinivasan, M.V},
  title =	 {Navigation, path planning, and homing for autonomous
                  mobile robots using panoramic visual sensors},
  booktitle =	 {Proceedings of AISB Workshop on Spatial Reasoning in
                  Mobile Robots and Animals},
  pages =	 {47-55},
  year =	 1997,
  address =	 {Manchester, UK},
}

@article{Challa02fusion,
  author =	 {S. Challa and R.J. Evans and X. Wang and J. Legg},
  volume =	 2,
  number =	 4,
  pages =	 {325--348},
  title =	 {A Fixed-Lag Smoothing Solution To Out-Of-Sequence
                  Information Fusion Problems},
  journal =	 {Communications In Information and Systems},
  year =	 2002,
}

@inproceedings{Cham94iapr,
  Author =	 {T. Cham and Cipolla, R.},
  FullAuthor =	 {Tat-Jen Cham and Cipolla, Roberto},
  Pages =	 {222--226},
  Title =	 {A local approach to recovering global skewed
                  symmetry},
  Volume =	 1,
  booktitle =	 IAPR,
  Year =	 1994
}

@InProceedings{Cham97,
  author =	 "Tat-Jen Cham and Roberto Cipolla",
  title =	 "Stereo Coupled Active Contours",
  booktitle =	 CVPR,
  pages =	 "1094-1099",
  year =	 1997,
}

@article{Cham99,
  author =	 "Tat-Jen Cham and Roberto Cipolla",
  title =	 "Automated {B}-Spline Curve Representation
                  Incorporating {MDL} and Error-Minimizing Control
                  Point Insertion Strategies",
  journal =	 "PAMI",
  volume =	 21,
  number =	 1,
  pages =	 "49-53",
  year =	 1999,
  url =		 "citeseer.nj.nec.com/cham97automated.html"
}

@InProceedings{Chan05iccv,
  author =	 {A. B. Chan and N. Vasconcelos},
  fullauthor =	 {Antoni B. Chan and Nuno Vasconcelos},
  title =	 {Mixtures of {D}ynamic {T}extures},
  booktitle =	 ICCV,
  year =	 2005,
}

@Article{Chan08pami,
  author =	 {A. B. Chan and N. Vasconcelos},
  fullauthor =	 {Antoni B. Chan and Nuno Vasconcelos},
  title =	 {Modeling, clustering, and segmenting video with
                  mixtures of dynamic textures},
  booktitle =	 PAMI,
  year =	 2008,
  month =	 May,
  volume =	 30,
  issue =	 5,
  pages =	 {909-926},
}

@article{Chang86itac,
  Author =	 {Kuo-Chu Chang and Chee-Yee Chong and Bar-Shalom, Y.},
  Journal =	 ITAC,
  Number =	 10,
  Pages =	 {889--897},
  Title =	 {Joint probabilistic data association in distributed
                  sensor networks},
  Volume =	 31,
  Year =	 1986,
  Abstract =	 {A distributed multitarget tracking problem is
                  considered. The joint probabilistic data association
                  (JPDA) algorithm, which has been successfully used
                  for tracking multiple targets in a cluttered
                  environment, assumes a centralized processing
                  architecture. It assumes that measurements are
                  transmitted to a central site and processed. In some
                  applications, however, it may be desirable for the
                  sensor measurements to be processed at or near the
                  sensors instead of transmitting them to the central
                  processor. The local processed results are then sent
                  over a communication network to be used by other
                  processors. This paper presents a distributed
                  version of the JPDA algorithm which is applicable
                  under such a situation.},
  r-DurrantWhyte90icra ={[The DKF] differs from the sub-optimal
                  decomposition described in \cite{Chang86itac}.},
  r-Ra091cta =	 {\cite{Chang86itac} discuss various architectures for
                  implementing a distributed Kalman filter algorithm
                  starting from a centralised distributed system
                  through to a decentralised system. They fail to
                  simplify the equations for the decentralised case
                  and do not consider its relevance to decentralised
                  decision making.},
  c-dellaert =	 {2 nodes and a "fusion node", filtering
                  framework. Don't quite know what HDW refers to when
                  he says this is "suboptimal".},
}

@InProceedings{Chang98,
  author =	 {P. Chang and M. Hebert},
  title =	 {Omni-directional visual servoing for human-robot
                  interaction},
  booktitle =	 ICRA,
  pages =	 {1801-1807},
  year =	 1998,
  volume =	 3,
  month =	 {October},
}

@inproceedings{Chao05,
  author =	 {Chao, C. and Stamos, I.},
  title =	 {Semi-automatic range registration: a feature-based
                  method},
  booktitle =	 _3DIM,
  year =	 2005,
}

@inproceedings{Chao06,
  author =	 {Chao, C. and Stamos, I.},
  title =	 {Range Image Registration based on Circular Features},
  booktitle =	 {3D Data Processing Visualization and Transmission},
  year =	 2006,
}

@article{Charniak93ai,
  author =	 "E. Charniak and R. P. Goldman",
  title =	 {{A Bayesian model of plan recognition}},
  journal =	 AI,
  volume =	 64,
  issue =	 1,
  pages =	 "53-79",
  year =	 1993,
}

@InProceedings{Chatila85,
  author =	 {R. Chatila and J.-P. Laumond},
  title =	 {Position referencing and consistent world modeling
                  for mobile robots},
  booktitle =	 ICRA,
  pages =	 {138-145},
  year =	 1985,
}

@InProceedings{CheBin05icme,
  author =	 {C-B. Liu and R-S. Lin and N. Ahuja},
  fullauthor =	 {Che-Bin Liu and Ruei-Sung Lin and Narendra Ahuja},
  title =	 {Modeling Dynamic Textures Using Subspace Mixtures},
  booktitle =	 ICME,
  year =	 2005,
}

@InProceedings{CheBin06bmvc,
  author =	 {C-B. Liu and R-S. Lin and N. Ahuja and M. Yang},
  fullauthor =	 {Che-Bin Liu and Ruei-Sung Lin and Narendra Ahuja and
                  Ming-Hsuan Yang},
  title =	 {Dynamic Textures Synthesis as Nonlinear Manifold
                  Learning and Traversing},
  booktitle =	 BMVC,
  year =	 2006,
}

@TechReport{Cheeseman94,
  author =	 {P.~Cheeseman and B.~Kanefsky and R.~Kraft and
                  J.~Stutz and R.~Hanson},
  title =	 {Super-Resolved Surface Reconstruction from Multiple
                  Images},
  institution =	 {{NASA} Ames Research Center},
  year =	 1994,
  number =	 {{FIA}-94-12},
  address =	 {Moffet Field, CA},
  month =	 {December}
}

@InCollection{Cheeseman96,
  author =	 "P. Cheeseman and B. Kanefsky and R. Kraft and
                  J. Stutz and R. Hanson",
  title =	 "Super-Resolved Surface Reconstruction from Multiple
                  Images",
  booktitle =	 "Maximum Entropy and {B}ayesian Methods",
  publisher =	 kluwer,
  year =	 1996,
  editor =	 "G. R. Heidbreder",
  pages =	 "293-308",
  address =	 "the Netherlands",
}

@InProceedings{Chen00cvpr,
  author =	 {X. Chen and J. Davis and P. Slusallek},
  title =	 {Wide Area Camera Calibration Using Virtual
                  Calibration Objects},
  booktitle =	 CVPR,
  year =	 2000,
}

@Article{Chen02itac,
  author =	 {L. Chen and P.O. Aramble and R.K. Mehra},
  title =	 {Estimation Under Unknown Correlation: Covariance
                  Intersection Revisited},
  journal =	 ITAC,
  year =	 2002,
  volume =	 47,
  number =	 11,
}

@InProceedings{Chen03iccv,
  author =	 {X. Chen and J. Yang and A. Waibel},
  full =	 {Xilin Chen and Jie Yang and Alex Waibei},
  title =	 {Calibration of a Hybrid Camera Network},
  booktitle =	 ICCV,
  year =	 2003,
}

@Article{Chen85,
  author =	 {T.C.~Chen and R.J.P.~deFigueiredo},
  title =	 {Two-Dimensional Interpolation by Generalized Spline
                  Filters based on Partial Differential Equation Image
                  Models},
  journal =	 ASSP,
  year =	 1985,
  volume =	 33,
  number =	 3,
  pages =	 {631--642}
}

@InProceedings{Chen91,
  author =	 {Y. Chen and G. Medioni},
  title =	 {Object Modelling by Registration of Multiple Range
                  Images},
  booktitle =	 ICRA,
  pages =	 {2724--2729},
  year =	 1991
}

@Article{Chen93,
  author =	 {G.~Chen and R.J.P.~deFigueiredo},
  title =	 {A Unified Approach to Optimal Image Interpolation
                  Problems based on Linear Partial Differential
                  Equation Models},
  journal =	 IP,
  year =	 1993,
  volume =	 2,
  number =	 1,
  pages =	 {41--49}
}

@TechReport{Chen94,
  author =	 {S.S. Chen and D.L. Donoho},
  title =	 {Basis Pursuit},
  institution =	 {Stanford University},
  year =	 1994,
}

@TechReport{Chen96,
  author =	 {S.S. Chen and D.L. Donoho and M.A. Saunders},
  title =	 {Atomic Decomposition by Basis Pursuit},
  institution =	 {Stanford University},
  year =	 1996,
}

@inproceedings{Cheng94,
  author =	 "Y. Cheng and R. Collins and A. Hanson and
                  E. Riseman",
  title =	 "Triangulation without Correspondences",
  booktitle =	 IUW,
  year =	 1994
}

@inproceedings{Cheng96,
  author =	 "Y. Cheng and V. Wu and R. Collins and A. Hanson and
                  E. Riseman",
  title =	 "Maximum-Weight Bipartite Matching Technique and Its
                  Application in Image Feature Matching",
  booktitle =	 "Proc. SPIE Visual Comm. and Image Processing,
                  Orlando, FL.",
  year =	 1996
}

@InProceedings{Cheng98,
  author =	 {L.Cheng and J.Robinson},
  title =	 {Dealing With Speed and Robustness Issues for
                  Video-Based Registration on a Wearable Computing
                  Platform},
  booktitle =	 {ISWC},
  year =	 1998,
}

@InProceedings{Chetverikov02,
  author =	 {Chetverikov, D. and Stepanov, D. and Krsek, P.},
  title =	 {The Trimmed Iterative Closest Point Algorithm},
  booktitle =	 ICPR,
  year =	 2002,
  url =
                  "doi.ieeecomputersociety.org/10.1109/ICPR.2002.1047997",
}

@InProceedings{Chia02,
  author =	 {K.Chia and A.Cheok and S.Prince},
  title =	 {Online 6 DOF Augmented Reality Registration from
                  Natural Features},
  booktitle =	 {ISMAR},
  year =	 2002,
}

@InProceedings{Chiang96,
  author =	 {M.-C.~Chiang and T.E.~Boult},
  title =	 {Efficient Image Warping and Super-Resolution},
  booktitle =	 WACV,
  year =	 1996,
  month =	 {December},
  pages =	 {56--61}
}

@InProceedings{Chiang97,
  author =	 {M.-C.~Chiang and T.E.~Boult},
  title =	 {Imaging-Consistent Super-Resolution},
  booktitle =	 IUW,
  year =	 1997
}

@InProceedings{Chiang97b,
  author =	 {M.-C.~Chiang and T.E.~Boult},
  title =	 {Local Blur Estimation and Super-Resolution},
  booktitle =	 CVPR,
  year =	 1997,
  address =	 {San Juan, Puerto Rico},
  month =	 {June},
  pages =	 {821--826}
}

@article{Chib95,
  author =	 {S. Chib and E. Greenberg},
  title =	 {Understanding the {M}etropolis-{H}astings Algorithm},
  year =	 1995,
  journal =	 {American {S}tatistician},
  pages =	 {327-335},
  volume =	 49,
  number =	 4
}

@Book{Chirikjian01,
  author =	 {G.~S. Chirikjian and A.~B. Kyatkin},
  fullauthor =	 {Gregory S. Chirikjian and Alexander B. Kyatkin},
  title =	 {Engineering Applications of Noncommutative Harmonic
                  Analysis: With Emphasis on Rotation and Motion
                  Groups},
  publisher =	 {CRC Press},
  year =	 2001,
  address =	 {Boca Raton},
}

@InProceedings{Chiuso00eccv,
  author =	 {A. Chiuso and P. Favaro and H. Jin and S. Soatto},
  title =	 {{MFm}: {3-D} motion from {2-D} motion causally
                  integrated over time},
  booktitle =	 ECCV,
  year =	 2000,
}

@ARTICLE{Chiuso02pami,
  title =	 {Structure from motion causally integrated over time},
  author =	 {Chiuso, A. and Favaro, P. and Hailin Jin and Soatto,
                  S.},
  journal =	 PAMI,
  year =	 {2002},
  month =	 {Apr},
  volume =	 {24},
  number =	 {4},
  pages =	 {523-535},
  abstract =	 {We describe an algorithm for reconstructing
                  three-dimensional structure and motion causally, in
                  real time from monocular sequences of images. We
                  prove that the algorithm is minimal and stable, in
                  the sense that the estimation error remains bounded
                  with probability one throughout a sequence of
                  arbitrary length. We discuss a scheme for handling
                  occlusions (point features appearing and
                  disappearing) and drift in the scale factor. These
                  issues are crucial for the algorithm to operate in
                  real time on real scenes. We describe in detail the
                  implementation of the algorithm, which runs on a
                  personal computer and has been made available to the
                  community. We report the performance of our
                  implementation on a few representative long
                  sequences of real and synthetic images. The
                  algorithm, which has been tested extensively over
                  the course of the past few years, exhibits honest
                  performance when the scene contains at least 20-40
                  points with high contrast, when the relative motion
                  is "slow" compared to the sampling frequency of the
                  frame grabber (30 Hz), and the lens aperture is
                  "large enough" (typically more than 30 of visual
                  field)},
  c-dellaert =	 {Originally in ECCV 2000 (and also Jin00cvpr?),
                  monocular SLAM, very control theoretic}
}

@InCollection{Chong90chapter,
  author =	 {Chong, C. and S. Mori and K. Chan},
  title =	 {Distributed mutitarget multisensor tracking.},
  booktitle =	 {Multitarget Multisensor Tracking},
  year =	 1990,
  editor =	 {Y. Bar-Shalom},
  publisher =	 {Artech House},
  c-Grime94cep = {The recent paper by Chong, Mori and Chang (1990) is
                  most closely related to the work described in this
                  paper. The formulation of the nodal estimators is
                  also based on the information filter form of the
                  Kalman filter. In addition, the paper describes a
                  model for communication or information flow in a
                  sensor network based on the idea of an information
                  graph.},
}

@InProceedings{Chong97fsr,
  author =	 {K.S. Chong and L. Kleeman},
  title =	 {Large scale sonarray mapping using multiple
                  connected local maps},
  booktitle =	 FSR,
  year =	 1997,
  abstract =	 {This paper presents a strategy for achieving
                  practical mapping navigation using a wheels driven
                  robot equipped with a sonarray (an advanced sonar
                  array). The original mapping navigation experiment,
                  carried out with the same robot configuration,
                  builds a feature map consisting of commonplace
                  indoor landmarks crucial for localisation, namely
                  planes, corners and edges. The map exhaustively
                  maintains covariance matrices among all features,
                  thus presents a time and memory impediment to
                  practical navigation in large environments. The new
                  local mapping strategy proposed here breaks down a
                  large environment into a topology of local regions,
                  only maintaining the covariance among features in
                  the same local region, and the covariance among
                  local maps. This notion of two hierarchy
                  representation drastically improves the memory and
                  processing time requirements of the original global
                  approach, while preserving the statistical details
                  necessary for an accurate map and prolonged
                  navigation. The new local mapping scheme also
                  extends the endeavour towards reducing error
                  accumulation made in the global mapping strategy by
                  eliminating totally error accumulated between visits
                  to the same part of an environment. This is achieved
                  with a map matching strategy developed exclusively
                  for the advanced sonar sensor employed. The local
                  mapping strategy has been tested in large, real life
                  indoor environments and successful results are
                  reported here.},
c-dellaert={interconnected local maps, },
}

@InProceedings{Chong97icra,
  author =	 {K.S. Chong and L. Kleeman},
  title =	 {Sonar feature map building for a mobile robot},
  booktitle =	 ICRA,
  year =	 1997,
  pages =	 {1700-1705},
}

@InProceedings{Chong97iros,
  author =	 {K.S. Chong and L. Kleeman},
  title =	 {Indoor exploration using a sonar sensor array: a
                  dual representation strategy},
  booktitle =	 IROS,
  year =	 1997,
}

@Article{Choset01tra,
  author =	 {Choset, H. and Nagatani, K.},
  title =	 {Topological simultaneous localization and mapping
                  ({SLAM}): toward exact localization without explicit
                  localization},
  journal =	 TRA,
  year =	 2001,
  volume =	 17,
  number =	 2,
  pages =	 {125 - 137},
  month =	 {April},
  Abstract =	 {One of the critical components of mapping an unknown
                  environment is the robot? ability to locate itself
                  on a partially explored map. This becomes
                  challenging when the robot experiences positioning
                  error, does not have an external positioning device,
                  nor the luxury of engineered landmarks placed in its
                  free space. This paper presents a new method for
                  simultaneous localization and mapping that exploits
                  the topology of the robot? free space to localize
                  the robot on a partially constructed map. The
                  topology of the environment is encoded in a
                  topological map; the particular topological map used
                  in this paper is the generalized Voronoi graph
                  (GVG), which also encodes some metric information
                  about the robot? environment, as well. In this
                  paper, we present the low-level control laws that
                  generate the GVG edges and nodes, thereby allowing
                  for exploration of an unknown space. With these
                  prescribed control laws, the GVG (or other
                  topological map) can be viewed as an arbitrator for
                  a hybrid control system that determines when to
                  invoke a particular low-level controller from a set
                  of controllers all working toward the high-level
                  capability of mobile robot exploration. The main
                  contribution, however, is using the graph structure
                  of the GVG, via a graph matching process, to
                  localize the robot. Experimental results verify the
                  described work.},
  c-dellaert =	 {Very much like Kuipers},
}

@PhdThesis{Choset96phd,
  author =	 {H. Choset},
  title =	 {Sensor based motion planning: The hierarchical
                  generalized voronoi graph},
  school =	 {California Institute of Technology},
  year =	 {1996},
}

@inproceedings{Chou87,
  AUTHOR =	 "T.-C. Chou and K.-I. Kanatani",
  TITLE =	 "Recovering {3D} Rigid Motions without
                  Correspondence",
  BOOKTITLE =	 ICCV,
  YEAR =	 1987,
  PAGES =	 "534-538"
}


@Article{Chow68,
  author =	 {C. K. Chow and C. N. Liu},
  title =	 {Approximating discrete probability distributions
                  with dependence trees},
  journal =	 IT,
  year =	 1968,
  volume =	 {IT-14},
  number =	 3,
  pages =	 {462-- 467},
  month =	 {May},
}

@Article{Chow68it,
  author =	 {Chow, C. and Liu, C.},
  title =	 {Approximating discrete probability distributions
                  with dependence trees},
  journal =	 IT,
  year =	 1968,
  volume =	 14,
  number =	 3,
  pages =	 {462--467},
  month =	 {May},
  abstract =	 {A method is presented to approximate optimally an
                  $n$-dimensional discrete probability distribution by
                  a product of second-order distributions, or the
                  distribution of the first-order tree dependence. The
                  problem is to find an optimum set of $n-1$ first
                  order dependence relationship among the $n$
                  variables. It is shown that the procedure derived in
                  this paper yields an approximation of a minimum
                  difference in information. It is further shown that
                  when this procedure is applied to empirical
                  observations from an unknown distribution of tree
                  dependence, the procedure is the maximum-likelihood
                  estimate of the distribution.},
  r-Bach01nips = {In the current paper we describe a methodology that
                  can be viewed as a generalization of the Chow-Liu
                  algorithm for constructing tree models
                  \citep{Chow68it}.},
}

@ARTICLE{Chown95a,
  AUTHOR =	 {Chown, E. and Kaplan, S. and Kortenkamp, D.},
  TITLE =	 {Prototypes, Location, and Associative Networks
                  (PLAN): Towards a Unified Theory of Cognitive
                  Mapping},
  JOURNAL =	 {Cognitive Science},
  YEAR =	 {1995},
  VOLUME =	 {19},
  PAGES =	 {1--51}
}

@Article{Chown95cs,
  title =	 {Prototypes, location, and associative networks
                  (PLAN): Towards a unified theory of cognitive
                  mapping},
  author =	 {E. Chown and S. Kaplan and D. Kortenkamp},
  fullauthor =	 {Eric Chown and Stephen Kaplan and David Kortenkamp},
  journal =	 {Cognitive Science: A Multidisciplinary Journal},
  Volume =	 19,
  number =	 1,
  year =	 1995,
  pages =	 {1--51},
  abstract =	 {An integrated representation of large-scale space,
                  or cognitive map, colled PLAN, is presented that
                  attempts to address a broader spectrum of issues
                  than has been previously attempted in a single
                  model. Rather than examining way-finding as a
                  process separate from the rest of cognition, one or
                  the fundamental goals of this work is to examine how
                  the wayfinding process is integrated into general
                  cognition. One result of this approach is that the
                  model is ?eads-up? or scene-based, because it takes
                  advantage of the properties of the human visual
                  system and, particularly, the visual system's split
                  into two pathways. The emphasis on the human
                  location or ?here?system is new to cognitive mapping
                  and is port of an attempt to synthesize prototype
                  theory, associative networks and location together
                  in a connectionist system. Not all of PLAN is new,
                  however. Many of its parts have analogues in one or
                  another preexisting theory. What makes PLAN unique
                  is integrating the various components into a
                  coherent whole, and the capacity of this resulting
                  system to speak to a wide range of constraints. Our
                  approach emphasizes adaptiveness; thus, our focus on
                  such issues as ease of use and efficiency of
                  learning. The result is a model that has a stronger
                  relationship both to the environment, and to the
                  ways that humans interact with it, compared with
                  previous models. The resulting model is examined in
                  some detail and compared to other systems.},
  r-Kuipers00ai ={PLAN [9] is a multiple-representation theory of
                  cognitive mapping with a close relationship to the
                  SSH. PLAN? ?ocal maps?provide an initial bridge
                  between large-scale and visual space
                  representations.},
}

@Article{Christensen94,
  author =	 {H. Christensen and N. Kirkeby},
  title =	 {Model-driven vision for in-door navigation},
  journal =	 {Robotics and Autonomous Systems},
  year =	 1994,
  volume =	 {12},
  pages =	 {199-207},
}

@INPROCEEDINGS{Chuang2000siggraph,
  AUTHOR =	 {Yung-Yu Chuang and Douglas E. Zongker and Joel
                  Hindorff and Brian Curless and David H. Salesin and
                  Richard Szeliski},
  TITLE =	 {Environment Matting Extensions: Towards Higher
                  Accuracy and Real-Time Capture},
  YEAR =	 {2000},
  BOOKTITLE =	 {Proceedings of ACM SIGGRAPH},
  PAGES =	 {121--130},
}

@inproceedings{Chudova02kdd,
  Author =	 {Darya Chudova and Padhraic Smyth},
  Title =	 {Pattern Discovery in Sequences under a Markov
                  Pattern Discovery in Sequences under a Markov
                  Assumption},
  Booktitle =	 KDD,
  Year =	 {2002},
  Keywords =	 {markov, discovery, detection},
  c-sangmin =	 {KDD02 best paper award. Great work. The use of Bayes
                  error framework to identify the hardness of the
                  problem is really interesting. The analysis on the
                  limit (Bayes error rate) w.r.t. various factors are
                  indeed really interesting, and provides a lot of
                  insights into how the problems should be dealt with,
                  and also clearly provides the direction for future
                  research direction. For example, the authors state
                  that the sequential data alone will not be enough
                  alone for learning since the Bayes error rate can
                  not be adjusted anyway, and provides insight that
                  addition of features would be necessary. A similar
                  direction of research on the analytical studies on
                  the labeling problem would be indeed interesting
                  too.},
}

@InProceedings{Chui00,
  author =	 "H. Chui and A. Rangarajan",
  title =	 "A new algorithm for non-rigid point matching",
  booktitle =	 CVPR,
  year =	 2000,
}

@InProceedings{Chum05cvpr,
  author =	 "O. Chum and J. Matas",
  title =	 "Matching with {PROSAC} - Progressive Sample Consensus",
  booktitle =	 CVPR,
  year =	 2005,
}

@InProceedings{Chum05cvpr2,
  author =	 "O. Chum and T. Werner and J. Matas",
  title =	 "Two-view Geometry Estimation Unaffected by a
                  Dominant Plane",
  booktitle =	 CVPR,
  year =	 2005,
}

@Article{Chung94jct,
  author =	 {F.R.K. Chung, D. Mumford},
  title =	 {Chordal completions of planar graphs},
  journal =	 {J. Combin. Theory},
  year =	 1994,
  volume =	 31,
  pages =	 {96--106},
  r-Heggernes06dm ={Chordal graphs in computer vision},
  c-dellaert =	 {with Mumford},
}

@incollection{Churchland94chapter,
  author =	 {Churchland, P.S. and Ramachandran, V.S. and
                  Sejnowski, T.J.},
  title =	 {A critique of pure vision},
  booktitle =	 {Large Scale Neuronal Theories of the Brain},
  editor =	 {Koch, C. andDavis, J.L.},
  address =	 {Cambridge,MA},
  publisher =	 {MIT Press},
  year =	 1994,
  pages =	 {23--60},
  quotes =	 {The idea of "pure vision" is a fiction, we suggest,
                  that obscures some of the most important
                  computational strategies used by the
                  brain. .. 1. The Visual World. What we see at any
                  given moment is in general a fully elaborated
                  representation of a visual scene. .. 2. Hierarchical
                  Processing. Signal elaboration proceeds from the
                  various retinal stages, to the LGN, and thence to
                  higher and higher cortical processing
                  stages. .. 3. Dependency Relations. Higher levels in
                  the processing hierarchy depend on lower levels, but
                  not, in general, vice versa. .. Note finally that
                  the caricature, and, most especially, the "visual
                  world" assumption of the caricature, gets compelling
                  endorsement from common sense. .. We conjecture that
                  the undeniable feeling of having whole scene visual
                  representation is the result mainly of (1) repeated
                  visual visits to stimuli in the scene, (2)
                  short-term semantic memory on the order of a few
                  seconds that maintains the general sense of what is
                  going on without creating and maintaining the
                  point-by-point detail, (3) the brain's
                  "objectification" of sensory perception such that a
                  signal processed in cortex is represented as being
                  about an object in space. .. In any event, it may be
                  worth trying to rethink and reinterpret many
                  physiological and anatomical results under the
                  auspices of the idea that perception is driven by
                  the need to learn action sequences to be performed
                  in space and time.},
  r-Findlay04cb ={Our understanding of these processes has progressed
                  to the point where vision is often described as a
                  flagship topic within neuroscience. Nevertheless,
                  the great majority of studies contributing to this
                  tradition involve a passive observer, thus
                  neglecting the continuous and sequential nature of
                  visual activity. The need for a different
                  perspective was given impetus by a recent
                  provocative paper, entitled ? Critique of Pure
                  Vision? written jointly by several eminent vision
                  scientists \cite{Churchland94chapter}. Active vision
                  is a name frequently used for the new approach, and
                  the questions it seeks to address are now beginning
                  to be clearly delineated.},
  c-dellaert =	 {Active vision manifesto, as a response to the
                  caricature of "pure vision".},
}

@Article{Cid02ar,
  author =	 {R. Murrieta-Cid and C. Parra and M. Devy},
  fullauthor =	 {Rafael Murrieta-Cid and Carlos Parra and Michel
                  Devy},
  title =	 {Visual Navigation in Natural Environments: From
                  Range and Color Data to a Landmark-based Model},
  journal =	 AR,
  volume =	 13,
  number =	 2,
  pages =	 {143-168},
  month =	 {Aug},
  year =	 2002,
  abstract =	 {This paper concerns the exploration of a natural
                  environment by a mobile robot equipped with both a
                  video color camera and a stereo-vision system. We
                  focus on the interest of such a multi-sensory system
                  to deal with the navigation of a robot in an a
                  priori unknown environment, including (1) the
                  incremental construction of a landmark-based model,
                  and the use of these landmarks for (2) the 3-D
                  localization of the mobile robot and for (3) a
                  sesnor-based navigation mode. For robot
                  localization, a slow process and a fast one are
                  simultaneously executed during the robot motions. In
                  the Modeling process (currently 0.1 Hz), the global
                  landmark-based model is incrementally built and the
                  robot situation can be estimated from discriminant
                  landmarks selected amongst the detected objects in
                  the range data. In the tracking process (currently 4
                  Hz), selected landmarks are tracked in the visual
                  data; the tracking results are used to simplify the
                  matching between landmarks in the modeling
                  process. Finally, a sensor-based visual navigation
                  mode, based on the same landmark selection and
                  tracking, is also presented; in order to navigate
                  during a long robot motion, different landmarks
                  (targets) can be selected as a sequence of sub-goals
                  that the robot must successively reach.},
}

@InProceedings{Cipolla99bmvc,
  author =	 {R. Cipolla and T. Drummond and D.P. Robertson},
  title =	 {Camera calibration from vanishing points in images
                  of architectural scenes},
  booktitle =	 BMVC,
  year =	 1999,
}

@InProceedings{Cipolla99icmcs,
  author =	 "R. Cipolla and D. Robertson and E. Boyer",
  fullauthor =	 "Roberto Cipolla and Duncan Robertson and Edmond
                  Boyer",
  title =	 "PhotoBuilder - {3D} Models of Architectural Scenes
                  from Uncalibrated Images",
  booktitle =	 "{ICMCS}, Vol. 1",
  pages =	 "25-31",
  year =	 1999,
  url =		 "citeseer.nj.nec.com/293509.html",
  abstract =	 {We address the problem of recovering 3D models from
                  uncalibrated images of architectural scenes. We
                  propose a simple, geometrically intuitive method
                  which exploits the strong rigidity constraints of
                  parallelism and orthogonality present in indoor and
                  outdoor architectural scenes. We show how these
                  simple constraints can be used to calibrate the
                  cameras and to recover the projection matrices for
                  each viewpoint. The projection matrices are used to
                  recover partial 3D models of the scene and these can
                  be used to visualise new viewpoints. Our approach
                  does not need any a priori information about the
                  cameras being used. A working system called
                  PhotoBuilder had been designed and implemented to
                  allow a user to interactively build a VRML model of
                  a building from uncalibrated images from arbitrary
                  viewpoints.},
  r-Dick99bmvc = { More recent interactive modelling systems such as
                  PhotoBuilder and [Shum98cvpr] require only that the
                  user specify key image features such as parallel or
                  orthogonal lines, but the effort required of the
                  user quickly becomes prohibitive as the desired
                  model complexity and number of images increases.},
  c-self =	 {The last step consists in using these projection
                  matrices to find more correspondences between the
                  images and then to compute 3D textured triangles
                  that represent a model of the scene. More
                  specifically, From these projection matrices, we can
                  determine the epipolar geometry to help find more
                  point correspondences and then the 3D point
                  positions. These points are then used in association
                  with an image point triangulation to obtain 3D
                  structure. This structure is rendered afterwards
                  using a standard texture mapping procedure and the
                  final model is stored in standard VRML format.},
}

@InProceedings{Clapp99bs,
  author =	 {T.C. Clapp and S.J. Godsill},
  title =	 {Fixed-lag smoothing using sequential importance
                  sampling},
  booktitle =	 {Bayesian Statistics VI},
  editor =	 {J.M. Bernardo and J.O. Berger and A.P. Dawid and
                  A.F.M. Smith},
  pages =	 {743--752},
  year =	 {1999},
}

@InProceedings{Clark01icra,
  author =	 {J.E. Clark and J.G. Cham and S.A. Bailey and
                  E.M. Froehlich and P.K. Nahata and R.J. Full and
                  M.R. Cutkosky},
  fullauthor =	 {Jonathan E. Clark and Jorge G. Cham and Sean
                  A. Bailey and Edward M. Froehlich and Pratik
                  K. Nahata and Robert J. Full and Mark R. Cutkosky},
  title =	 {Biomimetic Design and Fabrication of a Hexapedal
                  Running Robot},
  booktitle =	 ICRA,
  year =	 2001,
}

@inproceedings{Clark06crv,
  author =	 {James J. Clark},
  title =	 {Photometric Stereo with Nearby Planar Distributed
                  Illuminants},
  booktitle =	 {Canadian Conference on Computer and Robot Vision},
  year =	 {2006},
}

@InCollection{Clark92chapter,
  author =	 {Clark, J.J. and Ferrier, N.J.},
  title =	 {Attentive Visual Servo Control},
  booktitle =	 {Active Vision},
  pages =	 {137--154},
  publisher =	 {MIT Press},
  year =	 1992,
  editor =	 {A. Blake and A. Yuille},
  chapter =	 10,
  month =	 {December},
  quotes =	 {Humans and other advanced animals process visual
                  data in a dynamic fashion, where instead of applying
                  image analysis operations to a single "snapshot" of
                  the environment, they operate in an purposive and
                  integrative manner on a temporal and spatially
                  disparate sequence of images. .. one can argue that
                  sensor motion actually helps in extracting
                  information from visual sense data. In accepting
                  this viewpoint we need to answer the important
                  question: What does the ability to move image
                  sensors give us in terms of solving vision tasks?},
  c-dellaert =	 {Servo-control of stereo-head based on Koch/Ullman
                  saliency detector.},
}

@InProceedings{Clark92cvpr,
  author =	 {J. J. Clark},
  title =	 "Active photometric stereo",
  booktitle =	 CVPR,
  year =	 1992,
  pages =	 {29-34},
}

@InProceedings{Clark99,
  author =	 {S. Clark and G. Dissanayake},
  title =	 {Simultaneous localization and map building using
                  millimetre wave radar to extract natural features},
  booktitle =	 ICRA,
  year =	 1999,
  pages =	 {1316-1321},
}

@Article{ClarkCarter86,
  author =	 {Clark-Carter, D.D. and Heyes, A.D. and Howarth,
                  C.I.},
  year =	 1986,
  title =	 {The efficiency and walking speed of visually
                  impaired people},
  journal =	 {Ergonomics},
  volume =	 29,
  number =	 6,
  pages =	 {779-789},
}

@Article{Clausen01,
  author =	 {M. Clausen and M. Muller},
  title =	 {Generating Fast {Fourier} Transforms of Solvable
                  Groups},
  journal =	 {Symbolic Computation},
  year =	 2001,
  volume =	 11,
  pages =	 {1-18},
}

@Article{Clausen93,
  author =	 {Michael Clausen and Ulrich Baum},
  title =	 {Fast {Fourier} Transforms for Symmetric Groups:
                  Theory and Implementation},
  journal =	 {Mathematics and Computation},
  year =	 1993,
  volume =	 {61(204)},
  pages =	 {833-847},
}

@InProceedings{Clemente07rss,
  author =	 {L.A. Clemente and A.J. Davison and I.D. Reid and
                  J. Neira and J.D. Tard\'{o}s},
  fullauthor =	 {Laura A. Clemente and Andrew J. Davison and Ian
                  D. Reid and Jos\'{e} Neira and Juan Domingo
                  Tard\'{o}s},
  title =	 {Mapping Large Loops with a Single Hand-Held Camera},
  booktitle =	 RSS,
  location =	 {Atlanta, GA},
  month =	 {Jun},
  year =	 2007,
  abstract =	 {This paper presents a method for Simultaneous
                  Localization and Mapping (SLAM) relying on a
                  monocular camera as the only sensor, which is able
                  to build outdoor, closed-loop maps much larger than
                  previously achieved with such input. Our system,
                  based on the Hierarchical Map approach by Estrada et
                  al. (2005), builds independent local maps in
                  real-time using the EKF-SLAM technique and the
                  inverse depth representation proposed by Montiel et
                  al. (2006). The main novelty in the local mapping
                  process is the use of a data association technique
                  that greatly improves its robustness in dynamic and
                  complex environments. A new visual map matching
                  algorithm stitches these maps together and is able
                  to detect large loops automatically, taking into
                  account the unobservability of scale intrinsic to
                  pure monocular SLAM. The loop closing constraint is
                  applied at the upper level of the Hierarchical Map
                  in near real-time. We present experimental results
                  demonstrating monocular SLAM as a human carries a
                  camera over long walked trajectories in outdoor
                  areas with people and other clutter, even in the
                  more difficult case of forward-looking camera, and
                  show the closing of loops of several hundred
                  meters.},
  c-kaess =	 {Monocular, no other sensors, near real-time,
                  hierarchial SLAM similar to submaps, branch and
                  bound joint compatibility, inverse depth, separate
                  algorithm to detect loop closing, outdoor/city},
}

@article{Codd70cacm,
  author =	 {E. F. Codd},
  title =	 {A relational model of data for large shared data
                  banks},
  journal =	 {Commun. ACM},
  volume =	 13,
  number =	 6,
  year =	 1970,
  issn =	 {0001-0782},
  pages =	 {377--387},
  doi =		 {http://doi.acm.org/10.1145/362384.362685},
  publisher =	 {ACM Press},
  address =	 {New York, NY, USA},
  abstract =	 {Future users of large data banks must be protected
                  from having to know how the data is organized in the
                  machine (the internal representation). A prompting
                  service which supplies such information is not a
                  satisfactory solution. Activities of users at
                  terminals and most application programs should
                  remain unaffected when the internal representation
                  of data is changed and even when some aspects of the
                  external representation are changed. Changes in data
                  representation will often be needed as a result of
                  changes in query, update, and report traffic and
                  natural growth in the types of stored
                  information. Existing noninferential, formatted data
                  systems provide users with tree-structured files or
                  slightly more general network models of the data. In
                  Section 1, inadequacies of these models are
                  discussed. A model based on n-ary relations, a
                  normal form for data base relations, and the concept
                  of a universal data sublanguage are introduced. In
                  Section 2, certain operations on relations (other
                  than logical inference) are discussed and applied to
                  the problems of redundancy and consistency in the
                  user's model.},
  quotes =	 {The totality of data in a data bank may be viewed as
                  a collection of time-varying relations. These
                  relations are of assorted degrees. As time
                  progresses, each n-ary relation may be subject to
                  insertion of additional n-tuples, deletion of
                  existing ones, and alteration of components of any
                  of its existing n-tuples.},
  r-Beeri83jacm ={In the relational model of data, as defined by Codd
                  \cite{Codd70cacm}, an arbitrary database scheme is
                  possible.},
  c-dellaert =	 {A n-ary relation is a subset of cartesian product of
                  n domains. Defines operations: permutation,
                  projection, join, composition,
                  restriction. Relations are joinable if projection
                  yeilds the original relations. My view:
                  relation=density, projection = marginalization}
}

@misc{Cohen00eurographics,
  author =	 "D. Cohen-Or and Y. Chrysanthou and C. Silva",
  title =	 "A survey of visibility for walkthrough applications",
  text =	 "D. Cohen-Or, Y. Chrysanthou, and C. T. Silva. A
                  survey of visibility for walkthrough
                  applications. Proc. of EUROGRAPHICS'00, course
                  notes, 2000.",
  year =	 "2000",
  url =		 "citeseer.ist.psu.edu/cohen-or00survey.html"
}

@Article{Cohen96ras,
  journal =	 RAS,
  year =	 1996,
  number =	 18,
  pages =	 {441-434},
  author =	 {W. Cohen},
  title =	 {Adaptive mapping and navigation by teams of simple
                  robots},
  r-Burgard05tro ={Cohen [this] considers the problem of collaborative
                  mapping and navigation of teams of mobile
                  robots. The team consists of a navigator that has to
                  reach an initially unknown target location and a set
                  of cartographers that randomly move through the
                  environment to nd the target location. When a robot
                  discovers the goal point, the location is
                  communicated among the cartographers to the
                  navigation robot which then starts to move to that
                  location. In extensive experiments, the author
                  analyzes the performance of this approach and
                  compares it to the optimal solution for different
                  environments and different sizes of robot teams.},
  c-dellaert =	 {simulated, algorithmic},
}

@book{Colledge97book,
  title =	 {Spatial Behavior: A Geographic Perspective},
  author =	 {R.G. Golledge and R.J. Stimson},
  fullauthor =	 {Reginald G. Golledge and Robert John Stimson},
  Publisher =	 {Guilford Press},
  year =	 1997,
  r-Huebner07ar ={A second difference is that precise metric knowledge
                  evolves slowly over time, while technical systems
                  are built to achieve an acceptable level of
                  confidence quite fast. Evidence for this could be
                  seen from a long term experiment described in
                  \citet{Golledge97book}. This study addressed the
                  metric knowledge of people, who had newly arrived in
                  an unknown city, and therefore were totally
                  unfamiliar with the new environment. In order to
                  monitor the gain of spatial knowledge the spatial
                  layout of the cognitive map has been reconstructed
                  using a multidimensional scaling (MDS)
                  algorithm. The learning progress, which has been
                  observed over nine months, showed a steadily
                  increasing precision of metric knowledge. It has
                  further been shown that subjects tend to stick to
                  preferred routes, and that these routes are
                  represented more accurately than less experienced
                  routes.},
  c-dellaert =	 {Don't have book}
}

@Article{Collin94,
  author =	 {S. Collin and D. Colnet},
  title =	 {Syntactic Analysis of Technical Drawing Dimensions},
  journal =	 {International Journal of Pattern Recognition and
                  Artificial Intelligence},
  year =	 1994,
  volume =	 8,
  pages =	 {1131-1148},
}

@techreport{Collins00tech,
  author =	 "R. Collins and A. Lipton and T. Kanade and
                  H. Fujiyoshi and D. Duggins and Y. Tsin and
                  D. Tolliver and N. Enomoto and O. Hasegawa",
  fullauthor =	 "Robert Collins and Alan Lipton and Takeo Kanade and
                  Hironobu Fujiyoshi and David Duggins and Yanghai
                  Tsin and David Tolliver and Nobuyoshi Enomoto and
                  Osamu Hasegawa",
  title =	 {{A System for Video Surveillance and Monitoring}},
  institution =	 "Robotics Institute, Carnegie Mellon University",
  month =	 "May",
  year =	 2000,
  number =	 "CMU-RI-TR-00-12",
  keywords =	 {surveillance},
}

@Article{Collins02,
  author =	 "M. Collins and R. E. Schapire and Y. Singer",
  fullauthor =	 "Michael Collins and Robert E. Schapire and Yoram
                  Singer",
  title =	 "Logistic Regression, {AdaBoost} and {Bregman}
                  Distances",
  volume =	 48,
  booktitle =	 "Machine Learning",
  year =	 2002,
}

@Article{Collins92aes,
  author =	 {J. B. Collins and J. K. Uhlmann},
  title =	 {Efficient gating in data association with
                  multivariate Gaussian distributed states},
  journal =	 AES,
  year =	 1992,
  volume =	 28,
  number =	 3,
}

@inproceedings{Collins95iccv,
  author =	 "R.T. Collins and Y.-Q. Cheng and C. Jaynes and
                  F. Stolle and X. Wang and A.R. Hanson and
                  E.M. Riseman",
  fullauthor =	 "Robert T. Collins and Yong-Qing Cheng and Chris
                  Jaynes and Frank Stolle and Xiaoquang Wang and Allen
                  R. Hanson and Edward M. Riseman",
  title =	 "Site Model Acquisition and Extension from Aerial
                  Images",
  booktitle =	 ICCV,
  pages =	 "888-893",
  year =	 1995,
  url =		 "citeseer.nj.nec.com/collins95site.html"
}

@article{Collins98cviu,
  author =	 "R.T. Collins and Y.-Q. Cheng and C. Jaynes and
                  F. Stolle and X. Wang and A.R. Hanson and
                  E.M. Riseman",
  fullauthor =	 "Robert T. Collins and Yong-Qing Cheng and Chris
                  Jaynes and Frank Stolle and Xiaoquang Wang and Allen
                  R. Hanson and Edward M. Riseman",
  title =	 "The Ascender System: Automated Site Modeling from
                  Multiple Aerial Images",
  journal =	 "Computer Vision and Image Understanding: CVIU",
  volume =	 72,
  number =	 2,
  pages =	 "143--162",
  year =	 1998,
  url =		 "citeseer.nj.nec.com/collins98ascender.html"
}

@InProceedings{Collins99,
  author =	 "Robert Collins and Yanghai Tsin",
  title =	 "Calibration of an Outdoor Active Camera System",
  pages =	 "528-534",
  booktitle =	 "CVPR",
  year =	 1999,
}

@InProceedings{Collins99cvpr,
  author =	 {R. Collins and Y. Tsin},
  title =	 {Calibration of an Outdoor Active Camera System},
  booktitle =	 CVPR,
  year =	 1999,
}

@Article{Comaniciu02pami,
  author =	 "D. Comaniciu and P. Meer",
  title =	 "Mean Shift: A Robust Approach Toward Feature Space
                  Analysis",
  journal =	 PAMI,
  year =	 2002,
  volume =	 24,
  number =	 5,
  pages =	 "603-619",
}

@InProceedings{Comaniciu97,
  author =	 {Dorin Comaniciu and Peter Meer},
  title =	 {Robust Analysis of Feature Spaces: Color Image
                  Segmentation},
  booktitle =	 CVPR,
  pages =	 {750-755},
  year =	 1997,
}

@InProceedings{Comport03,
  author =	 {A.Comport and E.Marchand and F.Chaumette},
  title =	 {A Real-Time Tracker for Markerless Augmented
                  Reality},
  booktitle =	 {ISMAR},
  year =	 2003,
}

@Unpublished{Constantini04,
  title =	 {Herding and clustering in Economics: the
                  {Y}ule-{Z}ipf-{S}imon model},
  author =	 {D. Constantini and S. Donadio and U. Garibaldi and
                  P. Viarengo},
  year =	 2004,
  note =	 "Working Draft"
}

@Book{Cook98,
  author =	 "W.J. Cook and W.H. Cunningham and W.R. Pulleyblank
                  and A. Schrijver",
  title =	 "Combinatorial Optimization",
  publisher =	 Wiley,
  year =	 1998,
}

@InProceedings{Cooper02,
  author =	 {D. Cooper and A.. Willis and S. Andrews and J. Baker
                  and Y. Cao and D. Han and K. Kang and W. Kong and
                  F. Leymarie and X. Orriols and S. Velipasalar and
                  E. Vote and M. Joukowsky and B. Kimia and D. Laidlaw
                  and D. Mumford},
  title =	 {Bayesian Virtual Pot-Assembly from Fragments as
                  Problems in Perceptual-Grouping and
                  Geometric-Learning},
  booktitle =	 ICPR,
  pages =	 {11-15},
  year =	 2002,
  month =	 {August},
  publisher =	 {IEEE Computer Society Press},
}

@InProceedings{Cooper94,
  author =	 {S. Cooper and H. Durrant-Whyte},
  pages =	 {157--163},
  title =	 {A Kalman filter model for GPS navigation of land
                  vehicles},
  booktitle =	 IROS,
  year =	 1994,
}

@InCollection{Cooper96,
  author =	 "M.A.R. Cooper and S. Robson",
  title =	 "Theory of close range photogrammetry",
  booktitle =	 "Close range photogrammetry and machine vision",
  publisher =	 "Whittles Publishing",
  year =	 1996,
  editor =	 "K.B. Atkinson",
  chapter =	 1,
  pages =	 "9-51",
}

@inproceedings{Coorg99cvpr,
  author =	 "S. Coorg and S. Teller",
  title =	 "Extracting Textured Vertical Facades from Controlled
                  Close-Range Imagery",
  booktitle =	 CVPR,
  year =	 1999,
  pages =	 "625--632",
  url =		 "citeseer.nj.nec.com/coorg99extracting.html"
}

@InProceedings{Coors00,
  author =	 {V.Coors and T.Huch and U.Kretschmer},
  title =	 {Matching Buildings: Pose Estimation in an Urban
                  Environment},
  booktitle =	 {ISAR},
  year =	 2000,
}

@InProceedings{Cootes00,
  author =	 "T. Cootes and K. Walker and C. Taylor",
  title =	 "View-based active appearance models",
  booktitle =	 "4 th International Conference on Automatic Face and
                  Gesture Recognition",
  year =	 2000,
  pages =	 "227-232",
  address =	 "Grenoble,France",
  url =		 "citeseer.nj.nec.com/cootes00viewbased.html"
}

@Article{Cootes94ivc,
  author =	 {T.F. Cootes and A. Hill and C.J. Taylor and
                  J. Haslam},
  title =	 {The Use of Active Shape Models for Locating
                  Structures in Medical Images},
  journal =	 {Image and Vision Computing},
  year =	 1994,
  volume =	 12,
  number =	 6,
  pages =	 {355-366},
  month =	 {July},
}

@Article{Cootes95cviu,
  author =	 "T.F. Cootes and C.J. Taylor and D.H. Cooper and
                  J. Graham",
  title =	 "Active shape models - their training and
                  application",
  journal =	 CVIU,
  year =	 1995,
  month =	 "January",
  volume =	 61,
  number =	 1,
  pages =	 "38-59",
}

@InProceedings{Cootes98,
  author =	 "T.F. Cootes and G,J, Edwards and C.J. Taylor",
  title =	 "Active Appearance Models",
  booktitle =	 ECCV,
  year =	 1998,
}

@InProceedings{Cootes98b,
  author =	 "G.J. Edwards and T.F. Cootes and C.J. Taylor",
  title =	 "Face Recognition Using Active Appearance Models",
  booktitle =	 ECCV,
  year =	 1998,
}

@InProceedings{Coradeschi00aaai,
  author =	 {S. Coradeschi and A. Saffiotti},
  title =	 {Anchoring Symbols to Sensor Data: preliminary
                  report},
  crossref =	 {_AAAI00},
  pages =	 {129--135},
  url =		 {http://www.aass.oru.se/~asaffio/Papers/aaai00.html},
}

@Article{Coradeschi03ras,
  author =	 {S. Coradeschi and A. Saffiotti},
  title =	 {An Introduction to the Anchoring Problem},
  journal =	 {Robotics and Autonomous Systems},
  year =	 2003,
  volume =	 43,
  number =	 {2-3},
  pages =	 {85--96},
  url =		 {http://www.aass.oru.se/~asaffio/Papers/ras03.html},
}

@Article{Corbit93,
  author =	 {J.D. Corbit and D.J. Garbary},
  title =	 {Computer simulation of the morphology and
                  development of several species of seaweed using
                  Lindenmayer systems},
  journal =	 {Computers and Graphics},
  year =	 1993,
  volume =	 {17(1)},
  pages =	 {85-88 },
}

@inproceedings{Corke04iros,
  author =	 "P.I. Corke and D. Strelow and S. Singh",
  fullauthor =	 "Peter Ian Corke and Dennis Strelow and Sanjiv Singh",
  title =	 "Omnidirectional Visual Odometry for a Planetary
                  Rover",
  booktitle =	 IROS,
  year =	 2004
}

@InCollection{Corke93,
  author =	 "P. I Corke",
  title =	 "Visual Control of Robot Manipulators - A Review",
  booktitle =	 "Visual Servoing",
  publisher =	 "World Scientific",
  year =	 1993,
  editor =	 "Koichi Hashimoto",
}

@article{Costeira98ijcv,
  title =	 {{A Multibody Factorization Method for Independently
                  Moving Objects}},
  author =	 {Costeira, J.P. and Kanade, T.},
  journal =	 IJCV,
  volume =	 29,
  number =	 3,
  pages =	 {159--179},
  year =	 1998,
  publisher =	 {Springer}
}

@Article{Coughlan03,
  author =	 "J.M. Coughlan and A.L. Yuille",
  title =	 "Manhattan World",
  journal =	 "Neural Computatio",
  year =	 2003
}

@inproceedings{Coughlan99iccv,
  author =	 "J. Coughlan and A. Yuille",
  title =	 "Manhattan {W}orld: {C}ompass {D}irection from a
                  {S}ingle {I}mage by {B}ayesian {I}nference",
  booktitle =	 ICCV,
  pages =	 "941--947",
  year =	 1999,
  url =		 "http://citeseer.nj.nec.com/coughlan99manhattan.html",
  pdf =		 "pdf/coughlan99manhattan.pdf"
}

@Article{Courtney97pr,
  author =	 {J.D. Courtney},
  title =	 {Automatic video indexing via object motion analysis},
  journal =	 PR,
  year =	 1997,
  volume =	 30,
  number =	 4,
  pages =	 {607--625},
  month =	 {April},
}

@Book{Cover91book,
  author =	 {T.M. Cover and J.A. Thomas},
  title =	 {Elements of Information Theory},
  publisher =	 Wiley,
  year =	 1991,
}

@Book{Cowell99book,
  author =	 {R. G. Cowell and A. P. Dawid and S. L. Lauritzen and
                  D. J. Spiegelhalter},
  title =	 {Probabilistic Networks and Expert Systems},
  publisher =	 {Springer-Verlag},
  year =	 1999,
  fulladdress =	 {Berlin-Heidelberg-New York},
  series =	 {Statistics for Engineering and Information Science},
}

@ARTICLE{Cox91,
  AUTHOR =	 {Cox, I.J.},
  TITLE =	 {Blanche---An Experiment in Guidance and Navigation
                  of an Autonomous Robot Vehicle},
  JOURNAL =	 TRA,
  YEAR =	 1991,
  VOLUME =	 7,
  NUMBER =	 2,
  PAGES =	 {193--204}
}

@article{Cox93,
  AUTHOR =	 "Cox, I.J.",
  TITLE =	 "A Review of Statistical Data Association Techniques
                  for Motion Correspondence",
  JOURNAL =	 IJCV,
  VOLUME =	 10,
  YEAR =	 1993,
  NUMBER =	 1,
  MONTH =	 "February",
  PAGES =	 "53-66"
}

@Article{Cox94,
  author =	 {I.J. Cox and J.J. Leonard},
  title =	 {Modeling a dynamic environment using a {B}ayesian
                  multiple hypothesis approach},
  journal =	 AI,
  year =	 1994,
  volume =	 66,
  number =	 2,
  pages =	 {311-344},
  month =	 {April},
}

@InProceedings{Cox94b,
  author =	 "I.J. Cox and S.L. Hingorani",
  title =	 "An efficient implementation and evaluation of
                  {R}eid's multiple hypothesis tracking algorithm for
                  visual tracking",
  volume =	 1,
  pages =	 "437-442",
  booktitle =	 ICPR,
  year =	 1994,
  address =	 "Jerusalem, Israel",
  month =	 "October",
}

@Article{Cox95,
  author =	 {I.J. Cox and M.L. Miller},
  title =	 {On finding ranked assignments with application to
                  multi-target tracking and motion correspondence},
  journal =	 AES,
  year =	 1995,
  volume =	 31,
  number =	 1,
  pages =	 486,
  month =	 {January},
}

@Article{Cox96,
  author =	 "I.J. Cox and S.L. Hingorani",
  title =	 "An Efficient Implementation of {R}eid's Multiple
                  Hypothesis Tracking Algorithm and its Evaluation for
                  the Purpose of Visual Tracking",
  journal =	 PAMI,
  year =	 1996,
  volume =	 18,
  number =	 2,
  pages =	 "138--150",
  month =	 "February",
}

@Article{Cox96b,
  author =	 {I.J. Cox and S.L. Hingorani and S.B. Rao and
                  B. Maggs},
  title =	 {A maximum Likelihood Stereo Algorithm},
  journal =	 CVIU,
  year =	 1996,
  volume =	 63,
  number =	 3,
  pages =	 {542-567},
  month =	 {May},
}

@Book {Coxeter80book,
  Author =	 {Coxeter, H.S.M. and Moser, W.O.J.},
  Title =	 {Generators and Relations for Discrete Groups},
  Publisher =	 {Springer-Verlag},
  Address =	 {New York},
  Edition =	 {fourth},
  Year =	 1980
}

@InProceedings{Crick03uai,
  author =	 {C. Crick and A. Pfeffer},
  full.author =	 {Cristopher Crick and Avi Pfeffer},
  title =	 {Loopy Belief Propagation as a Basis for
                  Communication in Sensor Networks},
  booktitle =	 UAI,
  year =	 2003,
  address =	 {Acapulco, Mexico},
  month =	 {August},
  c-Paskin05ipsn ={Recently, there have been some proposals to use
                  existing centralized inference algorithms in sensor
                  networks, e.g., belief propagation. However, these
                  inference approaches are not as general as ours, and
                  more importantly, they do not fully address the
                  practical issues that arise in real deployments:...},
  c-dellaert =	 {DDF is required to be tree-connected, which rules
                  out many useful applications, hence loopy BP}
}

@article{Criminisi00ijcv,
  author =	 "A. Criminisi and I.D. Reid and A.Zisserman",
  fullauthor =	 "Antonio Criminisi and Ian D. Reid and Andrew
                  Zisserman",
  title =	 "Single View Metrology",
  journal =	 IJCV,
  volume =	 40,
  number =	 2,
  pages =	 "123--148",
  year =	 2000,
  url =		 "citeseer.nj.nec.com/article/criminisi99single.html"
}

@Article{Crisan02tsp,
  author =	 {D. Crisan and A. Doucet},
  title =	 {A Survey of Convergence Results on Particle
                  Filtering for Practitioners},
  journal =	 SP,
  year =	 2002,
}

@InCollection{Crisman92,
  author =	 {J.D. Crisman},
  title =	 {Color Region Tracking for Vehicle Guidance},
  crossref =	 {Blake92},
  chapter =	 7,
}

@Article{Cross98,
  author =	 "A.D.J. Cross and E.R. Hancock",
  title =	 "Graph Matching with a Dual-Step {EM} Algorithm",
  journal =	 PAMI,
  year =	 1998,
  volume =	 20,
  number =	 11,
  pages =	 "1236--1253",
  month =	 "November",
}

@InProceedings{Crowley85,
  author =	 {J.L. Crowley},
  title =	 {Dynamic world modeling for an intelligent mobile
                  robot using a rotating ultra-sonic ranging sensor},
  booktitle =	 ICRA,
  pages =	 {128-135},
  year =	 1985,
}

@inproceedings{Crowley88,
  AUTHOR =	 "Crowley, J.L. and Stelmaszyk, P. and Skordas, T. and
                  Puget, P. and Discours, C.",
  TITLE =	 "Measuring Image Flow by Tracking Edge-Lines",
  BOOKTITLE =	 ICCV,
  YEAR =	 1988,
  PAGES =	 "658-664"
}

@InProceedings{Crowley89,
  author =	 {J.L. Crowley},
  title =	 {World modeling and position estimation for a mobile
                  robot using ultra-sonic ranging},
  booktitle =	 ICRA,
  pages =	 {674-680},
  year =	 1989,
}

@InProceedings{Cucchiara01icits,
  author =	 {R. Cucchiara and C. Grana and M. Piccardi and
                  A. Prati and S. Sirotti},
  title =	 {Improving Shadow Suppression in Moving Object
                  Detection with HSV Color Information},
  booktitle =	 {International Conference on Intelligent
                  Transportation Systems},
  pages =	 {334-339},
  year =	 2001,
  month =	 {August},
  abstract =	 {Video-surveillance and traffic analysis systems can
                  be heavily improved using vision-based techniques
                  able to extract, manage and track objects in the
                  scene. However, problems arise due to shadows. In
                  particular, moving shadows can affect the correct
                  localization, measurements and detection of moving
                  objects. This work aims to present a technique for
                  shadow detection and suppression used in a system
                  for moving visual object detection and tracking. The
                  major novelty of the shadow detection technique is
                  the analysis carried out in the HSV color space to
                  improve the accuracy in detecting shadows. Signal
                  processing and optic motivations of the approach
                  proposed are described. The integration and
                  exploitation of the shadow detection mod- ule into
                  the system are outlined and experimental results are
                  shown and evaluated.},
  c-houdan =	 {Using HSV is more accurate to seperate chromaticity
                  and luminosity than using RGB. But Prati03pami
                  reports that it is poor in penumbra detection},
}

	

@Article{Cucchiara03pami,
  author =	 {R. Cucchiara and C. Grana and M. Piccardi and
                  A. Prati},
  title =	 {Detecting Moving Objects, Ghosts, and Shadows in
                  Video Streams},
  journal =	 PAMI,
  year =	 2003,
  volume =	 25,
  number =	 10,
  pages =	 {1337-1342},
  month =	 {October},
  abstract =	 {Background subtraction methods are widely exploited
                  for moving object detection in videos in many
                  applications, such as traffic monitoring, human
                  motion capture, and video surveillance. How to
                  correctly and efficiently model and update the
                  background model and how to deal with shadows are
                  two of the most distinguishing and challenging
                  aspects of such approaches. This work proposes a
                  general-purpose method that combines statistical
                  assumptions with the object- level knowledge of
                  moving objects, apparent objects (ghosts), and
                  shadows acquired in the processing of the previous
                  frames. Pixels belonging to moving objects, ghosts,
                  and shadows are processed differently in order to
                  supply an object-based selective update. The
                  proposed approach exploits color information for
                  both background subtraction and shadow detection to
                  improve object segmentation and background
                  update. The approach proves fast, flexible, and
                  precise in terms of both pixel accuracy and
                  reactivity to background changes.},
  c-houdan =	 {the similar method as Cucchiara01icits to detect
                  shadow, using HSV color space which explicitly
                  separates chromaticity and luminosity},
}

@article{Cummins08ijrr,
  author =	 {M. Cummins and P. Newman},
  title =	 {{FAB-MAP: Probabilistic Localization and Mapping in
                  the Space of Appearance}},
  journal =	 IJRR,
  volume =	 {27},
  number =	 {6},
  pages =	 {647-665},
  year =	 {2008},
  c-annath =	 {Cummins and Newman [Cummins08ijrr] also provide an
                  appearance-based technique for loop closing based on
                  generative-modeling of bag-of-words models of
                  location images. However, the decision of whether to
                  close a loop is based on a maximum-likelihood
                  computation.},
  abstract =	 {This paper describes a probabilistic approach to the
                  problem of recognizing places based on their
                  appearance. The system we present is not limited to
                  localization, but can determine that a new
                  observation comes from a previously unseen place,
                  and so augment its map. Effectively this is a SLAM
                  system in the space of appearance. Our probabilistic
                  approach allows us to explicitly account for
                  perceptual aliasing in the environment--identical
                  but indistinctive observations receive a low
                  probability of having come from the same place. We
                  achieve this by learning a generative model of place
                  appearance. By partitioning the learning problem
                  into two parts, new place models can be learned
                  online from only a single observation of a
                  place. The algorithm complexity is linear in the
                  number of places in the map, and is particularly
                  suitable for online loop closure detection in mobile
                  robotics. 10.1177/0278364908090961},
  fullauthor =	 {Cummins, Mark and Newman, Paul},
  month =	 {June},
}

@InCollection{Curwen92,
  author =	 "Rupert Curwen and A. Blake",
  crossref =	 "Blake92",
  title =	 "Dynamic Contours: Real-time Active Splines",
}

@PhdThesis{Curwen93,
  author =	 "Rupert Curwen",
  title =	 "Dynamic and Adaptive Contours",
  school =	 "Department of Engineering Science, University of
                  Oxford",
  year =	 1993
}

@inproceedings{Cuthill69acmnc,
  author =	 {E. Cuthill and J. McKee},
  title =	 {Reducing the bandwidth of sparse symmetric matrices},
  booktitle =	 {Proc. of the 1969 24th ACM national conference},
  year =	 1969,
  pages =	 {157--172},
  doi =		 {http://doi.acm.org/10.1145/800195.805928},
  publisher =	 {ACM Press},
  address =	 {New York, NY, USA},
  abstract =	 {The finite element displacement method of analyzing
                  structures involves the solution of large systems of
                  linear algebraic equations with sparse, structured,
                  symmetric coefficient matrices. There is a direct
                  correspondence between the structure of the
                  coefficient matrix, called the stiffness matrix in
                  this case, and the structure of the spatial network
                  delineating the element layout. For the efficient
                  solution of these systems of equations, it is
                  desirable to have an automatic nodal numbering (or
                  renumbering) scheme to ensure that the corresponding
                  coefficient matrix will have a narrow
                  bandwidth. This is the problem considered by
                  R. Rosen I. A direct method of obtaining such a
                  numbering scheme is presented. In addition several
                  methods are reviewed and compared.},
  c-dellaert =	 {A greedy numbering algorithm for finite element
                  bandwidth reduction},
}

@InProceedings{Cutler02multimedia,
  author =	 {R. Cutler and Y. Rui and A. Gupta and J.J. Cadiz and
                  I. Tashev and L. He and A. Colburn and Z. Zhang and
                  Z. Liu and S. Silverberg},
  title =	 {Distributed Meetings: A Meeting Capture and
                  Broadcasting System},
  booktitle =	 {ACM Multimedia},
  year =	 2002,
}

@INPROCEEDINGS{DAmbrosio94uai,
  AUTHOR =	 {B. {D'Ambrosio}},
  FULLAUTHOR =	 {Bruce {D'Ambrosio}},
  TITLE =	 {Symbolic Probabilistic Inference in Large {BN2O}
                  Networks},
  crossref =	 {_UAI94},
  PAGES =	 {128-135},
  r-Dechter03jacm ={Ref for variable elimination}
}

@Unpublished{DSouza,
  author =	 {Aaron A. D'Souza},
  title =	 {Using EM to Estimate a Probablity Density with a
                  Mixture of Gaussians},
  institution =	 {USC},
  note =	 {technical notes}
}

@techreport{Dahl03tr,
  author =	 {D. B. Dahl},
  year =	 2003,
  title =	 "Modal clustering in a univariate class of product
                  partition models",
  number =	 1085,
  institution =	 "Department of Statistics, University of Wisconsin",
}

@InProceedings{Dahlkamp06rss,
  author =	 {H. Dahlkamp and A. Kaehler and D. Stavens and
                  S. Thrun and G. R. Bradski},
  fullauthor =	 {Hendrik Dahlkamp and Adrian Kaehler and David
                  Stavens and Sebastian Thrun and Gary R. Bradski},
  title =	 {{Self-supervised Monocular Road Detection in Desert
                  Terrain}},
  booktitle =	 RSS,
  year =	 2006,
}

@InProceedings{Dailey05aciar,
  author =	 {M.N. Dailey and M. Parnichkun},
  fullauthor =	 {Matthew N. Dailey and Manukid Parnichkun},
  title =	 {Landmark-based Simultaneous Localization and Mapping
                  with Stereo Vision},
  booktitle =	 {Proc. Asian Conference on Industrial Automation and
                  Robotics},
  location =	 {Bangkok, Thailand},
  month =	 {May},
  year =	 2005,
  abstract =	 {SLAM, the problem of a mobile robot building a map
                  of its environment while simultaneously having to
                  determine its location within that map, is one of
                  the current fundamental challenges of
                  robotics. Although a great deal of success has been
                  achieved with laser range finders as sensors and a
                  planar world assumption, low-cost commercial robots
                  will benefit from robust SLAM using cameras
                  only. Towards the goal of a robust, six
                  degree-of-freedom, vision-based SLAM algorithm, we
                  describe the application of "FastSLAM" [1] to the
                  problem of estimating a map from observations of 3D
                  line segments using a trinocular stereo camera
                  rig. By maintaining not only multiple hypotheses
                  about the robot's position in space, but also
                  maintaining multiple maps corresponding to those
                  possible position hypothesis, the algorithm has the
                  potential to overcome the systematic map errors
                  induced by incorrect correspondence estimation.},
  c-kaess =	 {see Dailey06icarcv},
}

@InProceedings{Dailey06icarcv,
  author =	 {M.N. Dailey and M. Parnichkun},
  fullauthor =	 {Matthew N. Dailey and Manukid Parnichkun},
  title =	 {Simultaneous Localization and Mapping with Stereo
                  Vision},
  booktitle =	 {Proc. of the 9th Intl. Conf. on Control, Automation,
                  Robotics and Vision},
  location =	 {Singapore},
  month =	 {Dec},
  year =	 2006,
  abstract =	 {In the simultaneous localization and mapping (SLAM)
                  problem, a mobile robot must build a map of its
                  environment while simultaneously determining its
                  location within that map. We propose a new
                  algorithm, for visual SLAM (VSLAM), in which the
                  robot? only sensory information is video
                  imagery. Our approach combines stereo vision with a
                  popular sequential Monte Carlo (SMC) algorithm, the
                  Rao-Blackwellised particle filter, to simultaneously
                  explore multiple hypotheses about the robot? six
                  degree-of-freedom trajectory through space and
                  maintain a distinct stochastic map for each of those
                  candidate trajectories. We demonstrate the
                  algorithm's effectiveness in mapping a large outdoor
                  virtual reality environment in the presence of
                  odometry error.},
  c-kaess =	 {Visual line-based SLAM (VS-SLAM): FastSLAM based,
                  results only for synthetic data. Does not close a
                  loop, not very convincing.},
}

@InProceedings{Dalal05cvpr,
  author =	 {N. Dalal and B. Triggs},
  fullauthor =	 {Navneet Dalal and Bill Triggs},
  title =	 {Histograms of oriented gradients for human
                  detection},
  booktitle =	 CVPR,
  pages =	 {886--893},
  year =	 2005,
}

@article{Damien99,
  author =	 {P. Damien and J. C. Wakefield and S. G. Walker},
  year =	 1999,
  title =	 {Gibbs sampling for {Bayesian} nonconjugate and
                  hierarchical models using auxiliary variables},
  journal =	 {Journal of the Royal Statistical Society Series B},
  volume =	 61,
  pages =	 "331-344",
}

@misc{Dana94,
  author =	 {Peter H. Dana},
  title =	 {{G}lobal {P}ositioning {S}ystem {O}verview},
  year =	 1994,
  url =
                  {http://www.colorado.edu/geography/gcraft/notes/gps/gps_f.html}
}

@article{Danchick93,
  author =	 "R. Danchick and G. Newnam",
  title =	 "A fast method for finding the exact N-best
                  hypotheses for multitarget tracking",
  journal =	 AES,
  volume =	 29,
  pages =	 "555--560",
  year =	 1993
}

@Book{Daniilidis00omnivis,
  editor =	 {Daniilidis, K.},
  title =	 {IEEE Workshop on Omnidirectional Vision, Hilton Head
                  Island, SC, June 12},
  publisher =	 {IEEE},
  year =	 2000,
}

@InProceedings{Daniilidis00realtime,
  author =	 "K. Daniilidis and J. Mulligan and R. McKendall and
                  G. Kamberova and D. Schmid and R. Bajcsy",
  title =	 "Real-time {3D} tele-immersion",
  booktitle =	 "A. Leonardis et al., editor, The Confluence of
                  Vision and Graphics. Kluwer Academic Publishers",
  year =	 2000,
}

@Book{Daniilidis04ram,
  editor =	 {K. Daniilidis and N. Papanikolopoulos},
  title =	 {IEEE Robotics \& Automation Magazine},
  publisher =	 {IEEE},
  year =	 2004,
  month =	 {December},
  note =	 {Special Issue on Panoramic Robotics},
}

@InProceedings{Darabiha03,
  author =	 "A.Darabiha and J.R.Rose and W.J.MacLean",
  title =	 "Video Rate Stereo Depth Measurement on Programmable
                  Hardware",
  pages =	 "18--20",
  booktitle =	 CVPR,
  year =	 2003,
}

@Article{Darwiche01ai,
  author =	 {A. Darwiche},
  fullauthor =	 {Adnan Darwiche},
  title =	 {Recursive Conditioning},
  journal =	 AI,
  year =	 2001,
  volume =	 126,
  number =	 {1-2},
  pages =	 {5--41},
  month =	 {February},
  abstract =	 {We introduce an any-space algorithm for exact
                  inference in Bayesian networks, called recursive
                  conditioning. On one extreme, recursive conditioning
                  takes O(n) space and O(nexp(wlogn)) time - where n
                  is the size of a Bayesian network and w is the width
                  of a given elimination order - therefore,
                  establishing a new complexity result for
                  linear-space inference in Bayesian networks. On the
                  other extreme, recursive conditioning takes
                  O(nexp(w)) space and O(nexp(w)) time, therefore,
                  matching the complexity of state-of-the-art
                  algorithms based on clustering and elimination. In
                  between linear and exponential space, recursive
                  conditioning can utilize memory at increments of
                  X-bytes, where X is the number of bytes needed to
                  store a floating point number in a cache. Moreover,
                  the algorithm is equipped with a formula for
                  computing its average running time under any amount
                  of space, hence, providing a valuable tool for
                  time-space tradeoffs in demanding
                  applications. Recursive conditioning is therefore
                  the first algorithm for exact inference in Bayesian
                  networks to offer a smooth tradeoff between time and
                  space, and to explicate a smooth, quantitative
                  relationship between these two important resources.},
  r-Mateescu07ijcai ={was recently recast as context-based AND/OR
                  search \cite{Dechter04uai}},
  c-dellaert =	 {Similar to Dechter01ai},
}

@InProceedings{Davies02uia,
  author =	 {Scott Davies and A.W. Moore},
  title =	 {Interpolating Conditional Density Trees},
  crossref =	 {_UAI02},
}

@InProceedings{Davis03iccv,
  author =	 {J. Davis and X. Chen},
  title =	 {Calibrating pan-tilt cameras in wide-area
                  surveillance networks},
  booktitle =	 ICCV,
  year =	 2003,
}

@InProceedings{Davis04pp,
  author =	 {T.A. Davis and K. Stanley},
  fullauthor =	 {Tim Davis and Ken Stanley},
  title =	 {{KLU}: a "{Clark Kent}" sparse {LU} factorization
                  algorithm for circuit matrices},
  booktitle =	 {2004 SIAM Conference on Parallel Processing for
                  Scientific Computing (PP04)},
  year =	 2004
}

@article{Davis04toms,
  author =	 {T.A. Davis and J.R. Gilbert and S.I. Larimore and
                  E.G. Ng},
  fullauthor =	 {Timothy A. Davis and John R. Gilbert and Stefan
                  I. Larimore and Esmond G. Ng},
  title =	 {A column approximate minimum degree ordering
                  algorithm},
  journal =	 {ACM Trans. Math. Softw.},
  volume =	 30,
  number =	 3,
  year =	 2004,
  issn =	 {0098-3500},
  pages =	 {353--376},
  publisher =	 {ACM Press},
  address =	 {New York, NY, USA},
}

@TechReport{Davis04tr,
  author =	 {T. A. Davis},
  title =	 {Algorithm 8xx: a concise sparse {Cholesky}
                  factorization package},
  institution =	 {Univ. of Florida},
  year =	 2004,
  number =	 {TR-04-001},
  month =	 {January},
  note =	 {Submitted to ACM Trans. Math. Software.},
}

@InProceedings{Davis05cvpr,
  author =	 {J.W. Davis and V. Sharma},
  title =	 {Fusion-Based Background-Subtraction using Contour
                  Saliency},
  booktitle =	 CVPR,
  year =	 2005,
  abstract =	 {We present a contour-based background-subtraction
                  technique using thermal and visible imagery for
                  persistent object detection in urban
                  settings. Statistical background- subtraction in the
                  thermal domain is used to identify the ini- tial
                  regions-of-interest. Color and intensity information
                  are used within these areas to obtain the
                  corresponding regions-of-interest in the visible
                  domain. Within each region, input and background
                  gradient information are combined to form a Contour
                  Saliency Map. The binary contour fragments, obtained
                  from corresponding Contour Saliency Maps, are then
                  combined. An A* path-constrained search along wa-
                  tershed boundaries is used to complete and close any
                  bro- ken contour segments. Lastly, the contour image
                  is flood-filled to produce silhouettes. Results of
                  our approach are presented and compared against
                  manually segmented data.},
  c-houdan =	 {Thermal imagery is a new way to improve video
                  tracking. This paper uses thermal imagery to get
                  foreground region candidates, and visible imagery to
                  apply standard background subtraction in these
                  regions.},
}

@article{Davis05pami,
  title =	 {{Spacetime stereo: a unifying framework for depth
                  from triangulation}},
  author =	 {Davis, J. and Nehab, D. and Ramamoorthi, R. and
                  Rusinkiewicz, S.},
  journal =	 PAMI,
  volume =	 {27},
  number =	 {2},
  pages =	 {296--302},
  year =	 {2005}
}

@article{Davis05toms,
  author =       {T.A. Davis},
  fullauthor =   {Timothy A. Davis},
  title =        {Algorithm 849: A concise sparse Cholesky factorization package},
  journal =      {ACM Trans. Math. Softw.},
  volume =       31,
  number =       4,
  year =         2005,
  issn =         {0098-3500},
  pages =        {587--591},
  publisher =    {ACM Press},
  address =      {New York, NY, USA},
}

@Book{Davis06,
  author =	 {T.A. Davis},
  fullauthor =	 {Timothy A. Davis},
  title =	 {Direct Methods for Sparse Linear Systems},
  publisher =	 {Society for Industrial and Applied Mathematics},
  year =	 2006,
  series =	 {Fundamentals of Algorithms},
}

@Article{Davis60jacm,
  author =	 {M. Davis and H. Putnam},
  title =	 {A computing procedure for quantification theory},
  journal =	 {J. ACM},
  year =	 1960,
  volume =	 7,
  number =	 3,
  pages =	 {201--215},
  r-MathSciNet = {Efficient rules for simplifying propositional
                  formulae are applied to testing the consistency of
                  the Herbrand conjunction of any quantificational
                  formula in the prenex form and with a matrix in the
                  conjunctive normal form. The superiority of this
                  method over the brute force approach is illustrated
                  by an example on which an ordinary "routine for the
                  IBM 704 causes the machine to compute for 21 minutes
                  without obtaining a result" but which "was worked
                  successfully by hand computation using the present
                  method in 30 minutes". It is pointed out in a note
                  added in proof that the propositional rules have
                  been anticipated to a considerable extent by the
                  slightly earlier work of B. Dunham, R. Fridshal, and
                  G. L. Sward. In fact, this work contains a more
                  general method from which the rules formulated
                  explicitly by the authors of the paper under review
                  can all be derived rather directly.},
  r-Bartels06uai ={Vertex elimination is an algorithm that can be used
                  to triangulate graphs.},
  c-dellaert =	 {Elimination procedure for proving/formal logic.},
}

@InProceedings{Davis98,
  author =	 {Davis, J.},
  title =	 {Mosaics of Scenes with Moving Objects},
  booktitle =	 CVPR,
  year =	 1998,
}

@Article{Davis99siam,
  author =	 {T. Davis and W. Hager},
  title =	 {Modifying a Sparse {Cholesky} Factorization},
  journal =	 {SIAM Journal on Matrix Analysis and Applications},
  year =	 1996,
  volume =	 20,
  number =	 3,
  pages =	 {606-627},
}

@inproceedings{Davision95bmvc,
  title =	 {The active camera as a projective pointing device},
  booktitle =	 BMVC,
  volume =	 2,
  address =	 {Birmingham, UK},
  Pages =	 {453--462},
  Year =	 1995,
  Author =	 {A.J. Davison and I.D. Reid and D.W. Murray },
  fullAuthor =	 {Andrew J. Davison and Ian D. Reid and David
                  W. Murray },
  abstract =	 {This paper demonstrates an approach which exploits
                  an active camera as a projective pointing
                  mechanism. The optical centre of a static camera is
                  notionally substituted by the centre of rotation of
                  the active camera, as is the image plane by a
                  frontal plane, a plane perpendicular to the optical
                  axis of the active camera in its resting
                  direction. Algorithms devised for 3D motion and 3D
                  structure recovery using a single passive camera
                  become immediately applicable to the active camera
                  without need for reformulation. Furthermore, because
                  the active camera can access a panoramic field of
                  view, instabilities which may arise when the field
                  of view is small, or because the shared field of
                  view between successive views after movement is
                  small, are lessened. Two quite different
                  applications of the idea are presented. In the
                  first, the homography between a planar surface in
                  the scene and the frontal plane is recovered and
                  used to recover scene trajectories. In the second,
                  the essential matrix between points in two
                  frontal-plane "views" is recovered and used to
                  determine the motion of a mobile vehicle.},
  quotes =	 {We do not suggest that the [our motion recovery
                  method] is a satisfactory method of frame by frame
                  visually guided navigation. Clearly the serial
                  search for points would be too time consuming. The
                  method has more immediate promise as a method of
                  re-orientation, perhaps after the vehicle becomes
                  interrupted during some purposive navigation task by
                  a more urgent reactive task.},
  c-dellaert =	 {Davison has been working on this for a long time,
                  obviously. The paper discusses using an active
                  stereo head to fixate seraily on features, then
                  move, then re-fixate and compute the motion of the
                  platform. As they admit, this is not advocated as a
                  practical navigation method.},
}

@inproceedings{Davison00iros,
  title =	 {Active Visual Localisation for Cooperating
                  Inspection Robots},
  author =	 {A.J. Davison and N. Kita},
  fullauthor =	 {Andrew J. Davison and Nobuyuki Kita},
  booktitle =	 IROS,
  year =	 2000,
  c-dellaert =	 {Just adds relative pose measurements between two
                  robots},
}

@InProceedings{Davison01cvpr,
  author =	 {A.J. Davison and N. Kita},
  title =	 {3{D} Simulataneous Localisation and Map-Building
                  Using Active Vision for a Robot Moving on Undulating
                  Terrain},
  booktitle =	 CVPR,
  location =	 {Hawaii, USA},
  month =	 {Dec},
  year =	 2001,
  abstract =	 {Work in simultaneous localisation and map-building
                  (SLAM) for mobile robots has focused on the
                  simplified case in which a robot is considered to
                  move in two dimensions on a ground plane. While this
                  is often a good approximation, a large number of
                  real-world applications require robots to move
                  around terrain which has significant slopes and
                  undulations, and it is desirable that these robots
                  too should be able to estimate their locations by
                  building maps of natural features. In this paper we
                  describe a real-time EKF-based SLAM system
                  permitting unconstrained 3D localisation, and in
                  particular develop models for the motion of a
                  wheeled robot in the presence of unknown slope
                  variations. In a fully automatic implementation, our
                  robot observes visual point features using fixating
                  stereo vision and builds a sparse map
                  on-the-fly. Combining this visual measurement with
                  information from odometry and a roll/pitch
                  accelerometer sensor, the robot performs accurate,
                  repeatable localisation while traversing an
                  undulating course.},
}

@InProceedings{Davison02cml,
  author =	 {A.J. Davison},
  fullauthor =	 {Andrew J. Davison},
  title =	 {{SLAM} with a Single Camera},
  booktitle =	 {{SLAM/CML} Workshop at {ICRA} 2002},
  location =	 {Washington, DC},
  month =	 {May},
  year =	 2002,
  abstract =	 {Real-time motion estimation for a generally moving,
                  agile single camera is a particularly challenging
                  SLAM problem, but one whose solution will lead to a
                  host of lucrative and interesting applications in
                  robotics, multimedia and television. We argue that
                  mapping research in mobile robotics, despite rarely
                  being camera-based, is more relevant when tackling
                  this problem than recent structure from motion work
                  in computer vision which has focused on off-line
                  reconstruction of camera trajectories. We present a
                  framework for EKF-based single-camera localisation
                  and initial experimental results, and discuss
                  current and future research issues.},
  c-kaess =	 {Presents real-time 3D SLAM with one feature
                  measurement per frame, selecting the least
                  predictable measurement to reduce the biggest
                  uncertainty available. This leads to very rapid
                  switching between different features. The system
                  starts from a known state, tracking known features
                  to avoid the initialization problem.},
}

@Article{Davison02pami,
  author =	 {A.J. Davison and D.W. Murray},
  fullauthor =	 {Andrew J. Davison and David W. Murray},
  title =	 {Simulataneous Localization and Map-Building using
                  Active Vision},
  journal =	 PAMI,
  volume =	 24,
  number =	 7,
  pages =	 {865-880},
  month =	 {Jul},
  year =	 2002,
  abstract =	 {An active approach to sensing can provide the
                  focused measurement capability over a wide field of
                  view which allows correctly formulated Simltaneous
                  Localisation and Map-Building (SLAM) to be
                  implemented with vision, permitting repeatable
                  long-term localisation using only naturally
                  occurring, automatically-detected features. In this
                  paper we present the first example of a general
                  system for autonomous localisation using active
                  vision, enabled here by a high-performance stereo
                  head, addressing such issues as uncertainty-based
                  measurement selection, automatic map-maintenance and
                  goal-directed steering. We present varied real-time
                  experiments in a complex environment.},
  r-Meltzer04iros ={Davidson and Murray [this] used active vision for
                  realtime, sequential map-building within a SLAM
                  framework. Assuming that the robot trajectory was
                  given, they controlled the active head? movement and
                  sensing on a shortterm tactical basis, making a
                  choice between a selection of currently visible
                  features. Persistent features re-detected after
                  lengthy neglect could be re-matched, even if the
                  area was passed through along a different trajectory
                  or in a different direction. --- Davidson et. al
                  [this] expect the feature to be visible only if the
                  angular difference is less than 45 degrees in
                  magnitude.},
}

@InProceedings{Davison03iccv,
  author =	 {A.J. Davison},
  fullauthor =	 {Andrew J. Davison},
  title =	 {Real-Time Simultaneous Localisation and Mapping with
                  a Single Camera},
  booktitle =	 ICCV,
  pages =	 {1403-1410},
  location =	 {Nice, France},
  month =	 {Oct},
  year =	 2003,
  abstract =	 {Ego-motion estimation for an agile single camera
                  moving through general, unknown scenes becomes a
                  much more challenging problem when real-time
                  performance is required rather than under the
                  off-line processing conditions under which most
                  successful structure from motion work has been
                  achieved. This task of estimating camera motion from
                  measurements of a continuously expanding set of
                  selfmapped visual features is one of a class of
                  problems known as Simultaneous Localisation and
                  Mapping (SLAM) in the robotics community, and we
                  argue that such real-time mapping research, despite
                  rarely being camera-based, is more relevant here
                  than off-line structure from motion methods due to
                  the more fundamental emphasis placed on propagation
                  of uncertainty. We present a top-down Bayesian
                  framework for singlecamera localisation via mapping
                  of a sparse set of natural features using motion
                  modelling and an informationguided active
                  measurement strategy, in particular addressing the
                  difficult issue of real-time feature initialisation
                  via a factored sampling approach. Real-time handling
                  of uncertainty permits robust localisation via the
                  creating and active measurement of a sparse map of
                  landmarks such that regions can be re-visited after
                  periods of neglect and localisation can continue
                  through periods when few features are
                  visible. Results are presented of real-time
                  localisation for a hand-waved camera with very
                  sparse prior scene knowledge and all processing
                  carried out on a desktop PC.},
  r-Elinas06icra ={Work on monocular SLAM that does not depend on
                  robot odometry has been presented in [this]. Their
                  approach is mostly tailored to real-time
                  performance. In consequence, they identify visual
                  landmarks using salient visual features that are not
                  necessarily distinctive enough for operation in
                  large environments. This approach is also based on
                  the Extended Kalman Filter that is inefficient
                  because the filter scales quadratically in the
                  number of landmarks.},
  r-Smith06bmvc ={Practical real-time monocular SLAM was first
                  demonstrated by Davison [this], who uses the
                  Extended Kalman Filter, a mainstay of SLAM
                  literature. He resolves the problem of real-time
                  operation by careful maintenance of the map to
                  ensure that it is sparse but sufficient, and by
                  using the map uncertainty to guide feature
                  matching.},
  c-kaess =	 {Presents real-time 3D SLAM with a single camera,
                  restricted to a desk-like environment. A motion
                  model is defined that locally assumes constant
                  velocity with Gaussian noise, ie. undetermined
                  accelaration. The best Shi/Tomasi feature is
                  detected in a small search region whenever a new
                  feature needs to be added to the database. Detection
                  is performed only once, while matching in subsequent
                  frames is based on SSD. Since matching is performed
                  against structure, the uncertainty of a 3D point is
                  used to restrict the search window to an elliptical
                  region. After seeing a feature once, a line is
                  instantiated consisting of 100 samples distributed
                  over some range, that are all reprojected for the
                  matching process. Results from a 20 second real-time
                  tracking experiment at 30 Hz are shown.},
  c-dellaert =	 {Is a conventional EKF based approach but focuses on
                  real-time feature initialization using factored
                  sampling.},
}

@InProceedings{Davison03ismar,
  author =	 {A.J. Davison and W.W. Mayol and D.W. Murray},
  fullauthor =	 {Andrew J. Davison and Walterio W. Mayol and David
                  W. Murray},
  title =	 {Real-Time Localisation and Mapping with Wearable
                  Active Vision},
  booktitle =	 ISMAR,
  location =	 {Tokyo, Japan},
  month =	 {Oct},
  year =	 2003,
  abstract =	 {We present a general method for real-time,
                  visiononly single-camera simultaneous localisation
                  and mapping (SLAM) - an algorithm which is
                  applicable to the localisation of any camera moving
                  through a scene - and study its application to the
                  localisation of a wearable robot with active
                  vision. Starting from very sparse initial scene
                  knowledge, a map of natural point features spanning
                  a section of a room is generated on-the-fly as the
                  motion of the camera is simultaneously estimated in
                  full 3D. Naturally this permits the annotation of
                  the scene with rigidly-registered graphics, but
                  further it permits automatic control of the robot?
                  active camera: for instance, fixation on a
                  particular object can be maintained during extended
                  periods of arbitrary user motion, then shifted at
                  will to another object which has potentially been
                  out of the field of view. This kind of functionality
                  is the key to the understanding or "management" of a
                  workspace which the robot needs to have in order to
                  assist its wearer usefully in tasks. We believe that
                  the techniques and technology developed are of
                  particular immediate value in scenarios of remote
                  collaboration, where a remote expert is able to
                  annotate, through the robot, the environment the
                  wearer is working in.},
}

@InProceedings{Davison04iav,
  author =	 {A.J. Davison and Y.G. Cid and N. Kita},
  title =	 {Real-Time 3{D} {SLAM} with wide-angle Vision},
  booktitle =	 {5th IFAC/EURON Symp. on Intelligent Autonomous
                  Vehicles, IAV'04},
  location =	 {Lisbon, Portugal},
  month =	 {Jul},
  year =	 2004,
  abstract =	 {The performance of single-camera SLAM is improved
                  when wide-angle optics provide a field of view
                  greater than the 40 to 50 degrees lenses normally
                  used in computer vision. The issue is one of feature
                  contact: each landmark object mapped remains visible
                  through a larger range of camera motion, meaning
                  that feature density can be reduced and camera
                  movement range can be increased. Further,
                  localisation stability is improved since features at
                  widely differing viewing angles are simultaneously
                  visible. We present the first real-time (30 frames
                  per second), fully automatic implementation of 3D
                  SLAM using a hand-waved wide-angle camera, and
                  demonstrate significant advances in the range and
                  agility of motions which can be tracked over
                  previous narrow field-of-view implementations.},
  c-kaess =	 {Demonstrates that wide-angle vision provides better
                  constraints for the previously presented real-time
                  3D SLAM in Davison03iccv. In an experiment, a normal
                  and a wide-angle camera are fixed together to
                  achieve direct comparability.},
}

@InProceedings{Davison05iccv,
  author =	 {A.J. Davison},
  fullauthor =	 {Andrew J. Davison},
  title =	 {Active Search for Real-Time Vision},
  booktitle =	 ICCV,
  location =	 {Beijing, China},
  month =	 {Oct},
  year =	 2005,
  abstract =	 {In most cases when information is to be extracted
                  from an image, there are priors available on the
                  state of the world and therefore on the detailed
                  measurements which will be obtained. While such
                  priors are commonly combined with the actual
                  measurements via Bayes?rule to calculate posterior
                  probability distributions on model parameters, their
                  additional value in guiding efficient image
                  processing has almost always been overlooked. Priors
                  tell us where to look for information in an image,
                  how much computational effort we can expect to
                  expend to extract it, and of how much utility to the
                  task in hand it is likely to be. Such considerations
                  are of importance in all practical real-time vision
                  systems, where the processing resources available at
                  each frame in a sequence are strictly limited ?and
                  it is exactly in high frame-rate real-time systems
                  such as trackers where strong priors are most likely
                  to be available. In this paper, we use Shannon
                  information theory to analyse the fundamental value
                  of measurements using mutual information scores in
                  absolute units of bits, specifically looking at the
                  overwhelming case where uncertainty can be
                  characterised by Gaussian probability
                  distributions. We then compare these measurement
                  values with the computational cost of the image
                  processing required to obtain them. This theory puts
                  on a firm footing for the first time principles of
                  ?ctive search?for efficient guided image processing,
                  in which candidate features of possibly different
                  types can be compared and selected automatically for
                  measurement.},
  quota =	 {In inference, the only reason to resort to random
                  sampling must be when the cost of actively deducing
                  a more informative measurement strategy is
                  prohibitively high,...},
  c-kaess =	 {Analyses information-theoretic guided search for
                  Gaussian measurement and model uncertainties. States
                  that such methods are much more satisfactory than
                  methods like RANSAC that rely on random numbers and
                  arbitrary thresholds.},
}

@Article{Davison07pami,
  author =	 {A.J. Davison and I. Reid and N. Molton and
                  O. Stasse},
  fullauthor =	 {Andrew J. Davison and Ian Reid and Nicholas Molton
                  and Olivier Stasse},
  title =	 {Mono{SLAM}: Real-Time Single Camera {SLAM}},
  journal =	 PAMI,
  volume =	 29,
  number =	 6,
  pages =	 {1052-1067},
  month =	 {Jun},
  year =	 2007,
  abstract =	 {We present a real-time algorithm which can recover
                  the 3D trajectory of a monocular camera, moving
                  rapidly through a previously unknown scene. Our
                  system, which we dub MonoSLAM, is the first
                  successful application of the SLAM methodology from
                  mobile robotics to the ?ure vision?domain of a
                  single uncontrolled camera, achieving real-time but
                  drift-free performance inaccessible to Structure
                  from Motion approaches. The core of the approach is
                  the on-line creation of a sparse but persistent map
                  of natural landmarks within a probabilistic
                  framework. Our key novel contributions include an
                  active approach to mapping and measurement, the use
                  of a general motion model for smooth camera
                  movement, and solutions for monocular feature
                  initialization and feature orientation
                  estimation. Together, these add up to an extremely
                  efficient and robust algorithm which runs at 30Hz
                  with standard PC and camera hardware. This work
                  extends the range of robotic systems in which SLAM
                  can be usefully applied, but also opens up new
                  areas. We present applications of MonoSLAM to
                  real-time 3D localization and mapping for a
                  high-performance full-size humanoid robot, and live
                  augmented reality with a hand-held camera.},
  quotes =	 {Repeatable localization, in which gradual drift from
                  ground truth does not occur, will be essential here,
                  and much more important than in cases where a moving
                  camera continually explores new regions without
                  returning. ...a method like ours using active search
                  will always outperform invariant matching for
                  speed.},
  c-kaess =	 {Good summary of Davison's work, with an application
                  on a humanoid robot. The goal is long-term,
                  repeatable localization within restricted volumes,
                  based on cheap hardware, ie. only one camera. Shi
                  and Tomasi features from monochrome images, no
                  invariant features, but active search for speed (30
                  Hz), which chooses the features that provide most
                  information while predicting their measurement to
                  restrict the search region. Uses relatively large
                  templates, that are warped full projectively during
                  the prediction, combined with normalized
                  cross-correlation. Based on a wide-angle camera (100
                  degrees FOV), only a small number of features
                  (around 12) need to be matched in each frame, to
                  update an EKF based map with a maximum of 100
                  landmarks. Bad features are pruned, new features
                  initialized by placing samples along a line - only
                  the depth is updated in the next steps, while
                  unsupported samples get pruned - assumes sideways
                  motion, to provide sufficient parallax. Templates
                  are not updated over time to prevent drift. Start-up
                  requires a known target placed in front of the
                  camera. Claims that natural selection over time
                  leads to a map of stable, static, widely-observable
                  point features.},
}

@InProceedings{Davison98eccv,
  author =	 {A.J. Davison},
  title =	 {Mobile Robot Localization Using Active Vision},
  booktitle =	 ECCV,
  year =	 1998,
  c-dellaert =	 {Describes a robot with an active stereo-head that
                  (slowly) maps out a visual map of features on the
                  floor. Also see \cite{Davison98thesis}.},
}

@InProceedings{Davison98eccv,
  author =	 {A.J. Davison},
  title =	 {Mobile Robot Localization Using Active Vision},
  booktitle =	 ECCV,
  year =	 1998,
}

@inproceedings{Davison98eccv,
  title =	 {Mobile Robot Localisation Using Active Vision},
  author =	 {A.J. Davison and D.W. Murray},
  fullauthor =	 {Andrew J. Davison and David W. Murray},
  booktitle =	 ECCV,
  year =	 1998,
  c-dellaert =	 {Conference version of thesis. Geometric features.}
}

@PhdThesis{Davison98thesis,
  author =	 {A.J. Davison},
  title =	 {Mobile Robot Navigation Using Active Vision},
  school =	 {University of Oxford},
  year =	 1998,
  c-dellaert =	 {Good source for related work up to that
                  point. Describes all methods up to that point as not
                  dealing well with long motions and closing the
                  loop. Also see \cite{Davison98eccv}.},
}

@PhdThesis{Davison98thesis,
  author =	 {A.J. Davison},
  title =	 {Mobile Robot Navigation Using Active Vision},
  school =	 {University of Oxford},
  year =	 1998,
}

@PhdThesis{Davison98thesis,
  author =	 {A.J. Davison},
  fullauthor =	 {Andrew John Davison},
  title =	 {Mobile Robot Navigation using Active Vision},
  school =	 {Keble College, Oxford},
  year =	 1998,
  quotes =	 {We have shown that features can be tracked
                  continuously in an effident manner as the robot
                  moves, and that intelligent choices can be made
                  about which features should be tracked when to
                  provide good navigation information.},
  c-dellaert =	 {Uses active vision for robot navigation. Visual SLAM
                  one feature at a time, switching. Not a good idea:
                  we need to consider the periphery as well. Also,
                  likely very painful to do the experiments.},
}

@article{Dawkins00nature,
  Author =	 {Dawkins, Marian Stamp and Woodington, Alan},
  Journal =	 {Nature},
  Number =	 6770,
  Pages =	 652,
  Title =	 {Pattern recognition and active vision in chickens},
  Volume =	 403,
  Year =	 2000,
  abstract =	 {Recognition of objects or environmental landmarks is
                  problematic because appearance can vary widely
                  depending on illumination, viewing distance, angle
                  of view and so on. Storing a separate image or
                  `template' for every possible view requires vast
                  numbers to be stored and scanned, has a high
                  probability of recognition error and appears not to
                  be the solution adopted by primates. However, some
                  invertebrate template matching systems can achieve
                  recognition by `active vision' in which the animal's
                  own behaviour is used to achieve a fit between
                  template and object, for example by repeatedly
                  following a set path. Recognition is thus limited to
                  views from the set path but achieved with a minimal
                  number of templates. Here we report the first
                  evidence of similar active vision in a bird, in the
                  form of locomotion and individually distinct head
                  movements that give the eyes a similar series of
                  views on different occasions. The hens' ability to
                  recognize objects is also found to decrease when
                  their normal paths are altered.},
  Summary =	 {Deals with hens' ability to recognize
                  objects. Recapitulation of similar views of objects
                  on different occasions by repeated patterns of
                  locomotion and head movements; Frame-by-frame video
                  analysis of the body and head movements of six
                  freely moving hens; Evidence of active vision in a
                  bird.},
  quotes =	 {The results are consistent with the idea that birds
                  use active vision for object recognition, in the
                  form of precisely repeated locomotory and head
                  movements that allow them to recapitulate views of
                  objects from the same distance and with the same
                  part of the eye on successive occasions.},
  c-dellaert =	 {Seems to indicate a view-based recognition
                  strategy.},
}

@Book{DeGroot04,
  author =	 {Morris De Groot},
  title =	 {Optimal Statistical Decisions},
  publisher =	 {Wiley Classics Library},
  year =	 {2004},
}

@InProceedings{DeMenthon92,
  author =	 "D.DeMenthon and L.Davis",
  title =	 "Model-based Object Pose in 25 Lines of Code",
  pages =	 "335-343",
  booktitle =	 ECCV,
  year =	 1992,
}

@Misc{Dean08NYTimes,
  Author =	 {Dean, C.},
  year =	 2008,
  title =	 {Coral Reefs and What Ruins Them},
  journal =	 {New York Times},
  Url =		 {
                  http://www.nytimes.com/2008/02/26/science/earth/26reef.html?ex=1362286800&en=ab13ec602339343e&ei=5124&partner=permalink&exprod=permalink
                  on 5/22/08},
}

@inproceedings{Deans00icra,
  author =	 "M. Deans and M. Hebert",
  fullauthor =	 "Matthew Deans and Martial Hebert",
  title =	 "Invariant filtering for simultaneous localization
                  and mapping",
  booktitle =	 ICRA,
  month =	 "April",
  year =	 2000,
  pages =	 "1042-7"
}

@inproceedings{Deans00iser,
  author =	 "M. Deans and M. Hebert",
  fullauthor =	 "Matthew Deans and Martial Hebert",
  title =	 "Experimental Comparison of Techniques for
                  Localization and Mapping using a Bearings Only
                  Sensor",
  booktitle =	 ISER,
  month =	 "December",
  year =	 2000
}

@Article{Deb97,
  author =	 {S. Deb and M. Yeddanapudi and K. Pattipati and
                  Bar-Shalom, Y.},
  title =	 {A generalized {S-D} assignment algorithm for
                  multisensor-multitarget state estimation},
  journal =	 AES,
  year =	 1997,
  volume =	 33,
  number =	 2,
  pages =	 {523--538},
  month =	 {April},
}

@inproceedings{Debevec2000siggraph,
  title =	 "Acquiring the Reflectance Field of a Human Face",
  author =	 "P. Debevec and T. Hawkins and C. Tchou and H. Duiker
                  and W. Sarokin and M. Sagar",
  booktitle =	 SIGGRAPH,
  year =	 2000,
  pages =	 "145--156",
}

@article{Debevec96siggraph,
  author =	 "P.E. Debevec and C.J. Taylor and J. Malik",
  fullauthor =	 "Paul E. Debevec and Camillo J. Taylor and Jitendra
                  Malik",
  title =	 "Modeling and Rendering Architecture from
                  Photographs: {A} Hybrid Geometry- and Image-Based
                  Approach",
  journal =	 SIGGRAPH,
  volume =	 30,
  pages =	 "11--20",
  year =	 1996,
  url =		 "citeseer.nj.nec.com/debevec96modeling.html",
  r-Dick99bmvc = {Facade, can produce highly realistic models of
                  architectural scenes from relatively few, widely
                  spaced images at less computational
                  expense. However, Facade requires a user to specify
                  a coarse polyhedral model of the scene and register
                  it in each each image. This is a laborious process
                  and limits the complexity of the model which can be
                  practically recovered.},
}

@article{Debevec97siggraph,
  author =	 "P.E. Debevec and J. Malik",
  title =	 "Recovering high dynamic range radiance maps from
                  photographs ",
  journal =	 SIGGRAPH,
  pages =	 "369--378",
  year =	 1997,
}

@InProceedings{Debevec98egrw,
  author =	 {P. Debevec and Y. Yu and G. Borshukov},
  title =	 {Efficient view-dependent image-based rendering with
                  projective texture-mapping},
  booktitle =	 {Eurographics Workshop on Rendering},
  pages =	 {105--116},
  year =	 1998,
  r-Kang06ftcgv ={A three-step view-dependent texture mapping method
                  was also proposed later by Debevec et al. [23] to
                  further reduce the computational cost and to have
                  smoother blending. This method employs visibility
                  preprocessing, polygon-view maps, and projective
                  texture mapping.}
}

@article{Dechter01ai,
  author =	 "R. Dechter and Y. El Fattah",
  fullauthor =	 "Rina Dechter and Yousri El Fattah",
  title =	 "Topological parameters for time-space tradeoff",
  journal =	 AI,
  volume =	 125,
  number =	 "1--2",
  pages =	 "93--118",
  year =	 2001,
  r-Mateescu07ijcai ={proposes the use of secondary join trees, which
                  simply combine any two neigh- boring clusters whose
                  separator is too big to be stored. The resulting
                  algorithm that uses less memory at the expense of
                  more time is called space based join tree
                  clustering, The computation in each cluster can be
                  done by any suitable method. The obvious one would
                  be to simply enumerate all the instantiations of the
                  cluster, which corresponds to an OR search over the
                  variables of the cluster. A more advanced method
                  advocated by \cite{Dechter and Fattah, 2001} is the
                  use of cycle cutset inside each cluster. }
}

@inproceedings{Dechter02aaai,
  author =	 {R. Dechter and K. Kask and E. Bin and R. Emek},
  fullcauthor =	 {Rina Dechter and Kalev Kask and Eyal Bin and Roy
                  Emek},
  title =	 {Generating random solutions for constraint
                  satisfaction problems},
  crossref =	 {_AAAI02},
  pages =	 {15--21},
}

@article{Dechter03jacm,
  author =	 {R. Dechter and I. Rish},
  fullauthor =	 {Rina Dechter and Irina Rish},
  title =	 {Mini-buckets: A general scheme for bounded
                  inference},
  journal =	 {J. ACM},
  volume =	 50,
  number =	 2,
  year =	 2003,
  issn =	 {0004-5411},
  pages =	 {107--153},
  doi =		 {http://doi.acm.org/10.1145/636865.636866},
  publisher =	 {ACM Press},
  address =	 {New York, NY, USA},
  abstract =	 {This article presents a class of approximation
                  algorithms that extend the idea of
                  bounded-complexity inference, inspired by successful
                  constraint propagation algorithms, to probabilistic
                  inference and combinatorial optimization. The idea
                  is to bound the dimensionality of dependencies
                  created by inference algorithms. This yields a
                  parameterized scheme, called mini-buckets, that
                  offers adjustable trade-off between accuracy and
                  efficiency. The mini-bucket approach to optimization
                  problems, such as finding the most probable
                  explanation (MPE) in Bayesian networks, generates
                  both an approximate solution and bounds on the
                  solution quality. We present empirical results
                  demonstrating successful performance of the proposed
                  approximation scheme for the MPE task, both on
                  randomly generated problems and on realistic domains
                  such as medical diagnosis and probabilistic
                  decoding.},
}

@Article{Dechter07ai,
  author =	 {R. Dechter and R. Mateescu},
  fullauthor =	 {Rina Dechter and Robert Mateescu},
  title =	 {{AND/OR} Search Spaces for Graphical Models},
  journal =	 AI,
  year =	 2007,
  note =	 {To Appear},
  abstract =	 {The paper introduces an AND/OR search space
                  perspective for graphical models that include
                  probabilistic networks (directed or undirected) and
                  constraint networks. In contrast to the traditional
                  (OR) search space view, the AND/OR search tree
                  displays some of the independencies present in the
                  graphical model explicitly and may sometimes reduce
                  the search space exponentially. Indeed, most
                  algorithmic advances in search-based constraint
                  processing and probabilistic inference can be viewed
                  as searching an AND/OR search tree or
                  graph. Familiar parameters such as the depth of a
                  spanning tree, treewidth and pathwidth are shown to
                  play a key role in characterizing the effect of
                  AND/OR search graphs vs. the traditional OR search
                  graphs. We compare memory intensive AND/OR graph
                  search with inference methods, and place various
                  existing algorithms within the AND/OR search
                  space. },
}

@Article{Dechter87ai,
  author =	 {R. Dechter and J. Pearl},
  fullauthor =	 {Rina Dechter and Judea Pearl},
  title =	 {Network-based heuristics for constraint-satisfaction
                  problems},
  journal =	 AI,
  year =	 1987,
  volume =	 34,
  number =	 1,
  pages =	 {1--38},
  month =	 {December},
  quotes =	 {easy problems advertise their simplicity via salient
                  features of their constraint networks},
  r-Dechter92chapter ={Seminal reference for Adaptive-Consistency, the
                  variant of elimination for CSP. In spite of the nice
                  structure and complexity guarantees that are
                  provided by adaptive consistency, experimental
                  results have shown that unless w is very low
                  (namely, one or two) the algorithm is too expensive
                  on the average. Its cost stems from the
                  determination to ensure an absolutely backtrack-
                  free search, often investing a disproportional
                  amount of computation trying to eliminate just a few
                  remaining dead-ends.},
  r-Kask05ai =	 {Join tree transformations and their associated
                  variable elimination algorithms were proposed for
                  the efficient solution of constraints satisfaction
                  problems \cite{Dechter87ai} and their role was
                  re-formalized and extended more recently in
                  \cite{Gottlob00ai}},
  c-dellaert =	 {Does not yet cite \cite{Seidel81ijcai}.},
}

@Inproceedings{Dechter88aaai,
  author =	 {R. Dechter and J. Pearl},
  fullauthor =	 {Rina Dechter and Judea Pearl},
  title =	 {Tree clustering for constraint networks},
  crossref =	 {_AAAI88},
  pages =	 {150-154},
  c-dellaert =	 {Conference version of \citep{Dechter89ai}}
}

@Article{Dechter89ai,
  author =	 {R. Dechter and J. Pearl},
  fullauthor =	 {Rina Dechter and Judea Pearl},
  title =	 {Tree clustering for constraint networks},
  journal =	 AI,
  year =	 1989,
  volume =	 38,
  number =	 3,
  pages =	 {353--366},
  month =	 {April},
  r-Kask05ai =	 {Tree clustering schemes have been widely used for
                  constraint processing, probabilistic reasoning and
                  for graphical models in general. The most popular
                  variants are join-tree clustering algorithms, also
                  called junction-trees. The schemes vary somewhat in
                  their graph definitions as well as in the way
                  tree-decompositions are processed \cite{Maier83book,
                  Dechter89ai, Jensen90csq, Lauritzen97amai,
                  Shenoy96uai, Gottlob00ai}. However, they all involve
                  a decomposition of a hyper-graph into a hyper-tree.},
  r-Kask05ai =	 {In both the constraint satisfaction and the Bayesian
                  networks communities the common tree-clustering
                  methods, called join-tree (or junction-tree)
                  clustering \cite{Dechter89ai, Lauritzen97amai}, are
                  based on a triangulation algorithm that transforms
                  the primal graph G (V,E) of a problem instance P
                  into a chordal graph G'.},
}

@Article{Dechter90ai,
  author =	 {R. Dechter},
  title =	 {Enhancement schemes for constraint processing:
                  Backjumping, learning and cutset decomposition},
  journal =	 AI,
  year =	 1990,
  volume =	 41,
  pages =	 {273--312},
  r-Dechter99ai ={Cutset-conditioning \cite{Dechter90ai, Pearl88book}
                  applies conditioning to a subset of variables that
                  cut all cycles of the interaction graph and solve
                  the resulting subproblem by bucket-elimination.}
}

@Article{Dechter91ai,
  author =	 {R. Dechter and I. Meiri and J. Pearl},
  title =	 {Temporal constraint networks},
  journal =	 AI,
  year =	 1991,
  volume =	 49,
  number =	 3,
  pages =	 {61--95},
  month =	 {May},
}

@incollection{Dechter92chapter,
  author =	 "R. Dechter",
  fullauthor =	 "Rina Dechter",
  title =	 "{Constraint Networks}",
  booktitle =	 "Encyclopedia of Artificial Intelligence",
  edition =	 "$2^{nd}$",
  publisher =	 "John Wiley and Sons",
  editor =	 "Stuart C. Shapiro",
  year =	 1992,
  pages =	 "276--285",
  quotes =	 {Although tree clustering differs conceptually from
                  adaptive consistency, it effectively results in the
                  same behavior and same performance. When applied on
                  the same ordered constraint graph, both algorithms
                  pro- duce the same induced graph. In other words,
                  adaptive consistency can be viewed as an e ective
                  scheme for assembling ACNs. It seems desirable to
                  use adaptive consistency when one-time solutions are
                  required, and to use tree-clustering when the
                  network is used as a knowledge base subjected to
                  repeated queries.},
  c-dellaert =	 {A review paper on CSP. Reviews i-consistency,
                  variable ordering heuristics. In top-down
                  backtracking: most constrained first, meshes well
                  with mmd bottom up. Hypergraphs formalize
                  overlapping sets as "hyperedges". Dual constraint
                  graph uses nodes for the constraints. Binary
                  constraint trees can be solved in linear time, via
                  bottom-up arc consistency then backtracking. My
                  note: this can be viewed exactly as elimination
                  using uniform densities. Defines "width", and
                  Adaptive-Consistency algorithm which is exactly CSP
                  elimination, refers to \cite{Dechter87,Siedel81} as
                  its source. Induced width, cites \cite{Arnborg85bit}
                  for NP-completeness of ordering. Says join-tree and
                  AC is the same thing, prefers AC if one solution. I
                  disagree: AC should yield densities or
                  functions. k-trees as a special chordal graph.},
}

@InProceedings{Dechter96uai,
  author =	 {R. Dechter},
  fullauthor =	 {Rina Dechter},
  title =	 {Bucket elimination: A unifying framework for several
                  probabilistic inference algorithms},
  crossref =	 {_UAI96},
  r-Bartels06uai ={Vertex elimination is an algorithm that can be used
                  to triangulate graphs.},
  c-dellaert =	 {\citet{Dechter96uai} gives a similar unifying view
                  but not graphical},
}

@InCollection{Dechter98chapter,
  author =	 "R. Dechter",
  fullauthor =	 "Rina Dechter",
  booktitle =	 {Learning in Graphical Models},
  title =	 "{Bucket Elimination}: A Unifying Framework for
                  Reasoning",
  crossref =	 {_Jordan98book},
  pages =	 "75--104",
  abstract =	 {Probabilistic inference algorithms for belief
                  updating, finding the most probable explanation, the
                  maximum a posteriori hypothesis, and the maximum
                  expected utility are reformulated within the bucket
                  elimination framework. This emphasizes the
                  principles common to many of the algorithms
                  appearing in the probabilistic inference literature
                  and clarifies the relationship of such algorithms to
                  nonserial dynamic programming algorithms. A general
                  method for combining conditioning and bucket
                  elimination is also presented. For all the
                  algorithms, bounds on complexity are given as a
                  function of the problem's structure.},
}

@article{Dechter99ai,
  author =	 "R. Dechter",
  fullauthor =	 "Rina Dechter",
  title =	 "{Bucket Elimination}: A Unifying Framework for
                  Reasoning",
  journal =	 AI,
  volume =	 "113",
  number =	 "1-2",
  pages =	 "41--85",
  year =	 "1999",
  abstract =	 {Bucket elimination is an algorithmic framework that
                  generalizes dynamic programming to accommodate many
                  problem-solving and reasoning tasks. Algorithms such
                  as directional-resolution for propositional
                  satisfiability, adaptive-consistency for constraint
                  satisfaction, Fourier and Gaussian elimination for
                  solving linear equalities and inequalities, and
                  dynamic programming for combinatorial optimization,
                  can all be accommodated within the bucket
                  elimination framework. Many probabilistic in-
                  ference tasks can likewise be expressed as
                  bucket-elimination algorithms. These include: belief
                  updating, finding the most probable explanation, and
                  expected utility maximization. These algorithms
                  share the same performance guarantees; all are time
                  and space exponential in the induced-width of the
                  problem's interaction graph. While elimination
                  strategies have extensive demands on memory, a
                  contrasting class of algorithms called "conditioning
                  search" require only linear space. Algorithms in
                  this class split a problem into subproblems by
                  instantiating a subset of variables, called a
                  conditioning set, or a cutset. Typical examples of
                  conditioning search algorithms are: backtracking (in
                  constraint satisfaction), and branch and bound (for
                  combinatorial optimization). The paper presents the
                  bucket-elimination framework as a unifying theme
                  across probabilistic and deterministic reasoning
                  tasks and show how conditioning search can be
                  augmented to systematically trade space for time.},
  quotes =	 {The main virtues of the bucket-elimination framework
                  are simplicity and generality. ... In general the
                  structure of a given theory will be associated with
                  an interaction graph describing dependencies between
                  variables. The induced-width describes the largest
                  cluster in a tree-embedding of that graph (also
                  known as tree-width). ... The complexity of
                  conditioning algorithms is exponential in the
                  conditioning set, however, their space complexity is
                  only linear. Also, empirical studies show that their
                  average performance is often far superior to their
                  worst-case bound. This suggests that combining
                  elimination with conditioning may be essential for
                  improving reasoning processes.},
  c-dellaert =	 {Variable ordering is from root to leaves, there is a
                  bucket for each variable, functions go to bucket of
                  highest ordered variable (closest to
                  leaves). Elimination is done from last to first. Jon
                  + projection = combination + marginzalization. I
                  find the bucket elimination explanation overly
                  cumbersome, and no mention is made of the resulting
                  directed graph = Bayes net = upper triangular
                  matrix.}
}

@inproceedings{Dedeoglu99,
  author =	 {G. Dedeoglu and M. Mataric and G. Sukhatme},
  title =	 {Incremental, online topological map building with a
                  mobile robot},
  booktitle =	 {Proceedings of Mobile Robots},
  year =	 1999,
  c-ananth =	 {Dedeoglu et al. [Dedeoglu99] provide a mapping
                  technique that uses specific features of the
                  environment such as open doors and orthogonal walls,
                  and identifies them using low-level characteristics
                  of laser scans.},
}

@InProceedings{Dellaert00,
  author =	 {F. Dellaert and S.M. Seitz and C.E. Thorpe and
                  S. Thrun},
  title =	 {Structure from Motion without Correspondence},
  booktitle =	 CVPR,
  month =	 {June},
  year =	 2000,
}

@TechReport{Dellaert00b,
  author =	 {F. Dellaert},
  title =	 {Addressing the Correspondence Problem: A {M}arkov
                  Chain {M}onte {C}arlo Approach},
  institution =	 {Robotics Institute, School of Computer Science,
                  Carnegie Mellon},
  number =	 {CMU-RI-TR-00-11},
  month =	 {January},
  year =	 2000
}

@inproceedings{Dellaert01b,
  author =	 "F. Dellaert and S.M. Seitz and C.E. Thorpe and
                  S. Thrun",
  fullauthor =	 "Frank Dellaert and Steven M. Seitz and Charles
                  E. Thorpe and Sebastian Thrun",
  title =	 "Feature Correspondence: A {M}arkov Chain {M}onte
                  {C}arlo Approach",
  booktitle =	 "Advances in Neural Information Processing Systems 13
                  (NIPS 2000)",
  year =	 2001
}

@PhdThesis{Dellaert01c,
  author =	 {F. Dellaert},
  title =	 {Monte {C}arlo {EM} for Data Association and its
                  Applications in Computer Vision},
  school =	 {School of Computer Science, Carnegie Mellon},
  year =	 2001,
  month =	 {September},
  note =	 {Also available as Technical Report CMU-CS-01-153}
}

@InProceedings{Dellaert02aaai,
  author =	 {F. Dellaert and T. Balch and M. Kaess and
                  R. Ravichandran and F. Alegre and M. Berhault and
                  R. McGuire and E. Merrill and L. Moshkina and
                  D. Walker},
  fullauthor =	 {Frank Dellaert and Tucker Balch and Michael Kaess
                  and Ram Ravichandran and Fernando Alegre and Marc
                  Berhault and Robert McGuire and Ernest Merrill and
                  Lilia Moshkina and Daniel Walker},
  title =	 {The {Georgia} {Tech} {Y}ellow {J}ackets: A Marsupial
                  Team for Urban Search and Rescue},
  booktitle =	 {AAAI Mobile Robot Competition Workshop},
  pages =	 {44-49},
  _publisher =	 {AAAI Press},
  address =	 {Edmonton, Alberta, Canada},
  isbn =	 {1-57735-176-2},
  year =	 2002,
  abstract =	 {We describe our entry in the AAAI 2002 Urban Search
                  and Rescue (USAR) competition, a marsupial team
                  consisting of a larger wheeled robot and several
                  small legged robots, carried around by the larger
                  robot. This setup exploits complimentary strengths
                  of each robot type in a challenging domain. We
                  describe both the hardware and software
                  architecture, and the on-board real-time mapping
                  which forms the basis of accurate
                  victim-localization crucial to the USAR domain. We
                  also evaluate what challenges remain to be resolved
                  in order to deploy search and rescue robots in
                  realistic scenarios.},
}

@TechReport{Dellaert02em,
  author =	 {F. Dellaert},
  title =	 {The Expectation Maximization Algorithm},
  institution =	 CoC,
  year =	 2002,
  month =	 {February},
  number =	 {GIT-GVU-02-20}
}

@TechReport{Dellaert02ilm,
  author =	 {F. Dellaert and F. Alegre and E.B. Martinson},
  title =	 {Intrinsic Mapping and Localization},
  institution =	 CoC,
  year =	 2002,
  month =	 {September},
  note =	 {Also submitted as a regular paper to ICRA 2003}
}

@inproceedings{Dellaert02linear,
  author =	 "F. Dellaert and A. Stroupe",
  fullauthor =	 "Frank Dellaert and Ashley Stroupe",
  title =	 "Linear {2D} Localization and Mapping for Single and
                  Multiple Robots",
  booktitle =	 ICRA,
  month =	 "May",
  year =	 2002,
  publisher =	 "IEEE"
}

@Article{Dellaert03,
  author =	 {F. Dellaert and S.M. Seitz and C.E. Thorpe and
                  S. Thrun},
  title =	 {{EM}, {MCMC}, and Chain Flipping for Structure from
                  Motion with Unknown Correspondence},
  journal =	 ML,
  year =	 2003,
  volume =	 50,
  number =	 {1-2},
  month =	 {January - February},
  pages =	 {45-71},
  note =	 {Special issue on Markov chain Monte Carlo methods},
}

@InProceedings{Dellaert03icra,
  author =	 {F. Dellaert and F. Alegre and E.B. Martinson},
  title =	 {Intrinsic Localization and Mapping with 2
                  Applications: Diffusion Mapping and {Marco} {Polo}
                  Localization},
  booktitle =	 ICRA,
  year =	 2003,
  month =	 {May},
}

@inProceedings{Dellaert03ism,
  author =	 {F. Dellaert},
  title =	 {A sample of {M}onte {C}arlo methods in robotics and
                  vision},
  booktitle =	 {Proc. of the ISM Intl. Symp. on the Science of
                  Modeling - The 30th Anniversary of the Information
                  Criterion (AIC)},
  year =	 2003,
  pages =	 {211-222},
  address =	 {Yokohama, Japan}
}

@Unpublished{Dellaert03mixture,
  author =	 "F. Dellaert",
  fullauthor =	 "Frank Dellaert",
  title =	 "Mixture Trees for Density Estimation and Fast
                  Conditional Resampling",
  note =	 "Submitted to NIPS",
  year =	 2003,
}

@Unpublished{Dellaert03tutorial,
  author =	 {Frank Dellaert},
  title =	 {An Intuitive Introduction to {ML} and {MAP}
                  Estimation, {Kalman} and Particle Filters, and
                  {Rao-Blackwellization}},
  note =	 {In preparation},
  year =	 2003,
}

@InProceedings{Dellaert05aaai,
  author =	 {F. Dellaert and A. Kipp and P. Krauthausen},
  title =	 {A Multifrontal {QR} Factorization Approach to
                  Distributed Inference applied to Multi-robot
                  Localization and Mapping},
  crossref =	 {_AAAI05},
  url =
                  {http://www.cc.gatech.edu/~dellaert/pubs/Dellaert05aaai.pdf},
  abstract =	 {QR factorization is most often used as a black box
                  algorithm, but is in fact an elegant computation on
                  a factor graph. By computing a rooted clique tree on
                  this graph, the computation can be parallelized
                  across subtrees, which forms the basis of so-called
                  multifrontal QR methods. By judiciously choosing the
                  order in which variables are eliminated in the
                  clique tree computation, we show that one
                  straightforwardly obtains a method for performing
                  inference in distributed sensor networks. One
                  obvious application is distributed localization and
                  mapping with a team of robots. We phrase the problem
                  as inference on a large-scale Gaussian Markov Random
                  Field induced by the measurement factor graph, and
                  show how multifrontal QR on this graph solves for
                  the global map and all the robot poses in a
                  distributed fashion. The method is illustrated using
                  both small and large-scale simulations, and
                  validated in practice through actual robot
                  experiments.},
  quotes =	 {To the best of our knowledge, our approach
                  represents the first comprehensive approach to
                  distributed, landmark-based SLAM.},
  c-kaess =	 {Exploits sparsity at the structural level, and uses
                  fast dense QR factorization locally. Mentions
                  connection to junction tree, by stating that focus
                  is on large-scale inference rather than clique
                  marginals. Notes that same sparsity pattern can be
                  reused, especially at each non-linear minimization
                  iteration when relinearizing.},
}

@InProceedings{Dellaert05cvavi,
  author =	 {F. Dellaert and S. Tariq},
  title =	 {A Multi-Camera Pose Tracker for Assisting the
                  Visually Impaired},
  booktitle =	 {1st IEEE Workshop on Computer Vision Applications
                  for the Visually Impaired},
  year =	 {2005},
}

@InProceedings{Dellaert05cvpr,
  author =	 {F. Dellaert and V. Kwatra and S.M. Oh},
  title =	 {Mixture Trees for Modeling and Fast Conditional
                  Sampling with Applications in Vision and Graphics},
  booktitle =	 CVPR,
  year =	 2005,
}

@InProceedings{Dellaert05rss,
  author =	 {F. Dellaert},
  title =	 {Square {Root} {SAM}: Simultaneous Location and
                  Mapping via Square Root Information Smoothing},
  booktitle =	 RSS,
  year =	 2005,
  Abstract =	 {Solving the SLAM problem is one way to enable a
                  robot to explore, map, and navigate in a previously
                  unknown environment. We investigate smoothing
                  approaches as a viable alternative to extended
                  Kalman filter-based solutions to the problem. In
                  particular, we look at approaches that factorize
                  either the associated information matrix or the
                  measurement matrix into square root form. Such
                  techniques have several significant advantages over
                  the EKF: they are faster yet exact, they can be used
                  in either batch or incremental mode, are better
                  equipped to deal with non-linear process and
                  measurement models, and yield the entire robot
                  trajectory, at lower cost. In addition, in an
                  indirect but dramatic way, column ordering
                  heuristics automatically exploit the locality
                  inherent in the geographic nature of the SLAM
                  problem. In this paper we present the theory
                  underlying these methods, an interpretation of
                  factorization in terms of the graphical model
                  associated with the SLAM problem, and simulation
                  results that underscore the potential of these
                  methods for use in practice.}
}

@TechReport{Dellaert05tr,
  author =	 {F. Dellaert},
  title =	 {Square {Root} {SAM}: Simultaneous Localization and
                  Mapping via Square Root Information Smoothing},
  institution =	 {Georgia Institute of Technology},
  year =	 {2005},
  number =	 {GIT-GVU-05-11},
}

@TechReport{Dellaert05tr-pflp,
  title =	 "{A Partially Fixed Linearization Approach for
                  Submap-Parametrized Smoothing and Mapping}",
  author =	 {Alexander Kipp and Peter Krauthausen and Frank
                  Dellaert},
  institution =	 {Georgia Institute of Technology},
  number =	 {GIT-GVU-05-25},
  year =	 2005
}

@Article{Dellaert06ijrr,
  author =	 {F. Dellaert and M. Kaess},
  fullauthor =	 {Frank Dellaert and Michael Kaess},
  title =	 {Square {Root} {SAM}: Simultaneous Localization and
                  Mapping via Square Root Information Smoothing},
  journal =	 IJRR,
  volume =	 25,
  number =	 12,
  pages =	 {1181-1203},
  month =	 {Dec},
  year =	 2006,
  abstract =	 {Solving the SLAM problem is one way to enable a
                  robot to explore, map, and navigate in a previously
                  unknown environment. We investigate smoothing
                  approaches as a viable alternative to extended
                  Kalman filter-based solutions to the problem. In
                  particular, we look at approaches that factorize
                  either the associated information matrix or the
                  measurement Jacobian into square root form. Such
                  techniques have several significant advantages over
                  the EKF: they are faster yet exact, they can be used
                  in either batch or incremental mode, are better
                  equipped to deal with non-linear process and
                  measurement models, and yield the entire robot
                  trajectory, at lower cost for a large class of SLAM
                  problems. In addition, in an indirect but dramatic
                  way, column ordering heuristics automatically
                  exploit the locality inherent in the geographic
                  nature of the SLAM problem. In this paper we present
                  the theory underlying these methods, along with an
                  interpretation of factorization in terms of the
                  graphical model associated with the SLAM problem. We
                  present both simulation results and actual SLAM
                  experiments in large-scale environments that
                  underscore the potential of these methods as an
                  alternative to EKF-based approaches.},
}

@InProceedings{Dellaert94,
  author =	 "F. Dellaert and R.D. Beer",
  title =	 "Toward an Evolvable Model of Development for
                  Autonomous Agent Synthesis",
  booktitle =	 "Artificial Life IV, Proceedings of the Fourth
                  International Workshop on the Synthesis and
                  Simulation of Living Systems" ,
  year =	 1994
}

@InProceedings{Dellaert94b,
  author =	 "F. Dellaert and J. Vandewalle",
  fullauthor =	 "Frank Dellaert and Joos Vandewalle",
  title =	 "Automatic design of Cellular Neural Networks by
                  means of Genetic Algorithms: Finding a Feature
                  Detector",
  booktitle =	 "CNNA '94: proceedings, fourth International IEEE
                  Workshop on Cellular Neural Networks and their
                  Applications",
  year =	 1994
}

@InProceedings{Dellaert96,
  author =	 "F. Dellaert and R.D. Beer",
  fullauthor =	 "Frank Dellaert and Randall D. Beer",
  title =	 "A Developmental Model for the Evolution of Complete
                  Autonomous Agents",
  booktitle =	 "From Animals to Animats 4: Proceedings of the Fourth
                  International Conference on Simulation of Adaptive
                  Behavior",
  year =	 1996
}

@InProceedings{Dellaert96b,
  author =	 "Frank Dellaert and Thomas Polzin and Alex Waibel",
  title =	 "Recognizing Emotion in Speech",
  booktitle =	 "ICSLP '96",
  year =	 1996
}

@TechReport{Dellaert97,
  author =	 "Frank Dellaert",
  title =	 "{CANSS}: A Candidate Selection and Search Algorithm
                  to Initialize Car Tracking",
  institution =	 "Robotics Institute, Carnegie Mellon",
  year =	 1997,
  number =	 "CMU-RI-TR-97-34"
}

@InProceedings{Dellaert97b,
  author =	 "F. Dellaert and C.E. Thorpe",
  title =	 "Robust car tracking using {K}alman filtering and
                  {B}ayesian templates",
  booktitle =	 SPIE,
  volume =	 3207,
  year =	 1997,
  month =	 "October"
}

@InProceedings{Dellaert98,
  author =	 "F. Dellaert and D. Pomerleau and C. Thorpe",
  fullauthor =	 "Frank Dellaert and Dean Pomerleau and Chuck Thorpe",
  title =	 "Model-Based Car Tracking Integrated with a
                  Road-Follower",
  booktitle =	 ICRA,
  year =	 1998,
  month =	 "May",
  address =	 "Leuven, Belgium",
  pages =	 "1889-1894",
}

@InProceedings{Dellaert98b,
  author =	 "F. Dellaert and C. Thorpe and S. Thrun",
  fullauthor =	 "Frank Dellaert and Chuck Thorpe and Sebastian Thrun",
  title =	 "Super-Resolved Tracking of Planar Surface Patches",
  booktitle =	 IROS,
  year =	 1998,
}

@InProceedings{Dellaert98c,
  fullauthor =	 "Frank Dellaert and Sebastian Thrun and Chuck Thorpe",
  author =	 "F. Dellaert and S. Thrun and C. Thorpe",
  title =	 "Jacobian Images of Super-Resolved Texture Maps for
                  Model-Based Motion Estimation and Tracking",
  booktitle =	 WACV,
  year =	 1998,
}

@InProceedings{Dellaert98d,
  author =	 "Yanxi Liu and Frank Dellaert",
  year =	 1998,
  title =	 "A Classification based {E}uclidean similarity metric
                  for {3D} image retrieval",
  booktitle =	 CVPR,
}

@InProceedings{Dellaert98e,
  author =	 "Yanxi Liu and Frank Dellaert",
  year =	 1998,
  title =	 "Classification Driven Medical Image Retrieval",
  booktitle =	 IUW
}

@InProceedings{Dellaert99,
  author =	 {F. Dellaert and D. Fox and W. Burgard and S. Thrun},
  title =	 {Monte {C}arlo {L}ocalization for Mobile Robots},
  booktitle =	 ICRA,
  year =	 1999,
}

@InProceedings{Dellaert99b,
  author =	 {F. Dellaert and D. Fox and W. Burgard and S. Thrun},
  title =	 {Using the Condensation Algorithm for Robust,
                  Vision-based Mobile Robot Localization},
  booktitle =	 CVPR,
  year =	 1999
}

@TechReport{Dellaert99c,
  author =	 {F. Dellaert and S. Thrun and C. Thorpe},
  title =	 {Mosaicing a Large Number of Widely Dispersed, Noisy,
                  and Distorted Images: A {B}ayesian Approach},
  institution =	 {Robotics Institute, School of Computer Science,
                  Carnegie Mellon},
  number =	 {CMU-RI-TR-99-34},
  year =	 1999,
}

@TechReport{Dellaert99d,
  author =	 {F. Dellaert and S.M. Seitz and C.E. Thorpe and
                  S. Thrun},
  title =	 {Structure from Motion without Correspondence},
  institution =	 {Robotics Institute, School of Computer Science,
                  Carnegie Mellon},
  number =	 {CMU-RI-TR-99-44},
  month =	 {December},
  year =	 1999
}

@inproceedings{Dellaert99e,
  AUTHOR =	 "Dellaert, F. and Collins, R.",
  TITLE =	 "Fast Image-Based Tracking by Selective Pixel
                  Integration",
  BOOKTITLE =	 "1999 ICCV Workshop on Frame Rate processing, Corfu,
                  Greece",
  YEAR =	 1999
}

@inproceedings{Delouille03,
  author =	 "V. Delouille and R. Neelamani and V. Chandrasekaran
                  and R. Baraniuk",
  title =	 "{The Embedded Triangles Algorithm for Distributed
                  Estimation in Sensor Networks}",
  booktitle =	 "{IEEE Workshop on Statistical Signal Processing
                  (SSP)}",
  year =	 {2003}
}

@inproceedings{Delouille04,
  title =	 "Robust Distributed Estimation in Sensor Networks
                  using the Embedded Polygons Algorithm",
  author =	 {V. Delouille and R. Neelamani and R. Baraniuk},
  booktitle =	 "Information Processing in Sensor Networks",
  year =	 2004
}

@article{Delouille06,
  author =	 "V. Delouille and R. Neelamani and R. Baraniuk",
  title =	 "{Robust Distributed Estimation Using the Embedded
                  Subgraphs Algorithm}",
  journal =	 "{IEEE Transactions on Signal Processing}",
  month =	 {August},
  year =	 2006,
  volume =	 54,
  number =	 8
}

@Article{Dempster77,
  author =	 {A.P. Dempster and N.M. Laird and D.B. Rubin},
  title =	 {Maximum Likelihood from Incomplete Data via the {EM}
                  Algorithm},
  journal =	 {Journal of the Royal Statistical Society, Series B},
  year =	 1977,
  volume =	 39,
  number =	 1,
  pages =	 {1-38},
}

@Article{Denison98,
  author =	 "D. G. T. Denison and B. K. Mallick and
                  A. F. M. Smith",
  title =	 "Automatic {Bayesian} Curve Fitting",
  journal =	 "Journal of the Royal Statistical Society, Series B",
  volume =	 60,
  number =	 2,
  year =	 1998,
  pages =	 "333-350",
}

@Book{Dennis83,
  author =	 {J.E. Dennis and R.B. Schnabel},
  title =	 {Numerical methods for unconstrained optimization and
                  nonlinear equations},
  publisher =	 {Prentice-Hall},
  year =	 1983,
  fulladdress =	 {Englewood Cliffs, NJ},
}

@article{Deriche90ivc,
  AUTHOR =	 "Deriche, R. and Faugeras, O.D.",
  TITLE =	 "Tracking Line Segments",
  JOURNAL =	 IVC,
  VOLUME =	 8,
  YEAR =	 1990,
  PAGES =	 "261-270"
}

@article{Deutscher02eccv,
  author =	 "J. Deutscher and M. Isard and J. MacCormick",
  title =	 "Automatic Camera Calibration from a Single Manhattan
                  Image",
  journal =	 ECCV,
  year =	 2002,
  pages =	 "175--205"
}

@InProceedings{Devarajan04basenet,
  author =	 {D. Devarajan and R. J. Radke},
  fullauthor =	 {Dhanya Devarajan and Richard J. Radke},
  title =	 {Distributed Metric Calibration of Large Camera
                  Networks},
  booktitle =	 {1st Workshop on Broadband Advanced Sensor Networks
                  (BASENETS)},
  year =	 2004,
}

@Article{Dhond89,
  author =	 {Dhond, U.R. and Aggarwal, J.K.},
  title =	 {Structure from stereo-a review},
  journal =	 SMC,
  year =	 1989,
  volume =	 19,
  number =	 6,
  pages =	 {1489 -1510},
  month =	 {December},
}

@InProceedings{DiMatteo01,
  author =	 {I. DiMatteo and C. R. Genovese and R. E. Kass},
  title =	 {Bayesian Curve Fitting with Free-Knot Splines},
  booktitle =	 {Biometrika},
  pages =	 {1055--1071},
  year =	 2001,
}

@InProceedings{Dick01iccv,
  author =	 {A.R. Dick and P.H.S. Torr and S. Ruffle and
                  R. Cipolla},
  title =	 {Combining Single View Recognition and Multiple View
                  Stereo for Architectural Scenes},
  booktitle =	 ICCV,
  year =	 2001,
}

@InProceedings{Dick02eccv,
  author =	 {A.R. Dick and P.H.S. Torr and R. Cipolla},
  title =	 {A {B}ayesian Estimation of Building Shape Using
                  {MCMC}},
  booktitle =	 ECCV,
  pages =	 {852--866},
  year =	 2002,
}

@Article{Dick04ijcv,
  author =	 "A.R.Dick and P.H.S. Torr and R. Cipolla",
  title =	 "Modelling and Interpretation of Architecture from
                  Several Images",
  journal =	 IJCV,
  year =	 2004,
  volume =	 60,
  number =	 2,
  pages =	 "111-134",
}

@InProceedings{Dick99bmvc,
  author =	 {A.R. Dick and R. Cipolla},
  title =	 {Model refinement from planar parallax},
  booktitle =	 BMVC,
  year =	 1999,
  abstract =	 {This paper presents a system for refining the
                  accuracy and realism of coarse piecewise planar
                  models from an uncalibrated sequence of
                  images. First, dense depth maps are estimated by
                  aligning a planar region of a scene in each image,
                  approximating camera calibration, and generating
                  dense planar parallax. These depth maps are then
                  robustly fused to obtain incrementally refined
                  surface estimates. It is envisaged that this system
                  will extend the modelling capability of existing
                  systems [Cipolla99icmcs] which generate simple,
                  piecewise planar architectural models.},
}

@InProceedings{Dickmanns87,
  author =	 "E.D. Dickmanns and A. Zapp",
  title =	 "A curvature-based scheme for improving road vehicle
                  guidance by computer vision",
  booktitle =	 SPIE,
  year =	 1987,
}

@InProceedings{Dickmanns88,
  author =	 "E.D. Dickmanns",
  title =	 "An integrated approach to feature based dynamic
                  vision",
  booktitle =	 CVPR,
  year =	 1988,
}

@InProceedings{Dickmanns97,
  author =	 "Dickmanns, E.D.",
  title =	 "Vehicles Capable of Dynamic Vision",
  booktitle =	 IJCAI,
  address =	 "Nagoya, Japan",
  year =	 1997,
}

@article{Digalakis93,
  Author =	 {V. Digalakis and J. R. Rohlicek and M. Ostendorf},
  Title =	 {A dynamical system approach to continuous speech
                  recognition},
  Journal =	 {IEEE Trans. Speech Audio Processing},
  Volume =	 1,
  Number =	 4,
  Year =	 1993,
  Pages =	 {431-442},
}

@misc{Dinsmore,
  author =	 {Dinsmore Instument Co.},
  title =	 {Digital {C}ompass {S}pecification and {P}rice
                  {W}ebsite},
  url =
                  {http://www.imagesco.com/catalog/DigitalCompass/DigitalCompass.html}
}

@Article{Dirac61,
  author =	 {G.A. Dirac},
  title =	 {On rigid circuit graphs},
  journal =	 {Abh. Math. Sem. Univ. Hamburg},
  year =	 1961,
  volume =	 25,
  pages =	 {71-76},
  r-Rose75stoc = {These graphs arise in other contexts and have also
                  been called chordal \cite{Gavril72siam} and rigid
                  circuit graphs \cite{Dirac61}.},
  r-Blair93chapter ={A graph G is chordal if and only if every minimal
                  vertex separator of G' is complete in G. Every
                  chordal graph G has a simplicial vertex. If G is not
                  complete, then it has two nonadjacent simplicial
                  vertices.},
  r-Heggernes06dm ={Chordal graphs were introduced several years
                  before the first graph theory results related to
                  sparse matrix computations appeared. The definition
                  of chordal graphs is thus independent of vertex
                  elimination, and graphs of this class can be
                  characterized by their minimal separators, as shown
                  by Dirac \cite{Dirac61} in 1961. At the same time,
                  they coincide with the class of graphs resulting
                  from Elimination Game, and they can also be
                  characterized through vertex orderings, as shown by
                  Fulkerson and Gross \cite{Fulkerson65pjm} in 1965.},
}

@UNPUBLISHED{Dissanayake00a,
  AUTHOR =	 {Dissanayake, G. and Durrant-Whyte, H. and Bailey,
                  T.},
  TITLE =	 {A Computationally efficient Solution to the
                  Simultaneous Localisation and Map Building ({SLAM})
                  Problem},
  YEAR =	 2000,
  ORGANIZATION = {Australian Centre for Field Robotics, University of
                  Sydney},
  ADDRESS =	 {Sydney, Australia},
  MONTH =	 {April},
  NOTE =	 {Working notes of ICRA'2000 Workshop W4: Mobile Robot
                  Navigation and Mapping}
}

@article{Dissanayake01tra,
  Author =	 {M.W.M.G. Dissanayake and P.M. Newman and
                  H.F. Durrant-Whyte and S. Clark and M. Csorba },
  Title =	 {A Solution to the Simultaneous Localization and Map
                  Building ({SLAM}) Problem},
  Journal =	 TRA,
  Volume =	 17,
  Number =	 3,
  Year =	 2001,
  Pages =	 {229-241},
}

@inproceedings{Djugash08icra,
  author =	 {Joseph Djugash and Sanjiv Singh and Benjamin
                  P. Grocholsky},
  title =	 {Decentralized Mapping of Robot-Aided Sensor
                  Networks},
  booktitle =	 ICRA,
  month =	 {May},
  year =	 {2008},
  pages =	 {583-589},
}

@article{Djuric02,
  Author =	 {P. M. Djuric and J-H. Chun},
  Title =	 {An {MCMC} {S}ampling {A}pproach to {E}stimation of
                  {N}onstationary {H}idden {M}arkov {M}odels},
  Journal =	 SP,
  Volume =	 50,
  Number =	 5,
  Year =	 2002,
  Pages =	 {1113-1123},
}

@Book{Dongarra79,
  author =	 {J. J. Dongarra and C. B. Moler and J. R. Bunch and
                  G. W. Stewart},
  title =	 {LINPACK: {users'} guide},
  publisher =	 {Society for Industrial and Applied Mathematics},
  year =	 1979,
  address =	 {Philadelphia},
}

@article{Donnelly86,
  title =	 "Partition structures, Polya urns, the Ewens sampling
                  formula, and the ages of alleles",
  author =	 {P. Donnelly},
  journal =	 "Theoretical Population Biology",
  volume =	 30,
  year =	 1986,
  pages =	 {271--288}
}

@Article{Doreto2003ijcv,
  title =	 {{Dynamic Textures}},
  author =	 {G. Doretto and A. Chiuso and Y. Wu and S. Soatto},
  fullauthor =	 {Gianfranco Doretto, Alessandro Chiuso, Ying Nian Wu,
                  Stefano Soatto},
  journal =	 IJCV,
  year =	 2003,
  volume =	 51,
  number =	 2,
  pages =	 {91-109},
}

@Article{Dori88,
  author =	 {D. Dori and A. Pnueli},
  title =	 {The Grammar of Dimensions in Machine Drawings},
  journal =	 GMIP,
  year =	 1988,
  volume =	 42,
  pages =	 {1-18},
}

@BOOK{Doucet00,
  EDITOR =	 {Doucet, A. and {de Freitas}, N. and Gordon, N.},
  TITLE =	 {Sequential {M}onte {C}arlo Methods In Practice},
  PUBLISHER =	 {Springer-Verlag},
  address =	 {New York},
  YEAR =	 2001
}

@Article{Doucet00a,
  author =	 "A. Doucet and S.Godsill and C. Andrieu",
  title =	 "On Sequential Monte Carlo sampling methods for
                  {Bayesian} filtering",
  journal =	 "Statistics and Computing",
  year =	 2000,
  volume =	 10,
  number =	 3,
  pages =	 {197-208},
}

@InProceedings{Doucet00uai,
  author =	 "A. Doucet and J.F.G {de Freitas} and K. Murphy and
                  S. Russell",
  title =	 "{R}ao-{B}lackwellised Particle Filtering for Dynamic
                  {B}ayesian networks",
  crossref =	 {_UAI00},
}

@Article{Doucet01,
  author =	 "A. Doucet and N. J. Gordon and V. Krishnamurthy",
  title =	 "Particle Filters for State Estimation of Jump
                  {Markov} Linear Systems",
  journal =	 SP,
  year =	 2001,
  volume =	 49,
  number =	 3,
  pages =	 "613-624",
}

@Article{Doucet01a,
  author =	 "A. Doucet and C. Andrieu",
  title =	 "Iterative {A}lgorithms for {S}tate {E}stimation of
                  {J}ump {M}arkov {L}inear {S}ystems",
  journal =	 SP,
  year =	 2001,
  volume =	 49,
  number =	 6,
  pages =	 "1216-1227",
}

@InProceedings{Doucet02,
  author =	 {A. Doucet and B. Vo and C. Andrieu and M. Davy},
  title =	 {Particle Filtering for Multitarget Tracking and
                  Sensor Management},
  booktitle =	 {Proceedings of the International Conference on
                  Information Fusion},
  year =	 2002,
}

@PhDThesis{Doucet97,
  EDITOR =	 {Doucet, A},
  TITLE =	 {Monte Carlo Methods for {Bayesian} Estimation of
                  Hidden {Markov} Models, Application to Radiation
                  Siganls},
  PUBLISHER =	 {Ph.D. Thesis, Univ. Paris-Sud, Orsay},
  YEAR =	 1997
}

@TechReport{Doucet98,
  author =	 {A. Doucet},
  title =	 {On sequential simulation-based methods for
                  {B}ayesian filtering},
  institution =	 {Department of Engineering, University of Cambridge},
  year =	 1998,
  number =	 "CUED/F-INFENG/TR.310",
}

@INPROCEEDINGS{Draper95,
  AUTHOR =	 "D. Draper ",
  FULLAUTHOR =	 "Denise Draper ",
  TITLE =	 "Clustering Without (Thinking About) Triangulation",
  crossref =	 {_UAI95},
  PAGES =	 "125-13",
  abstract =	 {The undirected technique for evaluating belief
                  networks [Jensen, et.al., 1990, Lauritzen and
                  Spiegelhalter, 1988] requires clustering the nodes
                  in the network into a junction tree. In the
                  traditional view, the junction tree is constructed
                  from the cliques of the moralized and triangulated
                  belief network: triangulation is taken to be the
                  primitive concept, the goal towards which any
                  clustering algorithm (e.g. node elimination) is
                  directed. In this paper, we present an alternative
                  conception of clustering, in which clusters and the
                  junction tree property play the role of primitives:
                  given a graph (not a tree) of clusters which obey (a
                  modified version of) the junction tree property, we
                  transform this graph until we have obtained a
                  tree. There are several advantages to this approach:
                  it is much clearer and easier to understand, which
                  is important for humans who are constructing belief
                  networks; it admits a wider range of heuristics
                  which may enable more efficient or superior
                  clustering algorithms; and it serves as the natural
                  basis for an incremental clustering scheme, which we
                  describe.}
}

@Article{Dreyden91,
  author =	 {I.L. Dreyden and K.V. Mardia},
  title =	 {General Shape Distributions in a Plane},
  journal =	 {Adv. Appl. Prob.},
  year =	 {1991},
  volume =	 23,
  pages =	 {259-276},
}

@InProceedings{Drinea02,
  author =	 {E. Drinea and A. Frieze and M. Mitzenmacher},
  title =	 "Balls and Bins Models with Feedback",
  booktitle =	 "Proceedings of the 11th Annual ACM-SIAM Symposium on
                  Discrete Algorithms",
  pages =	 {308-315},
  year =	 2002
}

@Article{Driscoll94,
  author =	 {J.R. Driscoll and D.M. Healy},
  title =	 {Computing {Fourier} transforms and convolutions on
                  the 2-sphere},
  journal =	 {Advances in Applied Mathematics},
  year =	 1994,
  pages =	 {202-250},
}

@InProceedings{Drocourt99,
  author =	 {X. Drocourt and L. Delahoche and C. Pegard and
                  A. Clerentin},
  title =	 {Mobile robot localization based on an
                  omnidirectional stereoscopic vision perception
                  system},
  booktitle =	 ICRA,
  pages =	 13291334,
  year =	 1999,
  month =	 {May},
  organization = {IEEE},
}

@InProceedings{Drudzel94fall,
  author =	 {M.J. Druzdzel and H.J. Suermondt},
  fullauthor =	 {Marek J. Druzdzel and Henri J. Suermondt},
  title =	 {Relevance in probabilistic models: {"}backyards{"}
                  in a {"}small world.{"}},
  booktitle =	 {Working notes of the AAAI-1994 Fall Symposium
                  Series: Relevance},
  pages =	 {60--63},
  year =	 1994,
  address =	 {New Orleans, LA},
  month =	 {November},
  c-dellaert =	 {\citet{Drudzel94fall} gives a nice overview of
                  relevance: the possibility of eliminating certain
                  nodes from consideration when querying a Bayes net.}
}

@Article{Duane87,
  author =	 "S. Duane and A.D. Kennedy and B.J. Pendleton and
                  D. Roweth",
  title =	 "Hybrid {M}onte {C}arlo",
  journal =	 "Physics Letters B",
  year =	 1987,
  volume =	 195,
  pages =	 "216-222",
}

@Article{ Dubois03ejor,
  author =	 {D. Dubois and H. Fargier and P. Fortemps},
  title =	 "{Fuzzy scheduling: Modelling flexible constraints
                  vs. coping with incomplete knowledge}",
  journal =	 {European Journal of Operational Research},
  publisher =	 {Elsevier Science},
  year =	 2003,
  volume =	 147,
  pages =	 {231--252},
  keywords =	 {RPDMP-SCF,RPDMP-PSI,RPDMP-MFD},
  abstract =	 {An overview of some fuzzy set-based approaches to
                  scheduling is proposed, emphasizing two distinct
                  uses of fuzzy sets: representing preference profiles
                  and modelling uncertainty distributions. The first
                  setting leads to a valued, noncompensatory
                  generalization of constraint-directed
                  scheduling. The other setting yields a
                  possibility-theoretic counterpart of PERT, where
                  probability distributions of activity durations are
                  changed into possibility distributions, for the
                  purpose of modelling incomplete information. It is
                  pointed out that a special case of the latter,
                  interval-valued PERT, is a difficult, ill-known
                  problem, regarding the determination of critical
                  activities, latest starting times and floats. Lastly
                  when flexible constraints and uncertain processing
                  times are to be jointly considered, the use of
                  possibilistic decision theory leads to the
                  computation of robust schedules. }
}

@Article{ Dubois96ai,
  author =	 {D. Dubois and H. Fargier and H. Prade},
  title =	 "{Possibility theory in constraint satisfaction
                  problems: Handling priority, preference and
                  uncertainty}",
  journal =	 {Applied Intelligence},
  year =	 1996,
  volume =	 6,
  pages =	 {287--309},
  URL =		 {ftp://ftp.irit.fr/pub/IRIT/RPDMP/PTCSPH.ps.gz},
  keywords =	 {RPDMP-RICL, RPDMP-SCF}
}

@INPROCEEDINGS{Duckett00icra,
  AUTHOR =	 "T. Duckett and S. Marsland and J. Shapiro",
  TITLE =	 "Learning Globally Consistent Maps by Relaxation",
  BOOKTITLE =	 ICRA,
  ADDRESS =	 "San Francisco, CA",
  YEAR =	 2000,
}

@ARTICLE{Duckett02ar,
  AUTHOR =	 "T. Duckett and S. Marsland and J. Shapiro",
  TITLE =	 "Fast, On-line Learning of Globally Consistent Maps",
  JOURNAL =	 AR,
  VOLUME =	 12,
  NUMBER =	 3,
  PAGES =	 {287--300},
  YEAR =	 2002
}


@inproceedings{Duckett03,
  author =	 {T. Duckett},
  title =	 {A Genetic Algorithm for Simultaneous Localization
                  and Mapping},
  booktitle =	 ICRA,
  year =	 2003,
  pages =	 {434-439},
}

@Book{DudaHart,
  author =	 "R. O. Duda and P. E. Hart",
  title =	 "Pattern Classification and Scene Analysis",
  publisher =	 "John Wiley and Sons",
  address =	 "New York",
  year =	 1973,
  ISBN =	 "0-471-22361-1"
}

@inproceedings{Dudek2000,
  author =	 {G. Dudek and D. Jugessur},
  title =	 {Robust Place Recognition using Local Appearance
                  based Methods},
  booktitle =	 ICRA,
  pages =	 {1030-1035},
  year =	 2000,
  c-ananth =	 {Dudek and Jugessur [Dudek2000] use Fourier
                  transforms of feature patches detected using
                  attention operators for recognizing landmarks and
                  overcoming ambiguity.},
}

@Article{Dudek91,
  author =	 {G. Dudek and M. Jenkin and E. Milios and D. Wilkes },
  title =	 "Robotic Exploration As Graph Construction",
  journal =	 TRA,
  year =	 1991,
  volume =	 7,
  number =	 6,
  pages =	 "859-865",
}

@article{Dudek91tra,
  title =	 {Robotic exploration as graph construction},
  author =	 {G. Dudek and M. Jenkin and E. Milios and D. Wilkes},
  journal =	 TRA,
  year =	 1991,
  month =	 {dec},
  Volume =	 7,
  number =	 6,
  pages =	 {859--865},
  abstract =	 {Addressed is the problem of robotic exploration of a
                  graphlike world, where no distance or orientation
                  metric is assumed of the world. The robot is assumed
                  to be able to autonomously traverse graph edges,
                  recognize when it has reached a vertex, and
                  enumerate edges incident upon the current vertex
                  relative to the edge via which it entered the
                  current vertex. The robot cannot measure distances,
                  and it does not have a compass. It is demonstrated
                  that this exploration problem is unsolvable in
                  general without markers, and, to solve it, the robot
                  is equipped with one or more distinct markers that
                  can be put down or picked up at will and that can be
                  recognized by the robot if they are at the same
                  vertex as the robot. An exploration algorithm is
                  developed and proven correct. Its performance is
                  shown on several example worlds, and heuristics for
                  improving its performance are discussed.},
  c-dellaert =	 {Not very interesting, toy-like examples.}
}

@InProceedings{Dudek93,
  author =	 {G. Dudek and S. Hadjres and P. Freedman},
  title =	 {Using local information in a non-local way for
                  mapping graph-like worlds},
  booktitle =	 IJCAI,
  pages =	 {1639--1645},
  year =	 1993,
  c-ananth =	 {Dudek. et. al. [Dudek93] have also given a technique
                  that maintains multiple hypotheses regarding the
                  topological structure of the environment in the form
                  of an exploration tree.},
}

@Article{Duff77ieee,
  author =	 {I.S. Duff},
  fullauthor =	 {Iain S. Duff},
  title =	 {A Survey of Sparse Matrix Research},
  journal =	 {Proceedings of the IEEE},
  year =	 1977,
  volume =	 65,
  number =	 4,
  pages =	 {500--535},
  month =	 {April},
  c-dellaert =	 {Long review paper, very thorough and useful},
}

@article{Duff78toms,
  author =	 {I. S. Duff and J. K. Reid},
  title =	 {An Implementation of Tarjan's Algorithm for the
                  Block Triangularization of a Matrix},
  journal =	 {ACM Trans. Math. Softw.},
  volume =	 4,
  number =	 2,
  year =	 1978,
  issn =	 {0098-3500},
  pages =	 {137--147},
  doi =		 {http://doi.acm.org/10.1145/355780.355785},
  publisher =	 {ACM Press},
  address =	 {New York, NY, USA},
}

@article{Duff83toms,
  author =	 {I. S. Duff and J. K. Reid},
  title =	 {The Multifrontal Solution of Indefinite Sparse
                  Symmetric Linear Systems},
  journal =	 {ACM Trans. Math. Softw.},
  volume =	 9,
  number =	 3,
  year =	 1983,
  issn =	 {0098-3500},
  pages =	 {302--325},
  doi =		 {http://doi.acm.org/10.1145/356044.356047},
  publisher =	 {ACM Press},
  address =	 {New York, NY, USA},
  abstract =	 {We extend the frontal method for solving linear
                  systems of equations by permitting more than one
                  front to occur at the same time. This enables us to
                  develop code for general symmetric systems. We
                  discuss the organization and implementation of a
                  multifrontal code which uses the minimum-degree
                  ordering and indicate how we can solve indefinite
                  systems in a stable manner We illustrate the
                  performance of our code both on the IBM 3033 and on
                  the CRAY-1.},
  quotes =	 {Less obviously, the general-purpose and remarkably
                  successful pivotal strategy of "minimum degree" can
                  be implemented in this way. Here each pivot is
                  chosen from the diagonal of the current reduced
                  matrix in a row with least nonzeros. },
  r-Blair93chapter ={However, chordal graphs and clique trees have
                  found a niche in more recent work in this area,
                  primarily due to various research questions
                  associated with advanced computer architectures. For
                  instance, the multifrontal method \cite{Duff83toms},
                  which was developed to obtain good performance on
                  vector supercomputers, can be expressed very
                  succinctly in terms of a clique tree representation
                  of the underlying chordal graph
                  \cite{Peyton86thesis, Pothen92siam}.},
  r-Heggernes96siam ={... the multifrontal technique, originally
                  proposed for symmetric sparse linear systems by
                  \cite{Duff83toms}, ...},
  c-dellaert =	 {Very sparse matrix}
}

@InProceedings{Duong05cvpr,
  author =	 "T. V. Duong and H. H. Bui and D. Q. Phung and
                  S. Venkatesh",
  title =	 {{Activity Recognition and Abnormality Detection with
                  the Switching Hidden Semi-Markov Model}},
  booktitle =	 CVPR,
  pages =	 "838- 845",
  year =	 2005,
  keywords =	 "HMM, Hierarchical model, activity recognition,
                  duration modeling",
  c-sangmin =	 "use two-layer HHMM for activity
                  recognition. introduce coxian duration model for
                  semi markov models which is simply done by splitting
                  the long time range into several coarser time
                  windows.The first layer is high-level activity,
                  second layer is Segmental HMM for each of the
                  high-level activities. The authors claim to use
                  novel discrete Coxian distribution, But, it turns
                  out that discrete Coxian is simply left-to-right
                  Markov chain with self-looping parameters as
                  (1-lambda_i), instead, the major point is that it
                  has prior distribution which can start at any point
                  on the chain with probability mu_i. So, discrete
                  Coxian is not at all more general than normal Markov
                  chain parameterization. Still, it is an interesting
                  attmpt to implement a compact duration
                  representation than explicit duration modeling.",
}

@InProceedings{Duong05is,
  author =	 "T. V. Duong and D. Q. Phung and H. H. Bui and
                  S. Venkatesh",
  title =	 {{Efficient Coxian Duration Modelling for Activity
                  Recognition in Smart Environments with the Hidden
                  semi-Markov Model}},
  booktitle =	 {{Proceedings of International Conference on
                  Intelligent Sensors, Sensor Networks and Information
                  Processing Conference}},
  pages =	 "277-282",
  year =	 2005,
  keywords =	 "HMM, Hierarchical model, activity recognition,
                  duration modeling, coxian distribution",
  c-sangmin =	 "almost identical to duong05cvpr",
}

@InProceedings{Duong06icpr,
  author =	 "T. V. Duong and D. Q. Phung and H. H. Bui and
                  S. Venkatesh",
  title =	 {{Human Behavior Recognition with Generic Exponential
                  Family Duration Modeling in the Hidden Semi-Markov
                  Model}},
  booktitle =	 ICPR,
  pages =	 "202-207",
  year =	 2006,
  keywords =	 "HMM, Hierarchical model, activity recognition,
                  duration modeling, coxian distribution",
  c-sangmin =	 "instead of Coxian distribution studied in
                  Duong05cvpr, the authors studied the use of general
                  class of exponential class duration models here,
                  which results in more descriptive basis unit, but
                  losing the power to create a duration model through
                  additive modeling as have been done for Coxian. The
                  results show that the choice of exponential
                  distributions do not over-perform simple multinomial
                  which is basically non-parametric, or coxian
                  distributions, but better than base HMMs. A good
                  reference which used exponential distribution for
                  duration modeling in speech is Mitchell93icassp.",
}

@InProceedings{	Durand00,
  author =	 "Frdo Durand and George Drettakis and Jolle
                  Thollot and Claude Puech",
  title =	 "Conservative Visibility Preprocessing Using Extended
                  Projections",
  booktitle =	 "Computer Graphics Proceedings (SIGGRAPH 00)",
  pages =	 "239--248",
  year =	 2000,
  editor =	 "Kurt Akeley",
  publisher =	 "ACM Press / ACM SIGGRAPH",
  note =	 "Annual Conference Series, SIGGRAPH'00",
  url =
                  "http://www-sop.inria.fr/reves/publications/data/2000/DDTP00"
}

@article{Durand02siggraph,
  author =	 {F.Durand and J.Dorsey},
  title =	 {Fast bilateral filtering for the display of
                  high-dynamic-range images},
  journal =	 "ACM SIGGRAPH",
  pages =	 {257--266},
  year =	 2002,
}

@Article{Durbin87,
  author =	 "R. Durbin and D. Willshaw",
  title =	 "An analog approach to the travelling salesman
                  problem using an elastic net method",
  journal =	 "Nature",
  volume =	 326,
  pages =	 "689--691",
  year =	 1987
}

@article{Durbin89,
  author =	 "R. Durbin and R. Szeliski and A. Yuille",
  title =	 "An analysis of the elastic net approach to the
                  travelling salesman problem",
  journal =	 "Neural Computation",
  volume =	 1,
  pages =	 "348--358",
  year =	 1989
}

@InProceedings{DurrantWhyte01,
  author =	 {H.F. Durrant-Whyte and S. Majunder and S. Thrun and
                  M. de Battista and S. Scheding},
  title =	 {A {B}ayesian algorithm for simultaneous localization
                  and map building},
  booktitle =	 {Proceedings of the 10th International Symposium of
                  Robotics Research},
  year =	 2001
}

@InProceedings{DurrantWhyte01fusion,
  author =	 {Durrant-Whyte, H. and Stevens, M.},
  title =	 {Data Fusion in Decentralized Sensing Networks},
  booktitle =	 {4th Intl. Conf. on Information Fusion},
  year =	 2001,
  address =	 {Montreal},
  abstract =	 {This paper briefly describes the results of a ten
                  year, and still on-going, research program in
                  decentralised sensing systems. This program covers
                  both the theoretical development of data fusion
                  methods appropriate to networks of decentralised
                  sensors and the practical implementation of these in
                  both civilian and military contexts. The methods
                  employed for studying the decentralized data fusion
                  problem are based on the information-filter
                  formulation of the Kalman filter algorithm and on
                  information-theoretic methods derived from Bayes
                  theorem. This theory is briefly described in context
                  of a number of practical implementations of
                  decentralised data fusion methods in surveillance
                  and control applications. The paper describes
                  specific theoretical tools developed to address such
                  issues as; decentralised communication management,
                  model distribution, decentralised data association
                  and fault detection, sensor control (information
                  gathering, target cuing and hand-off), decentralised
                  picture compilation and map building. Finally, we
                  describe our current work deployment of
                  decentralized, large-scale systems of systems
                  demonstrations.},
  c-dellaert =	 {DDF=3 constraints:no center, no global comms, no
                  global topology. Hence: scalable, survivable,
                  modular. Disses hierarchical. Decentralized is more
                  efficient. Information form: each sensor creates
                  (i,I) which are centrally fused, details in
                  Manyika94book. Decentralize by replication, needs
                  fully connected or tree (Utete, not well-published)},
}

@Article{DurrantWhyte06ram,
  author =	 {H.F. Durrant-Whyte and T. Bailey},
  fullauthor =	 {Hugh F. Durrant-Whyte and Tim Bailey},
  title =	 {Simultaneous Localisation and Mapping ({SLAM}): Part
                  {I} The Essential Algorithms},
  journal =	 {Robotics \& Automation Magazine},
  month =	 {Jun},
  year =	 {2006},
  abstract =	 {This tutorial provides an introduction to
                  Simultaneous Localisation and Mapping (SLAM) and the
                  extensive research on SLAM that has been undertaken
                  over the past decade. SLAM is the process by which a
                  mobile robot can build a map of an environment and
                  at the same time use this map to compute it's own
                  location. The past decade has seen rapid and
                  exciting progress in solving the SLAM problem
                  together with many compelling implementations of
                  SLAM methods. Part I of this tutorial (this paper),
                  describes the probabilistic form of the SLAM
                  problem, essential solution methods and significant
                  implementations. Part II of this tutorial will be
                  concerned with recent advances in computational
                  methods and new formulations of the SLAM problem for
                  large scale and complex environments.},
  c-kaess =	 {Good SLAM overview, history and related work; see
                  Bailey06ram for the second part},
}

@Article{DurrantWhyte88tra,
  author =	 {H.F. Durrant-Whyte},
  title =	 {Uncertain geometry in robotics},
  journal =	 TRA,
  Volume =	 4,
  number =	 1,
  pages =	 {23-31},
  year =	 1988,
  r-DurrantWhyte06ram ={Work by Smith and Cheesman [Smith87] and
                  Durrant-Whyte [this] established a statistical basis
                  for describing relationships between landmarks and
                  manipulating geometric uncertainty. A key element of
                  this work was to show that there must be a high
                  degree of correlation between estimates of the
                  location of different landmarks in a map and that
                  indeed these correlations would grow with successive
                  observations.},
}

@inproceedings{DurrantWhyte90icra,
  Author =	 {Durrant-Whyte, H. F. and Rao, B. Y. S. and Hu, H.},
  booktitle =	 ICRA,
  Pages =	 {1331--1336},
  volume =	 2,
  Title =	 {Toward a fully decentralized architecture for
                  multi-sensor data fusion},
  Year =	 1990,
  Abstract =	 {A fully decentralized architecture is presented for
                  data fusion problems. This architecture takes the
                  form of a network of sensor nodes, each with its own
                  processing facility, which together do not require
                  any central processor or any central communication
                  facility. In this architecture, computation is
                  performed locally and communication occurs between
                  any two nodes. Such an architecture has many
                  desirable properties, including robustness to
                  sensors failure and flexibility to the addition or
                  loss of one or more sensors. This architecture is
                  appropriate for the class of extended Kalman filter
                  (EKF)-based geometric data fusion problems. The
                  starting point for this architecture is an algorithm
                  which allows the complete decentralization of the
                  multisensor EKF equations among a number of sensing
                  nodes. This algorithm is described, and it is shown
                  how it can be applied to a number of different
                  data-fusion problems. An application of this
                  algorithm to the problem of multicamera, real-time
                  tracking of objects and people moving through a room
                  is described},
  quotes =	 {This architecture has no central processing facility
                  and no centralized communications medium, it does
                  not require any ad hoc structure, such as a
                  hierarchy, to be imposed on it, and it does not
                  require a controller to organize it. [...] the
                  Decentralized Kalman Filter (DKF) is an
                  implementation of a multi-sensor EKF which has been
                  divided up into modules, one associated with each
                  sensor. [...] The partitioning of [the centralized
                  EKF] equations follows the work of
                  \citet{Hashemipour88itac} in which a hierarchical
                  formulation of the Kalman Filter is derived. [...]
                  The extension of the linear DKF to deal with
                  non-linear state transitions and non-linear
                  observations is quite straight-forward.},
  c-dellaert =	 {H matrix is divided up in the obvious way, per
                  sensor. Some sleight of hand by having each sensor
                  have its own system model - not sure what he
                  means. The measurement story is really simple in
                  graph terms: there is only a single node of
                  unknowns, connect to a prior factor and several
                  measurement factors. The algorithm simply repeats
                  the information filter at each measurement factor,
                  i.e., the measurement information H'inv(R)H is
                  computed at each node and added to the information
                  matrix I. Then it gets the same quantities
                  (presumably n<m) from the other factors. The state
                  estimate is simply a weighted average. All of this
                  is obfuscated a bit by the cumbersome notation used,
                  i.e., P(k+1|k+1) style. Implementation on
                  transputers.}
}

@InCollection{DurrantWhyte96isrr,
  author =	 {H.F. Durrant-Whyte and D. Rye and E. Nebot},
  title =	 {Localisation of automatic guided vehicles},
  booktitle =	 {Robotics Research: The 7th International Symposium
                  ({ISRR} 95)},
  publisher =	 {Springer-Verlag},
  editor =	 {G. Giralt and G. Hirzinger},
  pages =	 {613-625},
  year =	 1996,
  r-DurrantWhyte06ram ={The conceptual break-through came with the
                  realisation that the combined mapping and
                  localisation problem, once formulated as a single
                  estimation problem, was actually convergent. Most
                  importantly, it was recognised that the correlations
                  between landmarks, that most researchers had tried
                  to minimize, were actually the critical part of the
                  problem and that, on the contrary, the more these
                  corre- lations grew, the better the solution. The
                  structure of the SLAM problem, the convergence
                  result and the coining of the acronym `SLAM' was
                  rst presented in a mobile robotics survey paper
                  presented at the 1995 International Symposium on
                  Robotics Research [this].},
}

@InProceedings{Duygulu02,
  author =	 {Pinar Duygulu, Kobus Barnard, Nando {de Freitas} and
                  David Forsyth},
  title =	 {Object recognition as machine translation: Learning
                  a lexicon for a fixed image vocabulary},
  booktitle =	 {ECCV},
  year =	 2002,
  pages =	 {97-112}
}

@article{Dyer90,
  author =	 {Harry Plantinga and Charles R. Dyer},
  title =	 {Visibility, occlusion, and the aspect graph},
  journal =	 {Int. J. Comput. Vision},
  volume =	 5,
  number =	 2,
  year =	 1990,
  issn =	 {0920-5691},
  pages =	 {137--160},
  doi =		 {http://dx.doi.org/10.1007/BF00054919},
  publisher =	 {Kluwer Academic Publishers},
  address =	 {Hingham, MA, USA},
}

@article{Dyer93,
  author =	 {D. W. Eggert and K. W. Bowyer and C. R. Dyer and
                  H. I. Christensen and D. B. Goldgof},
  title =	 {The Scale Space Aspect Graph},
  journal =	 {IEEE Trans. Pattern Anal. Mach. Intell.},
  volume =	 15,
  number =	 11,
  year =	 1993,
  issn =	 {0162-8828},
  pages =	 {1114--1130},
  doi =		 {http://dx.doi.org/10.1109/34.244674},
  publisher =	 {IEEE Computer Society},
  address =	 {Washington, DC, USA},
}

@InProceedings{Eade06cvpr,
  author =	 {E. Eade and T. Drummond},
  title =	 {Scalable Monocular {SLAM}},
  booktitle =	 CVPR,
  location =	 {New York, NY},
  month =	 {Jun},
  year =	 2006,
  abstract =	 {Localization and mapping in unknown environments
                  becomes more difficult as the complexity of the
                  environment increases. With conventional techniques,
                  the cost of maintaining estimates rises rapidly with
                  the number of landmarks mapped. We present a
                  monocular SLAM system that employs a particle filter
                  and top-down search to allow realtime performance
                  while mapping large numbers of landmarks. To our
                  knowledge, we are the first to apply this
                  FastSLAM-type particle filter to single-camera
                  SLAM. We also introduce a novel partial
                  initialization procedure that efficiently determines
                  the depth of new landmarks. Moreover, we use
                  information available in observations of new
                  landmarks to improve camera pose estimates. Results
                  show the system operating in real-time on a standard
                  workstation while mapping hundreds of landmarks.},
  r-Smith06bmvc ={Eade and Drummond [this] have developed a system
                  based on the FastSLAM algorithm, which combines
                  particle filtering for localisation with Kalman
                  filtering for mapping. FastSLAM has the advantage
                  that it scales better with the number of features,
                  but the absence of an explicit full covariance
                  matrix can make loop-closing more difficult.},
  c-kaess =	 {Combines FastSLAM with Davisons single camera
                  SLAM. top/down observations: constraint active
                  search for landmarks. Partial initialization based
                  on inverse depth formulation. Shows 200 landmark
                  example at frame rate with short range loop
                  closing. Uses eigenvalue analysis on covariance
                  matrix of landmarks over all particles. Claims that
                  for different numbers of particles (50-1000), all
                  capture a 30 dimensional space, implying "that 50
                  particles is sufficient for the sequence", but
                  remark that more analysis is necessary. Comment: 50
                  particles seem pretty lost in a 30 dimensional
                  state. For 30 dimensions 2^30=1G particles would
                  barely sample two alternatives per dimension - or am
                  I missing something here?},
}

@InProceedings{Eade07iccv,
  author =	 {E. Eade and T. Drummond},
  fullauthor =	 {Ethan Eade and Tom Drummond},
  title =	 {Monocular {SLAM} as a Graph of Coalesced
                  Observations},
  booktitle =	 ICCV,
  location =	 {Rio de Janeiro, Brazil},
  month =	 {Oct},
  year =	 2007,
  abstract =	 {We present a monocular SLAM system that avoids
                  inconsistency by coalescing observations into
                  independent local coordinate frames, building a
                  graph of the local frames, and optimizing the
                  resulting graph. We choose coordinates that minimize
                  the nonlinearity of the updates in the nodes, and
                  suggest a heuristic measure of such nonlinearity,
                  using it to guide our traversal of the graph. The
                  system operates in real-time on sequences with
                  several hundreds of landmarks while performing
                  global graph optimization, yielding accurate and
                  nearly consistent estimation relative to offline
                  bundle adjustment, and considerably better
                  consistency than EKF SLAM and FastSLAM.},
  c-kaess =	 {monocular, vision only, submaps; Monocular SLAM with
                  multiple local coordinate frames (nodes) in
                  combination with inverse depth representation to
                  avoid linearization issues. Local nodes are fully
                  optimized by (dense?) Cholesky/LM. The nodes are
                  combined in a larger graph that is fully optimized
                  by preconditioned gradient descent. 30Hz for 400
                  landmarks, 50 nodes.},
}

@article{Easton95jeplmc,
  author =	 {Easton, R. D. and Sholl, M. J.},
  year =	 1995,
  title =	 {Object-array structure, frames of reference, and
                  retrieval of spatial knowledge},
  journal =	 JEPLMC,
  volume =	 21,
  pages =	 {483--500},
  abstract =	 {Experiments are reported that assessed the ability
                  of people, without vision, to locate the positions
                  of objects from imagined points of observation that
                  are related to their actual position by rotational
                  or translational components. Theoretical issues
                  addressed were whether spatial relations stored in
                  an object-to-object system are directly retrieved or
                  whether retrieval is mediated by a bodycentered
                  coordinate system, and whether body-centered access
                  involves a process of imaging updating of
                  self-position. The results, with those of Rieser
                  (1989), indicate that in the case of regularly
                  structured object arrays, interobject relations are
                  directly retrieved for the translation task, but for
                  the rotation task, retrieval occurs by means of a
                  body-centered coordinate system, requiring imagined
                  body rotation. For irregularly structured arrays,
                  access of interobject spatial structure occurs by
                  means of a body-centered coordinate system for both
                  translation and rotation tasks, requiring imagined
                  body translation or rotation. Array regularity
                  affected retrieval of spatial structure in terms of
                  global shape of interobject relations and local
                  object position within global shape.},
  c-dellaert =	 {Allocentric (seperate from body) interrelations
                  between objects appear to be accessed through a
                  body-centered "view". Experiments showed that for
                  irregular arrays of objects, subjects needed to
                  "imagine" their body at the correct viewpoint in
                  order to answer questions. Tidbit: mentions objet
                  relations are obtained through body coordinates when
                  listening to fiction.},
}

@Article{Eckart36,
  author =	 {C. Eckart and G. Young},
  title =	 {The Approximation of One Matrix by Another Low Rank},
  journal =	 {Psychometrika},
  year =	 1936,
  volume =	 1,
  pages =	 {211-218}
}

@InCollection{Edelman08chapter,
  author =	 {S. Edelman},
  fullauthor =	 {Shimon Edelman},
  title =	 {On what it means to see, and what we can do about
                  it},
  booktitle =	 {Object Categorization: Computer and Human Vision
                  Perspectives,},
  publisher =	 {Cambridge University Press,},
  year =	 2008,
  editor =	 {S. Dickinson, A. Leonardis, B. Schiele, and
                  M. J. Tarr},
  quotes =	 {A being with such powers of observation would be
                  very good at "seeing as": for instance, should it
                  have had sufficient experience in outer space
                  travel, it may be capable of seeing the street scene
                  as a reenactment of a series of collisions among
                  rock and ice fragments in a particular cubic
                  kilometer of the Oort cloud on January 1, 0800 hours
                  UTC, 2008 CE, which it happened to have viewed while
                  on a heliopause cruise. .. Note that although the
                  evolution of visual systems may well be driven by
                  their role in supporting action and by their being
                  embodied in active, purposive agents (Noe, 2004),
                  once the system is in place no action is required
                  for it to "just see" (Edelman, 2006). .. [A key
                  realization is that] rather than conceptual,
                  purposive, and interpretation-driven, visual
                  experience, whether rich or impoverished, is
                  representational. As Wittgenstein (1958) noted, "To
                  interpret is to think, to do something; seeing is a
                  state." .. Both the feasibility of and the need for
                  an explicit and sweeping reconstruction of the
                  geometry of the visual world have been subsequently
                  questioned (Aloimonos et al., 1988; Bajcsy,
                  1988). Noting that biological vision is purposive
                  and active, researchers proposed that computer
                  vision too should aim at serving certain
                  well-defined goals such as navigation or recognition
                  rather than at constructing a general-purpose
                  representation of the world. .. From the
                  computational standpoint, this development amounted
                  to shifting the focus of research from "inverse
                  optics" approaches (Bertero et al., 1988), which aim
                  to recover the solid geometry of the viewed scene,
                  to managing feature-based evidence for task-specific
                  hypotheses about the input (Edelman and Poggio,
                  1989). .. Anticipating the idea of O'Regan (1992)
                  and O'Regan and Noe (2001) who argued that the world
                  is its own best representation, Reitman et
                  al. (1978, p.72) observed that "The primary function
                  of perception is to keep our internal framework in
                  good registration with that vast external memory,
                  the external environment itself."},
  c-dellaert =	 {Distinction between "just seeing" and "seeing as",
                  repectively open-ended reconstruction-like and
                  categorization/recognition.},
}

@TechReport{Edelman89,
  author =	 "S Edelman and S Bulthoff and D Weinshall",
  title =	 "Stimulus familiarity determnines recognition
                  strategy for novel {3D} objects",
  institution =	 "MIT AI Lab",
  year =	 "1989",
  number =	 "1138",
}

@article{Edelman97tics,
  author =	 {Edelman, S.},
  title =	 {Computational theories of object recognition},
  journal =	 {Trends Cogn. Sci.},
  volume =	 1,
  pages =	 {296--304},
  year =	 1997,
  abstract =	 {This paper examines four current theoretical
                  approaches to the representation and recognition of
                  visual objects: structural descriptions, geometric
                  constraints, multidimensional feature spaces, and
                  shape-space approximation. The strengths and the
                  weaknesses of the theories are considered, with a
                  special focus on their approach to categorization ?
                  a computationally challenging task which is not
                  widely addressed in computer vision (where the
                  stress is rather on the generalization of
                  recognition across changes of viewpoint).},
  quotes =	 {Because of the effects of orientation, for instance,
                  simply storing a particular snapshot of an object
                  for future reference would not do: another view of
                  the same object may turn out to be less similar to
                  the stored view than to a view of a different
                  object, leading to an erroneous recognition.},
  c-dellaert =	 {Two axes: Shape vs. Recognition, Recognition
                  vs. Categorization. 4 Approaches: Structural
                  Decomposition, Geometric Constraints,
                  Multidimensional Feature Spaces, Approximation in
                  feature Spaces (prototypes). },
}

@book{Edelman99book,
  title =	 {Representation and Recognition in Vision},
  author =	 {S. Edelman},
  fullauthor =	 {Shimon Edelman},
  year =	 1999,
  address =	 {Cambridge,MA},
  publisher =	 {The MIT Press},
  review =	 {David Foster Department of Optometry and
                  Neuroscience, UMIST, Manchester, UK \\ As we move
                  about the world and view objects from different
                  distances and directions, the images projected onto
                  the retina are correspondingly transformed?y
                  translation, magnification, rotation and so on. How,
                  despite rarely experiencing the same image twice, do
                  we recognize an object as being the same? This
                  problem has had a long and varied history involving
                  disparate disciplines: philosophy and psychology;
                  computer science, mathematics, and engineering;
                  anatomy and physiology; and, to a limited extent,
                  neurology. There is still no universally accepted
                  solution. In broad terms, explanatory theories can
                  be divided into two kinds: those that concentrate on
                  the nature of the internal model or representation
                  that the visual system forms of an object in the
                  external world, and those that concentrate on how
                  that representation alters with changes in the pose
                  of the object or changes in observer viewpoint. The
                  two approaches involve a trade-off. Thus, if the
                  representation is assumed to alter with a change in
                  viewpoint, then the visual system needs to apply an
                  internal restoring, interpolating, or normalizing
                  transformation for recognition to occur; and the
                  more work that is done in forming the representation
                  (the more invariant it is to viewpoint changes), the
                  less work that needs to be done in normalizing
                  it. In practice, factors such as the need to retain
                  information about viewpoint changes and whether
                  objects are to be compared simultaneously or
                  sequentially influence the extent of the
                  trade-off. \\ One of the first significant
                  theoretical analyses of visual (and auditory)
                  representation and recognition was undertaken in the
                  1940s by Walter Pitts and Warren McCulloch, who
                  showed how a biological system could calculate
                  constant properties?nvariants?f entire images under
                  changes in viewpoint. It was not at all clear,
                  however, whether these global invariants could, or
                  should, be computed; moreover, the required
                  biological machinery seemed demanding, and the
                  representations assumed to be produced took little
                  account of the structure of the images presented to
                  the organism. \\ In the decades that followed, a
                  more object-centred approach to the problem of
                  extracting invariants developed. The idea was to
                  associate with each image a `structural
                  description', specifying the configuration of an
                  object's components or local features (e.g. lines
                  and edges) in terms of discrete or qualitative
                  relations between those features (e.g. `joined to',
                  `above', `left of'). Such a description was
                  naturally invariant to translations and
                  magnifications of the image on the retina, and,
                  depending on the choice of relations, to its
                  rotations. \\ A particular structural-description
                  theory of recognition, called
                  `recognition-by-components', has been advocated by
                  Irving Biederman. Here, the object components are
                  generalized cones, derived from contrasts of five
                  edge cues in a two-dimensional image: curvature,
                  collinearity, symmetry, parallelism and
                  co-termination. Visual detection of these elementary
                  properties is assumed to be invariant over viewing
                  position. Experiments on picture priming, where
                  speed and accuracy of recognition of a briefly
                  presented picture is facilitated by prior
                  presentation, suggested that priming depends on
                  activation of these components. Changes in position,
                  size, orientation-in-depth, or the particular lines
                  and vertices present in the image did not affect the
                  magnitude of the priming, as long as the same
                  generalized-cone components were assumed to be
                  activated. \\ Descriptions of the structure of
                  images based on object parts are appealing because
                  objects are often only part-seen, for example, from
                  the front only, or occluded by other objects. Such
                  descriptions naturally represent non-rigid or
                  articulated objects, for example, a body or hand;
                  and, phenomenologically, they accommodate our
                  experience that objects, such as a cup or a face,
                  are actually perceived as comprising
                  parts. Nevertheless, there has been some debate in
                  the literature about how well object parts can be
                  extracted from images and how well such descriptions
                  account for data on the recognition of novel and
                  familiar objects that have been rotated in depth. \\
                  An alternative to describing the structure of images
                  in terms of combinations of generic primitive shapes
                  is to describe them in terms of memory records of
                  similar images. One starting point for this theory
                  is that it is unreasonable for a visual system to
                  treat all possible shapes within the same parametric
                  framework: whereas similar shapes may need to be
                  compared in detail, very different shapes need
                  merely to be distinguished from each other. How,
                  then, should similar images be described? For a
                  given class of similar shapes, it is known from
                  statistical pattern-recognition theory that a
                  representation can be obtained in a common space
                  spanned by a small set of reference shapes,
                  generally referred to as basis functions. One way of
                  generating basis functions is to apply the
                  statistical technique of principal-components
                  analysis, which has been used successfully to
                  explain how the visual system approximates a
                  solution to the theoretically simpler problem of
                  surface colour constancy, that is, the constant
                  colour appearance of an object's surface independent
                  of the illuminant on the scene. Another way of
                  generating basis functions from a set of data is to
                  expose an artificial neural network to prototypical
                  examples drawn from that set. \\ In Representation
                  and Recognition in Vision, Shimon Edelman sets out
                  the case for such a network-based scheme called
                  Chorus. In this scheme, vectors of proximities to a
                  small number of prototypes are used to span the
                  representation space. The prototypes are derived
                  from recurring stable patterns of primitive
                  features, which, by definition, correspond to
                  frequently observed objects. Each prototype is
                  represented by an interpolation mechanism similar to
                  a basis-function neural network tuned to several of
                  the object's views, and is learned from examples. \\
                  The elementary building block of Chorus? unit tuned
                  to a specific view of a specific object?s inherently
                  viewpoint-dependent, but, because the tuning of the
                  individual units is wide (that is, they also
                  respond, usually less well, to views that differ
                  from the optimal), it is possible for a collection
                  of such units to interpolate the entire space of
                  views for a given object. Viewpoint invariance
                  achieved in this way will be approximate and
                  specific for the given object and the degree of
                  viewpoint invariance will decrease when the objects
                  to be discriminated are similar to each other. A
                  system of several object-specific modules of this
                  kind should exhibit some viewpoint invariance for
                  novel objects, by interpolating between the view
                  spaces of the familiar ones. \\ Support for Chorus
                  has come from experiments with synthesized images of
                  abstract, paperclip-like objects and more natural
                  animal-like objects. In one experiment, human
                  subjects were trained to discriminate between
                  computer images selected from classes of monkey-like
                  and dog-like objects. After subjects reached 90\%
                  correct on a fixed canonical view of each object,
                  discrimination performance was tested for novel
                  views that differed by up to 60?from the training
                  view. Despite differing only parametrically, that
                  is, in degree rather than in kind, these objects
                  were recognized virtually independently of
                  viewpoint, providing that the two classes were
                  sufficiently dissimilar. These and the results of
                  other experimental tests were taken as evidence for
                  a theory of recognition by views and against a
                  theory of recognition by components. \\ Which of
                  these two theories is the more appropriate
                  description of human object recognition is unlikely
                  to be resolved by appeals to neurobiology. For
                  example, recordings in macaque temporal cortex have
                  shown specificity for face view and gaze direction,
                  and the extent of any invariance to viewing
                  conditions is limited to about ?0?rotation in
                  depth. These results are certainly consistent with
                  Chorus, but, as Edelman points out, it is possible
                  that the function of the underlying units could be
                  irrelevant to the process of object recognition. \\
                  Views-based theories suffer from certain
                  foundational problems, as Edelman readily
                  acknowledges. Thus, a principled way needs to be
                  found for defining the set of objects constituting
                  the training set and for dealing with occlusion and
                  interference between the images of neighbouring
                  objects in a scene. There are also some outstanding
                  experimental issues; for example, how to account for
                  psychophysical data showing that shape recognition
                  and discrimination vary systematically with the
                  position of the image on the retina. More
                  critically, there is persistent evidence that small
                  changes in object shape can influence visual
                  perception in a way that seems more naturally
                  explained by components-based theory than by
                  views-based theory. \\ In Representation and
                  Recognition in Vision, Edelman argues strongly for a
                  particular approach to modelling human object
                  recognition, focusing arguments and evidence to that
                  end. It is a stimulating and informative book, but
                  better suited to the sophisticated reader, and
                  rather less so to the beginner hoping to achieve a
                  broad understanding of a sometimes contentious
                  field.},
  c-dellaert =	 {Book advocating view-based recognition, with an
                  implementation called Chorus}
}

@inproceedings{Efros03iccv,
  author =	 "A. A. Efros, A. C. Berg, G. Mori, J. Malik",
  fullauthor =	 "Alexei A. Efros, Alexander C. Berg, Greg Mori,
                  Jitendra Malik",
  title =	 {{Recognizing Action at a Distance}},
  booktitle =	 ICCV,
  pages =	 "726-733",
  year =	 "2003",
}

@inproceedings{Efros99iccv,
  author =	 "A.A. Efros and T.K. Leung",
  fullauthor =	 "Alexei A. Efros and Thomas K. Leung",
  title =	 "Texture Synthesis by Non-parametric Sampling",
  booktitle =	 ICCV,
  pages =	 "1033-1038",
  year =	 "1999",
}

@InProceedings{Egerstedt05icra,
  author =	 {M. Egerstedt and T. Balch and F. Dellaert and
                  F. Delmotte and Z. Khan},
  title =	 {What Are the Ants Doing? {Vision}-Based Tracking and
                  Reconstruction of Control Programs},
  booktitle =	 ICRA,
  year =	 2005,
  month =	 {April},
}

@article{Eggert93,
  author =	 {D. W. Eggert and K. W. Bowyer and C. R. Dyer and
                  H. I. Christensen and D. B. Goldgof},
  title =	 {The Scale Space Aspect Graph},
  journal =	 {IEEE Trans. Pattern Anal. Mach. Intell.},
  volume =	 15,
  number =	 11,
  year =	 1993,
  issn =	 {0162-8828},
  pages =	 {1114--1130},
  doi =		 {http://dx.doi.org/10.1109/34.244674},
  publisher =	 {IEEE Computer Society},
  address =	 {Washington, DC, USA},
}

@inproceedings{Ekvall06iros,
  title =	 "{Integrating Active Mobile Robot Object Recognition
                  and SLAM in Natural Environments}",
  author =	 {S. Ekvall and P. Jensfelt and D. Kragic},
  booktitle =	 IROS,
  year =	 2006,
}

@article{Ekvall07robotica,
  title =	 "{Integrating SLAM and Object Detection for Service
                  Robot Tasks}",
  author =	 {S. Ekvall and P. Jensfeld and D. Kragic},
  journal =	 {Robotica},
  year =	 2007,
  note =	 {Accepted},
}

@Article{Elad97,
  author =	 {M. Elad and A. Feuer},
  title =	 {Restoration of Single Super-Resolution Image From
                  Several Blurred, Noisy and Down-Sampled Measured
                  Images},
  journal =	 IP,
  year =	 1997,
  volume =	 6,
  number =	 12,
  month =	 {December},
  pages =	 {1646-58}
}

@Article{Elad98,
  author =	 {M. Elad and A. Feuer},
  title =	 {Super-Resolution Restoration of An Image Sequence -
                  Adaptive Filtering Approach},
  journal =	 IP,
  year =	 1998,
  note =	 {(Accepted for Publication)}
}

@PhdThesis{EladPhd,
  author =	 {M. Elad},
  title =	 {???},
  school =	 {Technion University},
  year =	 1996,
}

@Article{Elfes87ra,
  author =	 {A. Elfes},
  title =	 {Occupancy Grids: A Probabilistic Framework for Robot
                  Perception and Navigation},
  journal =	 {Journal of Robotics and Automation},
  year =	 1987,
  volume =	 {RA-3},
  number =	 3,
  pages =	 {249-265},
  month =	 {June},
}

@InProceedings{Elgammal00eccv,
  author =	 {A. Elgammal and D. Harwood and L. Davis},
  title =	 {Non-parametric Model for Background Subtraction},
  booktitle =	 ECCV,
  pages =	 {751-767},
  year =	 2000,
  abstract =	 {Background subtraction is a method typically used to
                  seg- ment moving regions in image sequences taken
                  from a static camera by comparing each new frame to
                  a model of the scene background. We present a novel
                  non-parametric background model and a background
                  subtraction approach. The model can handle
                  situations where the back- ground of the scene is
                  cluttered and not completely static but contains
                  small motions such as tree branches and bushes. The
                  model estimates the probability of observing pixel
                  intensity values based on a sample of intensity
                  values for each pixel. The model adapts quickly to
                  changes in the scene which enables very sensitive
                  detection of moving targets. We also show how the
                  model can use color information to suppress detec-
                  tion of shadows. The implementation of the model
                  runs in real-time for both gray level and color
                  imagery. Evaluation shows that this approach
                  achieves very sensitive detection with very low
                  false alarm rates.},
  c-houdan =	 {Kernel Density Estimation (KDE) + spatial
                  correlation in modeling + chromaticity coordinates
                  for removing shadow},
}

@InProceedings{Eliazar03,
  title =	 {{DP-SLAM}: Fast, Robust Simultaneous Localization
                  and Mapping without Predetermined Landmarks},
  author =	 {Austin Eliazar and Ronald Parr},
  booktitle =	 IJCAI,
  year =	 {2003},
}

@InProceedings{Eliazar04icra,
  author =	 {A.I. Eliazar and R. Parr},
  fullauthor =	 {Austin I. Eliazar and Ronald Parr},
  title =	 {{DP-SLAM 2.0}},
  booktitle =	 ICRA,
  pages =	 {1314-1320},
  year =	 2004,
  abstract =	 {Probabilistic approaches have proved very successful
                  at addressing the basic problems of robot
                  localization and mapping and they have shown great
                  promise on the combined problem of simultaneous
                  localization and mapping (SLAM). One approach to
                  SLAM assumes relatively sparse, relatively
                  unambiguous landmarks and builds a Kalman filter
                  over landmark positions. Other approaches assume
                  dense sensor data which individually are not very
                  distinctive, such as those available from a laser
                  range finder. In earlier work, we presented an
                  algorithm called DP-SLAM, which provided a very
                  accurate solution to the latter case by efficiently
                  maintaining a joint distribution over robot maps and
                  poses. The approach assumed an extremely accurate
                  laser range finder and a deterministic
                  environment. In this work we demonstrate an improved
                  map representation and laser penetration model, an
                  improvement in the asymptotic efficiency of the
                  algorithm, and empirical results of loop closing on
                  a high resolution map of a very challenging domain.},
}

@InProceedings{Elinas06icra,
  author =	 {P. Elinas and R. Sim and J.J. Little},
  fullauthor =	 {Pantelis Elinas and Robert Sim and James J. Little},
  title =	 {$\sigma${SLAM}: Stereo Vision {SLAM} Using the
                  {R}ao-{B}lackwellised Particle Filter and a Novel
                  Mixture Proposal Distribution},
  booktitle =	 ICRA,
  location =	 {Orlando, FL},
  month =	 {May},
  year =	 2006,
  abstract =	 {We consider the problem of Simultaneous Localization
                  and Mapping (SLAM) using the Rao-Blackwellised
                  Particle Filter (RBPF) for the class of indoor
                  mobile robots equipped only with stereo vision. Our
                  goal is to construct dense metric maps of natural 3D
                  point landmarks for large cyclic environments in the
                  absence of accurate landmark position measurements
                  and motion estimates. Our work differs from other
                  approaches because landmark estimates are derived
                  from stereo vision and motion estimates are based on
                  sparse optical flow. We distinguish between
                  landmarks using the Scale Invariant Feature
                  Transform (SIFT). This is in contrast to current
                  popular approaches that rely on reliable motion
                  models derived from odometric hardware and accurate
                  landmark measurements obtained with laser
                  sensors. Since our approach depends on a particle
                  filter whose main component is the proposal
                  distribution, we develop and evaluate a novel
                  mixture proposal distribution that allows us to
                  robustly close large loops. We validate our approach
                  experimentally for long camera trajectories
                  processing thousands of images at reasonable frame
                  rates.},
  c-kaess =	 {Conference version and extension of Sim05rur, that
                  applied FastSLAM to Se02ijrr, in order to map larger
                  environments without the need for odometry. Uses
                  DoG/scale feature points together with SIFT
                  descriptors for stereo and structure matching. Wheel
                  odometry is replaced by visual odometry, derived
                  from minimizing the reprojection error (LM+SVD) for
                  two sets of 3D points from two consecutive stereo
                  images. The proposal distribution is a mixture of
                  the standard distribution based on the motion model
                  and a distribution based on the latest observation
                  and learned map (similar to FastSLAM 2.0). The
                  mixing ratio depends on the age of the landmarks,
                  and uses exclusively the standard distribution if no
                  loops are closed. Experimental results are shown for
                  two data sets (offline, average 1.5 seconds per
                  frame for 500 particles and 80000 landmarks), using
                  ground-truth poses and comparing with visual
                  odometry. Also shows a 2D occupancy grid, which can
                  be obtained if needed.},
}

@InProceedings{Elinas07vslam,
  author =	 {P. Elinas and J.J. Little},
  fullauthor =	 {Pantelis Elinas and James J. Little},
  title =	 {Stereo vision {SLAM}: Near real-time learning of 3D
                  point-landmark and 2D occupancy-grid maps using
                  particle filters},
  booktitle =	 {IROS visual SLAM workshop},
  location =	 {San Diego},
  month =	 {Oct},
  year =	 2007,
  abstract =	 {This paper summarizes our past work on solving the
                  visual Simultaneous Localization and Mapping Problem
                  (SLAM). We focus on robots equipped with stereo
                  vision and develop a SLAM solution based on the
                  theory of the Rao-Blackwellised particle filter
                  (RBPF). We refer to our method as $\sigma$SLAM. We
                  construct maps of 3D point-landmarks identified by
                  their visual appearance. Specifically, we use the
                  Scale Invariant Feature Transform (SIFT) for
                  distinguishing among the thousands of landmarks
                  present in the robot? environment. Our particle
                  filter approach utilizes a mixture proposal
                  distribution and accurately tracks the position of
                  the robot and the landmarks over long
                  trajectories. In addition, we do not depend on robot
                  odometry in the particle filter? proposal mechanism;
                  instead, we develop a proposal distribution that
                  relies on visual odometry easing the transition
                  towards a SLAM solution for robots performing 3D
                  motion. Most importantly, $\sigma$SLAM works in near
                  real-time making it applicable for use with mobile
                  robots today. Moreover, we show that we can
                  construct 2D occupancy-grid maps from stereo vision;
                  these are useful for path planning and obstacle
                  avoidance. Finally, we validate our approach
                  experimentally mapping large indoor environments
                  processing thousands of images.},
  c-kaess =	 {FastSLAM, stereo, sparse features, no odometry,
                  planar motion assumption, not real-time, 2 room
                  example},
}

@inproceedings{Elkan06icml,
  title =	 {Clustering documents with an exponential-family
                  approximation of the Dirichlet compound multinomial
                  distribution},
  author =	 {C. Elkan},
  booktitle =	 ICML,
  pages =	 {289--296},
  year =	 2006,
}

@article{ElliotGraphics,
  author =	 {Elliot},
  title =	 {Graphics},
  journal =	 {Languages},
  year =	 2001,
}

@article{ElliotImages,
  author =	 {Elliot},
  title =	 {Images},
  journal =	 {Languages},
  year =	 2001,
}

@Misc{EncBritPitViper06,
  author =	 {Encyclopedia {B}ritannica},
  title =	 "Pit Viper",
  year =	 2006,
  url =		 {http://www.britannica.com/eb/article-9375356},
}

@InProceedings{Engels06pcv,
  author =	 {C. Engels and H. Stew\'enius and D. Nist\'er},
  fullauthor =	 {Christopher Engels and Henrik Stew\'enius and David
                  Nist\'er},
  title =	 {Bundle Adjustment Rules},
  booktitle =	 {Symposium on Photogrammetric Computer Vision},
  location =	 {Bonn, Germany},
  pages =        {266-271},
  month =	 {Sep},
  year =	 2006,
  abstract =	 {In this paper we investigate the status of bundle
                  adjustment as a component of a real-time camera
                  tracking system and show that with current computing
                  hardware a significant amount of bundle adjustment
                  can be performed every time a new frame is added,
                  even under stringent real-time constraints. We also
                  show, by quantifying the failure rate over long
                  video sequences, that the bundle adjustment is able
                  to significantly decrease the rate of gross failures
                  in the camera tracking. Thus, bundle adjustment does
                  not only bring accuracy improvements. The accuracy
                  improvements also suppress error buildup in a way
                  that is crucial for the performance of the camera
                  tracker. Our experimental study is performed in the
                  setting of tracking the trajectory a calibrated
                  camera moving in 3D for various types of motion,
                  showing that bundle adjustment should be considered
                  an important component for a state-of-the-art
                  real-time camera tracking system.},
  c-kaess =	 {Nice bundle adjustment math review, including LM and
                  robust error function. Uses Schur complement to
                  obtain linear system for camera parameters, which is
                  then solved by plain Cholesky. Notes that for tens
                  of cameras, the outer product is more expensive than
                  plain Cholesky. Claims that bundle adjustment is the
                  way to go, but needs to be implemented
                  properly. Results show that bundle adjustment leads
                  to better camera tracking, by quantifying its impact
                  on the tracking failure rate. Also shows that
                  real-time applications are possible with todays
                  hardware, when adjusting a constant number of recent
                  views. An example is 1ms per SBA iteration (3-4
                  typically sufficient) for 260 features and 10 free
                  cameras.},
  c-dellaert =	 {They don't consider the "oter product" to be part of
                  linear solving, which is bogus. You could just do
                  sparse Cholesky and it would do the outer product
                  automatically, perhaps even faster. I wonder whether
                  we could write a Bundle Adjustment Rules 2.0 for
                  ICCV where we shou their results and compare them
                  with re-ordering and iSAM. Other interesting facts:
                  they use the "sines of the Euler angles" as rotation
                  parameterization, to initialize they do view 1-3
                  then resect view 2, to extend the sequence they do
                  three point resectioning ransac.},
}

@article{Eppstein92jacm,
  author =	 {D. Eppstein and Z. Galil and R. Giancarlo and
                  G.F. Italiano},
  fullauthor =	 {David Eppstein and Zvi Galil and Raffaele Giancarlo
                  and Giuseppe F. Italiano},
  title =	 {Sparse dynamic programming I: linear cost functions},
  journal =	 {J. ACM},
  volume =	 39,
  number =	 3,
  year =	 1992,
  issn =	 {0004-5411},
  pages =	 {519--545},
  doi =		 {http://doi.acm.org/10.1145/146637.146650},
  publisher =	 {ACM Press},
  address =	 {New York, NY, USA},
  abstract =	 {Dynamic programming solutions to a number of
                  different recurrence equations for sequence
                  comparison and for RNA secondary structure
                  prediction are considered. These recurrences are
                  defined over a number of points that is quadratic in
                  the input size; however only a sparse set matters
                  for the result. Efficient algorithms for these
                  problems are given, when the weight functions used
                  in the recurrences are taken to be linear. The time
                  complexity of the algorithms depends almost linearly
                  on the number of points that need to be considered;
                  when the problems are sparse this results in a
                  substantial speed-up over known algorithms.}
}

@article{Eppstein92jacm2,
  author =	 {D. Eppstein and Z. Galil and R. Giancarlo and
                  G.F. Italiano},
  fullauthor =	 {David Eppstein and Zvi Galil and Raffaele Giancarlo
                  and Giuseppe F. Italiano},
  title =	 {Sparse dynamic programming II: convex and concave
                  cost functions},
  journal =	 {J. ACM},
  volume =	 39,
  number =	 3,
  year =	 1992,
  issn =	 {0004-5411},
  pages =	 {546--567},
  doi =		 {http://doi.acm.org/10.1145/146637.146656},
  publisher =	 {ACM Press},
  address =	 {New York, NY, USA},
  abstract =	 {Dynamic programming solutions to two recurrence
                  equations, used to compute a sequence alignment from
                  a set of matching fragments between two strings, and
                  to predict RNA secondary structure, are
                  considered. These recurrences are defined over a
                  number of points that is quadratic in the input
                  size; however, only a sparse set matters for the
                  result. Efficient algorithms are given for solving
                  these problems, when the cost of a gap in the
                  alignment or a loop in the secondary structure is
                  taken as a convex or concave function of the gap or
                  loop length. The time complexity of our algorithms
                  depends almost linearly on the number of points that
                  need to be considered; when the problems are sparse,
                  this results in a substantial speed-up over known
                  algorithms.},
}

@TechReport{Epstein95,
  Title =	 "5+/-2 Eigenimages Suffice: An Empirical
                  Investigation of Low-Dimensional Lighting Models",
  author =	 "Russel Epstein and P. W Hallinan and Alan L Yuille",
  institution =	 "Division of Applied Sciences, Harvard University",
  year =	 1995,
}

@article{ Epstein96orcv,
  author =	 "R. Epstein and A. L. Yuille and P. N. Belhumeur",
  title =	 "Learning object representations from lighting
                  variations",
  journal =	 "Object Representation in Computer Vision II",
  pages =	 "179--199",
  year =	 1996,
}

@UnPublished{Escobar88,
  author =	 "Escobar, M. D.",
  year =	 1988,
  title =	 "Estimating the Means of Several Normal Populations
                  by Nonparametric Estimation of the Distribution of
                  the Means",
  note =	 "Unpublished dissertation, Yale University",
}

@Article{Estrada05tro,
  author =	 {C. Estrada and J. Neira and J.D. Tards},
  fullauthor =	 {Carlos Estrada and Jose Neira and Juan D. Tards},
  title =	 {Hierarchical {SLAM}: Real-Time Accurate Mapping of
                  Large Environments},
  journal =	 TRO,
  volume =	 21,
  number =	 4,
  pages =	 {588-596},
  month =	 {Aug},
  year =	 2005,
  abstract =	 {In this paper, we present a hierarchical mapping
                  method that allows us to obtain accurate metric maps
                  of large environments in real time. The lower (or
                  local) map level is composed of a set of local maps
                  that are guaranteed to be statistically
                  independent. The upper (or global) level is an
                  adjacency graph whose arcs are labeled with the
                  relative location between local maps. An estimation
                  of these relative locations is maintained at this
                  level in a relative stochastic map. We propose a
                  close to optimal loop closing method that, while
                  maintaining independence at the local level, imposes
                  consistency at the global level at a computational
                  cost that is linear with the size of the
                  loop. Experimental results demonstrate the
                  efficiency and precision of the proposed method by
                  mapping the Ada Byron building at our campus. We
                  also analyze, using simulations, the precision and
                  convergence of our method for larger loops.},
  c-Alireza =	 {In this paper they build independent local maps,
                  similar to Williams02icra. The reason that the local
                  maps are independent and it is not needed to update
                  the covariance of the other local maps when adding
                  an observation for a particular local map is that,
                  The reference of the local map is the location of
                  first robot pose with complete confidence(zero
                  covariance). This idea is same as
                  Williams02icra. But what makes this paper is
                  different is using the loop closing for improving
                  the relative location of local maps with respect to
                  each other in the global map. They don't use this
                  data to update the local maps, because if so they
                  would have become dependent to each other. The good
                  thing about using the local maps is that since the
                  updates are carried on local data, it reduces the
                  harmful effect of linearization. }
}

@article{Estrada05tro,
  author =	 {C. Estrada and J. Neira and J.D. Tards},
  fullauthor =	 {Carlos Estrada and Jose Neira and Juan D. Tards},
  year =	 {2005},
  month =	 {August},
  title =	 {Hierarchical {SLAM}: Real-Time Accurate Mapping of
                  Large Environments},
  journal =	 TRO,
  volume =	 {21},
  number =	 {4},
  pages =	 {588-596},
}

@InProceedings{Eustice05icra,
  author =	 {Eustice, R. and Singh, H. and Leonard, J.},
  title =	 {Exactly Sparse Delayed-State Filters},
  booktitle =	 ICRA,
  location =	 {Barcelona, Spain},
  pages =	 {2417--2424},
  month =	 {April},
  year =	 2005,
  abstract =	 {This paper presents the novel insight that the SLAM
                  information matrix is exactly sparse in a
                  delayed-state framework. Such a framework is used in
                  view-based representations of the environment which
                  rely upon scan-matching raw sensor
                  data. Scan-matching raw data results in virtual
                  observations of robot motion with respect to a place
                  its previously been. The exact sparseness of the
                  delayed-state information matrix is in contrast to
                  other recent feature based SLAM information
                  algorithms like Sparse Extended Information Filters
                  or Thin Junction Tree Filters. These methods have to
                  make approximations in order to force the
                  feature-based SLAM information matrix to be
                  sparse. The benefit of the exact sparseness of the
                  delayed-state framework is that it allows one to
                  take advantage of the information space
                  parameterization without having to make any
                  approximations. Therefore, it can produce equivalent
                  results to the "full-covariance" solution.},
  r-Wang05isrr = {In a recent development, Eustice et al. [this] show
                  that the inclusion of the robot trajectory in the
                  form of past robot poses in the state vector leads
                  to an exactly sparse information matrix. The
                  resulting Exactly Sparse Delayed State Filter
                  (ESDSF) provides clear computational advantages when
                  a viewbased map representation is used. In the
                  example presented the "map" is not represented
                  within the state vector and is therefore not
                  directly updated.},
}

@InProceedings{Eustice05iros,
  author =	 {Eustice, R. and Walter, M. and Leonard, J.},
  title =	 {Sparse Extended Information Filters: Insights into
                  Sparsification},
  booktitle =	 IROS,
  pages =	 {3281-3288},
  month =	 {Aug},
  year =	 2005,
  abstract =	 {Recently, there have been a number of variant
                  Simultaneous Localization and Mapping (SLAM)
                  algorithms which have made substantial progress
                  towards large-area scalability by parameterizing the
                  SLAM posterior within the information
                  (canonical/inverse covariance) form. Of these,
                  probably the most well-known and popular approach is
                  the Sparse Extended Information Filter (SEIF) by
                  Thrun et al. While SEIFs have been successfully
                  implemented with a variety of challenging real-world
                  data sets and have lead to new insights into
                  scalable SLAM, open research questions remain
                  regarding the approximate sparsification procedure
                  and its effect on map error and consistency. In this
                  paper, we examine the constant-time SEIF
                  sparsification procedure in depth and offer new
                  insight into issues of consistency. In particular,
                  we show that exaggerated map inconsistency occurs
                  within the global reference frame where estimation
                  is performed, but that empirical testing shows that
                  relative local map relationships are preserved. We
                  then present a slightly modified version of their
                  sparsification procedure which is shown to preserve
                  sparsity while also generating both local and global
                  map estimates comparable to those obtained by the
                  non-sparsified SLAM filter; this modified
                  approximation, however, is no longer
                  constant-time. We demonstrate our findings by
                  benchmark comparison of the modified and original
                  SEIF sparsification rule using simulation in the
                  linear Gaussian SLAM case and real-world experiments
                  for a nonlinear dataset.},
  r-Wang05isrr = {However, Eustice et al. [this] demonstrated that the
                  process of sparsification proposed in [Thrun04ijrr]
                  leads to inconsistent estimates.},
}

@InProceedings{Eustice05rss,
  author =	 {R. Eustice and H. Singh and J. Leonard and M. Walter
                  and R. Ballard},
  fullauthor =	 {Ryan Eustice and Hanumant Singh and John Leonard and
                  Matthew Walter and Robert Ballard},
  title =	 {Visually Navigating the {RMS} Titanic with {SLAM}
                  Information Filters},
  booktitle =	 RSS,
  location =	 {Cambridge, USA},
  month =	 {Jun},
  year =	 2005,
  abstract =	 {This paper describes a vision-based, large-area,
                  simultaneous localization and mapping (SLAM)
                  algorithm that respects the low-overlap imagery
                  constraints typical of underwater vehicles while
                  exploiting the inertial sensor information that is
                  routinely available on such platforms.We present a
                  novel strategy for efciently accessing and
                  maintaining consistent covariance bounds within a
                  SLAM information lter, thereby greatly increasing
                  the reliability of data association. The technique
                  is based upon solving a sparse system of linear
                  equations coupled with the application of
                  constant-time Kalman updates. The method is shown to
                  produce consistent covariance estimates suitable for
                  robot planning and data association. Real-world
                  results are presented for a vision-based 6-DOF SLAM
                  implementation using data from a recent ROV survey
                  of the wreck of the RMS Titanic.},
  r-Davison07pami ={Most recently Eustice et al. [this] have used a
                  single downward-looking camera and inertial sensing
                  to localize an underwater remote vehicle and produce
                  detailed seabed reconstructions from low frame-rate
                  image sequences. Using an efficient sparse
                  information filter their approach scales well to
                  large-scale mapping in their experimental setup
                  where loop closures are relatively infrequent.},
  c-kaess =	 {Uses camera and several different pose sensors for
                  underwater mapping. Exploits sparsity of smoothing
                  information matrix (originally described in
                  Eustice05icra), but calls it view-based SLAM,
                  ie. doesn't realize that the same can be done with
                  landmarks, and occasionally even calls it
                  filtering. Especially refers to square-root
                  smoothing [Dellaert05rss] as an extended information
                  filter, which is wrong. Presents interesting
                  insights into accessing the covariances, as well as
                  conservative estimates (which are called
                  "consistent" in the paper) for data association,
                  based on an incremental estimation.},
}

@Article{Eustice06ijrr,
  author =	 {R.M. Eustice and H. Singh and J.J. Leonard and
                  M.R. Walter},
  fullauthor =	 {Ryan M. Eustice and Hanumant Singh and John
                  J. Leonard and Matthew R. Walter},
  title =	 {Visually Mapping the {RMS} {T}itanic: Conservative
                  Covariance Estimates for {SLAM} Information Filters},
  journal =	 IJRR,
  volume =	 25,
  number =	 12,
  pages =	 {1223-1242},
  month =	 {Dec},
  year =	 2006,
  abstract =	 {This paper describes a vision-based, large-area,
                  simultaneous localization and mapping (SLAM)
                  algorithm that respects the low-overlap imagery
                  constraints typical of underwater vehicles while
                  exploiting the inertial sensor information that is
                  routinely available on such platforms. We present a
                  novel strategy for efficiently accessing and
                  maintaining consistent covariance bounds within a
                  SLAM information filter, thereby greatly increasing
                  the reliability of data association. The technique
                  is based upon solving a sparse system of linear
                  equations coupled with the application of
                  constant-time Kalman updates. The method is shown to
                  produce consistent covariance estimates suitable for
                  robot planning and data association. Real-world
                  results are reported for a vision-based, six degree
                  of freedom SLAM implementation using data from a
                  recent survey of the wreck of the RMS Titanic.},
}

@Article{Eustice06tro,
  author =	 {R.M. Eustice and H. Singh and J.J. Leonard},
  fullauthor =	 {Ryan M. Eustice and Hanumant Singh and John
                  J. Leonard},
  title =	 {Exactly Sparse Delayed-State Filters for View-Based
                  SLAM},
  journal =	 TRO,
  volume =	 22,
  number =	 6,
  pages =	 {1100-1114},
  month =	 {Dec},
  year =	 2006,
  abstract =	 {This paper reports the novel insight that the
                  simultaneous localization and mapping (SLAM)
                  information matrix is exactly sparse in a
                  delayed-state framework. Such a framework is used in
                  view-based representations of the environment that
                  rely upon scan-matching raw sensor data to obtain
                  virtual observations of robot motion with respect to
                  a place it has previously been. The exact sparseness
                  of the delayed-state information matrix is in
                  contrast to other recent feature-based SLAM
                  information algorithms, such as sparse extended
                  information filter or thin junction-tree filter,
                  since these methods have to make approximations in
                  order to force the feature-based SLAM information
                  matrix to be sparse. The benefit of the exact
                  sparsity of the delayed-state framework is that it
                  allows one to take advantage of the information
                  space parameterization without incurring any sparse
                  approximation error. Therefore, it can produce
                  equivalent results to the full-covariance
                  solution. The approach is validated experimentally
                  using monocular imagery for two datasets: a
                  test-tank experiment with ground truth, and a
                  remotely operated vehicle survey of the RMS
                  Titanic. },
}

@ARTICLE{Eustice06tro,
  title =	 {Exactly Sparse Delayed-State Filters for View-Based
                  SLAM},
  author =	 {Eustice, R.M. and Singh, H. and Leonard, J.J.},
  journal =	 {Robotics, IEEE Transactions on},
  year =	 2006,
  month =	 {Dec. },
  volume =	 22,
  number =	 6,
  pages =	 {1100-1114},
}

@Book{Evans00book,
  author =	 {Evans, M. and Hastings, N. and Peacock, B.},
  title =	 {Statistical Distributions},
  publisher =	 {Wiley},
  year =	 {2000},
  edition =	 {3},
  c-dellaert =	 {given as reference for beta distribution (ch 5) on
                  Wolfram}
}

@InCollection{Evans04,
  author =	 {S.N.Evans},
  title =	 {Fourier analysis and phylogenetic trees},
  booktitle =	 {Modern Signal Processing},
  publisher =	 {Cambridge University Press},
  editor =	 {D. Healy and D. Rockmore},
  series =	 {MSRI Summer School Lecture Notes},
  year =	 2004,
}

@InProceedings{Everett94,
  author =	 {Everett, H. and Gage, D. and Gilbreth, G. and Laird,
                  R. and Smurlo, R.},
  title =	 {Real-world issues in warehouse navigation},
  booktitle =	 {Proceedings of the SPIE Conference on Mobile Robots
                  IX},
  year =	 1994,
  volume =	 2352,
}

@Article{Ewens72,
  author =	 {W. J. Ewens},
  year =	 1973,
  title =	 {The sampling theory of selectively neutral alleles},
  journal =	 {Theoretical {P}opulation {B}iology},
  volume =	 3,
  pages =	 {87-112}
}

@article{Fagin82tods,
  author =	 {R. Fagin and A.O. Mendelzon and J.D. Ullman},
  fullauthor =	 {Ronald Fagin and Alberto O. Mendelzon and Jeffrey
                  D. Ullman},
  title =	 {A simplied universal relation assumption and its
                  properties},
  journal =	 {ACM Trans. Database Syst.},
  volume =	 7,
  number =	 3,
  year =	 1982,
  issn =	 {0362-5915},
  pages =	 {343--360},
  doi =		 {http://doi.acm.org/10.1145/319732.319735},
  publisher =	 {ACM Press},
  address =	 {New York, NY, USA},
  r-Beeri83jacm ={\citet{Beeri81stoc} introduced a special class of
                  database schemes, called
                  acyclic. \citet{Fagin82tods} have shown that this
                  class enjoys a certain desirable property},
}

@INPROCEEDINGS{Fakih08icpr,
  title =	 {Structure from Motion: Combining features
                  correspondences and optical flow},
  author =	 {Fakih, A. and Zelek, J.},
  booktitle =	 {Pattern Recognition, 2008. ICPR 2008. 19th
                  International Conference on},
  year =	 2008,
  month =	 {Dec.},
  pages =	 {1-4},
  keywords =	 {Monte Carlo methods, feature extraction, filtering
                  theory, image sequences, motion estimation,
                  statistical distributionsMonte-Carlo filtering,
                  camera motion, discrete feature displacement,
                  feature correspondence, feature detection, motion
                  estimation, optical flow, probability distribution,
                  structure from motion},
}

@Article{Fan79,
  author =	 {T.I. Fan and K.S. Fu},
  title =	 {A syntactic approach to time-varying image analysis},
  journal =	 GMIP,
  year =	 1979,
  volume =	 11,
  pages =	 {138-149},
}

@InProceedings{Fathi07iccv,
  author = {Alireza Fathi and Greg Mori},
  title = {Human pose estimation using motion exemplars},
  booktitle = ICCV,
  year = {2007}
}

@InProceedings{Fathi08cvpr,
  author = {Alireza Fathi and Greg Mori},
  title = {Action recognition by mid-level motion features},
  booktitle = CVPR,
  year = {2008}
}

@article{Fattal02siggraph,
  author =	 {R.Fattal and D.Lischinski and M.Werman},
  title =	 {Gradient domain high dynamic range compression},
  journal =	 {ACM Transactions on Graphics},
  volume =	 21,
  number =	 3,
  pages =	 {249--256},
  year =	 2002
}

@article{Faugeras00pami,
  AUTHOR =	 "Faugeras, O.D. and Quan, L. and Sturm, P.F.",
  TITLE =	 "Self-Calibration of a {1D} Projective Camera and Its
                  Application to the Self-Calibration of a {2D}
                  Projective Camera",
  JOURNAL =	 "PAMI",
  VOLUME =	 22,
  YEAR =	 2000,
  NUMBER =	 10,
  MONTH =	 "October",
  PAGES =	 "1179-1184"
}

@Book{Faugeras01book,
  author =	 {Faugeras, O.D. and Luong, Q.T.},
  title =	 {The geometry of multiple images},
  publisher =	 MIT,
  year =	 2001,
  note =	 {with contributions from T. Papadopoulo},
}

@inproceedings{Faugeras87iccv,
  author =	 "Faugeras, O.D. and Lustman, F. and Toscani, G.",
  title =	 "Motion and Structure from Motion from Point and Line
                  Matches",
  booktitle =	 ICCV,
  pages =	 "25-34",
  year =	 1987
}

@InProceedings{Faugeras87iccv2,
  author =	 {O.D. Faugeras and N. Ayache},
  title =	 {Building, registering and fusing noisy visual maps},
  booktitle =	 ICCV,
  pages =	 {73-82},
  year =	 1987,
}

@article{Faugeras90ai,
  author =	 {O. D. Faugeras and E. Le Bras-Mehlman and
                  J. D. Boissonnat},
  title =	 {Representing stereo data with the {D}elaunay
                  triangulation},
  journal =	 {Artif. Intell.},
  volume =	 44,
  number =	 {1-2},
  year =	 1990,
  issn =	 {0004-3702},
  pages =	 {41--87},
}

@inproceedings{Faugeras92b,
  AUTHOR =	 "Faugeras, O.D.",
  TITLE =	 "What Can Be Seen in Three Dimensions with an
                  Uncalibrated Stereo Rig?",
  BOOKTITLE =	 ECCV,
  YEAR =	 1992,
  PAGES =	 "563-578"
}

@inproceedings{Faugeras92eccv,
  AUTHOR =	 "Faugeras, O.D. and Luong, Q.T. and Maybank, S.J.",
  TITLE =	 "Camera Self-Calibration: Theory and Experiments",
  BOOKTITLE =	 ECCV,
  YEAR =	 1992,
  PAGES =	 "321-334"
}

@Book{Faugeras93book,
  author =	 "O.D. Faugeras",
  title =	 "Three-dimensional computer vision: {A} geometric
                  viewpoint",
  publisher =	 MIT,
  year =	 1993,
}

@InProceedings{Faugeras98eccv,
  author =	 "O.D. Faugeras and R. Keriven",
  title =	 "Complete Dense Stereovision Using Level Set Methods",
  pages =	 "379--393",
  booktitle =	 ECCV,
  year =	 1998
}

@Article{Feder71,
  author =	 {T. Feder},
  title =	 {Plex Languages},
  journal =	 {Info. Sciences},
  volume =	 3,
  year =	 1971,
  pages =	 {225-241},
}

@inproceedings{Feder93stoc,
  author =	 {T. Feder and M.Y. Vardi},
  title =	 {Monotone monadic SNP and constraint satisfaction},
  booktitle =	 STOC,
  year =	 1993,
  isbn =	 {0-89791-591-7},
  pages =	 {612--622},
  location =	 {San Diego, California, United States},
  doi =		 {http://doi.acm.org/10.1145/167088.167245},
  publisher =	 {ACM Press},
  address =	 {New York, NY, USA},
  r-Kolaitis00css ={The concept of treewidth of a relational structure
                  was introduced by \citet{Feder93stoc} and
                  generalizes the concept of treewidth of a graph},
  c-dellaert =	 {mostly about complexity of CSP classes},
}

@InProceedings{Feder98,
  author =	 {H.-J. S. Feder and J.J. Leonard and C.M. Smith},
  title =	 {Adaptive concurrent mapping and localization using
                  sonar},
  booktitle =	 IROS,
  year =	 1998,
}

@Article{Feder99,
  author =	 {H. J. S. Feder and J. J. Leonard and C. M. Smith},
  title =	 {Adaptive mobile robot navigation and mapping},
  journal =	 {International Journal of Robotics Research, Special
                  Issue on Field and Service Robotics},
  year =	 1999,
  volume =	 18,
  number =	 7,
  pages =	 {650-668},
  month =	 {July},
}

@Unpublished{Feder99b,
  author =	 {H.-J. S. Feder and J.J. Leonard},
  title =	 {Decoupled {S}tochastic {M}apping, {P}art {II}:
                  {P}erformance {A}nalysis},
  note =	 {Submitted to IEEE Transactions on Robotics and
                  Automation},
}

@InProceedings{FeiFei03iccv,
  author =	 {L. Fei-Fei and R. Fergus and P. Perona},
  title =	 {A {Bayesian} approach to unsupervised One-Shot
                  learning of Object categories},
  booktitle =	 ICCV,
  year =	 2003,
}

@InProceedings{FeiFei04ws,
  author =	 {L. Fei-Fei and R. Fergus and P. Perona},
  title =	 {Learning generative visual models from few training
                  examples: an incremental {Bayesian} approach tested
                  on 101 object categories},
  booktitle =	 {CVPR 2004 Workshop on Generative-Model Based Vision},
  year =	 2004,
}

@article{FeiFei06pami,
  author =	 {L. Fei-Fei and Fergus, R. and Perona, P.},
  title =	 {One-shot learning of object categories},
  journal =	 PAMI,
  year =	 2006,
  volume =	 28,
  number =	 4,
  pages =	 {594--611},
  month =	 {April},
  doi =		 {10.1109/TPAMI.2006.79},
}

@InProceedings{Feiner97,
  author =	 {S. Feiner and B. MacIntyre and T. Hollerer and
                  A. Webster},
  title =	 {A Touring Machine: Prototyping {3D} Mobile Augmented
                  Reality Systems for Exploring the Urban Enviroment},
  booktitle =	 {Proc of ISWC},
  pages =	 {74-81},
  year =	 1997
}

@inproceedings{Feiner97touring,
  author =	 {S.Feiner and B.MacIntyre and T.Hollerer and
                  T.Webster},
  title =	 {A {T}ouring machine: Prototyping {3D} mobile
                  augmented reality systems for exploring the urban
                  environment},
  booktitle =	 {Proc. ISWC'97 (First Int. Symp. on Wearable
                  Computers)},
  month =	 {October 13-14},
  year =	 1997,
  pages =	 {208-217},
  address =	 {Cambridge, MA.},
  url =
                  {http://www.cs.columbia.edu/graphics/projects/mars/mars.html},
  pdf =		 {pdf/touring.pdf},
  ps =
                  {http://www.cs.columbia.edu/graphics/publications/iswc97.ps.gz}
}

@InProceedings{Feldman03masi,
  author =	 {Feldman, A. and Balch, T.},
  title =	 {Automatic Identification of Bee Movement},
  booktitle =	 {Proceedings of the 2nd International Workshop on the
                  Mathematics and Algorithms of Social Insects},
  editor =	 {Anderson, C. and Balch, T},
  address =	 {Atlanta},
  month =	 {December},
  crossref =	 {MASI03},
}

@article{Feldman04AB,
  author =	 "Feldman, A. and Balch, T",
  title =	 "Representing Honey Bee Behavior for Recognition
                  Using Human Trainable Models",
  journal =	 {Adaptive Behavior},
  year =	 2004,
  volume =	 12,
  pages =	 "241-250",
}

@article{Feldmar96,
  author =	 "J. Feldmar and N. Ayache",
  title =	 "Rigid, affine and locally affine registration of
                  free-form surfaces",
  journal =	 IJCV,
  volume =	 18,
  pages =	 "99--119",
  year =	 1996
}

@InProceedings{Fennema90,
  author =	 {C. Fennema and A.R. Hanson},
  title =	 {Experiments in autonomous navigation},
  booktitle =	 IUW,
  year =	 1990,
}

@Article{Fennema90b,
  author =	 {C. Fennema and A.R. Hanson and E. Riseman and
                  J.R. Beveridge and R. Kumar},
  title =	 {Model-directed mobile robot navigation},
  journal =	 SMC,
  year =	 1990,
  volume =	 20,
  number =	 6,
  pages =	 {1352-1369},
}

@InProceedings{Fenwick02icra,
  author =	 "J. Fenwick and P. Newman and J. Leonard",
  title =	 "Cooperative concurrent mapping and localization",
  booktitle =	 ICRA,
  pages =	 {1810--1817},
  year =	 2002,
  volume =	 2,
  abstract =	 {Autonomous vehicles require the ability to build
                  maps of an unknown environment while concurrently
                  using these maps for navigation. Current algorithms
                  for this concurrent mapping and localization (CML)
                  problem have been implemented for single vehicles,
                  but do not account for extra positional information
                  available when multiple vehicles operate
                  simultaneously. Multiple vehicles have the potential
                  to map an environment more quickly and robustly than
                  a single vehicle. This paper presents a cooperative
                  CML algorithm that merges sensor and navigation
                  information from multiple autonomous vehicles. The
                  algorithm presented is based on stochastic
                  estimation and uses a feature-based approach to
                  extract landmarks from the environment. The
                  theoretical framework for the collaborative CML
                  algorithm is presented, and a convergence theorem
                  central to the cooperative CML problem is proved for
                  the first time. This theorem quanties the
                  performance gains of collaboration, allowing for
                  determination of the number of cooperating vehicles
                  required to accomplish a task. A simulated
                  implementation of the collaborative CML algorithm
                  demonstrates substantial performance improvement
                  over non-cooperative CML.},
  r-Rodriguez04icra ={Recently [11] implements a multirobot SLAM-EKF
                  system for an indoor environment, but without real
                  results in large environments neither handling real
                  time constraints},
  r-Fox06ieee =	 {If the initial locations of the robots are known,
                  map merging is a rather straightforward extension of
                  single robot mapping},
}

@InProceedings{Fergus03cvpr,
  author =	 "Fergus, R. and Perona, P. and Zisserman, A.",
  title =	 "Object Class Recognition by Unsupervised
                  Scale-Invariant Learning",
  booktitle =	 CVPR,
  year =	 2003,
  month =	 "June",
}

@InProceedings{Fergus05iccv,
  author =	 "Fergus, R. and Perona, P. and Zisserman, A.",
  title =	 "A Sparse Object Category Model for Efficient
                  Learning and Exhaustive Recognition",
  booktitle =	 ICCV,
  year =	 2005,
}

@InProceedings{Fergus05iccvb,
  author =	 "Fergus, R. and Fei-Fei, L. and Perona, P. and
                  Zisserman, A.",
  title =	 "Learning Object Categories from Google's Image
                  Search.",
  booktitle =	 ICCV,
  year =	 2005,
}

@InProceedings{Fergus06siggraph,
  author =	 {Rob Fergus and Barun Singh and Aaron Hertzmann and
                  Sam T. Roweis and William T. Freeman},
  title =	 {Removing camera shake from a single photograph},
  booktitle =	 SIGGRAPH,
  year =	 2006,
}

@Article {Ferguson73aos,
  author =	 "T. S. Ferguson",
  year =	 1973,
  title =	 "A {Bayesian} analysis of some nonparametric
                  problems",
  journal =	 "Annals of Statistics",
  volume =	 1,
  pages =	 {209-230},
}

@InProceedings{Ferguson80,
  author =	 "J. Ferguson",
  title =	 "Variable duration models for speech",
  booktitle =	 "Symposium on the Aplication of HMMs to Text and
                  Speech",
  year =	 1980,
  pages =	 "143-179",
}

@Article{Fermuller00ijcv,
  author =	 {Ferm{\"u}ller, C. and Aloimonos, Y.},
  title =	 {Observability of {3D} Motion},
  journal =	 IJCV,
  year =	 2000,
  volume =	 37,
  number =	 1,
  pages =	 {43-62},
}

@InProceedings{Fernyhough96eccv,
  author =	 "J. H. Fernyhough, A. G. Cohn and D. Hogg",
  fullauthor =	 "Jonathan H. Fernyhough and Anthony G. Cohn and David
                  Hogg",
  title =	 {{Generation of Semantic Regions from Image
                  Sequences}},
  booktitle =	 ECCV,
  volume =	 2,
  pages =	 "475-484",
  year =	 1996,
}

@InProceedings{Ferrari01,
  author =	 {V.Ferrari and T.Tuytelaars and L. Van Gool},
  title =	 {Markerless Augmented Reality with Real-time Affine
                  Region Tracker},
  booktitle =	 {ISAR},
  year =	 2001,
}

@InProceedings{Ferrier94,
  author =	 "Ferrier, N and S. Rowe and A. Blake",
  booktitle =	 "2nd IEEE Workshop on Applications of Computer
                  Vision, Sarasota, Florida",
  title =	 "Real-Time Traffic Monitoring",
  year =	 1994,
}

@InProceedings{Ferris07ijcai,
  author =	 {Brian Ferris and Dieter Fox and Neil Lawrence},
  title =	 {{WiFi-SLAM} Using Gaussian Process Latent Variable Models},
  booktitle =	 IJCAI,
  year =	 2007,
  added-by =	 {richard},
}

@Article{Fessler91mi,
  title =	 "Object-based 3-D reconstruction of arterial trees
                  from magnetic resonance angiograms",
  author =	 "J.A. Fessler and A. Macovski",
  journal =	 "IEEE Transactions on Medical Imaging",
  volume =	 10,
  number =	 1,
  month =	 March,
  year =	 1991,
  pages =	 "25 -39"
}

@Inproceedings{Fiala05cvpr,
  author =	 {M. Fiala},
  title =	 {ARTag, a fiducial marker system using digital
                  techniques},
  booktitle =	 CVPR,
  year =	 {2005},
  c-Alireza =	 {Fiducial marker systems consist of patterns that are
                  mounted in the environment and automatically
                  detected in digital camera images using an
                  accompanying detection algorithm. They are useful
                  for augmented reality (AR), robot navigation, and
                  general applications where the relative pose between
                  a camera and object is required. Important
                  parameters for such marker systems is their false
                  detection rate (false positive rate), their
                  inter-marker confusion rate, minimal detection size
                  (in pixels) and immunity to lighting
                  variation. ARTag is a marker system that uses
                  digital coding theory to get a very low false
                  positive and inter-marker confusion rate with a
                  small required marker size, employing an edge
                  linking method to give robust lighting variation
                  immunity. ARTag markers are bi-tonal planar patterns
                  containing a unique ID number encoded with robust
                  digital techniques of checksums and forward error
                  correction (FEC). This proposed new system, ARTag
                  has very low and numerically quantifiable error
                  rates, does not require a grey scale threshold as
                  does other marker systems, and can encode up to 2002
                  different unique ID's with no need to store
                  patterns. Experimental results are shown validating
                  this system.}
}

@InProceedings{Fiala05cvpr,
  author =	 {M. Fiala},
  title =	 {ARTag, a fiducial marker system using digital
                  techniques},
  booktitle =	 CVPR,
  year =	 {2005},
  Alireza_Abstract ={Fiducial marker systems consist of patterns that
                  are mounted in the environment and automatically
                  detected in digital camera images using an
                  accompanying detection algorithm. They are useful
                  for augmented reality (AR), robot navigation, and
                  general applications where the relative pose between
                  a camera and object is required. Important
                  parameters for such marker systems is their false
                  detection rate (false positive rate), their
                  inter-marker confusion rate, minimal detection size
                  (in pixels) and immunity to lighting
                  variation. ARTag is a marker system that uses
                  digital coding theory to get a very low false
                  positive and inter-marker confusion rate with a
                  small required marker size, employing an edge
                  linking method to give robust lighting variation
                  immunity. ARTag markers are bi-tonal planar patterns
                  containing a unique ID number encoded with robust
                  digital techniques of checksums and forward error
                  correction (FEC). This proposed new system, ARTag
                  has very low and numerically quantifiable error
                  rates, does not require a grey scale threshold as
                  does other marker systems, and can encode up to 2002
                  different unique ID's with no need to store
                  patterns. Experimental results are shown validating
                  this system.},
}

@InProceedings{Fiduccia82,
  author =	 "C.M. Fiduccia and R.M. Mattheyses",
  title =	 "A linear time heuristic for improving network
                  partitions",
  booktitle =	 "Proc. 19th IEEE Design Automation and Conference",
  year =	 1982,
  pages =	 "175-181"
}

@Article{Field94neuralcomp,
  author =	 {David J. Field},
  title =	 {What is the Goal of Sensory Coding?},
  year =	 1994,
  journal =	 {Neural Computation},
  volume =	 6,
  number =	 4,
  pages =	 {559-601},
  publisher =	 {MIT Press},
}

@Article{Fielding00,
  author =	 {G. Fielding and M. Kam},
  title =	 {Weighted matchings for dense stereo correspondence},
  journal =	 PR,
  year =	 2000,
  volume =	 9,
  pages =	 {1511-1524},
}

@InProceedings{Fielding97cdc,
  author =	 "G. Fielding and M. Kam",
  title =	 "Applying the {Hungarian} method to stereo matching",
  booktitle =	 CDC,
  pages =	 "549--558",
  month =	 "December",
  year =	 1997,
}

@article{Filippini03chem,
  author =	 {D. Filippini and S. P. S. Svensson and I. Lundstrom},
  title =	 "Computer screen as a programmable light source for
                  visible absorption characterization of (bio)chemical
                  assays",
  journal =	 {Chem. Commun.},
  number =	 2,
  pages =	 {240--241},
  year =	 2003,
}

@InProceedings{Filliat02,
  author =	 {D. Filliat and J. Meyer},
  title =	 {Global localization and topological map learning for
                  robot navigation},
  booktitle =	 {From Animals to Animats 7. Proceedings of the
                  Seventh International Conference on Simulation of
                  Adaptive Behavior (SAB'02)},
  year =	 2002,
}

@book{Findlay03book,
  title =	 {Active Vision:The Psychology of Looking and Seeing},
  author =	 {J.M. Findlay and I.D. Gilchrist},
  fullauthor =	 {John M. Findlay and Iain D. Gilchrist},
  year =	 2003,
  publisher =	 {Oxford University Press},
  Series =	 {Oxford Psychology Series},
  Review =	 {More than one third of the human brain is devoted to
                  the processes of seeing - vision is after all the
                  main way in which we gather information about the
                  world. But human vision is a dynamic process during
                  which the eyes continually sample the
                  environment. Where most books on vision consider it
                  as a passive activity, this book is unique in
                  focusing on vision as an 'active' process. It goes
                  beyond most accounts of vision where the focus is on
                  seeing, to provide an integrated account of seeing
                  AND looking. The book starts by pointing out the
                  weaknesses in our traditional approaches to vision
                  and the reason we need this new approach. It then
                  gives a thorough description of basic details of the
                  visual and oculomotor systems necessary to
                  understand active vision. The book goes on to show
                  how this approach can give a new perspective on
                  visual attention, and how the approach has
                  progressed in the areas of visual orienting,
                  reading, visual search, scene perception and
                  neuropsychology. Finally, the book summarises
                  progress by showing how this approach sheds new
                  light on the old problem of how we maintain
                  perception of a stable visual world. Written by two
                  leading vision scientists, this book will be
                  valuable for vision researchers and psychology
                  students, from undergraduate level upwards.},
  url =		 {http://www.oup.com/uk/catalogue/?ci=9780198524793},
  c-dellaert =	 {Should buy}
}

@article{Findlay04cb,
  author =	 {John Findlay},
  title =	 {Active vision: Visual activity in everyday life},
  journal =	 {Current Biology},
  Volume =	 8,
  number =	 18,
  month =	 {September},
  year =	 2004,
  Pages =	 {640--642},
  Abstract =	 {Recent studies that consider how vision is used in
                  everyday life have led to a new perspective in
                  visual science, in which more emphasis is placed on
                  the active role of the viewer.},
  Summary =	 {Discusses recent studies that consider how vision is
                  used in everyday life, and how they have led to a
                  new perspective in visual science, in which more
                  emphasis is placed on the active role of the
                  viewer. The article discusses two bodies of research
                  presented at the conference of the Association for
                  Research in Vision and Ophthalmology (Ft Lauderdale,
                  Florida; May 1998). M. Land, et al and R. Steinman,
                  et al highlighted the detailed patterns of visual
                  behavior involving the constant reflection of the
                  fovea of a freely moving human S to new locations in
                  the visual field, with the gaze direction changing
                  several times each second. The findings of these
                  bodies of research are discussed.},
  quotes =	 {The direction of the eyes showed how the activity
                  sequence was directed by vision: the
                  ?o-it-where-you-look?strategy. .. Thus, as
                  emphasized by various authors [3,4], gaze activity
                  is generally under tight cognitive control from
                  high-level plans. Only very occasionally did the
                  eyes appear possibly to stray to a distracting
                  visually salient object. .. Human observers are
                  loath to make use of internalised visual memory,
                  rather using the alternative option of accessing
                  visual information in the external environment
                  whenever it is needed. .. This transfer of the same
                  behaviour from the eyes to the head suggests that
                  active vision processes can be transferred from one
                  motor system to another.},
  c-dellaert =	 {Nice overview of recent important papers regarding a
                  new active vision paradigm.}
}

@article{Fine99ml,
  author =	 "S. Fine and Y. Singer and N. Tishby",
  fullauthor =	 "Shai Fine, Yoram Singer and Naftali Tishby",
  title =	 {{The Hierarchical Hidden Markov Model : Analysis and
                  Applications}},
  journal =	 ML,
  year =	 1998,
  volume =	 32,
  pages =	 "41-62",
  keywords =	 "hierarchical model, HMM",
}

@InProceedings{Finkelstein94,
  author =	 {A. Finkelstein and D.H. Salesin},
  title =	 {Multiresolution curves},
  booktitle =	 SIGGRAPH,
  pages =	 {261-268},
  year =	 1994,
}

@article{Fischer99,
  author =	 "A. Fischer and T. Kolbe and F. Lang",
  title =	 "On the Use of Geometric and Semantic Models for
                  Component Based Building Reconstruction",
  journal =	 "Institut fur Photogrammetrie, Universitat Bonn",
  year =	 1999,
  pages =	 "101-119",
}

@article{Fischler81,
  author =	 "M. Fischler and R. Bolles",
  title =	 "Random sample consensus: a paradigm for model
                  fitting with application to image analysis and
                  automated cartography",
  journal =	 "Commun. Assoc. Comp. Mach.",
  volume =	 24,
  pages =	 "381-395",
  year =	 1981
}

@article{Fisher22trs,
  author =	 {R. A. Fisher},
  title =	 {On the mathematical foundations of theoretical
                  statistics},
  journal =	 "{Philosophical Transactions of the Royal Society,
                  A}",
  volume =	 222,
  pages =	 {309--368},
  year =	 1922,
  c-ananth =	 { As the title suggests, this is the seminal paper
                  that can be said to have put all of statistics on a
                  firm theoretical basis. Starts by talking about what
                  are the aims of statistics and the philosophy
                  (i.e. convergence with infinite samples etc.). Then
                  moves onto sufficiency and necessity of
                  statistics. Contains a number of calculations that
                  demonstrate the concept for estimating mean and
                  variance of various distributions (Gamma, for
                  example). Cite this for sufficient/necessary/minimal
                  statistics }
}

@article{Fisher25cps,
  author =	 {R. A. Fisher},
  title =	 {Theory of statistical estimation},
  journal =	 "{Proceedings of the Cambridge Philosophical
                  Society}",
  volume =	 {22},
  pages =	 {700-725},
  year =	 {1925},
  c-ananth =	 { Seminal paper on frequentist statistical
                  estimation. Talks about statistics needed for
                  estimating various quantities of interest (QOI), for
                  example expected values. Some statistics are more
                  efficient than others in incorporating
                  information. If an estimate of the QOI from the raw
                  data is better than that from the statistic, then
                  the statistic loses information over the
                  data. Conditions for zero loss statistics
                  (i.e. sufficient statistics) are provided. }
}

@Article{Fisher36,
  author =	 {R Fisher},
  title =	 {The use of multiple measures in taxonomic problems},
  journal =	 {Ann. Eugenics},
  year =	 1936,
  volume =	 7,
  pages =	 {179-188},
}

@article{Fitzgibbon05,
  author =	 "A.Fitzgibbon and Y.Wexler and A.Zisserman",
  title =	 "Image-Based Rendering Using Image-Based Priors",
  journal =	 IJCV,
  volume =	 63,
  number =	 2,
  pages =	 "141-151",
  year =	 2005
}

@InProceedings{Fitzpatrick03,
  author =	 {P. Fitzpatrick and G. Metta and L. Natale and S. Rao
                  and G. Sandini},
  fullauthor =	 {Paul Fitzpatrick and Giorgio Metta and Lorenzo
                  Natale and Sajit Rao and Giulio Sandini},
  title =	 {Learning about objects through action - initial
                  steps towards artificial cognition},
  booktitle =	 ICRA,
  year =	 2003,
  address =	 {Taipei, Taiwan},
  month =	 {May 12 - 17}
}

@Article{Flasinski89,
  author =	 {M. Flasinski},
  title =	 {Characteristics of edNLC-Graph Grammar for Syntactic
                  Pattern Recognition},
  journal =	 GMIP,
  year =	 1989,
  volume =	 47,
  pages =	 {1-21},
}

@InProceedings{Folkesson04iav,
  AUTHOR =	 {J. Folkesson and H. I. Christensen},
  TITLE =	 {Robust {SLAM}},
  BOOKTITLE =	 {IAV-2004},
  YEAR =	 2004,
  ADDRESS =	 {Lisboa, PT},
  MONTH =	 {July 5-7},
}

@InProceedings{Folkesson04icra,
  author =	 {J. Folkesson and H.I. Christensen},
  title =	 {Graphical {SLAM} - a self-correcting map},
  booktitle =	 ICRA,
  pages =	 {383-390},
  year =	 2004,
  volume =	 1,
  abstract =	 {In this paper we describe an approach to
                  simultaneous localization and mapping, SLAM. This
                  approach has the highly desirable property of
                  robustness to data association errors. Another
                  important advantage of our algorithm is that
                  non-linearities are computed exactly, so that global
                  constraints can be imposed even if they result in
                  large shifts to the map. We represent the map as a
                  graph and use the graph to find an efficient map
                  update algorithm. We also show how topological
                  consistency can be imposed on the map, such as,
                  closing a loop. The algorithm has been implemented
                  on an outdoor robot and we have experimental
                  validation of our ideas. We also explain how the
                  graph can be simplified leading to linear
                  approximations of sections of the map. This
                  reduction gives us a natural way to connect local
                  map patches into a much larger global map.},
  r-Bailey06ram ={Nevertheless, it is possible to retain a reasonably
                  sparse estimate without having to keep an entire
                  pose history [this]. By judicious selection of
                  anchoring poses to decouple different regions of the
                  map, a great proportion of poses can be marginalised
                  away without inducing excessive density as shown in
                  Figure 2(b).},
  c-kaess =	 {Graphical SLAM adds new measurements to a graph, and
                  solves by relaxation. The graph can be reduced by
                  collapsing parts into so-called star nodes, loosing
                  the capability of re-linearization in the local
                  context. Shows laser-based indoor results.},
}

@InProceedings{Folkesson05icra,
  author =	 {J. Folkesson and P. Jensfelt and H.I. Christensen},
  fullauthor =	 {John Folkesson and Patric Jensfelt and Henrik
                  I. Christensen},
  title =	 {Vision {SLAM} in the Measurement Subspace},
  booktitle =	 ICRA,
  location =	 {Barcelona, Spain},
  month =	 {Apr},
  year =	 2005,
  abstract =	 {In this paper we describe an approach to feature
                  representation for simultaneous localization and
                  mapping, SLAM. It is a general representation for
                  features that addresses symmetries and constraints
                  in the feature coordinates. Furthermore, the
                  representation allows for the features to be added
                  to the map with partial initialization. This is an
                  important property when using oriented vision
                  features where angle information can be used before
                  their full pose is known. The number of the
                  dimensions for a feature can grow with time as more
                  information is acquired. At the same time as the
                  special properties of each type of feature are
                  accounted for, the commonalities of all map features
                  are also exploited to allow SLAM algorithms to be
                  interchanged as well as choice of sensors and
                  features. In other words the SLAM implementation
                  need not be changed at all when changing sensors and
                  features and vice versa. Experimental results both
                  with vision and range data and combinations thereof
                  are presented.},
  c-kaess =	 {M-space is a flexible representation of
                  measurements, that allows incorporation of
                  measurements even if they only describe parts of
                  features, by exploiting symmetries. For example the
                  distance and orientation of a line segment might be
                  known, but not its end points, yielding a 2-dim
                  description of a 4-dim feature, that can later be
                  updated when more measurements arrive.},
}

@InProceedings{Folkesson05iros,
  author =	 {J. Folkesson and P. Jensfelt and H.I. Christensen},
  fullauthor =	 {John Folkesson and Patric Jensfelt and Henrik
                  I. Christensen},
  title =	 {Graphical {SLAM} using Vision and the Measurement
                  Subspace},
  booktitle =	 IROS,
  location =	 {Edmonton, Canada},
  month =	 {Aug},
  year =	 2005,
  abstract =	 {In this paper we combine a graphical approach for
                  simultaneous localization and mapping, SLAM, with a
                  feature representation that addresses symmetries and
                  constraints in the feature coordinates, the
                  measurement subspace, M-space. The graphical method
                  has the advantages of delayed linearizations and
                  soft commitment to feature measurement matching. It
                  also allows large maps to be built up as a network
                  of small local patches, star nodes. This local map
                  net is then easier to work with. The formation of
                  the star nodes is explicitly stable and invariant
                  with all the symmetries of the original
                  measurements. All linearization errors are kept
                  small by using a local frame. The construction of
                  this invariant star is made clearer by the Mspace
                  feature representation. The M-space allows the
                  symmetries and constraints of the measurements to be
                  explicitly represented. We present results using
                  both vision and laser sensors.},
  c-kaess =	 {Combines Graphical SLAM [Folkesson04icra] and
                  measurement subspace [Folkesson05icra], and shows
                  results based on different sensors, including vision
                  only. Experimental results took longer than EKF on a
                  simple loop sequence, but it is predicted that this
                  should be faster than EKF for larger environments.},
}

@InProceedings{Folkesson07iros,
  author =	 {J. Folkesson and J. Leonard and J. Leederkerken and
                  R. Williams},
  fullauthor =	 {John Folkesson and John Leonard and Jacques
                  Leederkerken and Rob Williams},
  title =	 {Feature Tracking For Underwater Navigation using
                  Sonar},
  booktitle =	 IROS,
  pages =	 {3678-3684},
  month =	 {Oct},
  year =	 2007,
}

@Article{Folkesson07tro,
  author =	 {J. Folkesson and H.I. Christensen},
  title =	 {Closing the Loop With Graphical {SLAM}},
  journal =	 TRO,
  volume =	 23,
  number =	 4,
  pages =	 {731-741},
  month =	 {Aug},
  year =	 2007,
}

@Article{Forney01it,
  author =	 {Forney, G.D., Jr.},
  title =	 {Codes on graphs: {Normal} realizations},
  journal =	 it,
  year =	 2001,
  volume =	 47,
  number =	 2,
  pages =	 {520-548},
  quotes =	 {We restrict attention to normal realizations,
                  defined as generalized state realizations in which
                  the degree of a state variable (the number of
                  constraints in which it is involved) is restricted
                  to two, and the degree of a symbol variable is
                  restricted to one. ... Normal realizations have a
                  natural graphical model, which we call a normal
                  graph, in which constraints are represented by
                  vertices, state variables are represented by
                  ordinary edges, and symbol variables are represented
                  by leaf edges ("half-edges"). We show that the
                  normal graph of a normalized generalized state
                  realization has the same topology as the factor
                  graph of the original realization. ... A code is any
                  subset of a symbol configuration space. ... Symbol
                  variables are visible (manifest, observable),
                  whereas state variables are hidden (latent,
                  unobservable). ... Because of these degree
                  restrictions, a normal realization has a natural
                  graphical model that is different from a factor
                  graph, which we call a normal graph. In a normal
                  graph, variables are represented by edges and
                  constraints by vertices.},
  r-Loeliger04spm ={The later introduction of factor graphs
                  \citep{Frey97ccc,Kschischang03spm} may be viewed as
                  a further elaboration of the ideas by Wiberg et
                  al. In the present article, we will use Forney-style
                  factor graphs (FFGs), which were introduced in
                  \citep{Forney01it} (and there called "normal
                  graphs").},
  r-Loeliger04spm ={\citet{Forney01it} and \citet{Mao05it} showed that
                  the Fourier transform of a multi-variable function
                  can be carried out directly in the FFG (which may
                  have cycles) according to the following recipe... },
  c-dellaert =	 {Seems like a very cool paper (esp. the dual code
                  part, which uses Fourier transforms) but it will
                  take a lot of work to truly understand. For
                  starters, abstract algebra and linear algebraic
                  codes, as in the Edinborough course (research
                  link).}
}

@article{Forsyth01ijcv,
  author =	 "D.A. Forsyth and J.A. Haddon and S. Ioffe",
  fullauthor =	 "David A. Forsyth and John A. Haddon and Sergey
                  Ioffe",
  title =	 "The Joy of Sampling",
  journal =	 "International Journal of Computer Vision",
  volume =	 "41",
  number =	 "1/2",
  pages =	 "109-134",
  year =	 "2001",
  url =		 "citeseer.nj.nec.com/forsyth01joy.html"
}

@Book{Forsyth02book,
  fullauthor =	 "D.A. Forsyth and Jean Ponce",
  author =	 "D.A. Forsyth and J. Ponce",
  title =	 "Computer Vision: A Modern Approach",
  publisher =	 "Prentice-Hall",
  year =	 2002,
}

@inproceedings{Forsyth99,
  AUTHOR =	 "Forsyth, D.A. and Ioffe, S. and Haddon, J.",
  TITLE =	 "Bayesian Structure from Motion",
  BOOKTITLE =	 ICCV,
  YEAR =	 1999,
  PAGES =	 "660-665"
}

@InProceedings{Fortmann80,
  author =	 {T.E. Fortmann and Y. Bar-Shalom and M. Scheffe},
  title =	 {Multi-target tracking using joint probabilistic data
                  association},
  booktitle =	 {Proc. 19th IEEE Conf. on Decision \& Control},
  year =	 1980,
}

@Article{Fortmann83,
  author =	 {T.E. Fortmann and Y. Bar-Shalom and M. Scheffe},
  title =	 {Sonar tracking of multiple targets using joint
                  probabilistic data association},
  journal =	 {IEEE Journal of Oceanic Engineering},
  year =	 1983,
  volume =	 8,
  month =	 {July},
}

@article{Fox00ar,
  author =	 "D. Fox and W. Burgard and H. Kruppa and S. Thrun",
  fullauthor =	 "Dieter Fox and Wolfram Burgard and Hannes Kruppa and
                  Sebastian Thrun",
  title =	 "A Probabilistic Approach to Collaborative
                  Multi-Robot Localization",
  journal =	 AR,
  volume =	 8,
  number =	 3,
  pages =	 "325-344",
  year =	 2000,
  url =		 "citeseer.nj.nec.com/fox00probabilistic.html"
}

@Article{Fox03ar,
  AUTHOR =	 {D. Fox and J. Hightower and L. Liao and D. Schulz
                  and G. Borriello},
  TITLE =	 {Bayesian Filtering for Location Estimation},
  journal =	 {IEEE Pervasive Computing},
  MONTH =	 {July},
  YEAR =	 2003,
  PAGES =	 {10--19},
  KEYWORDS =	 {bayesian filtering, location awareness, particle
                  filter},
}

@Article{Fox06ieee,
  author =	 {D. Fox and J. Ko and K. Konolige and B. Limketkai
                  and D. Schulz and B. Stewart},
  title =	 {Distributed Multi-robot Exploration and Mapping},
  journal =	 "Proceedings of the IEEE - Special Issue on
                  Multi-robot Systems",
  year =	 2006,
  volume =	 94,
  number =	 9,
  month =	 "Jul",
  Abstract =	 {Efcient exploration of unknown environments is a
                  fundamental problem in mobile robotics. In this
                  paper we present an approach to distributed
                  multi-robot mapping and exploration. Our system
                  enables teams of robots to efciently explore
                  environments from different, unknown locations. In
                  order to ensure consistency when combining their
                  data into shared maps, the robots actively seek to
                  verify their relative locations. Using shared maps,
                  they coordinate their exploration strategies so as
                  to maximize the efciency of exploration. Our system
                  was evaluated under extremely realistic real-world
                  conditions. An outside evaluation team found the
                  system to be highly efcient and robust. The maps
                  generated by our approach are consistently more
                  accurate than those generated by manually measuring
                  the locations and extensions of rooms and objects.},
  quotes =	 {Compared to the problems occurring in single robot
                  exploration, the extension to multiple robots poses
                  several new challenges, including (1) coordination
                  of robots, (2) integration of information collected
                  by different robots into a consistent map, and (3)
                  dealing with limited communication... Our technique
                  for exploration with unknown start locations
                  integrates robot detections into a Bayesian,
                  decision-theoretic exploration strategy....Similar
                  to [Howard04iser], this is done by using robot
                  detections. However, in contrast to [Howard04iser],
                  these detections are not coincidental; they are
                  pursued actively.},
  c-dellaert =	 {SDR results overview paper. Good index into the
                  literature. Uses particle filters. Has large-scale
                  mapping from Konolige in it.}
}

@INPROCEEDINGS{Fox08nips,
  AUTHOR =	 {E. B. Fox and E. B. Sudderth and M. I. Jordan and
                  A. S. Willsky},
  fullAUTHOR =	 {Emily B. Fox and Erik B. Sudderth and Michael
                  I. Jordan and Alan S. Willsky},
  TITLE =	 {{Nonparametric Bayesian Learning of Switching Linear
                  Dynamic Systems}},
  booktitle =	 NIPS,
  year =	 2008,
}

@INPROCEEDINGS{Fox98aaai,
  AUTHOR =	 {D. Fox and W. Burgard and S. Thrun and A.B. Cremers},
  TITLE =	 {Position Estimation for Mobile Robots in Dynamic
                  Environments},
  crossref =	 {_AAAI98},
}

@Article{Fox98b,
  author =	 {Fox, D. and Burgard, W. and Thrun, S.},
  title =	 {Active {M}arkov Localization for Mobile Robots},
  journal =	 {Robotics and Autonomous Systems},
  year =	 1998,
}

@InProceedings{Fox99aaai,
  author =	 {D. Fox and W. Burgard and F. Dellaert and S. Thrun},
  title =	 {Monte {C}arlo {L}ocalization -- {E}fficient position
                  estimation for mobile robots},
  crossref =	 {_AAAI99},
}

@InProceedings{Foxlin02iros,
  author =	 {E.M. Foxlin},
  title =	 {Generalized Architecture for Simultaneous
                  Localization, Auto-Calibration, and Map-building},
  booktitle =	 IROS,
  year =	 2002,
  c-dellaert =	 {A variant of recursive SFM, integrated with inertial
                  navigation and using a distributed version of the
                  full EKF, called the "Federated filter". Not very
                  clear.},
}

@InProceedings{Foxlin02iros,
  author =	 "E.M. Foxlin",
  title =	 "Generalized Architecture for Simultaneous
                  Localization, Auto-Calibration, and Map-building",
  booktitle =	 IROS,
  year =	 2002
}

@InProceedings{Frahm06cvpr,
  author =	 {J.M. Frahm and M. Pollefeys},
  title =	 {{RANSAC} for (Quasi-)Degenerate data ({QDEGSAC})},
  booktitle =	 CVPR,
  year =	 2006
}

@ARTICLE{Franz00ras,
  author =	 {Matthias O. Franz and Hanspeter A. Mallot},
  title =	 {Biomimetic robot navigation},
  journal =	 {Robotics and autonomous Systems},
  year =	 2000,
  volume =	 30,
  pages =	 {133--153},
  Abstract =	 { In the past decade, a large number of robots has
                  been built that explicitly implement biological
                  navigation behaviours. We review these biomimetic
                  approaches using a framework that allows for a
                  common description of biological and technical
                  navigation behaviour. The review shows that
                  biomimetic systems make significant contributions to
                  two fields of research: First, they provide a real
                  world test of models of biological navigation
                  behaviour; second, they make new navigation
                  mechanisms available for technical applications,
                  most notably in the field of indoor robot
                  navigation. While simpler insect navigation
                  behaviours have been implemented quite successfully,
                  the more complicated way-finding capabilities of
                  vertebrates still pose a challenge to current
                  systems.},
  quotes =	 {we adopt a slightly modified version of Gallistel?
                  [The organization of Learning, 1990] definition
                  ?avigation is the process of determining and
                  maintaining a course or trajectory to a goal
                  location.?.. The forms of spatial behaviour captured
                  by the above definition fall into two fundamentally
                  different groups: local navigation and
                  way-finding. .. [navigation hierarchy:] Local
                  navigation behaviours are divided into four levels:
                  search, direction-following, aiming and guidance;
                  way-finding behaviours into three levels:
                  recognition-triggered response, topological and
                  survey navigation. .. In computer science, a similar
                  hierarchy has been presented by Kuipers. .. Examples
                  of local navigation mechanisms, recognition-
                  triggered responses and topological navigation can
                  be found throughout the animal kingdom, whereas
                  survey navigation may be limited to
                  vertebrates. .. 4.1. Recognition-triggered response:
                  Insects can associate movement decisions with visual
                  landmarks. Ants, for instance, may learn to always
                  pass a landmark on the right side. .. Bees are able
                  to learn routes, i.e., connected chains of
                  recognition-triggered responses. .. biological
                  systems seem to construct topological
                  representations by integrating routes in a bottom-up
                  manner [38]. This ability has been observed in many
                  animals, ranging from honeybees [16] to humans
                  [21]. ..The above described robot systems show that,
                  mostly within the last five years, biomimetic
                  approaches have been developed for most types of
                  biological navigation, with the exception of search
                  and survey navigation. However, the field is still
                  at the beginning of its development. This is
                  documented by the fact that all of the reviewed
                  approaches aim at testing biological models or
                  mechanisms rather than at finding an optimal
                  technical solution to a given problem. .. From the
                  bionic point of view, biomimetic research has
                  yielded a number of interesting new navigation
                  mechanisms. In particular, corridor-following based
                  on optic flow, path integration with a polarization
                  compass, snapshot-based guidance and
                  recognition-triggered responses are now well
                  understood. .. Before a biomimetic survey navigation
                  system can be built, the hurdle of topological
                  navigation has to be taken. Although the principle
                  problems are well understood, there is currently no
                  system that autonomously builds graphs from routes
                  in a larger scale environment. In our opinion,
                  reliable topological navigation could be the
                  challenge of the near future. Once this is achieved,
                  a number of interesting questions concerning survey
                  navigation can be addressed; for instance, how the
                  topological representation should be embedded in a
                  common reference frame, or how much metric
                  information is necessary for this behaviour. A
                  biomimetic robot capable of survey navigation would
                  finally close the loop that began with abandoning
                  the traditional map-based navigation systems.},
  c-dellaert =	 {SAB-like. 3 top levels of "navigaton hierarchy" are
                  interesting, top two = topological, metric. .. Quite
                  interesting.},
}

@article{Franz98ar,
  author =	 {Franz, M.O. and Sch\"{o}lkopf, B. and Mallot,
                  H.A. and B\"{u}lthoff, H.H.},
  year =	 1998,
  title =	 {Learning view graphs for robot navigation},
  journal =	 {Autonomous Robots},
  volume =	 5,
  pages =	 {111--125},
  abstract =	 {We present a purely vision-based scheme for learning
                  a topological representation of an open
                  environment. The system represents selected places
                  by local views of the surrounding scene, and finds
                  traversable paths between them. The set of recorded
                  views and their connections are combined into a
                  graph model of the environment. To navigate between
                  views connected in the graph, we employ a homing
                  strategy inspired by findings of insect ethology. In
                  robot experiments, we demonstrate that complex
                  visual exploration and navigation tasks can thus be
                  performed without using metric information.},
  quotes =	 {The purpose of the present study is to extend the
                  view graph approach from the mazes of
                  \cite{Sch\"{o}lkopf95ab} to open environments. .. In
                  view-based navigation tasks, visual information is
                  used to guide an agent through space. The reason why
                  this is feasible at all, is the fact that there is a
                  continuous mapping between position space (x- and
                  y-coordinates, possibly supplemented by gaze
                  directions) and the space of all possible
                  views. .. The vertices of the acquired view graph
                  are panoramic views of the environment, and its
                  edges are connections between views that can be
                  traversed using a visual homing procedure.},
  r-Goedeme04jrs ={\citet{Franz98ar} studied topological navigation
                  from a more theoretical point of view. They built a
                  simple robot that builds a topological map. As
                  landmarks they use global features of snapshot
                  images.},
  c-dellaert =	 {Khepera with omni-vision in toy-city. Conceptual
                  mapping from state to view echoes plenoptic function
                  ideas and is cool. View manifold. Homing procedure
                  to make run-time omni-directional image identical to
                  stored snapshot.},
}

@article{Franz98bc,
  author =	 {Franz, M.O. and Sch\"{o}lkopf, B. and Mallot,
                  H.A. and B\"{u}lthoff, H.H.},
  year =	 1998,
  title =	 {Where did I take this snapshot? Scene-based homing
                  by image matching},
  journal =	 {Biological Cybernetics},
  volume =	 79,
  pages =	 {191--202},
  c-dellaert =	 {Did not read: something about homing with priors on
                  landmark distances.}
}

@Book{Fraser00,
  author =	 {N. Fraser},
  title =	 {Stage Lighting Design: A practical Guide.},
  publisher =	 {Crowood Press},
  year =	 2000,
}

@Book{Fraser00,
  author =	 {N. Fraser},
  title =	 {Stage Lighting Design: A practical Guide.},
  publisher =	 {Crowood Press},
  year =	 2000,
}

@InProceedings{Freeman96fg,
  author =	 {W. T. Freeman and K. Tanaka and J. Ohta and
                  K. Kyuma},
  fullauthor =	 {William T. Freeman, Ken-ichi Tanaka, Jun Ohta, Kazuo
                  Kyuma},
  title =	 {Computer vision for computer games},
  booktitle =	 FG,
  pages =	 {100-105},
  year =	 1996,
}

@article{Freitas02,
  author =	 {N. Freitas},
  title =	 {{Rao-Blackwellised} Particle Filtering for Fault
                  Diagnosis},
  journal =	 AS,
  year =	 2002
}

@InProceedings{Frese01ijcai,
  author =	 {U. Frese and G. Hirzinger},
  title =	 {Simultaneous Localization and Mapping - A
                  Discussion},
  booktitle =	 {Proceedings of the IJCAI Workshop on Reasoning with
                  Uncertainty in Robotics},
  pages =	 {17-26},
  year =	 2001,
}

@Inproceedings{Frese03ijcai,
  author =	 {U. Frese and T. Duckett},
  title =	 {A multigrid approach for accelerating
                  relaxation-based {SLAM}},
  booktitle =	 {Proc. of the IJCAI-03 on Reasoning with Uncertainty
                  in Robotics},
  year =	 2003,
}

@PhdThesis{Frese04thesis,
  author =	 {U. Frese},
  fullauthor =	 {Udo Frese},
  title =	 {An {$O(\log n)$} Algorithm for Simultaneous
                  Localization and Mapping of Mobile Robots in Indoor
                  Environments},
  year =	 2004,
  school =	 {{University of Erlangen-N{\"u}rnberg}},
}

@InProceedings{Frese05icra,
  author =	 {U. Frese},
  fullauthor =	 {Udo Frese},
  title =	 {A Proof for the Approximate Sparsity of {SLAM}
                  Information Matrices},
  booktitle =	 ICRA,
  pages =	 {331-337},
  year =	 2005,
}

@Inproceedings{Frese05sc,
  author =	 {U. Frese},
  fullauthor =	 {Udo Frese},
  year =	 2005,
  title =	 {Treemap: {A}n {$O(\log n)$} Algorithm for
                  Simultaneous Localization and Mapping},
  booktitle =	 {Spatial Cognition IV},
  publisher =	 {Springer Verlag},
  pages =	 "455-476",
}

@Article{Frese05tro,
  author =	 {U. Frese and P. Larsson and T. Duckett},
  fullauthor =	 {Udo Frese and Per Larsson and Tom Duckett},
  title =	 {A Multilevel Relaxation Algorithm for Simultaneous
                  Localisation and Mapping},
  journal =	 TRO,
  year =	 2005,
  volume =	 21,
  number =	 2,
  pages =	 {196-207},
  month =	 {April},
}

@Article{Frese06ar,
  author =	 {U. Frese},
  fullauthor =	 {Udo Frese},
  title =	 {A Discussion of Simultaneous Localization and
                  Mapping},
  journal =	 AR,
  year =	 2006,
  volume =	 20,
  pages =	 {25-42},
}

@Article{Frese06ar2,
  author =	 {U. Frese},
  fullauthor =	 {Udo Frese},
  title =	 {Treemap: An {$O(\log n)$} Algorithm for Indoor
                  Simultaneous Localization and Mapping},
  journal =	 AR,
  year =	 2006,
  volume =	 21,
  number =	 2,
  pages =	 {103-122},
}

@InProceedings{Frese06iros,
  author =	 {U. Frese and L. Schr\"oder},
  fullauthor =	 {Udo Frese and Lutz Schr\"oder},
  title =	 {Closing a Million-Landmarks Loop},
  booktitle =	 IROS,
  pages =	 {5032-5039},
  month =	 {Oct},
  year =	 2006,
}

@article{Freuder82jacm,
  author =	 {Eugene C. Freuder},
  title =	 {A Sufficient Condition for Backtrack-Free Search},
  journal =	 {J. ACM},
  volume =	 29,
  number =	 1,
  year =	 1982,
  issn =	 {0004-5411},
  pages =	 {24--32},
  doi =		 {http://doi.acm.org/10.1145/322290.322292},
  publisher =	 {ACM Press},
  address =	 {New York, NY, USA},
  abstract =	 {A constraint satisfaction problem revolves finding
                  values for a set of variables subject to a set of
                  constraints (relations) on those
                  variables. Backtrack search is often used to solve
                  such problems. A relationship involving the
                  structure of the constraints is described which
                  characterizes to some degree the extreme case of
                  minimum backtracking (none). The relationship
                  involves a concept called "width," which may provide
                  some guidance in the representation of constraint
                  satisfaction problems and the order in which they
                  are searched. The width concept is studied and
                  applied, in particular, to constraints which form
                  tree structures.},
  r-Dechter92chapter ={Graphical properties of CN were initially
                  investigated through the class of binary constraint
                  networks \cite{Freuder82jacm}. A binary constraint
                  network is one in which every constraint subset
                  involves at most two variables.},
  c-dellaert =	 {I did not read the paper in a lot of detail, but did
                  discover several noteworthy things: Freuder actually
                  did his thesis with Minsky on "A Computer System for
                  Visual Recognition Using Active Knowledge" and
                  references early vision work by Tenenbaum & Barrow
                  and Waltz as "more serious examples" of constraint
                  problems. The paper uses the "scene labeling" work
                  by (his MIT officemate) David Waltz as an example,
                  and an interesting history of their history is given
                  in \cite{Waltz06}. },
}

@Article{Frey00,
  author =	 "B. Frey and N. Jojic",
  fullauthor =	 "Brendan J. Frey and Nebojsa Jojic",
  title =	 "Transformation-{I}nvariant {C}lustering and
                  {D}imensionality {R}eduction {U}sing {EM}",
  journal =	 PAMI,
  year =	 2003,
  volume =	 25,
  number =	 1,
  pages =	 {1-17},
  month =	 {January},
  c-sangmin =	 {introduce pre-defined sets of transformations for
                  images to learn the representative appearances from
                  un-aligned examples. EM procedure builds PDFs on
                  discrete transformations and iterates updating the
                  apperaances of examples. Different clusters are
                  found as well by mixture modeling. The materials are
                  the basis for Jojic00,Jojic01,i.e., sprite learning
                  works.},
}

@INPROCEEDINGS{Frey03uai,
  AUTHOR =	 "B. Frey",
  FULLAUTHOR =	 "Brendan Frey",
  TITLE =	 "Extending Factor Graphs so as to Unify Directed and
                  Undirected Graphical Models",
  quotes =	 {Whereas BNs are well suited to construction using
                  known causal relationships, MRFs are well-suited to
                  construction using known Markov blankets, or
                  non-causal relationships. ... BNs and MRFs also have
                  common weaknesses.},
  crossref =	 {_UAI03},
  c-dellaert =	 {Extends original factor graphs with directed
                  edges. According to me this destroys the nice
                  relationship with linear algebra.},
}

@Article{Frey05,
  author =	 "B. Frey and N. Jojic",
  fullauthor =	 "Brendan J. Frey and Nebojsa Jojic",
  title =	 "A Comparison of Algorithms for Inference and
                  Learning in Probabilistic Graphical Models",
  journal =	 PAMI,
  year =	 2005,
  volume =	 27,
  number =	 9,
  month =	 {September},
}

@TechReport{Frey1999fa,
  author =	 "B.J. Frey",
  title =	 "Factor analysis using batch and online {EM}",
  institution =	 "Internal UW/CS Adaptive Computation",
  year =	 1999,
  number =	 "TR-99-2"
}

@InProceedings{Frey96ccc,
  author =	 {B.J. Frey and F.R. Kschischang},
  title =	 {Probability propagation and iterative decoding},
  booktitle =	 {Proc. 34th Allerton Conf. Communications, Control,
                  and Computing},
  year =	 1996,
  month =	 {October},
  r-Loeliger04spm ={It was therefore exciting when, in the wake of
                  turbo coding, probability propagation and the
                  sum-product algorithm were found to be the same
                  thing \citep{Frey96ccc,Aji00it}. In particular, the
                  example of iterative decoding proved that
                  probability propagation, which had been used only
                  for cycle-free graphs, could be used also for graphs
                  with cycles. },
}

@InProceedings{Frey97ccc,
  author =	 {B.J. Frey and F.R. Kschischang and H.-A. Loeliger
                  and N. Wiberg},
  title =	 {Factor graphs and algorithms},
  booktitle =	 {Proc. 35th Allerton Conf. Communications, Control,
                  and Computing},
  pages =	 {666--680},
  year =	 1997,
  month =	 {September},
  r-Loeliger04spm ={The later introduction of factor graphs
                  \citep{Frey97ccc,Kschischang03spm} may be viewed as
                  a further elaboration of the ideas by Wiberg et
                  al. In the present article, we will use Forney-style
                  factor graphs (FFGs), which were introduced in
                  \citep{Forney01it} (and there called "normal
                  graphs").}
}

@Book{Frey98book,
  author =	 {B.J. Frey},
  title =	 {Graphical Models for Machine Learning and Digital
                  Communication},
  publisher =	 {MIT Press},
  year =	 1998,
  address =	 {Cambridge, MA},
  r-Kask05ai =	 {Tree-decomposition techniques were also introduced
                  in the context of machine learning
                  \cite{Frey98book}},
}

@inproceedings{Frey98mixtures,
  author =	 "B. Frey and A. Colmenarez and T. Huang",
  title =	 "Mixtures of local linear subspaces for face
                  recognition",
  booktitle =	 CVPR,
  pages =	 "32-37",
  year =	 1998,
  url =		 "citeseer.nj.nec.com/frey98mixtures.html"
}

@InProceedings{Frey98nips,
  author =	 {B.J. Frey and D.J.C. MacKay},
  title =	 {A revolution: Belief propagation in graphs with
                  cycles},
  booktitle =	 NIPS,
  year =	 1998,
}

@InProceedings{Friedman00,
  author =	 "N. Friedman and D. Koller",
  title =	 "Being {B}ayesian about Network Structure",
  crossref =	 {_UAI00},
}

@InProceedings{Friedman97uai,
  author =	 {N. Friedman and S. Russell},
  title =	 {Image segmentation in video sequences: A
                  probabilistic approach},
  crossref =	 {_UAI97},
  abstract =	 {``Background subtraction'' is an old technique for
                  finding moving objects in a video sequence---for
                  example, cars driving on a freeway. The idea is that
                  subtracting the current image from a time-averaged
                  background image will leave only nonstationary
                  objects. It is, however, a crude approximation to
                  the task of classifying each pixel of the current
                  image; it fails with slow-moving objects and does
                  not distinguish shadows from moving objects. The
                  basic idea of this paper is that we can classify
                  each pixel using a model of how that pixel looks
                  when it is part of different classes. We learn a
                  mixture-of-Gaussians classification model for each
                  pixel using an unsupervised technique---an
                  efficient, incremental version of EM. Unlike the
                  standard image-averaging approach, this
                  automatically updates the mixture component for each
                  class according to likelihood of membership; hence
                  slow-moving objects are handled perfectly. Our
                  approach also identifies and eliminates shadows much
                  more effectively than other techniques such as
                  thresholding. Application of this method as part of
                  the Roadwatch traffic surveillance project is
                  expected to result in significant improvements in
                  vehicle identification and tracking.},
  c-houdan =	 {use EM is learn a three-model mixture of Gaussians
                  for road, shadow and vehicle},
}

@InProceedings{Friedman98,
  author =	 "Nir Friedman",
  title =	 "The {B}ayesian structural {EM} algorithm",
  crossref =	 {_UAI98},
}

@InProceedings{Friedman99ijcai,
  author =       {Nir Friedman and Lise Getoor and Daphne Koller and Avi Pfeffer},
  title =        {Learning Probabilistic Relational Models},
  booktitle =    IJCAI,
  year =         1999,
  added-by =     {Alex},
}

@InCollection{Frintrop07acs,
  author =	 {S. Frintrop and P. Jensfelt and H. Christensen},
  fullauthor =	 {Simone Frintrop and Patric Jensfelt and Henrik
                  Christensen},
  title =	 {Simultaneous Robot Localization and Mapping Based on
                  a Visual Attention System},
  booktitle =	 {Attention in Cognitive Systems},
  publisher =	 {Springer-Verlag},
  year =	 {2007},
  volume =	 {4840},
  series =	 {Lecture Notes on Artificial Intelligence (LNAI)},
  c-dellaert =	 {Interesting paper that uses saliency to detect
                  landmarks, and active gaze control to detect
                  landmarks in a map built by SLAM. There is not whole
                  lot of argument for why this is a good thing.},
}

@Book{FrischBook67,
  author =	 {K. Frisch},
  title =	 {The Dance Language and Orientation of Bees},
  publisher =	 {Harvard University Press},
  year =	 1967,
}

@inproceedings{Fritz05icra,
  Abstract =	 {Autonomous mobile agents require object recognition
                  for high level interpretation and localization in
                  complex scenes. In urban environments, recognition
                  of buildings might play a dominant role in robotic
                  systems that need object based navigation, that take
                  advantage of visual feedback and multimodal
                  information for self-localization, or that enable
                  association to related information from the
                  identified semantics. We present a new method "the
                  informative local features approach" based on an
                  information theoretic saliency measure that is
                  rapidly derived from a local Parzen window density
                  estimation in feature subspace. From the learning of
                  a decision tree based mapping to informative
                  features, it enables attentive access to
                  discriminative information and thereby significantly
                  speeds up the recognition process. This approach is
                  highly robust with respect to severe degrees of
                  partial occlusion, noise, and tolerant to some
                  changes in scale and illumination. We present
                  performance evaluation on our publicly available
                  reference object database (TSG-20) that demonstrates
                  the efficiency of this approach, case wise even
                  outperforming the SIFT feature approach. Building
                  recognition will be advantageous in various
                  application domains, such as, mobile mapping,
                  unmanned vehicle navigation, and systems for car
                  driver assistance.},
  Author =	 {Fritz, G. and Seifert, C. and Paletta, L.},
  booktitle =	 ICRA,
  Pages =	 {131--137},
  Title =	 {Urban Object Recognition from Informative Local
                  Features},
  Year =	 2005,
}

@Book{Fu74book,
  author =	 {K.S. Fu},
  title =	 {Syntactic Methods in Pattern Recognition},
  publisher =	 ap,
  year =	 1974,
  address =	 {New York and London},
}

@Article{Fu83,
  author =	 {K.S. Fu and Q.Y. Shi},
  title =	 {Parsing and Translation of Attributed Expensive
                  Graph Languages for Scene Analysis},
  journal =	 PAMI,
  year =	 1983,
  volume =	 5,
  pages =	 {472-485},
}

@Article{Fu86,
  author =	 {K.S. Fu and T.I. Fan},
  title =	 {Tree translation and its application to time-varying
                  image analysis problem},
  journal =	 SMC,
  year =	 1986,
  volume =	 12,
  pages =	 {856-867},
}

@Article{Fua97,
  author =	 "P Fua",
  title =	 "From Multiple Stereo Views to Multiple {3D}
                  Surfaces",
  journal =	 IJCV,
  volume =	 24,
  number =	 1,
  month =	 "August",
  year =	 1997,
  pages =	 "19-35",
}

@inproceedings{Fuchs80,
  author =	 {Henry Fuchs and Zvi M. Kedem and Bruce F. Naylor},
  title =	 {On visible surface generation by a priori tree
                  structures},
  booktitle =	 {SIGGRAPH '80: Proceedings of the 7th annual
                  conference on Computer graphics and interactive
                  techniques},
  year =	 1980,
  isbn =	 {0-89791-021-4},
  pages =	 {124--133},
  location =	 {Seattle, Washington, United States},
  publisher =	 {ACM Press},
  address =	 {New York, NY, USA},
}

@Book{Fukunaga90,
  author =	 "K Fukunaga",
  title =	 "Introduction to Statistical Pattern Recognition",
  publisher =	 "Academic Press",
  year =	 1990,
  address =	 "London",
}

@Article{Fulkerson65pjm,
  author =	 {D.R. Fulkerson and O.A. Gross},
  title =	 {Incidence matrices and interval graphs},
  journal =	 {Pacific J. Math.},
  year =	 1965,
  volume =	 15,
  abstract =	 {According to present genetic theory, the fine
                  structure of genes consists of linearly ordered
                  elements. A mutant gene is obtained by alteration of
                  some connected portion of this structure. By
                  examining data obtained from suitable experiments,
                  it can be determined whether or not the blemished
                  portions of two mutant genes intersect or not, and
                  thus intersection data for a large number of mutants
                  can be represented as an undirected graph. If this
                  graph is an "interval graph", then the observed data
                  are consistent with a linear model of the
                  gene. Given a family of sets $S_1,S_2,\cdots,S_n$,
                  one can form the intersection graph of the family by
                  associating a vertex of the graph with each set and
                  joining two distinct vertices with an edge if their
                  corresponding sets have a nonempty
                  intersection. Conversely, any finite graph can, of
                  course, be viewed as the intersection graph of a
                  family of sets (in many ways). If each set can be
                  taken as an interval on the real line, the graph is
                  called an interval graph. The problem of determining
                  when a graph is an interval graph is a special case
                  of the following problem concerning
                  $(0,1)$-matrices: When can the rows of such a matrix
                  be permuted so as to make the 1's in each column
                  appear consecutively? A complete theory is obtained
                  for this latter problem, culminating in a
                  decomposition theorem which leads to a rapid
                  algorithm for deciding the question, and for
                  constructing the desired permutation when one
                  exists.},
  r-Heggernes06dm ={Chordal graphs were introduced several years
                  before the first graph theory results related to
                  sparse matrix compu- tations appeared.3 The
                  definition of chordal graphs is thus independent of
                  vertex elimination, and graphs of this class can be
                  characterized by their minimal separators, as shown
                  by Dirac \cite{Dirac61} in 1961. At the same time,
                  they coincide with the class of graphs resulting
                  from Elimination Game, and they can also be
                  characterized through vertex orderings, as shown by
                  Fulkerson and Gross \cite{Fulkerson65pjm} in 1965.},
  c-dellaert =	 {Only skimmed, application of chordal graphs to
                  genetics}
}

@InProceedings{Funge99siggraph,
  author =	 "J. Funge and X. Tu and D. Terzopoulos",
  fullauthor =	 "John Funge and Xiaoyuan Tu and Demetri Terzopoulos",
  title =	 {{Cognitive Modeling: Knowledge, Reasoning and
                  Planning for Intelligent Characters}},
  booktitle =	 SIGGRAPH,
  publisher =	 "Addison Wesley Longman",
  address =	 "Los Angeles",
  editor =	 "Alyn Rockwood",
  pages =	 "29--38",
  year =	 "1999",
}

@InProceedings{Funiak06ipsn,
  author =	 {S. Funiak and C. Guestrin and M. Paskin and
                  R. Sukthankar},
  fullauthor =	 {Stanislav Funiak and Carlos Guestrin and Mark Paskin
                  and Rahul Sukthankar},
  title =	 {Distributed Localization of Networked Cameras},
  booktitle =	 IPSN,
  year =	 2006,
  month =	 "April",
}

@inproceedings{Funk07crv,
  author =	 {Nathan Funk and Yee-Hong Yang},
  title =	 {Using a Raster Display for Photometric Stereo},
  booktitle =	 {Canadian Conference on Computer and Robot Vision},
  year =	 {2007},
  isbn =	 {0-7695-2786-8},
  pages =	 {201--207},
  doi =		 {http://dx.doi.org/10.1109/CRV.2007.66},
}

@InProceedings{Furst97,
  author =	 "S Furst and S Werner and D Dickmanns and E D
                  Dickmanns",
  title =	 "Landmark navigation and autonomous landing approach
                  with obstacle detection for aircraft",
  booktitle =	 SPIE,
  volume =	 3088,
  year =	 1997,
  pages =	 "28-39",
}

@PhdThesis{Gaffney04thesis,
  author =	 "Gaffney S.J.",
  fullauthor =	 "Scott John Gaffney",
  title =	 "Probabilistic Curve-Aligned Clustering and
                  Prediction with Regression Mixture Models",
  school =	 "University of California, Irvine",
  year =	 2004,
}

@inproceedings{Galindo05,
  author =	 {C. Galindo and A. Saffiotti and S. Coradeschi and
                  P. Buschka and J.A. Fernndez-Madrigal and
                  J. Gonzl ez},
  title =	 {Multi-Hierarchical Semantic Maps for Mobile
                  Robotics},
  booktitle =	 IROS,
  pages =	 {3492--3497},
  year =	 2005,
}

@Article{Gallager62it,
  author =	 {Gallager, R.},
  title =	 {Low-density parity-check codes},
  journal =	 IT,
  year =	 1962,
  volume =	 8,
  number =	 1,
  pages =	 {21--28},
  month =	 {January},
  r-Aji00it =	 {The earliest occurrence of a GDL-like algorithm that
                  we are aware of is Gallager's 1962 algorithm for
                  decoding low-density parity-check codes
                  \cite{Gallager62it}},
  r-Loeliger04spm ={In the context of error-correcting codes, the
                  sum-product algorithm was invented by
                  \citet{Gallager62it} as a decoding algorithm for
                  LDPC codes; it is still the standard decoding
                  algorithm for such codes.}
}

@Book{Gamerman97,
  author =	 "D. Gamerman",
  title =	 "Markov chain {M}onte {C}arlo",
  publisher =	 chap,
  year =	 1997,
}

@TechReport{Gansterer03tr,
  author =	 {W. Gansterer and T. Korimort},
  fullauthor =	 {Wilfried Gansterer and Thomas Korimort},
  title =	 {Matrix Reordering by Hypertree Decomposition},
  institution =	 {University of Vienna},
  year =	 2003,
  number =	 {AURORA TR2003-19},
  abstract =	 {Recently, in the area of constraint satisfaction a
                  new hypergraph decomposition technique has been
                  invented by Gottlob et al. called hypertree
                  decomposition. In this report hypertree
                  decomposition is applied to matrix reordering. A new
                  structure of a given matrix is obtained by reording
                  rows and columns according to a special hypertree
                  decomposition computed for a hypergraph related to
                  the non-zero structure of the matrix.},
  c-dellaert =	 {Evaluates hypertree method introduced by
                  \cite{Gottlob02jcss} for re-ordering matrices. The
                  results compare well with reverse Cuthill-McKee.}
}

@InProceedings{Gao00cvpr,
  author =	 {X. Gao and T.E. Boult and F. Coetzee and V. Ramesh},
  title =	 {Error Analysis of Background Adaption},
  booktitle =	 CVPR,
  year =	 2000,
  abstract =	 {Background modeling is a common component in video
                  surveillance systems and is used to quickly identify
                  regions of interest. To increase the robustness of
                  background subtraction techniques, researchers have
                  developed techniques to update the background model
                  and also developed probabilistic/statistical
                  approaches for thresholding the difference. This
                  paper presents an error analysis of this type of
                  background modeling and pixel labeling, providing
                  both theoretical analysis and experimental
                  validation. Evaluation is cen- tered around the
                  tradeoff of probability of false alarm and
                  probability of miss detection, and this paper shows
                  how to efficiently compute these probabilities from
                  simpler values that are more easily measured. It
                  includes an analysis for both static and dynamic
                  background modeling. The paper also examines the
                  assumptions of Gaussian and mixture of Gaussian
                  models for a pixel. },
  c-houdan =	 {Here the error analysis of adaptive Gaussian mixture
                  approach is divided into two parts: Probability of
                  False Alarm and Probability of Miss Detect},
}

@inproceedings{Gargallo05cvpr,
  author =	 "P.Gargallo and P.Sturm",
  title =	 "Bayesian 3D Modeling from Images using Multiple
                  Depth Maps",
  booktitle =	 CVPR,
  year =	 2005,
  pages =	 "885-891"
}

@Article{Garibaldi06ce,
  author =	 {U. Garibaldi and D. Constantini and S. Donadio and
                  P. Viarengo},
  title =	 "{Herding and Clustering in Economics: The
                  Yule-Zipf-Simon Model}",
  journal =	 "{Computational Economics}",
  volume =	 27,
  number =	 1,
  pages =	 {115--134},
  year =	 2006,
}

@Article{Gaspar00tra,
  author =	 {Gaspar, J. and Winters, N. and Santos-Victor, J.},
  title =	 {Vision-based Navigation and Environmental
                  Representations with an Omnidirectional Camera},
  journal =	 TRA,
  volume =	 16,
  number =	 6,
  pages =	 {890-898},
  month =	 {Dec},
  year =	 2000,
  abstract =	 {This paper proposes a method for the visual-based
                  navigation of a mobile robot in indoor environments,
                  using a single omni-directional (catadioptric)
                  camera. The geometry of the catadioptric sensor and
                  the method used to obtain a bird? eye (orthographic)
                  view of the ground plane are presented. This
                  representation significantly simplifies the solution
                  to navigation problems, by eliminating any
                  perspective effects. The nature of each navigation
                  taskis taken into account when designing the
                  required navigation skills and environmental
                  representations. We propose two main navigation
                  modalities: Topological Navigation and Visual Path
                  Following. Topological Navigation is used for
                  traveling long distances and does not require
                  knowledge of the exact position of the robot but
                  rather, a qualitative position on the topological
                  map. The navigation process combines appearance
                  based methods and visual servoing upon some
                  environmental features. Visual Path Following is
                  required for local, very precise navigation, for
                  e.g. door traversal, docking. The robot is
                  controlled to follow a pre-specified path
                  accurately, by tracking visual landmarks in bird?
                  eye views of the ground plane. By clearly separating
                  the nature of these navigation tasks, a simple and
                  yet powerful navigation system is obtained.},
}

@Book{Gauss1809,
  author =	 {C.F. Gauss},
  fullauthor =	 {Carl Friedrich Gauss},
  title =	 {Theoria Motus Corporum Coelestium in Sectionibus
                  Conicis Solem Mabientium [Theory of the Motion of
                  the heavenly Bodies Moving about the Sun in Conic
                  Sections]},
  publisher =	 {Perthes and Besser},
  year =	 1809,
  address =	 {Hamburg, Germany},
  r-Stewart =	 {The Cholesky decomposition (more precisely, an LDL'
                  decomposition) was the decomposition of Gauss's
                  elimination algorithm, which he sketched in 1809
                  \cite{Gauss1809} and presented in full in 1810
                  \cite{Gauss1810}},
  note =	 {English translation available at
                  http://name.umdl.umich.edu/AGG8895.0001.001}
}

@Article{Gauss1810,
  author =	 {C.F. Gauss},
  fullauthor =	 {Carl Friedrich Gauss},
  title =	 {Disquisitio de elementis ellipticis {Palladis}
                  [{Disquisition} on the elliptical Elements of
                  {Pallas}]},
  journal =	 {G\"{o}ttingische gelehrte Anzeigen},
  month =	 {December},
  year =	 1810,
  r-Stewart =	 {The Cholesky decomposition (more precisely, an LDL'
                  decomposition) was the decomposition of Gauss's
                  elimination algorithm, which he sketched in 1809
                  \cite{Gauss1809} and presented in full in 1810
                  \cite{Gauss1810}},
  c-dellaert =	 {This is actually an account of a lecture Gauss gave
                  on Nov. 25, on determining the orbit of the "planet"
                  Pallas (it is now considered an asteroid, the third
                  most massive object in the asteroid belt).},
}

@Article{Gauvrit97,
  author =	 {Gauvrit, H. and Le Cadre, J.P. and Jauffret, C.},
  title =	 {A formulation of multitarget tracking as an
                  incomplete data problem},
  journal =	 AES,
  year =	 1997,
  volume =	 33,
  number =	 4,
  pages =	 {1242-1257},
  month =	 {October},
}

@Article{Gavril72siam,
  author =	 {F. Gavril},
  title =	 {Algorithms for minimum coloring, maximum clique,
                  minimum covering by cliques and maximum independent
                  set of a chordal graph.},
  journal =	 {SIAM Journal on Computing},
  year =	 1972,
  volume =	 1,
  pages =	 {180-187},
  r-Rose75stoc = {These graphs arise in other contexts and have also
                  been called chordal \cite{Gavril72siam} and rigid
                  circuit graphs \cite{Dirac}. In
                  \cite{Gavril74unpublished} Gavril has constructed an
                  0(n 2.81) algorithm for testing when an undirected
                  graph is triangulated and in \cite{Gavril72siam} he
                  has presented efficient algorithms for finding all
                  maximal cliques, maximum cliques, minimum colorings,
                  maximum independent sets, and minimum clique
                  coverings in tirangulated graphs.}
}

@Article{Gavril74jct,
  author =	 {F. Gavril},
  title =	 {The intersection graphs of subtrees in trees are
                  exactly the chordal graphs},
  journal =	 {Journal of Combinatorial Theory, Series B},
  year =	 1974,
  volume =	 16,
  pages =	 {47--56},
  month =	 {February},
  r-Blair93chapter ={The notion of clique trees was introduced
                  independently by Buneman \cite{Buneman74dm},
                  Gavril\cite{Gavril74jct}, and Walter
                  \cite{Walter72thesis}},
  r-Heggernes06dm ={Chordal graphs are exactly the intersection graphs
                  of subtrees of a tree
                  \cite{Buneman74dm,Gavril74jct,Walter72thesis}: A
                  graph G is chordal if and only if there exists a
                  tree T whose vertex set is the set of maximal
                  cliques of G and that satisfies the following
                  property: for every vertex v in G, the set of
                  maximal cliques containing v induces a connected
                  subtree of T. Such a tree is called a clique tree,
                  and it can be computed in linear time
                  \cite{Blair93chapter}.},
}

@inproceedings{Gavrila00eccv,
  author =	 "D. Gavrila",
  title =	 "Pedestrian Detection from a Moving Vehicle",
  booktitle =	 ECCV,
  year =	 2000,
  pages =	 "37-49",
}

@InProceedings{Gavrila96,
  author =	 "D. Gavrila and L. Davis",
  title =	 "Model-based tracking of humans in action: a
                  multi-view approach",
  booktitle =	 CVPR,
  pages =	 "73--80",
  year =	 1996
}

@inproceedings{Gavrila99iccv,
  author =	 "D. Gavrila and V. Philomin",
  title =	 "Real-Time Object Detection for ``Smart`` Vehicles",
  booktitle =	 ICCV,
  year =	 1999,
  pages =	 "87--93",
}

@inproceedings{Ge00kdd,
  author =	 {X. Ge and P. Smyth},
  title =	 "Deformable {M}arkov model templates for time-series
                  pattern matching",
  booktitle =	 KDD,
  year =	 2000,
  pages =	 {81-90},
}

@inproceedings{Ge03ci,
  author =	 {{Ge}, M. and {D'Zmura}, M.},
  title =	 "{4D structure from motion: a computational
                  algorithm}",
  booktitle =	 {Computational Imaging.},
  year =	 2003,
  month =	 jun,
  pages =	 {13-23},
  doi =		 {10.1117/12.487987},
  adsurl =
                  {http://adsabs.harvard.edu/cgi-bin/nph-bib_query?bibcode=2003SPIE.5016...13G&db_key=PHY},
  adsnote =	 {Provided by the Smithsonian/NASA Astrophysics Data
                  System}
}

@InProceedings{Gee08tro,
  author =	 {Andrew P. Gee and Denis Chekhlov and Andrew Calway
                  and Walterio Mayol-Cuevas},
  title =	 {Discovering Higher Level Structure in Visual SLAM},
  booktitle =	 {IEEE Trans. on Robotics.},
  year =	 {2008}
}

@InProceedings{Gee08tro,
  author = {Andrew P. Gee and Denis Chekhlov and Andrew Calway and Walterio Mayol-Cuevas},
  title = {Discovering Higher Level Structure in Visual SLAM},
  booktitle = {IEEE Trans. on Robotics.},
  year = {2008}
}

@Article{Gelfand90,
  author =	 "A.E. Gelfand and A.F.M. Smith",
  title =	 "Sampling-Based Approaches to Calculating Marginal
                  Densities",
  journal =	 "J. Am. Statistical Association",
  year =	 1990,
  month =	 "June",
  volume =	 85,
  number =	 410,
  pages =	 "398-409"
}

@Article{Gelman92,
  author =	 "A. Gelman and D.B. Rubin",
  title =	 "Inference from iterative simulation using multiple
                  sequence",
  journal =	 "Statist. Sci.",
  year =	 1992,
  volume =	 7,
  pages =	 "457--511",
}

@Book{Gelman95,
  author =	 "A. Gelman and J.B. Carlin and H.S. Stern and
                  D.B. Rubin",
  title =	 "Bayesian Data Analysis",
  publisher =	 chap,
  year =	 1995,
}

@InCollection{Gelman96,
  author =	 "A. Gelman",
  title =	 "Inference and Monitoring Convergence",
  crossref =	 "Gilks96",
  pages =	 "131-140",
}

@Article{Geman84,
  author =	 {S. Geman and D. Geman},
  fullauthor =	 {Stuart Geman and Donald Geman},
  title =	 {Stochastic Relaxation, {G}ibbs Distributions, and
                  the {B}ayesian Restoration of Images },
  journal =	 PAMI,
  year =	 1984,
  volume =	 6,
  number =	 6,
  pages =	 {721-741},
  month =	 nov,
}

@InProceedings{Genc02,
  author =	 {Y.Genc and S.Riedel and F.Souvannavong and C.Akmlar
                  and N.Navab},
  title =	 {Marker-less Tracking for AR: A learning-Based
                  Approach},
  booktitle =	 {ISMAR},
  year =	 2002,
}

@InProceedings{Gennari04,
  author =	 {G. Gennari and G. D. Hager },
  title =	 {Probabilistic data association for visual tracking
                  of groups},
  booktitle =	 CVPR,
  year =	 2004,
}

@Article{Gennery90,
  author =	 "D. Gennery",
  title =	 "Visual tracking of known three-dimensional objects",
  journal =	 IJCV,
  volume =	 7,
  number =	 3,
  year =	 1990,
}

@InProceedings{Genovesio04,
  author =	 {A. Genovesio and J. C. Olivo-Marin},
  title =	 {Split and merge data association filter for dense
                  multi-target tracking},
  booktitle =	 ICPR,
  pages =	 {677-680},
  year =	 2004,
}

@Article{Gentleman73ma,
  author =	 {W.M. Gentleman},
  title =	 {Least squares computations by {Givens}
                  transformations without square roots},
  journal =	 {IMA J. of Appl. Math.},
  year =	 1973,
  volume =	 12,
  pages =	 {329-336},
  r-MathSciNet = {The author cites the cases where it is more
                  advantageous to use Givens transformations rather
                  than other methods, such as the Householder or the
                  Gram-Schmidt. The author modifies Givens
                  transformations in such a way as to eliminate the
                  square roots and also reduces the number of
                  multiplications by one-half. A round-off error
                  analysis reveals that one version of the proposed
                  method may run into some troubles with
                  overflows/underflows. However, such troubles may be
                  avoided.},
}

@Article{George73siam,
  author =	 {A. George},
  fullauthor =	 {Alan George},
  title =	 {Nested Dissection of a Regular Finite Element Mesh},
  journal =	 {SIAM Journal on Numerical Analysis},
  year =	 1973,
  volume =	 10,
  number =	 2,
  pages =	 {345-363},
  month =	 {April},
  r-MathSciNet = {The author considers a system of $(n+1)^2$ linear
                  equations $Ax=b$ derived, for example, from a
                  regular $n\times n$ mesh used in solving
                  self-adjoint elliptic boundary value problems. It is
                  assumed that $A$ is symmetric, positive definite,
                  and has a particular zero-nonzero structure
                  associated with such boundary value problems. No
                  further assumptions are made regarding the values of
                  the nonzero elements of $A$. Using a particular
                  ordering, the author shows that $A$ can be factored
                  in $O(n^3)$ operations and that the lower triangular
                  factor must have $O(n^2\ln_2n)$ nonzero
                  components. Since these bounds have been shown by
                  A. J. Hoffman, M. S. Martin and D. J. Rose [same
                  issue] to be lower bounds, it follows that the given
                  technique is optimal. }
}

@Book{George81book,
  author =	 {George, A. and Liu, J.W.H.},
  fullauthor =	 {George, Alan and Liu, Joseph W. H.},
  title =	 {Computer solution of large sparse positive definite
                  systems},
  publisher =	 {Prentice-Hall},
  year =	 1981,
  series =	 {Computational Mathematics},
  address =	 {Englewood Cliffs, N.J.},
  r-MathSciNett ={This book provides an excellent introduction to
                  techniques in the computer implementation of direct
                  methods for the solution of sparse positive definite
                  systems of linear equations. The opening three
                  chapters review Gaussian elimination and the
                  solution of triangular systems on both full and
                  sparse systems and introduce sparse data structures,
                  graph theory terminology, and basic operations on
                  graphs. Each of the next five chapters discusses a
                  method of organising the sparse elimination and
                  solution. Each method is divided into ordering,
                  storage allocation, factorization, and solution
                  phases, which are discussed in depth with the aid of
                  an algorithmic description based on graph theory and
                  a computer program taken from the SPARSPAK
                  package. These five chapters correspond to the five
                  solution techniques offered by SPARSPAK: envelope
                  methods (reverse Cutholl McKee), general sparse
                  methods (implementations of minimum degree),
                  quotient tree methods (refined quotient tree),
                  one-way dissection, and nested dissection....},
  r-Liu85toms =	 {The most widely used general-purpose ordering scheme
                  in sparse matrix computation is the minimum-degree
                  algorithm \cite{Duff82, Eisenstat77, George81book,
                  Tinney67ieee}},
  r-Heggernes06dm ={Although we know today that minimal triangulations
                  are closely related to minimal separators, sparse
                  matrix computations was the first field to study
                  different triangulations of a given graph
                  \cite{George81book, Parter61siam, Rose72chapter}.}
}

@article{George84laa,
  author =	 {George, A. and Liu, J. and Ng E.},
  title =	 {Row-ordering schemes for sparse {Givens}
                  transformations. {I. Bipartite} graph model},
  journal =	 {Linear Algebra Appl},
  volume =	 {61},
  pages =	 {55--81},
  year =	 {1984},
  c-dellaert =	 {Original use of bipartite graphs to model QR ?}
}

@Article{George89siam,
  author =	 {George, A. and Liu, J.W.H.},
  title =	 {The evolution of the minimum degree ordering
                  algorithm},
  journal =	 {SIAM Rev.},
  year =	 1989,
  volume =	 31,
  number =	 1,
  pages =	 {1--19},
  abstract =	 {Over the past fifteen years, the implementation of
                  the minimum degree algorithm has received much
                  study, and many important enhancements have been
                  made to it. This paper describes these various
                  enhancements, their historical development, and some
                  experiments showing how very effective they are in
                  improving the execution time of the algorithm. A
                  shortcoming is also presented that exists in all of
                  the widely used implementations of the algorithm,
                  namely, that the quality of the ordering provided by
                  the implementations is surprisingly sensitive to the
                  initial ordering. For example, changing the input
                  ordering can lead to an increase (or decrease) of as
                  much as a factor of three in the cost of the
                  subsequent numerical factorization. This sensitivity
                  is caused by the lack of an effective tie-breaking
                  strategy, and the authors' experiments illustrate
                  the importance of developing such a strategy.},
}

@Book{George93book,
  editor =	 {J.A. George and J.R. Gilbert and J.W-H. Liu},
  title =	 {Graph Theory and Sparse Matrix Computations},
  publisher =	 {Springer-Verlag},
  year =	 {1993},
  series =	 {IMA Volumes in Mathematics and its Applications},
  volume =	 {56},
}

@InProceedings{Georghiades1999ibi,
  author =	 {A.Georghiades and P.Belhumeur and D.Kriegman},
  title =	 {Illumination-based image synthesis: creating novel
                  images of humanfaces under differing pose and
                  lighting},
  booktitle =	 {IEEE Workshop on Multi-View Modeling and Analysis of
                  Visual Scenes},
  pages =	 {47-54},
  year =	 1999,
}

@Book{Gersho92,
  author =	 {A. Gersho and R. M. Gray},
  title =	 {Vector Quantization and Signal Compression},
  publisher =	 {Kluwer Academic Publishers},
  year =	 1992,
}

@InProceedings{Getoor01icml,
  author =	 {L. Getoor and N. Friedman and D. Koller and
                  B. Taskar},
  fullauthor =	 {Lise Getoor and Nir Friedman and Daphne Koller and
                  Benjamin Taskar},
  title =	 {Learning probabilistic models of relational
                  structure},
  booktitle =	 ICML,
  year =	 2001,
  pages =	 {170-177},
}

@InProceedings{Geyer01cvpr,
  author =	 {C. Geyer and K. Daniilidis},
  title =	 {Structure and Motion from Uncalibrated Catadioptric
                  Views},
  booktitle =	 CVPR,
  year =	 2001,
  month =	 {Dec},
}

@Article{Geyer01ijcv,
  author =	 {C. Geyer and K. Daniilidis},
  title =	 {Catadioptric Projective Geometry},
  journal =	 IJCV,
  year =	 2001,
  month =	 {Dec},
}

@InProceedings{Geyer04omni,
  author =	 {C. Geyer and S. Sastry and R. Bajcsy},
  title =	 {Euclid Meets {Fourier}: Applying Harmonic Analysis
                  to Essential Matrix Estimation in Omnidirectional
                  Cameras},
  booktitle =	 {Proceedings of Omnidirectional Vision, Camera
                  Networks and Non-classical Cameras},
  year =	 2004,
}

@Book{Geyer05omnivis,
  editor =	 {C. Geyer and M. Pollefeys and X. Ying},
  title =	 {The 6th IEEE Workshop on Omnidirectional Vision,
                  Beijing, China, Oct 21},
  publisher =	 {IEEE},
  year =	 2005,
}

@inproceedings{Geyer91,
  author =	 {C.J. Geyer},
  title =	 {Markov chain {Monte} {Carlo} maximum likelihood},
  booktitle =	 {Computing Science and Statistics: Proceedings of the
                  23rd Symposium on the Interface},
  year =	 1991,
  pages =	 {156-163},
  editor =	 "Keramidas",
  publisher =	 {Interface Foundation},
}

@article{Geyer95,
  author =	 {C. J. Geyer and E. A. Thompson},
  title =	 {Annealing {M}arkov Chain {M}onte {C}arlo with
                  applications to ancestral inference},
  volume =	 90,
  pages =	 {909-920},
  year =	 1995,
  journal =	 {Journal of the {A}merican {S}tatistical
                  {A}ssociation}
}

@TECHREPORT{Ghahramani94a,
  AUTHOR =	 {Ghahramani, Z. and Jordan, M.I.},
  TITLE =	 {Learning from incomplete data},
  INSTITUTION =	 {MIT Center for Biological and Computational
                  Learning},
  YEAR =	 1994,
  NUMBER =	 108
}

@techreport{Ghahramani96tr,
  author =	 "Z. Ghahramani and G.E. Hinton",
  fullauthor =	 "Zoubin Ghahramani and Geoffrey E. Hinton",
  title =	 "Parameter Estimation for Linear Dynamical Systems",
  institution =	 "Dept. of Computer Science, University of Toronto",
  number =	 "CRG-TR-96-2",
  year =	 1996,
  url =
                  "http://www.gatsby.ucl.ac.uk/~zoubin/papers/tr-96-2.ps.gz"
}

@article{Ghahramani97ml,
  author =	 "Z. Ghahramani and M.I. Jordan",
  fullauthor =	 "Zoubin Ghahramani and Michael I. Jordan",
  title =	 "Factorial Hidden Markov Models",
  journal =	 {Machine Learning},
  volume =	 29,
  pages =	 "25-273",
  year =	 1997,
}

@techreport{Ghahramani97tr,
  author =	 "Z. Ghahramani and G.E. Hinton",
  fullauthor =	 "Zoubin Ghahramani and Geoffrey E. Hinton",
  title =	 "The {EM} Algorithm for Mixtures of Factor Analyzers",
  institution =	 "Dept. of Computer Science, University of Toronto",
  number =	 "CRG-TR-96-1",
  month =	 "February",
  year =	 1997,
  url =		 "citeseer.nj.nec.com/ghahramani97em.html"
}

@INPROCEEDINGS{Ghahramani98a,
  author =	 "Z. Ghahramani and S. Roweis",
  title =	 "Learning Nonlinear Stochastic Dynamics using the
                  Generalized EM Algorithm",
  BOOKTITLE =	 {Advances in Neural Information Processing Systems
                  (NIPS)},
  PUBLISHER =	 MIT,
  year =	 1998
}

@Article{GharahmaniHinton98,
  author =	 "Ghahramani, Z. and Hinton, G. E.",
  title =	 "Variational learning for switching state-space
                  models",
  journal =	 "Neural Computation",
  year =	 1998,
  volume =	 12,
  number =	 4,
  pages =	 {963-996}
}

@InProceedings{Giannopoulos98,
  author =	 {Giannopoulos, E. and Streit, R.L. and Swaszek, P.F},
  title =	 {Multi-target track segment bearings-only association
                  and ranging},
  booktitle =	 {Conference Record of the Thirty-First Asilomar
                  Conference on Signals, Systems and Computers 97},
  pages =	 {1336 -1340},
  year =	 1998,
  volume =	 2,
}

@InProceedings{Gibbens00cdc,
  author =	 {Gibbens, P.W. and Dissanayake, G.M.W.M. and
                  Durrant-Whyte, H.F.},
  title =	 {A closed form solution to the single degree of
                  freedom simultaneous localisation and map building
                  ({SLAM}) problem},
  booktitle =	 {Proceedings of the 39th IEEE Conference on Decision
                  and Control},
  pages =	 {191--196},
  year =	 2000,
}

@Book{Gibson79,
  author =	 {J. J. Gibson},
  fullauthor =	 {James J. Gibson},
  title =	 {The Ecological Approach to Visual Perception},
  publisher =	 {Houghton Mifflin},
  year =	 1979,
  address =	 {Boston},
}

@InCollection{Gilbert93chapter,
  author =	 {Gilbert, J.R. and Ng, E.G.},
  fullauthor =	 {Gilbert, John R. and Ng, Esmond G.},
  title =	 {Predicting structure in nonsymmetric sparse matrix
                  factorizations},
  crossref =	 {_George93edited},
  abstract =	 {Many computations on sparse matrices have a phase
                  that predicts the nonzero structure of the output,
                  followed by a phase that actually performs the
                  numerical computation. We study structure prediction
                  for computations that involve nonsymmetric row and
                  column permutations and nonsymmetric or non-square
                  matrices. Our tools are bipartite graphs, matchings,
                  and alternating paths. ...},
  c-dellaert =	 {Use bipartite graphs}
}

@InProceedings{Gilbert99siam,
  author =	 {J.R. Gilbert and S. Toledo},
  fullauthor =	 {John R. Gilbert and Sivan Toledo},
  title =	 {High-performance out-of-core sparse {LU}
                  factorization},
  booktitle =	 {Proc. 9th SIAM Conf. on Parallel Processing for
                  Scientific Computing},
  year =	 1999,
  address =	 {Texas},
}

@article{Gilchrist97nature,
  Author =	 {Gilchrist, I.D. and Brown, V. and Findlay, J.M.},
  Journal =	 {Nature},
  Number =	 6656,
  Pages =	 {130--131},
  Title =	 {Saccades without eye movements.},
  Volume =	 390,
  Year =	 1997,
  month =	 {Nov},
  quotes =	 {Although AI? deficit is a peripheral one, her case
                  suggests that saccadic movements, of the head or the
                  eye, form the optimal sampling method for the
                  brain.},
  r-Findlay04cb ={If eye movements are so important for vision, it
                  might be expected that their loss would be
                  catastrophic. An opportunity arose recently
                  \cite{Gilchrist97nature} to examine this proposition
                  in an individual who was born without functional eye
                  muscles. The eyes of this unusual individual are
                  fixed in her head. Surprisingly she is hardly
                  impaired; she reads well and leads a normal life as
                  a university student. At first glance, this might
                  appear to support the traditional approach to
                  studying vision; after all she gets on perfectly
                  well without eye movements. It turns out, however,
                  that in visual tasks she makes head scanning
                  movements with comparable properties to the eye
                  movements of an unimpaired subject. This transfer of
                  the same behaviour from the eyes to the head
                  suggests that active vision processes can be
                  transferred from one motor system to another. Active
                  vision is crucially dependent upon orienting
                  movements, but these do not need to be eye
                  movements.},
  c-dellaert =	 {Very cool}
}

@Article{Gilks01,
  author =	 "W. Gilks and C. Berzuini",
  title =	 "Following a moving target--{Bayesian} inference for
                  dynamic {Bayesian} models",
  journal =	 {Journal of the Royal Statistical Society, Series B},
  volume =	 63,
  number =	 1,
  pages =	 {127--146},
  year =	 2001,
}

@Book{Gilks96,
  editor =	 "W.R. Gilks and S. Richardson and D.J. Spiegelhalter",
  title =	 "Markov chain {M}onte {C}arlo in practice",
  publisher =	 chap,
  year =	 1996,
}

@InCollection{Gilks96b,
  author =	 "W.R. Gilks and S. Richardson and D.J. Spiegelhalter",
  title =	 "Introducing {M}arkov chain {M}onte {C}arlo",
  booktitle =	 "Markov chain {M}onte {C}arlo in practice",
  crossref =	 "Gilks96",
}

@Article{Gill74,
  author =	 "P.E. Gill and G.H. Golub and W. Murray and
                  M.A. Saunders",
  title =	 "Methods for Modifying Matrix Factorizations",
  journal =	 "Mathematics and Computation",
  volume =	 28,
  number =	 126,
  pages =	 {505-535},
  year =	 1974,
}

@Book{Gilmore74book,
  author =	 {R. Gilmore},
  title =	 {Lie Groups, Lie Algebras, and Some of Their
                  Applications},
  publisher =	 {John Wiley and Sons, Inc.},
  year =	 {1974},
  c-dellaert =	 {Very cool book, I can only follow about one tenth,
                  available in Dover.}
}

@article{Gilner98,
  author =	 {Gillner, S. and Mallot, H.A.},
  year =	 1998,
  title =	 {Navigation and acquisition of spatial knowledge in a
                  virtual maze},
  journal =	 {J. Cognitive Neuroscience},
  volume =	 10,
  pages =	 {445--463},
  quotes =	 {The results indicate that human subjects are able to
                  learn a virtual maze from sequences of local views
                  and movements. The information acquired is local,
                  consisting of recognized positions and movement
                  decisions associated to them. Although simple
                  associations of this type can be shown to be present
                  in some subjects, more complete configurational
                  knowledge is acquired as well. The results are
                  discussed in a view-based framework of navigation
                  and the representation of spatial knowledge by means
                  of a view graph. .. evidence for a view-based
                  mechanism of navigation: "Returns Aren? Easy": After
                  having learned the four excursions, the returns to
                  the starting point along the very same paths are
                  almost as difficult as novel paths},
  c-dellaert =	 {Interesting, as it shows evidence for a view-action
                  association model. No conclusion yet on more global
                  representations},
}

@InProceedings{Giremus04esip,
  author =	 {A. Giremus and A. Doucet and A.-C. Escher and
                  J.-Y. Tourneret},
  title =	 "{Nonlinear Filtering Approaches for INS/GPS
                  Integration}",
  booktitle =	 "{European Signal and Image Processing Conference}",
  year =	 2004,
  pages =	 {873--876},
}

@misc{Giudici00,
  author =	 "Paolo Giudici, Peter Green, Claudia Tarantola",
  title =	 "Efficient Model Determination for Discrete Graphical
                  Models",
  journal =	 Biometrika,
  note =	 "to appear"
}

@Article{Giudici99,
  author =	 {Paolo Giudici and Peter Green},
  title =	 {Decomposable graphical gaussian model determination},
  journal =	 {Biometrika},
  year =	 1999,
  volume =	 86,
  pages =	 {785-801}
}

@InProceedings{Gleicher97,
  author =	 "M. Gleicher",
  title =	 "Projective Registration with Difference
                  Decomposition",
  pages =	 "331-337",
  booktitle =	 CVPR,
  year =	 1997,
}

@inproceedings{Glesner95ecsqaru,
  author =	 "S. Glesner and D. Koller",
  fullauthor =	 "Sabine Glesner and Daphne Koller",
  title =	 "Constructing Flexible Dynamic Belief Networks from
                  First-Order Probalistic Knowledge Bases",
  booktitle =	 "European Conference on Symbolic and Quantitative
                  Approaches to Reasoning and Uncertainty",
  pages =	 "217-226",
  year =	 1995,
}

@inproceedings{Gluckman98iccv,
  author =	 "J. Gluckman and S.K. Nayar",
  fullauthor =	 "Joshua Gluckman and Shree K. Nayar",
  title =	 "Ego-Motion and Omnidirectional Cameras",
  booktitle =	 ICCV,
  pages =	 "999-1005",
  year =	 1998,
}

@inproceedings{Goedeme04cvpr,
  title =	 {Fast Wide Baseline Matching for Visual Navigation},
  author =	 {Goedem\'{e}, T. and Tuytelaars, T. and Van Gool,
                  L. and Vanacker, G. and Nuttin, M.},
  abstract =	 {A new and fast way to find local image
                  correspondences for wide baseline image matching is
                  described. The targeted application is visual
                  navigation, e.g. of a semi-automatic
                  wheelchair. Such applications pose some additional
                  requirements, like the need to work with natural
                  landmarks rather than artificial markers, and the
                  need to recognize locations fast. The restricted
                  motion of the camera can be exploited to simplify
                  the feature extraction. These features should
                  support their identification from different, but
                  nevertheless restricted viewing directions, and
                  under variable illumination conditions. The paper
                  proposes a specialization of so-called affine
                  invariant regions for these particular conditions,
                  which in this case simplifies to column
                  segments. Their applicability is wider than robot
                  navigation, and includes localization for wearable
                  computing and scene recognition for automatic movie
                  indexing.},
  quotes =	 {An alternative, which seems to come closer to human
                  behavior [1], would be to build a scene model based
                  on images organized in graph-like structures and to
                  relate one? position to that at which the most
                  similar model image(s) have been taken.},
  c-dellaert =	 {Lots of small features, rather than one big
                  saccade. Makes use of 2D robot motion as a
                  constraint. Uses image column segments.},
  crossref =	 {_CVPR04},
  Pages =	 {24--29},
  Volume =	 1,
  r-wang06_3dpvt ={In \cite{Goedeme04cvpr} the recognition was
                  achieved by matching line segments and their
                  associated descriptors. False matches were rejected
                  by imposing epipolar geometry constraint. The
                  relative pose was recovered using planar motion
                  assumption between the views.},
}

@article{Goedeme04jrs,
  author =	 {T. Goedem\'{e} and M. Nuttin and T. Tuytelaars and
                  L. Van Gool},
  title =	 {Vision Based Intelligent Wheelchair Control: the
                  role of vision and inertial sensing in topological
                  navigation},
  journal =	 {J. Robotic Systems},
  volume =	 21,
  number =	 2,
  pages =	 {85--94},
  year =	 2004,
  abstract =	 {This paper describes ongoing research on vision
                  based mobile robot navigation for wheel
                  chairs. After a guided tour through a natural
                  environment while taking images at regular time
                  intervals, natural landmarks are extracted to
                  automatically build a topological map. Later on this
                  map can be used for place recognition and
                  navigation. We use visual servoing on the landmarks
                  to steer the robot. In this paper, we investigate
                  ways to improve the performance by incorporating
                  inertial sensors.},
  quotes =	 {Out of images taken at regular time intervals during
                  a guided tour, the system extracts automatically the
                  topological structure. To this end, we cluster the
                  images that belong to one distinct place (like a
                  room). Between these clusters there will be links
                  showing the traversable paths between these places.},
  c-dellaert =	 {Weelchair system paper, automatic topological
                  mapping through clustering, wide baseline matching,
                  omnidirectional images.}
}

@inproceedings{Goedeme05iros,
  title =	 {Feature based omnidirectional sparse visual path
                  following},
  author =	 {Goedem\'{e}, T. and Tuytelaars, T. and Van Gool,
                  L. and Vanacker, G. and Nuttin, M.},
  booktitle =	 IROS,
  year =	 2005,
  month =	 {Aug.},
  pages =	 {1806-1811},
  abstract =	 {Vision sensors are attractive for autonomous robots
                  because they are a rich source of environment
                  information. The main challenge in using images for
                  mobile robots is managing this wealth of
                  information. A relatively recent approach is the use
                  of fast wide baseline local features, which we
                  developed and used in the novel approach to sparse
                  visual path following described in this paper. These
                  local features have the great advantage that they
                  can be recognized even if the viewpoint differs
                  significantly. This opens the door to a memory
                  efficient description of a path by descriptors of
                  sparse images. We propose a method for re-execution
                  of these paths by a series of visual homing
                  operations which yield a navigation method with
                  unique properties: it is accurate, robust, fast, and
                  without odometry error build-up.},
  quotes =	 {The essence of our method is a new approach to
                  visual homing. .. Crucial in all visual homing
                  methods is the selection of the landmarks. .. Much
                  more descriptive and robust against occlusions is
                  the technique of local region matching. .. Related
                  to visual homing is visual ego-motion estimation,
                  which has become possible lately due to increasing
                  available processing power and powerful algorithms.},
  c-dellaert =	 {Local matching in omnidirectional images, Kalman
                  filter, control law.},
}

@article{Goedeme07ijrr,
  author =	 {T. Goedem\'{e} and M. Nuttin and T. Tuytelaars and
                  L. Van Gool},
  title =	 {Omnidirectional Vision based Topological Navigation},
  journal =	 "{International Journal of Computer Vision. Special
                  Issue: Joint Issue of IJCV and IJRR on Vision and
                  Robotics}",
  volume =	 {74},
  issue =	 {3},
  pages =	 {219--236},
  year =	 {2007},
  c-ananth =	 {A variation from the maximum-likelihood methods is
                  the topological mapping system given by Goedeme
                  et. al. [Goedeme07ijrr] that uses image clustering
                  to define regions of space as nodes in the
                  topology. Loop closing and correspondence are done
                  using Dempster-Shafer decision theory, but again the
                  decision is binding once taken.},
}

@InProceedings{Goesele07iccv,
  author =	 {M. Goesele and N. Snavely and B. Curless and
                  H. Hoppe and S. M. Seitz},
  fullauthor =	 {Michael Goesele and Noah Snavely and Brian Curless
                  and Hugues Hoppe and Steven M. Seitz},
  title =	 {Multi-View Stereo for Community Photo Collections},
  booktitle =	 ICCV,
  year =	 2007,
  address =	 {Rio de Janeiro, Brasil},
  month =	 {October},
}

@INPROCEEDINGS{Goesele07iccv,
  title =	 {Multi-View Stereo for Community Photo Collections},
  author =	 {Goesele, M. and Snavely, N. and Curless, B. and
                  Hoppe, H. and Seitz, S.M.},
  booktitle =	 {Computer Vision. ICCV 2007. IEEE 11th International
                  Conference on},
  year =	 2007,
  month =	 {Oct.},
  pages =	 {1-8},
}

@article{Gold96,
  AUTHOR =	 "S. Gold and A. Rangarajan",
  title =	 "A Graduated Assignment Algorithm for Graph Matching",
  journal =	 PAMI,
  year =	 1996,
  volume =	 18,
  number =	 4,
  pages =	 "377-388",
}

@article{Gold98,
  AUTHOR =	 "S. Gold and A. Rangarajan and C. Lu and S. Pappu and
                  E. Mjolsness",
  TITLE =	 "New algorithms for {2D} and {3D} point matching",
  JOURNAL =	 PR,
  VOLUME =	 31,
  YEAR =	 1998,
  NUMBER =	 8,
  PAGES =	 "1019-1031"
}

@InProceedings{Goldgof89,
  author =	 {Goldgof, D.B. and Huang, T.S. and Lee, H. },
  title =	 {Motion estimation from points without
                  correspondences from orthographic projections},
  booktitle =	 {Proc. Workshop on Visual Motion},
  pages =	 {352--358},
  year =	 1989,
}


@article{Goldgof92,
  AUTHOR =	 "Goldgof, D.B. and Lee, H. and Huang, T.S.",
  TITLE =	 "Matching and Motion Estimation of Three-Dimensional
                  Point and Line Sets Using Eigenstructure without
                  Correspondences",
  JOURNAL =	 PR,
  VOLUME =	 25,
  YEAR =	 1992,
  PAGES =	 "271-286"
}

@InProceedings{Goldman99uai,
  author =	 {R.P. Goldman, C. Geib and C. Miller},
  fullauthor =	 {Robert P. Goldman, Chris Geib and Chris Miller},
  title =	 {A New Model of Plan Recognition},
  booktitle =	 UAI,
  year =	 1999,
}

@InProceedings{Golfarelli98iros,
  author =	 {M. Golfarelli and D. Maio and S. Rizzi},
  fullauthor =	 {Matteo Golfarelli and Dario Maio and Stefano Rizzi},
  title =	 {Elastic Correction of Dead-Reckoning Errors in Map
                  Building},
  booktitle =	 IROS,
  pages =	 {905-911},
  year =	 1998,
}

@Article{Golfarelli98tra,
  author =	 {M. Golfarelli and D. Maio and S. Rizzi},
  fullauthor =	 {Matteo Golfarelli and Dario Maio and Stefano Rizzi},
  title =	 {Correction of Dead-Reckoning Errors in Map Building},
  journal =	 TRA,
  volume =	 17,
  number =	 1,
  year =	 2001,
}

@inproceedings{Golledge96,
  author =	 {R.G. Golledge and J.Marston and C.M. Costanzo},
  title =	 {The {I}mpact of {I}nformation {A}ccess on {T}ravel
                  {B}ehavior of {B}lind or {V}ision {I}mpaired
                  {P}eople},
  booktitle =	 {Spatial Technologies, Geographic Information, and
                  the City},
  month =	 {Septermber 9-11},
  year =	 1996,
  address =	 {Baltimore, Maryland},
  url =
                  {http://www.ncgia.ucsb.edu/conf/BALTIMORE/authors/golledge/paper.html}
}

@Book{Golledge97,
  author =	 {Golledge, R.G. and Stimpson, R.J.},
  year =	 1997,
  title =	 {Spatial Behavior: A geographic perspective},
  publisher =	 {New York: The Guilford Press},
}

@Article{Golub80laa,
  author =	 {G.H. Golub and R.J. Plemmons},
  title =	 {Large-scale geodetic least-squares adjustment by
                  dissection and orthogonal decomposition},
  journal =	 {Linear Algebra and Its Applications},
  year =	 1980,
  volume =	 34,
  pages =	 {3-28},
  month =	 {Dec},
}

@Book{Golub96,
  author =	 {G.H. Golub and C.F. Van Loan},
  title =	 {Matrix Computations},
  publisher =	 {Johns Hopkins University Press},
  year =	 1996,
  address =	 {Baltimore},
  edition =	 {Third},
}

@InProceedings{Goncalves05icra,
  author =	 {L. Goncalves, E.D. Bernardo, D. Benson, M. Svedman,
                  J. Ostrowski, N. Karlsson, P. Pirjanian},
  fullauthor =	 {Luis Goncalves, Enrico Di Bernardo, Dave Benson,
                  Marcus Svedman, Jim Ostrowski, Niklas Karlsson,
                  Paolo Pirjanian},
  title =	 {A Visual Front-end for Simultaneous Localization and
                  Mapping},
  booktitle =	 ICRA,
  pages =	 {44-49},
  location =	 {Barcelona, Spain},
  month =	 {Apr},
  year =	 2005,
  abstract =	 {We describe a method of generating and utilizing
                  visual landmarks that is well suited for SLAM
                  applications. The landmarks created are highly
                  distinctive and reliably detected, virtually
                  eliminating the data association problem present in
                  other landmark schemes. Upon subsequent detections
                  of a landmark, a 3-D pose can be estimated. The
                  scheme requires a single camera.},
  c-kaess =	 {for vSLAM, see Karlsson05icra},
}

@inproceedings{Gonzalez05iros,
  author =	 {J. P. Gonzalez and A. Stentz},
  title =	 "Planning with Uncertainty in Position: An Optimal
                  and Efficient Planner",
  booktitle =	 IROS,
  year =	 2005,
  pages =	 {2435--2442},
}

@article{Goodman82tods,
  author =	 {N. Goodman and O. Shmueli},
  fullauthor =	 {Nathan Goodman and Oded Shmueli},
  title =	 {Tree queries: a simple class of relational queries},
  journal =	 {ACM Trans. Database Syst.},
  volume =	 7,
  number =	 4,
  year =	 1982,
  issn =	 {0362-5915},
  pages =	 {653--677},
  doi =		 {http://doi.acm.org/10.1145/319758.319775},
  publisher =	 {ACM Press},
  address =	 {New York, NY, USA},
  abstract =	 {One can partition the class of relational database
                  schemas into tree schemas and cyclic schemas. (These
                  are called acyclic hypergraphs and cyclic
                  hypergraphs elsewhere in the literature.) This
                  partition has interesting implications in query
                  processing, dependency theory, and graph theory. The
                  tree/cyclic partitioning of database schemas
                  originated with a similar partition of equijoin
                  queries. Given an arbitrary equijoin query one can
                  obtain an equivalent query that calculates the
                  natural join of all relations in (an efficiently)
                  derived database; such a query is called a natural
                  join (NJ) query. If the derived database is a tree
                  schema the original query is said to be a tree
                  query, and otherwise a cyclic query. In this paper
                  we analyze query processing consequences of the
                  tree/cyclic partitioning. We are able to argue,
                  qualitatively, that queries which imply a tree
                  schema are easier to process than those implying a
                  cyclic schema. Our results also extend the study of
                  the semijoin operator.},
  c-dellaert =	 {\citet{Goodman82tods} also knows about acyclic
                  schemes, calls it tree schemas},
}

@InProceedings{Gopalratnum05aaai,
  fullauthor =	 {Karthik Gopalratnam and Henry Kautz and Daniel
                  S. Weld},
  author =	 {K. Gopalratnam and H. Kautz and D. S. Weld},
  booktitle =	 AAAI,
  year =	 2005,
  keywords =	 {continous time Bayesian network, Coxian, Erlang,
                  duration, approximation},
  c-sangmin =	 {extends continous time Bayesian network in two big
                  ways. (1) incoporates non-exponential duration
                  models where the non-parametric density can be
                  approximated in closed-form which they adopted from
                  Osogami03 (2) deals with non-existing measurements
                  (not checked this point very carefully. Duration
                  modeling results for short-tail, heavy tail,
                  non-exponential durations are quite impressive. The
                  basic closed-form solution comes from Osogami06},
}

@Article{Gordon93,
  author =	 {N.J. Gordon and D.J. Salmond and A.F.M. Smith},
  title =	 {Novel approach to nonlinear/non-{G}aussian
                  {B}ayesian state estimation},
  journal =	 {IEE Procedings F},
  year =	 1993,
  volume =	 140,
  number =	 2,
  pages =	 {107-113},
}

@InProceedings{Gortler96siggraph,
  author =	 {S.J. Gortler and R. Grzeszczuk and R. Szeliski and
                  M.F. Cohen},
  title =	 {The Lumigraph},
  booktitle =	 SIGGRAPH,
  pages =	 {43-54},
  year =	 1996,
}

@Article{Gottlob00ai,
  author =	 {G. Gottlob and N. Leone and F. Scarcello},
  fullauthor =	 {Georg Gottlob and Nicola Leone and Francesco
                  Scarcello},
  title =	 {A comparison of structural {CSP} decomposition
                  methods},
  journal =	 AI,
  year =	 2000,
  volume =	 124,
  number =	 2,
  pages =	 {243--282},
  month =	 {December},
  abstract =	 {We compare tractable classes of constraint
                  satisfaction problems (CSPs). We first give a
                  uniform presentation of the major structural CSP
                  decomposition methods. We then introduce a new class
                  of tractable CSPs based on the concept of hypertree
                  decomposition recently developed in Database Theory,
                  and analyze the cost of solving CSPs having bounded
                  hypertree-width. We provide a framework for
                  comparing parametric decomposition-based methods
                  according to tractability criteria and compare the
                  most relevant methods. We show that the method of
                  hypertree decomposition dominates the others in the
                  case of general CSPs (i.e., CSPs of unbounded
                  arity). We also make comparisons for the restricted
                  case of binary CSPs. Finally, we consider the
                  application of decomposition methods to the dual
                  graph of a hypergraph. In fact, this technique is
                  often used to exploit binary decomposition methods
                  for nonbinary CSPs. However, even in this case, the
                  hypertree-decomposition method turns out to be the
                  most general method.},
  quotes =	 {Constraint satisfiability is equivalent to various
                  database problems, e.g., to the problem of
                  conjunctive query containment, or to the problem of
                  evaluating Boolean conjunctive queries over a
                  relational database. ... Actually, evaluating
                  Boolean conjunctive queries, and deciding constraint
                  satisfaction can be also recast as the same
                  fundamental algebraic problem of deciding whether,
                  given two finite relational structures A and B ,
                  there exists a homomorphism f : A -> B
                  \cite{Kolaitis00css}. ... the method of Hypertree
                  Decompositions dominates all other methods, as it is
                  strongly more general than the other decomposition
                  methods. This method was originally introduced in
                  the database field for identifying a large class of
                  tractable conjunctive queries \cite{Gottlob99pods}.},
  r-Kask05ai =	 {Join tree transformations and their associated
                  variable elimination algorithms were proposed for
                  the efficient solution of constraints satisfaction
                  problems \cite{Dechter87ai} and their role was
                  re-formalized and extended more recently by
                  \citet{Gottlob00ai}},
  r-Kask05ai =	 {Tree clustering schemes have been widely used for
                  constraint processing, probabilistic reasoning and
                  for graphical models in general. The most popular
                  variants are join-tree clustering algorithms, also
                  called junction-trees. The schemes vary somewhat in
                  their graph definitions as well as in the way
                  tree-decompositions are processed \cite{Maier83book,
                  Dechter89ai, Jensen90csq, Shenoy96uai,
                  Lauritzen97amai, Gottlob00ai}. However, they all
                  involve a decomposition of a hyper-graph into a
                  hyper-tree.},
  c-dellaert =	 {Relates CSP to database literature. Constraint
                  scope=database table. Hypertree decomposition as a
                  new method: form a tree where each node has a set of
                  variables and a set of factors. Intuition very
                  unclear. Kask05ai generalizes to graphical models,
                  not just CSP.}
}

@article{Gottlob01jacm,
  author =	 {G. Gottlob and N. Leone and F. Scarcello},
  fullauthor =	 {Georg Gottlob and Nicola Leone and Francesco
                  Scarcello},
  title =	 {The complexity of acyclic conjunctive queries},
  journal =	 {J. ACM},
  volume =	 {48},
  number =	 {3},
  year =	 {2001},
  issn =	 {0004-5411},
  pages =	 {431--498},
  doi =		 {http://doi.acm.org/10.1145/382780.382783},
  publisher =	 {ACM Press},
  address =	 {New York, NY, USA},
  r-ACMPortal =	 {This excellent paper is devoted to the complexity
                  analysis of acyclic Boolean conjunctive queries
                  (ABCQ) in relational databases. ... These algorithms
                  explore the parallelism in acyclic queries, and
                  achieve a high degree of parallel processing of
                  different primitive operations, which have practical
                  use in designing parallel database management
                  systems. Finally, these complexity results have
                  impact on the direction of future
                  research. Specifically, I expect more efficient
                  parallel algorithms for these LOGCFL-complete
                  problems to be developed.}
}

@Article{Gottlob02jcss,
  author =	 {G. Gottlob and N. Leone and F. Scarcello},
  title =	 {Hypertree Decompositions and Tractable queries},
  journal =	 {Journal of Computer and System Sciences},
  year =	 2002,
  volume =	 64,
  number =	 3,
  pages =	 {579--627},
  c-dellaert =	 {Off Gottlob's web-page. As difficult to understand
                  as \cite{Gottlob00ai}, and more specialized to
                  databases.},
}

@inproceedings{Gottlob05wg,
  author =	 {G. Gottlob and M. Grohe and N. Musliu and M. Samer
                  and F. Scarcello},
  fullauthor =	 {Georg Gottlob and Martin Grohe and Nysret Musliu and
                  Marko Samer and Francesco Scarcello},
  title =	 {Hypertree Decompositions: Structure, Algorithms, and
                  Applications.},
  crossref =	 {_WG05},
  pages =	 {1-15},
}

@Article{Goyal88comp,
  author =	 {A. Goyal and A.N. Tantawi},
  title =	 {A measure of guaranteed availability and its
                  numerical evaluation},
  journal =	 Comp,
  year =	 1988,
  volume =	 37,
  number =	 1,
  pages =	 {25--32},
}

@INPROCEEDINGS{Gracias01oceans,
  title =	 {Underwater mosaicing and trajectory reconstruction
                  using global alignment},
  author =	 {Gracias, N. and Santos-Victor, J.},
  booktitle =	 {OCEANS, 2001. MTS/IEEE Conference and Exhibition},
  year =	 2001,
  volume =	 4,
  pages =	 {2557-2563 vol.4}
}

@INPROCEEDINGS{Gracias98oceans,
  title =	 {Automatic mosaic creation of the ocean floor},
  author =	 {Gracias, N. and Santos-Victor, J.},
  booktitle =	 {OCEANS '98 Conference Proceedings},
  year =	 1998,
  month =	 {Sep-1 Oct},
  volume =	 1,
  pages =	 {257-262 vol.1},
}

@InProceedings{Gracie68,
  author =	 {G. Gracie},
  title =	 {Analytical photogrammetry applied to a single
                  terrestrial photograph mensuration},
  booktitle =	 {XIth Intl. Conf. of Photogrammetry},
  year =	 1986,
  address =	 {Lausanne},
  month =	 {July},
}

@InProceedings{Graefe96,
  author =	 "Volker Graefe and Wolfgang Efenberger",
  title =	 "A Novel Approach for the Detection of Vehicles on
                  Freeways by Real-Time Vision",
  booktitle =	 "Proceedings of the 1996 IEEE Intelligent Vehicles
                  Symposium",
  year =	 1996,
  address =	 "Tokyo, Japan",
  month =	 "September",
}

@InProceedings{Granger02eccv,
  author =	 "S. Granger and X. Pennec",
  title =	 "Multi-scale {EM-ICP}: A Fast and Robust Approach for
                  Surface Registration",
  booktitle =	 ECCV,
  year =	 2002,
}

@Article{Granshaw80pr,
  author =	 {S. Granshaw},
  title =	 {Bundle adjustment methods in engineering
                  photogrammetry},
  journal =	 {Photogrammetric Record},
  year =	 1980,
  volume =	 10,
  number =	 56,
  pages =	 {181-207},
}

@InProceedings{Grau97,
  author =	 "O. Grau",
  title =	 "A scene analysis system for the generation of {3-D}
                  models",
  booktitle =	 "Proc. Intl. Conf. on Recent Advances in 3-D Digital
                  Imaging and Modeling",
  pages =	 "221-228",
  year =	 1997,
  url =		 "citeseer.nj.nec.com/grau97scene.html"
}

@InProceedings{Grau98,
  author =	 {O. Grau},
  title =	 {3-D Modelling of Buildings using High-Level
                  Knowledge},
  booktitle =	 {Proc. of Computer Graphics International 1998
                  (CGI'98)},
  year =	 1998,
  month =	 {June},
}

@InProceedings{Gray03ais,
  author =	 {Alexander Gray and A.W. Moore},
  title =	 {Rapid Evaluation of Multiple Density Models},
  Booktitle =	 {Artificial Intelligence and Statistics},
  Year =	 2003
}

@Unpublished{Gray03jsm,
  author =	 {Alexander G. Gray and Andrew W. Moore},
  title =	 {Very fast multivariate kernel density estimation via
                  computational geometry},
  note =	 {under review},
}

@UNPUBLISHED{Green03,
  author =	 "P.J. Green",
  fullauthor =	 "Peter J. Green",
  title =	 "Trans-dimensional {Markov} chain {Monte} {Carlo}",
  note =	 "Chapter in Highly Structured Stochastic Systems",
  year =	 2003,
}

@article{Green95biometrika,
  author =	 "P. Green",
  title =	 "Reversible jump {M}arkov chain {M}onte {C}arlo
                  computation and {Bayesian} model determination",
  journal =	 "Biometrika",
  volume =	 82,
  pages =	 "711--732",
  year =	 1995,
  url =		 "citeseer.nj.nec.com/green95reversible.html"
}

@InCollection{Green96,
  author =	 "P.J. Green",
  title =	 "{MCMC} in Image Analysis",
  crossref =	 "Gilks96",
}

@Article{Greene86,
  author =	 "Ned Greene and P. S. Heckbert",
  title =	 "Creating Raster Omnimax Images from Multiple
                  Perspective Views using the Elliptical Weighted
                  Average Filter ",
  journal =	 "IEEE Computer Graphics and Applications",
  volume =	 6,
  number =	 6,
  month =	 "June",
  year =	 1986,
  pages =	 "21-27",
}

@TechReport{Grenander83,
  author =	 "U. Grenander",
  title =	 "Tutorial in pattern theory",
  institution =	 "Brown University",
  year =	 1983,
  address =	 "Providence, RI",
}

@inproceedings{Griewank89,
  author =	 "A. Griewank",
  title =	 "{O}n {A}utomatic {D}ifferentiation",
  booktitle =	 "Mathematical Programming: Recent Developments and
                  Applications",
  publisher =	 "Kluwer Academic Publishers",
  editor =	 "Iri, M. and Tanabe, K.",
  pages =	 "83-108",
  year =	 1989,
}

@article{Grime94cep,
  author =	 {Grime, S. and Durrant-Whyte, H.F.},
  tit;e =	 {Data fusion in decentralized sensor networks},
  journal =	 {Control Engineering Practice,},
  Volume =	 2,
  number =	 1,
  year =	 1994,
  pages =	 {849--863},
  abstract =	 {This paper addresses the problem of data fusion in
                  decentralized sensor networks in which there is no
                  central fusion center and in which no single sensor
                  node has global knowledge of network topology. An
                  algorlthm is described which is able to locally
                  process and assimilate data in such networks and
                  which yields an identical result to that obtained in
                  a centralized system. An implementation of this
                  decentralized data fusion algorithm on a process
                  control rig incorporating over 150 sensors and 30
                  processors is described. The results show that the
                  decentralized data fusion system described in this
                  paper offers many advantages in terms of robustness,
                  scalability and flexibility over a centralized
                  system.},
  quotes =	 {It is demonstrated that the addition of this
                  estimator guarantees that tree-connected networks of
                  sensor nodes yield the same state estimate as fully
                  connected networks or centralized data fusion
                  systems. For more general sensor networks with
                  multiple paths between nodes, it is shown that
                  within the constraints imposed, there is no finite
                  set of estimators that will, in general, allow the
                  local computation of an estimate equivalent to the
                  centralized estimate. [...] The information filter
                  is directly an implementation of Bayes theorem in
                  terms of log-likelihood rather than in terms of
                  state. For this reason, it is occasionally referred
                  to as the likelihood filter. [The log likelihoods]
                  may simply be summed to yield the posterior
                  log-likelihood [which] provides a far more natural
                  method of aggregating data than does the
                  conventional Kalman filter. [Similar data fusion
                  methods] may be applied to cases when the underlying
                  probabilities are not Gaussian, and indeed in cases
                  where the underlying state-space is discrete. These
                  cases lead directly to an information theory
                  approach to data fusion as described in (Manyika and
                  Durrant-Whyte, 1994).},
  c-dellaert =	 {Now reference is made to the information filter as
                  in Maybeck. y+ = y- + H'inv(R)z, Y+ = Y- +
                  H'inv(R)H. They define i=H'inv(R)z, the
                  information-state contribution of measurement z, and
                  I=H'inv(R)H its information matrix. On page 4 there
                  is a very nice explanation of score and Fisher
                  information by looking at the log and derivative log
                  of Bayes law. Introduces the "information map", }
}

@article{Grimson84,
  author =	 "W.E.L. Grimson and T. Lozano-P\'{e}rez",
  title =	 "Model-Based Recognition and Localization From Sparse
                  Range or Tactile Data",
  journal =	 IJRR,
  year =	 1984,
}

@article{Grimson87,
  author =	 "W.E.L. Grimson and T. Lozano-P\'{e}rez",
  title =	 "{Localizing Overlapping Parts by Searching the
                  Interpretation Tree}",
  journal =	 PAMI,
  volume =	 9,
  number =	 4,
  pages =	 "469--482",
  year =	 1987
}

@Book{Grimson90,
  author =	 {W.E.L. Grimson},
  title =	 {Object recognition by computer : the role of
                  geometric constraints},
  publisher =	 MIT,
  year =	 1990,
}

@article{Grimson96,
  author =	 "W. E. L. Grimson and T. Lozano-P{\'e}rez and
                  W. M. Wells and G. J. Ettinger and S. J. White and
                  R. Kikinis",
  title =	 "An Automatic Registration Method for Frameless
                  Stereotaxy, Image Guided Surgery, and Enhanced
                  Reality Visualization",
  journal =	 "IEEE Trans. on Medical Imaging",
  year =	 1996,
  volume =	 15,
  pages =	 "126--141",
}

@InProceedings{Grisetti05icra,
  author =	 {G. Grisetti and C. Stachniss and W. Burgard},
  title =	 {Improving grid-based {SLAM} with
                  {R}ao-{B}lackwellized particle filters by adaptive
                  proposals and selective resampling},
  booktitle =	 ICRA,
  location =	 {Barcelona, Spain},
  pages =	 {667-672},
  year =	 2005,
  abstract =	 {Recently Rao-Blackwellized particle lters have been
                  introduced as effective means to solve the
                  simultaneous localization and mapping (SLAM)
                  problem. This approach uses a particle lter in which
                  each particle carries an individual map of the
                  environment. Accordingly, a key question is how to
                  reduce the number of particles. In this paper we
                  present adaptive techniques to reduce the number of
                  particles in a Rao-Blackwellized particle lter for
                  learning grid maps. We propose an approach to
                  compute an accurate proposal distribution taking
                  into account not only the movement of the robot but
                  also the most recent observation. This drastically
                  decrease the uncertainty about the robot's pose in
                  the prediction step of the lter. Furthermore, we
                  present an approach to selectively carry out
                  re-sampling operations which seriously reduces the
                  problem of particle depletion. Experimental results
                  carried out with mobile robots in large-scale indoor
                  as well as in outdoor environments illustrate the
                  advantages of our methods over previous approaches.},
}

@InProceedings{Grisetti07rss,
  author =	 {G. Grisetti and C. Stachniss and S. Grzonka and
                  W. Burgard},
  fullauthor =	 {Giorgio Grisetti and Cyrill Stachniss and Slawomir
                  Grzonka and Wolfram Burgard},
  title =	 {A Tree Parameterization for Efficiently Computing
                  Maximum Likelihood Maps using Gradient Descent},
  booktitle =	 RSS,
  location =	 {Atlanta, GA},
  month =	 {Jun},
  year =	 {2007},
  abstract =	 {In 2006, Olson et al. presented a novel approach to
                  address the graph-based simultaneous localization
                  and mapping problem by applying stochastic gradient
                  descent to minimize the error introduced by
                  constraints. Together with multi-level relaxation,
                  this is one of the most robust and efficient maximum
                  likelihood techniques published so far. In this
                  paper, we present an extension of Olson?
                  algorithm. It applies a novel parameterization of
                  the nodes in the graph that significantly improves
                  the performance and enables us to cope with
                  arbitrary network topologies. The latter allows us
                  to bound the complexity of the algorithm to the size
                  of the mapped area and not to the length of the
                  trajectory as it is the case with both previous
                  approaches. We implemented our technique and
                  compared it to multi-level relaxation and Olson?
                  algorithm. As we demonstrate in simulated and in
                  real world experiments, our approach converges
                  faster than the other approaches and yields accurate
                  maps of the environment.},
  c-kaess =	 {Solves a problem that only appears with iterative
                  batch solvers. Improves Olson06icra, which uses
                  stochastic gradient descent and relative coordinates
                  for fast updates. In contrast to Olson06icra, which
                  represents nodes relative to their successors in the
                  trajectory, a spanning tree over the nodes is
                  created, and nodes represented relative to their
                  parents. This reduces updates for loops to one
                  ascending and one descending tree traversal.},
}

@Article{Grisetti07tro,
  author =	 {G. Grisetti and C. Stachniss and W. Burgard},
  fullauthor =	 {Giorgio Grisetti and Cyrill Stachniss and Wolfram
                  Burgard},
  title =	 {Improved Techniques for Grid Mapping With
                  {R}ao-{B}lackwellized particle filters},
  journal =	 TRO,
  volume =	 23,
  number =	 1,
  pages =	 {34-46},
  year =	 2007,
  abstract =	 {Recently, Rao-Blackwellized particle filters (RBPF)
                  have been introduced as an effective means to solve
                  the simultaneous localization and mapping
                  problem. This approach uses a particle filter in
                  which each particle carries an individual map of the
                  environment. Accordingly, a key question is how to
                  reduce the number of particles. In this paper, we
                  present adaptive techniques for reducing this number
                  in a RBPF for learning grid maps. We propose an
                  approach to compute an accurate proposal
                  distribution, taking into account not only the
                  movement of the robot, but also the most recent
                  observation. This drastically decreases the
                  uncertainty about the robot's pose in the prediction
                  step of the filter. Furthermore, we present an
                  approach to selectively carry out resampling
                  operations, which seriously reduces the problem of
                  particle depletion. Experimental results carried out
                  with real mobile robots in large-scale indoor, as
                  well as outdoor, environments illustrate the
                  advantages of our methods over previous approaches},
}

@phdthesis{Grocholsky02thesis,
  author =	 "B. Grocholsky",
  title =	 "Information-Theoretic Control of Multiple Sensor
                  Platforms",
  school =	 "The University of Sydney",
  year =	 2002
}

@InProceedings{Grocholsky04iser,
  author =	 {B. Grocholsky and S. Bayraktar and V. Kumar and
                  C.J. Taylor and G. Pappas},
  title =	 {Synergies in Feature Localization by Air-Ground
                  Robot Teams},
  booktitle =	 {9th International Symposium on Experimental Robotics
                  (ISER'04)},
  year =	 2004,
}

@inproceedings{Gross02iros,
  author =	 {Gross, H.-M. and K\"{o}nig, A. and B\"{o}hme,
                  H.-J. and Schr\"{o}ter, Ch.},
  title =	 {Vision-Based Monte Carlo Self-localization for a
                  Mobile Service Robot Acting as Shopping Assistant in
                  a Home Store.},
  booktitle =	 IROS,
  pages =	 {256--262},
  year =	 2002,
  abstract =	 {We present a novel omnivision-based robot localiza-
                  tion approach which utilizes the Monte Carlo Lo-
                  calization (MCL) [2], a Bayesian filtering technique
                  based on a density representation by means of par-
                  ticles. The capability of this method to approximate
                  arbitrary likelihood densities is a crucial property
                  for dealing with highly ambiguous localization
                  hypotheses as are typical for real-world
                  environments. We show how omidirectional imaging can
                  be combined with the MCL-algorithm to globally
                  localize and track a mobile robot given a taught
                  graph-based representation of the operation area. In
                  contrast to other approaches, the nodes of our graph
                  are labeled with both visual fea- ture vectors
                  extracted from the omnidirectional im- age, and
                  odometric data about the pose of the robot at the
                  moment of the node insertion (position and heading
                  direction). To demonstrate the reliability of our
                  approach, we present first experimental results in
                  the context of a challenging robotics application,
                  the self-localization of a mobile service robot
                  acting as shopping assistant in a very regularly
                  structured, maze-like and crowded environment, a
                  home store.},
  r-Goedeme04jrs ={The topic of the research of \citet{Gross02iros} is
                  the development of a robot driving around in a
                  supermarket. They use a topological map that is
                  closely linked to the metrical reality. They perform
                  Monte Carlo Localization, using global image
                  features of a omnidirectional camera as
                  landmarks. All these methods use global features for
                  place recognition, which are less robust against
                  e.g. occlusions compared to the local features we
                  use.},
  c-dellaert =	 {Relatively straighforward MCL using panoramic
                  images. Topological-metric connection is unclear:
                  did not read in detail.}
}

@MastersThesis{Gross86,
  author =	 {D. Gross},
  title =	 {Super Resolution from sub-pixel shifted pictures},
  school =	 {Tel-Aviv University},
  year =	 1986,
}

@INPROCEEDINGS{Grudic06rss,
  AUTHOR =	 {G. Grudic and J. Mulligan},
  TITLE =	 {Outdoor Path Labeling Using Polynomial Mahalanobis
                  Distance},
  BOOKTITLE =	 RSS,
  YEAR =	 2006,
}

@InProceedings{Guestrin04ipsn,
  author =	 {C.E. Guestrin and P. Bodik and R Thibaux and
                  M.A. Paskin and S. Madden},
  title =	 {Distributed Regression: an Efficient Framework for
                  Modeling Sensor Network Data},
  booktitle =	 IPSN,
  year =	 2004,
  c-Paskin05ipsn ={For further detail on the application of our
                  architecture to probabilistic inference and
                  regression problems, see [this]},
  c-dellaert =	 {paskin04uai, Guestrin04ipsn, Paskin05ipsn all seem
                  to be the same thing},
}

@InProceedings{Guivant01fsr,
  author =	 {J. Guivant and E. Nebot},
  title =	 {Compressed Filter for Real Time Implementation of
                  Simultaneous Localization and Map Building},
  booktitle =	 {FSR Wan2001 International Conference on Field and
                  Service Robots},
  pages =	 {309-314},
  year =	 2001,
  volume =	 1,
}

@Article{Guivant01tra,
  author =	 {J. Guivant and E. Nebot},
  fullauthor =	 {Jose Guivant and Eduardo Nebot},
  title =	 {Optimization of the Simultaneous Localization and
                  Map Building Algorithm for Real Time Implementation},
  journal =	 TRA,
  month =	 {June},
  volume =	 17,
  number =	 3,
  pages =	 {242-257},
  year =	 2001,
  Abstract =	 {This work addresses real time implementation of the
                  Simultaneous Localization and Map Building (SLAM)
                  algorithm. It presents optimal algorithms that
                  consider the special form of the matrices and a new
                  compressed filter that can significantly reduce the
                  computation requirements when working in local areas
                  or with high frequency external sensors. It is shown
                  that by extending the standard Kalman filter models
                  the information gained in a local area can be
                  maintained with a cost O(Na^2), where Na is the
                  number of landmarks in the local area, and then
                  transferred to the overall map in only one iteration
                  at full SLAM computational cost. Additional
                  simplifications are also presented that are very
                  close to optimal when an appropriate map
                  representation is used. Finally the algorithms are
                  validated with experimental results obtained with a
                  standard vehicle running in a completely
                  unstructured outdoor environment.},
  c-dellaert =	 {Setting is EKF SLAM. First looks at improving the
                  efficiency of dynamics updates happening at high
                  frequency. "For n prediction steps the complexity
                  will be approximately 27n+9M." Covariance update in
                  measurement stage can be done in O(M^2), with M =
                  3+2N. But "it is not necessary to perform a full
                  SLAM update when working in a local area." Proceeds
                  to develop the local area updates, as well as (a) a
                  suboptimal faster SLAM variant, and (b)
                  constellations by introducing bases.},
  c-Alireza =	 {They introduce the compressed algorithm in which the
                  state vector for a local map is updated and the
                  updating of the global map is postponed until going
                  to another submap. update of the local map state is
                  O(N_a^2) where N_a is the number of features in the
                  local map. In cases that the robot traverses in a
                  local map for a long time or N_a is much less than
                  the total number of features in the global map and
                  at the same time the features are visited with a
                  high frequency, their algorithm is very
                  useful. Their solution is an exact solution,
                  however, they also introduce an approximate O(n)
                  solution in their paper as well. }
}

@inproceedings{Guivant02icra,
  author =	 {J. Guivant and E.M. Nebot},
  fullauthor =	 {Jose Guivant and Eduardo Mario Nebot},
  title =	 {Improving Computational and Memory Requirements of
                  Simultaneous Localization and Map Building
                  Algorithms.},
  booktitle =	 ICRA,
  year =	 2002,
  pages =	 {2731-2736},
}

@article{Guivant04ijrr,
  author =	 {J. Guivant and E. Nebot and J. Nieto and F. Masson},
  title =	 {Navigation and Mapping in Large Unstructured
                  Environments},
  journal =	 IJRR,
  month =	 {April},
  Volume =	 23,
  pages =	 {449-472},
  year =	 2004
}

@INPROCEEDINGS{Gupta08cvpr,
  title =	 {On controlling light transport in poor visibility
                  environments},
  author =	 {Gupta, M. and Narasimhan, S.G. and Schechner, Y.Y.},
  booktitle =	 {Computer Vision and Pattern Recognition, 2008. CVPR
                  2008. IEEE Conference on},
  year =	 2008,
  month =	 {June},
  pages =	 {1-8},
}

@Article{Gupta97pds,
  author =	 {A. Gupta and G. Karypis and V. Kumar},
  fullauthor =	 {Anshul Gupta and George Karypis and Vipin Kumar},
  title =	 {Highly Scalable Parallel Algorithms for Sparse
                  Matrix Factorization},
  journal =	 {{IEEE} Trans. Parallel and Distributed Systems},
  year =	 1997,
  volume =	 8,
  number =	 5,
  pages =	 {502-520},
}

@Book{Gusfield97,
  author =	 {Dan Gusfield},
  title =	 {{A}lgorithms on {S}trings, {T}rees and {S}equences:
                  {C}omputer {S}cience and {C}omputational {B}iology},
  publisher =	 {Cambridge University Press},
  year =	 1997,
}

@INPROCEEDINGS{Gut98Exp,
  AUTHOR =	 {J.-S. Gutmann and W. Burgard and D. Fox and
                  K. Konolige},
  TITLE =	 {An Experimental Comparison of Localization Methods},
  BOOKTITLE =	 IROS,
  YEAR =	 1998
}

@InProceedings{Gutchess01iccv,
  author =	 {D. Gutchesst and M. Trajkovic and E. Cohen-Solal and
                  D. Lyons and A. K. Jain},
  title =	 {A Background Model Initialization Algorithm for
                  Video Surveillance},
  booktitle =	 ICCV,
  pages =	 {733-740},
  year =	 2001,
  abstract =	 {Many motion detection and tracking algorithms rely
                  on the process of background subtraction, a
                  technique which f detects changes from a model of
                  the background scene. We present a new algorithm for
                  the purpose of background model initialization. The
                  algorithm takes as input a video sequence in which
                  moving objects are present, and outputs a
                  statistical background model describing the static
                  parts of the scene. Multiple hypotheses of the
                  background value at each pixel are generated by
                  locating periods o stable f intensity in the
                  sequence. The likelihood of each hypothesis is then
                  evaluated using optical flow information from the
                  neighborhood around the pixel, and the most likely
                  hypothesis is chosen to represent the
                  background. Our results are compared with those of
                  several standard background modeling techniques
                  using surveillance video of humans in indoor
                  environments.},
  c-houdan =	 {It uses optical flow to detect foreground objects
                  during the background initilization process. That's
                  quite useful when one can't get a video sequence
                  with no foreground objects in the scene to
                  initialize the background model},
}

@article{Gutierrez-Osuna96,
  author =	 {Gutierrez-Osuna, R. and R. C. Luo},
  year =	 {1996},
  title =	 {LOLA: Probabilistic Navigation for Topological Maps},
  journal =	 "AI Magazine",
  volume =	 "17",
  pages =	 {55-62},
  number =	 "1",
  c-ananth =	 {Other examples of HMM-based work include
                  [Kaelbling96][Gutierrez-Osuna96] and [Aycard97]
                  where a second order HMM is used to model the
                  environment.},
}

@INPROCEEDINGS{Gutmann00cira,
  AUTHOR =	 {J.-S. Gutmann and K. Konolige},
  TITLE =	 {Incremental Mapping of Large Cyclic Environments},
  YEAR =	 2000,
  pages =	 {318--325},
  month =	 {November},
  BOOKTITLE =	 CIRA,
}

@INPROCEEDINGS{Gutmann96,
  AUTHOR =	 "Gutmann, J.-S. and Schlegel, C.",
  TITLE =	 "AMOS: Comparison of Scan Matching Approaches for
                  Self-Localization in Indoor Environments",
  BOOKTITLE =	 "Proceedings of the 1st Euromicro Workshop on
                  Advanced Mobile Robots",
  PUBLISHER =	 "IEEE Computer Society Press",
  YEAR =	 1996
}

@INPROCEEDINGS{Gutmann96b,
  AUTHOR =	 "Gutmann, J.-S. and Schlegel, C.",
  TITLE =	 "{AMOS}: Comparison of Scan Matching Approaches for
                  Self-Localization in Indoor Environments",
  BOOKTITLE =	 "Proc.~of the 1st Euromicro Workshop on Advanced
                  Mobile Robots",
  PUBLISHER =	 ieeepress,
  YEAR =	 1996
}

@InProceedings{Gutmann97,
  author =	 {J.-S. Gutmann and B. Nebel},
  title =	 {Navigation Mobiler roboter mit laserscans},
  booktitle =	 {Autonome Mobile Systeme},
  year =	 1997,
  address =	 {Berlin},
  publisher =	 {Springer Verlag},
}

@InProceedings{Gutmann99cira,
  author =	 {J.-S. Gutmann and K. Konolige},
  title =	 {Incremental Mapping of Large Cyclic Environments},
  booktitle =	 CIRA,
  year =	 1999,
  pages =	 {318-325},
  abstract =	 {Mobile robots can use geometric or topological maps
                  of their environment to navigate reliably. Automatic
                  creation of such maps is still an unrealized goal,
                  especially in environments that have large cyclical
                  structures. Drawing on recent techniques of global
                  registration and correlation, we present a method,
                  called Local Registration and Global Correlation
                  (LRGC), for reliable reconstruction of consistent
                  global maps from dense range data. The method is
                  attractive because it is incremental, producing an
                  updated map with every new sensor input; and runs in
                  constant time independent of the size of the map
                  (except when closing large cycles). A real-time
                  implementation and results are presented for several
                  indoor environments.},
}

@inproceedings{Guy93iuw,
  author =	 "G. Guy and G. Medioni",
  title =	 "Inferring global perceptual contours from local
                  features",
  booktitle =	 "Image Understanding Workshop",
  pages =	 "881--892",
  year =	 1993,
  url =		 "citeseer.nj.nec.com/guy96inferring.html"
}

@Misc{HP,
  author =	 {HEWLETT-PACKARD},
  url =		 {http://www.hp.com/halo/index.html},
}

@Misc{HP,
  author =	 {HEWLETT-PACKARD},
  url =		 {http://www.hp.com/halo/index.html},
}

@inproceedings{Haehnel02,
  author =	 {Dirk H\"{a}hnel and Dirk Schulz and Wolfram Burgard},
  title =	 {Mapping with mobile robots in populated
                  environments},
  booktitle =	 IROS,
  year =	 2002,
}

@InProceedings{Haehnel03,
  author =	 {D. H\"{a}hnel and W. Burgard and D. Fox and
                  S. Thrun},
  title =	 {A Highly Efficient {F}ast{SLAM} Algorithm for
                  Generating Cyclic Maps of Large-Scale Environments
                  from Raw Laser Range Measurements},
  booktitle =	 IROS,
  pages =	 {206-211},
  year =	 2003,
  abstract =	 {The ability to learn a consistent model of its
                  environment is a prerequisite for autonomous mobile
                  robots. A particularly challenging problem in
                  acquiring environment maps is that of closing loops;
                  loops in the environment create challenging data
                  association problems [9]. This paper presents a
                  novel algorithm that combines Rao-Blackwellized
                  particle filtering and scan matching. In our
                  approach scan matching is used for minimizing
                  odometric errors during mapping. A probabilistic
                  model of the residual errors of scan matching
                  process is then used for the resampling steps. This
                  way the number of samples required is seriously
                  reduced. Simultaneously we reduce the particle
                  depletion problem that typically prevents the robot
                  from closing large loops. We present extensive
                  experiments that illustrate the superior performance
                  of our approach compared to previous approaches.},
}

@inproceedings{Haehnel03icra,
  AUTHOR =	 {H\"{a}hnel, D. and Triebel, R. and Burgard, W. and
                  Thrun, S.},
  TITLE =	 {Map Building with Mobile Robots in Dynamic
                  Environments},
  YEAR =	 2003,
  BOOKTITLE =	 ICRA,
  abstract =	 {The problem of generating maps with mobile robots
                  has received considerable attention over the past
                  years. Most of the techniques developed so far have
                  been designed for situations in which the
                  environment is static during the mapping
                  process. Dynamic objects, however, can lead to
                  serious errors in the resulting maps such as
                  spurious objects or misalignments due to
                  localization errors. In this paper we consider the
                  problem of creating maps with mobile robots in
                  dynamic environments. We present a new approach that
                  interleaves mapping and localization with a
                  probabilistic technique to identify spurious
                  measurements. In several experiments we demonstrate
                  that our algorithm generates accurate 2d and 3d in
                  different kinds of dynamic indoor and outdoor
                  environments. We also use our algorithm to isolate
                  the dynamic objects and to generate
                  three-dimensional representation of them.}
}

@INPROCEEDINGS{Haehnel03isrr,
  AUTHOR =	 {H\"{a}hnel, D. and Burgard, W. and Wegbreit, B. and
                  Thrun, S.},
  TITLE =	 {Towards Lazy Data Association in {SLAM}},
  YEAR =	 {2003},
  BOOKTITLE =	 {Proceedings of the 11th International Symposium of
                  Robotics Research (ISRR'03)},
  publisher =	 {Springer},
  address =	 {Sienna, Italy}
}

@ARTICLE{Haehnel03ras,
  AUTHOR =	 {H{\"a}hnel, D. and Burgard, W. and Thrun, S.},
  TITLE =	 {Learning Compact {3D} Models of Indoor and Outdoor
                  Environments with a Mobile Robot},
  YEAR =	 2003,
  journal =	 {Robotics and Autonomous Systems},
  volume =	 44,
  number =	 1,
  pages =	 {15-27},
}

@inproceedings{Haehnel04icra,
  AUTHOR =	 {H{\"a}hnel and W. Burgard and D. Fox and K. Fishkin
                  and M. Philipose},
  TITLE =	 {Mapping and Localization with RFID Technology},
  YEAR =	 2004,
  booktitle =	 ICRA,
}

@inproceedings{Hager96,
  AUTHOR =	 "Hager, G.D. and Belhumeur, P.N.",
  TITLE =	 "Real Time Tracking of Image Regions with Changes in
                  Geometry and Illumination",
  BOOKTITLE =	 CVPR,
  YEAR =	 1996,
  PAGES =	 "403-410"
}

@InProceedings{Hager97,
  author =	 {G. Hager and D. Kriegman and E. Yeh and
                  C. Rasmussen},
  title =	 {Image-based Prediction of landmark Features for
                  Mobile Robot Navigation},
  booktitle =	 ICRA,
  pages =	 {1040-1046},
  year =	 1997,
}

@Article{Hager98,
  author =	 {G. Hager and P. Belhumeur},
  title =	 {Efficient Regions Tracking With Parametric Models of
                  Geometry and Illumination},
  journal =	 PAMI,
  year =	 1998,
  volume =	 20,
  number =	 10,
  pages =	 {1025-1039},
  month =	 {October},
}

@article{HagerImages,
  author =	 {G. Hager},
  title =	 {Images},
  journal =	 {Languages},
  year =	 2001,
}

@article{HagerRobots,
  author =	 {Hager},
  title =	 {FRP},
  journal =	 {Languages},
  year =	 2001,
}

@article{Hahn03ps,
  Author =	 {S. Hahn and Andersen, G.J. and Saidpour,A.},
  fullAuthor =	 {Sowon Hahn and Andersen, George J. and Saidpour,
                  Asad},
  Journal =	 {Psychological Science},
  Number =	 6,
  Pages =	 {p543 - 548},
  Title =	 {Static scene analysis for the perception of
                  heading.},
  Volume =	 14,
  Year =	 2003,
  Abstract =	 {In the current study, we explored observers' use of
                  two distinct analyses for determining their
                  direction of motion, or heading: a scene-based
                  analysis and a motion-based analysis. In two
                  experiments, subjects viewed sequentially presented,
                  paired digitized images of real-world scenes and
                  judged the direction of heading; the pairs were
                  presented with various interstimulus intervals
                  (ISIs). In Experiment 1, subjects could determine
                  heading when the two frames were separated with a
                  1,000-ms ISI, long enough to eliminate apparent
                  motion. In Experiment 2, subjects performed two
                  tasks, a path-of-motion task and a memory-load task,
                  under three different ISIs, 50 ms, 500 ms, and 1,000
                  ms. Heading accuracy decreased with an increase in
                  ISI. Increasing memory load influenced heading
                  judgments only for the longer ISI when motion-based
                  information was not available. These results are
                  consistent with the hypothesis that the scene-based
                  analysis has a coarse spatial representation, is a
                  sustained },
  quotes =	 {The question we addressed in the present study is
                  whether observers can use static information to
                  determine heading. .. This demonstration, [...]
                  illustrates people? ability to perceive a change in
                  the observer? position independent of a perception
                  of motion. .. We propose that the motion-based
                  analysis is a transient system that updates
                  information very rapidly. .. In contrast, the
                  scene-based analysis is a sustained system in which
                  information is encoded and stored over long periods
                  of time. .. We propose that the scene-based analysis
                  is a high-level process that has encoding capacity
                  limitations. Informal reports from observers in our
                  pilot study suggested that they consciously scanned
                  the second frame to determine the change in observer
                  position. .. [Requiring] observers to perform a
                  secondary task does not influence heading judgments,
                  suggesting that recovering heading from flow fields
                  does not involve attention.},
  c-dellaert =	 {Optic flow is low-level and more accurate, but
                  high-level scene analysis can also determine motion,
                  albeit slower and needing visual search over the
                  scene.},
}

@book{Hall98,
  author =	 {M. Hall},
  title =	 {Combinatorial Theory, 2nd Edition},
  publisher =	 {Wiley-Interscience},
  year =	 {1998}
}

@inproceedings{Hallinan94,
  AUTHOR =	 "P W Hallinan",
  TITLE =	 "A low-dimensional representation of human faces for
                  arbitrary lighting conditions",
  BOOKTITLE =	 CVPR,
  YEAR =	 1994,
  PAGES =	 "995-999"
}

@InProceedings{Han04accv,
  author =	 {B. Han and D. Comaniciu and L. Davis},
  title =	 {Sequential Kernel Density Approximation Through Mode
                  Propagation: Application to Background Modeling},
  booktitle =	 ACCV,
  year =	 2004,
  month =	 {Febrary},
  abstract =	 {Density-based modeling of visual features is very
                  common in computer vision, either by using
                  non-parametric techniques or through representing
                  the underlying density function as a weighted sum of
                  Gaussians. A number of real-time tasks such as
                  background modeling or modeling the appearance of a
                  moving target require sequential density estimation,
                  where new data is incorporated in the model as it
                  becomes available. Nevertheless, current methods for
                  updating the density function either lack
                  flexibility, by fixing the number of Gaussians in
                  the mixture, or require large memory amounts, by
                  maintaining a non-parametric representation of the
                  den- sity. This paper presents an efficient method
                  for recursive density approximation that relies on
                  the propagation of the density modes. At each time
                  step, the modes of the density are re-estimated and
                  a Gaussian component is assigned to each mode. The
                  covariance of each component is derived from the
                  Hessian matrix estimated at the mode location. To
                  detect the modes we employ the variable-bandwidth
                  mean shift. While the proposed density
                  representation is memory efficient (which is typical
                  for mixture densities), it inherits the flexibility
                  of non-parametric methods, by allowing the number of
                  modes to adapt in time. We show that the same mode
                  propagation principle applies for subspaces derived
                  from eigen analysis. Extensive experimental
                  background modeling results demonstrate the
                  performance of the method. },
  c-houdan =	 {mean-shift based KDE for initialization + mode
                  propagation for updating the background model, good
                  related work describing},
}

@article{Han04ijcv,
  title =	 {{Range Image Segmentation by an Effective
                  Jump-Diffusion Method}},
  author =	 {F. Han and Z. W. Tu and S.C. Zhu},
  journal =	 PAMI,
  volume =	 {26},
  number =	 {9},
  pages =	 {1138--1153},
  year =	 {2004},
  month =	 {September},
}

@article{Han04pami,
  title =	 {{Reconstruction of a Scene with Multiple Linearly
                  Moving Objects}},
  author =	 {Han, M. and Kanade, T.},
  journal =	 IJCV,
  volume =	 {59},
  number =	 {3},
  pages =	 {285--300},
  year =	 {2004},
  publisher =	 {Springer},
}

@Article{Han98,
  author =	 {M.~Han and T.~Kanade},
  title =	 {Homography-Based {3D} Scene Analysis of Video
                  Sequences},
  journal =	 IUW,
  year =	 1998
}

@Article{Handschin70,
  author =	 {J.E. Handschin},
  title =	 {Monte {C}arlo Techniques for Prediction and
                  Filtering of Non-Linear Stochastic Processes},
  journal =	 {Automatica},
  year =	 1970,
  volume =	 6,
  pages =	 {555-563},
}

@Book{Hanna98,
  author =	 {Hanna, Karen C. and R. Brian Culpepper},
  title =	 {GIS in Site Design},
  publisher =	 {John Wiley \& Sons},
  year =	 1998,
  address =	 {New York},
}

@InProceedings{Hansen94,
  author =	 "M Hansen and P Anandan and K Dana and G Van der Wal
                  and P Burt",
  title =	 "Real-time Scene Stabilization and Mosaic
                  Construction",
  booktitle =	 "DARPA Image Understanding Workshop",
  year =	 1994,
  month =	 "November",
}

@InCollection{Hanson87,
  author =	 {K. M. Hanson},
  editor =	 {Henry Stark},
  booktitle =	 {Image Recovery, Theory and Applications},
  title =	 {Bayesian and Related Methods in Image Reconstruction
                  from Incomplete Data},
  publisher =	 ap,
  year =	 1987,
  pages =	 {79-125},
}

@article{Haralick94,
  author =	 "R. Haralick and C. Lee and K. Ottenberg and
                  M. Noelle",
  title =	 "Review and Analysis of Solutions to the Three Point
                  Perspective Pose Estimation Problem",
  journal =	 IJCV,
  volume =	 13,
  number =	 3,
  pages =	 "331--356",
  year =	 1994
}

@Article{Hardie97,
  author =	 {R.C.~Hardie and K.J.~Barnard and E.E.~Armstrong},
  title =	 {Joint {MAP} Registration and High-Resolution Image
                  Estimation Using a Sequence of Undersampled Images},
  journal =	 IP,
  year =	 1997,
  volume =	 6,
  number =	 12,
  month =	 {December},
  pages =	 {1621--1633}
}

@Article{Hardie98,
  author =	 {R.C. Hardie and K.J. Barnard and J.G. Bognar and
                  E.A. Armstrong and E.A. Watson},
  title =	 {High-resolution image reconstruction from a sequence
                  of rotated and translated frames and its application
                  to an infrared imaging system},
  journal =	 {Opt. Eng.},
  year =	 1998,
  volume =	 37,
  number =	 1,
  pages =	 {247-260},
}

@Article{Haritaoglu00,
  author =	 {I. Haritaoglu and D. Harwood and L. S. Davis},
  title =	 {{W4}: Real-Time Surveillance of People and Their
                  Activities},
  journal =	 PAMI,
  year =	 2000,
  volume =	 22,
  number =	 8,
  pages =	 {809-830},
}

@Article{Harris88,
  author =	 {C.G. Harris and J.M. Pike},
  title =	 {{3D} positional integration from image sequences},
  journal =	 {Image and Vision Computing},
  volume =	 6,
  number =	 2,
  pages =	 {87-90},
  month =	 {May},
  year =	 1988,
  url =
                  {http://www.fmrib.ox.ac.uk/~steve/altruism/droid_brief/},
  abstract =	 {An explicit three-dimensional (3D) representation is
                  constructed from feature points extracted from a
                  sequence of images taken by a moving camera. The
                  points are tracked through the sequence, and their
                  3D locations are accurately determined by use of
                  Kalman filters. The egomotion of the camera is also
                  determined.},
  c-dellaert =	 {Introduced the DROID system, which tracks Harris
                  corner features in a single camera using an EKF per
                  feature. Long-term drift occurs (Davison, Se).},
}

@Article{Harris88b,
  author =	 {C. Harris and M. Stephens},
  title =	 {A Combined Corner and Edge Detector},
  journal =	 {Proceedings of the 4th Alvey Vision Conference},
  address =	 {Manchester, UK},
  year =	 1988,
  month =	 {August},
  pages =	 {147--151},
}

@InCollection{Harris92,
  author =	 "Chris Harris",
  crossref =	 "Blake92",
  title =	 "Tracking with Rigid Models",
}

@InCollection{Harris92b,
  author =	 "Chris Harris",
  crossref =	 "Blake92",
  title =	 "Geometry from Visual Motion",
}

@article{Hartigan90,
  author =	 {J. A. Hartigan},
  year =	 1990,
  title =	 {Partition models},
  journal =	 {Communications in Statistics, Part A - Theory and
                  Methods},
  volume =	 19,
  pages =	 {2745-2756},
}

@Book{Hartley00,
  author =	 {R. Hartley and A. Zisserman},
  fullauthor =	 {Richard Hartley and Andrew Zisserman},
  title =	 {Multiple View Geometry in Computer Vision},
  publisher =	 {Cambridge University Press},
  year =	 2000,
}

@TechReport{Hartley00tr,
  author =	 {R. Hartley and F. Schaffalitzky},
  title =	 {PowerFactorization: 3D Reconstruction with Missing
                  or Uncertain Data},
  institution =	 {Australian National University},
  year =	 2000
}

@Article{Hartley58,
  author =	 {H.O. Hartley},
  title =	 {Maximum likelihood estimation from incomplete data},
  journal =	 {Biometrics},
  year =	 1958,
  volume =	 14,
  pages =	 {174-194},
}

@inproceedings{Hartley94,
  AUTHOR =	 "Hartley, R.I.",
  TITLE =	 "Euclidean Reconstruction from Uncalibrated Views",
  BOOKTITLE =	 AICV94,
  YEAR =	 1994,
  PAGES =	 "237-256"
}

@article{Hartley97,
  author =	 "R.I. Hartley",
  title =	 "Lines and points in three views and the trifocal
                  tensor",
  journal =	 IJCV,
  volume =	 22,
  number =	 2,
  pages =	 "125-- 140",
  year =	 1997
}

@article{Hashemipour88itac,
  Author =	 {Hashemipour, H. R. and Roy, S. and Laub, A. J.},
  Journal =	 ITAC,
  Number =	 1,
  Pages =	 {88--94},
  Title =	 {Decentralized structures for parallel Kalman
                  filtering},
  Volume =	 33,
  Year =	 1988,
  Abstract =	 {Various multisensor network scenarios with signal
                  processing tasks that are amenable to multiprocessor
                  implementation are described. The natural origins of
                  such multitasking are emphasized, and novel parallel
                  structures for state estimation using the Kalman
                  filter are proposed that extend existing results in
                  several directions. In particular, hierarchical
                  network structures are developed that have the
                  property that the optimal global estimate based on
                  all the available information can be reconstructed
                  from estimates computed by local processor nodes
                  solely on the basis of their own local information
                  and transmitted to a central processor. The
                  algorithms potentially yield an approximately linear
                  speedup rate, are reasonably failure-resistant, and
                  are optimized with respect to communication
                  bandwidth and memory requirements at the various
                  processors},
  r-DurrantWhyte90icra ={The communication overhead [of DKF] is also
                  low, indeed it is actually less than is required for
                  similar hierarchical organizations
                  \cite{Hashemipour88itac}. [...] The partitioning of
                  [the centralized EKF] equations follows the work of
                  \citet{Hashemipour88itac} in which a hierarchical
                  formulation of the Kalman Filter is derived.},
  r-Rao91cta =	 {\citet{Hashemipour88itac} has developed Kalman
                  filter algorithms for multisensor networks in which
                  each sensing node has embedded processing
                  capabilities and its own local model of the dynamics
                  of the system so that each sensing node can arrive
                  at a local estimate and prediction of the state of
                  the system. These algorithms are for hierarchically
                  distributed systems which rely on there being a
                  parent node to perform data fusion.},
  r-Grime94cep = {The paper by Hashemipour, Roy and Laub (1988) is
                  notable in employing, indirectly, the information
                  form of the Kalman filter to derive a hierarchical
                  estimation algorithm.}
}

@ARTICLE{Hastings70,
  AUTHOR =	 {Hastings, W.K.},
  TITLE =	 {Monte {C}arlo sampling methods using {M}arkov chains
                  and their applications},
  JOURNAL =	 {Biometrika},
  YEAR =	 {1970},
  VOLUME =	 {57},
  PAGES =	 {97--109}
}

@article{Hayakawa94,
  author =	 {H. Hayakawa},
  journal =	 {J. Opt. Soc. Am. A},
  pages =	 3079,
  title =	 {Photometric stereo under a light source with
                  arbitrary motion},
  volume =	 11,
  year =	 1994,
}

@Article{HayesRoth79,
  author =	 "B. Hayes-Roth and F. Hayes-Roth",
  title =	 "A Cognitive Model of Planning",
  journal =	 "Cognitive Science",
  year =	 1979,
  volume =	 3,
  pages =	 "275-310",
}

@inproceedings{Hayet02icra,
  author =	 {J.B. Hayet and F. Lerasle and M. Devy},
  title =	 {A visual landmark framework for indoor mobile robot navigation},
  booktitle =	 ICRA,
  year =	 {2002}
}

@article{Hayet02icra,
  author =	 {J.B. Hayet and F. Lerasle and M. Devy},
  title =	 {A visual landmark framework for indoor mobile robot
                  navigation},
  booktitle =	 {ICRA},
  year =	 {2002},
  c-alireza =	 {The paper uses quadrangular landmarks such as doors
                  and posters in indoor envirnoment for
                  navigation. The contribution of the paper is using
                  Hausdorff distance for landmark recognition. Also
                  they use a bunch of heuristics for detecting the
                  rectangular landmarks in the image.}
}

@InProceedings{Hayet02icra,
  author =	 {J.B. Hayet and F. Lerasle and M. Devy},
  title =	 {A visual landmark framework for indoor mobile robot
                  navigation},
  booktitle =	 ICRA,
  year =	 {2002},
  alireza =	 { The paper uses quadrangular landmarks such as doors
                  and posters in indoor envirnoment for
                  navigation. The contribution of the paper is using
                  Hausdorff distance for landmark recognition. Also
                  they use a bunch of heuristics for detecting the
                  rectangular landmarks in the image.}
}

@inproceedings{Hayet03cvpr,
 author = {J. B. Hayet and F. Lerasle and M. Davy},
 title = {Visual landmark detection and recognition for mobile robot navigation},
 booktitle = CVPR,
 year = {2003}
}

@article{Hayet03cvpr,
  author =	 {J.B. Hayet and F. Lerasle and M. Devy},
  title =	 {Visual landmark detection and recognition for mobile
                  robot navigation},
  booktitle =	 {CVPR},
  year =	 {2003},
  c-alireza =	 {Same as the Hayet02icra, just with a little bit more
                  detail.}
}

@InProceedings{Hayet03cvpr,
  author =	 {J.B. Hayet and F. Lerasle and M. Devy},
  title =	 {Visual landmark detection and recognition for mobile
                  robot navigation},
  booktitle =	 CVPR,
  year =	 {2003},
  alireza =	 { Same as the Hayet02icra, just with a little bit
                  more detail.}
}

@article{Hayhoe00vc,
  author =	 {Hayhoe, M.},
  year =	 2000,
  title =	 {Vision using routines: a functional account of
                  vision},
  journal =	 {Visual Cognition},
  volume =	 7,
  pages =	 {43--64},
  abstract =	 {This paper presents the case for a functional
                  account of vision. A variety of studies have
                  consistently revealed ?hange blindness?or
                  insensitivity to changes in the visual scene during
                  an eye movement. These studies indicate that only a
                  small part of the information in the scene is
                  represented in the brain from moment to moment. It
                  is still unclear, however, exactly what is included
                  in visual representations. This paper reviews
                  experiments using an extended visuo-motor task,
                  showing that display changes affect performance
                  differently depending on the observer? place in the
                  task. These effects are revealed by increases in
                  fixation duration following a change. Different
                  task-dependent increases suggest that the visual
                  system represents only the information that is
                  necessary for the immediate visual task. This allows
                  a principled exploration of the stimulus properties
                  that are included in the internal visual
                  representation. The task specificity also has a more
                  general implication that vision should be
                  conceptualized as an active process executing
                  special purpose ?outines?that compute only the
                  currently necessary information. Evidence for this
                  view and its implications for visual representations
                  are discussed. Comparison of the change blindness
                  phenomenon and fixation durations shows that
                  conscious report does not reveal the extent of the
                  representations computed by the routines.},
  quotes =	 {The role of vision from moment to moment is
                  determined almost exclusively by the current stage
                  in accomplishing the task. There appears to be
                  little room for other functions. Performance is also
                  highly serialized. .. Another compelling feature of
                  the behaviour was the similarity between
                  subjects. .. The crucial advantage of task-specific
                  routines is computational efficiency. .. In the case
                  of human vision the retinal image is changing every
                  several hundred milliseconds as the observer changes
                  gaze. Thus, the relevant information must be
                  extracted very quickly. .. Direction of gaze can be
                  used to specify the location of the needed
                  information in the visual scene and the time when it
                  is needed. This makes complex internal
                  representations unnecessary because the
                  observer/autonomous system can acquire the necessary
                  information from the scene during performance of the
                  task, rather than using the information inherent in
                  an internal model. .. The computational advantage of
                  task specific representations comes at a cost. A
                  crucial problem for any system like this is: How are
                  more complex behaviours composed using the
                  individual routines? That is, how is the scheduling
                  of the individual routines handled? .. What, then,
                  can we conclude about the content of visual
                  representations from the change blindness work and
                  the results described here? [] The general consensus
                  [] is that the visual information retained after a
                  change in fixation position is very limited.},
  c-dellaert =	 {presents computational, physiological,
                  psychophysiscs arguments for task-specific visual
                  routines. Arbitrartion/scheduling is then the big
                  problem. She also discusses what is represented, and
                  argues it is very little. Intersting discussion of
                  "initial access" problem described by Ullman.}
}

@article{Hayhoe05tics,
  author =	 {Hayhoe, M.M. and Ballard, D.H.},
  year =	 2005,
  Volume =	 9,
  number =	 4,
  month =	 {April},
  title =	 {Eye Movements in Natural Behavior},
  journal =	 {Trends in Cognitive Science},
  abstract =	 {The classic experiments of Yarbus over 50 years ago
                  revealed that saccadic eye movements reflect
                  cognitive processes. But it is only recently that
                  three separate advances have greatly expanded our
                  understanding of the intricate role of eye movements
                  in cognitive function. The first is the
                  demonstration of the pervasive role of the task in
                  guiding where and when to fixate. The second has
                  been the recognition of the role of internal reward
                  in guiding eye and body movements, revealed
                  especially in neurophysiological studies. The third
                  important advance has been the theoretical
                  developments in the fields of reinforcement learning
                  and graphic simulation. All of these advances are
                  proving crucial for understanding how behavioral
                  programs control the selection of visual
                  information.},
  quotes =	 {Together, these developments have allowed the
                  simulation of rewardbased systems that incorporate
                  realistic models of eye movements over extended time
                  scales. This has shifted the focus of experimental
                  understanding from where in a scene the eyes fixate
                  in an image, to why the eyes choose a location in a
                  scene, and when they choose it. .. The most novel
                  finding of task-oriented studies is that the eyes
                  are positioned at a point that is not the most
                  visually salient, but is the best for the
                  spatio-temporal demands of the job that needs to be
                  done. This line of investigation has been used in
                  extended visuo-motor tasks such as driving, walking,
                  sports, and making tea or sandwiches[]. .. Not only
                  is the sequence of fixations tightly linked to the
                  task, but in addition, fixations appear to have the
                  purpose of obtaining quite specific
                  information. .. In driving, Shinoda et al. [42]
                  showed that approximately 45\% of fixations fell
                  close to intersections. As a consequence of this,
                  subjects were more likely to notice ?top?signs
                  located at intersections as opposed to signs in the
                  middle of a block, suggesting in turn that subjects
                  have learnt that traffic signs are more likely
                  around intersections. .. The value of VR is that it
                  allows the creation of human models that implement
                  complex visuo-motor loops for the control of
                  temporally extended behaviors. .. One of the
                  principal findings of these simulations is that the
                  informationfromfixations supports behavior
                  indifferent ways. In this respect is very helpful to
                  think of the visual computations that need to be
                  done as hierarchically organized, a viewpoint that
                  has not been as obvious from the
                  attention/working-memory dichotomy. Table 1 shows
                  the basic elements of a representative hierarchy
                  that has three levels ?Behavior, Arbitration and
                  Context ?highlighting the different roles of vision
                  at each level. .. The mental programs that drive
                  gaze selection are increasingly seen to be
                  reward-based.},
  c-dellaert =	 {Makes a case for reinforcement learning as the
                  central mechanism driving learning of where to
                  look. Has interesting notes about hierarchy:
                  behavior, arbitration, context; refers to
                  subsumption in robotics as having explored this. },
}

@inproceedings{Hays06eccv,
  author =	 "J.H. Hays and M. Leordeanu and A.A. Efros and
                  Y. Liu",
  fullauthor =	 "James H. Hays and Marius Leordeanu and Alexei
                  A. Efros and Yanxi Liu",
  title =	 "Discovering Texture Regularity as a Higher-Order
                  Correspondence Problem",
  booktitle =	 ECCV,
  year =	 2006,
}

@article{Hays07siggraph,
  author =	 {James Hays and Alexei A Efros},
  title =	 {Scene Completion Using Millions of Photographs},
  journal =	 {ACM Transactions on Graphics (SIGGRAPH 2007)},
  volume =	 {26},
  number =	 {3},
  year =	 {2007},
}

@inproceedings{Hays08cvpr,
  Author =	 {James Hays and Alexei A. Efros},
  Title =	 {im2gps: estimating geographic information from a
                  single image},
  Booktitle =	 {Proceedings of the {IEEE} Conf. on Computer Vision
                  and Pattern Recognition ({CVPR})},
  Year =	 {2008},
}

@InProceedings{He09cvpr,
  author =	 {K. He and J. Sun and X. Tan},
  title =	 {Single Image Haze Removal using Dark Channel Prior},
  crossref =	 {_CVPR09}
}

@Article{Healy03,
  author =	 {D. Healy and D. Rockmore and P. Kostelec and
                  S. Moore},
  title =	 {{FFTs} for the 2-Sphere - Improvements and
                  Variations},
  journal =	 {The Journal of Fourier Analysis and Applications},
  year =	 2003,
  volume =	 9,
  number =	 4,
  pages =	 {341-385},
}

@MastersThesis{Heckbert89,
  author =	 "P. S. Heckbert",
  title =	 "Fundamentals of texture Mapping and Image Warping",
  school =	 "University of California, Berkeley",
  year =	 1989
}

@TechReport{Heckerman97,
  author =	 "D. Heckerman and C. Meek and G. Cooper",
  title =	 "A {B}ayesian approach to causal discovery",
  institution =	 "Microsoft Research",
  year =	 1997,
  number =	 "MSR-TR-97-05"
}

@Article{Heggernes06dm,
  author =	 {Heggernes, P.},
  fullauthor =	 {Heggernes, Pinar},
  title =	 {Minimal triangulations of graphs: a survey.},
  journal =	 {Discrete Math.},
  year =	 2006,
  volume =	 306,
  number =	 3,
  pages =	 {297--317},
  r-MathSciNet = {Any graph $G=(V,E)$ can be embedded in a chordal
                  graph $H=(V,F)$ by adding edges to $G$, and then $H$
                  is called a triangulation of $G$. A triangulation
                  $H=(V,F)$ of $G=(V,E)$ is called a minimal
                  triangulation of $G$ if no triangulation of $G$ is a
                  proper subgraph of $H$. Since the first papers
                  presenting algorithms to compute any minimal
                  triangulation of the input graph appeared in 1976,
                  several characterizations of minimal triangulations
                  of a graph have been established; among those, a
                  close relationship between minimal triangulations of
                  a graph and its minimal separators has been
                  exhibited. A variety of algorithms to compute any
                  minimal triangulation of the input graph has been
                  obtained both for general graphs and for restricted
                  graph classes. The survey presents and ties together
                  in a unified way, both graph-theoretic and
                  algorithmic results concerning minimal
                  triangulations.},
  c-dellaert =	 {Heggernes is aware of all the connections in related
                  fields, including computer vision
                  \cite{Chung94jct}. Note this paper is about
                  \emph{minimal} not \emph{minimum} triangulations.},
}

@InProceedings{Heggernes96siam,
  author =	 {P. Heggernes and P. Matstoms},
  fullauthor =	 {Pinar Heggernes and Pontus Matstoms},
  title =	 {Finding Good Column Orderings for Sparse {QR}
                  Factorization},
  booktitle =	 {Second SIAM Conference on Sparse Matrices},
  year =	 {1996},
  c-dellaert =	 {Develop multifrontal version of QR. Refers to
                  Manneback 1985 thesis for bipartite elimination
                  game.},
}

@inproceedings{Helal00drishti,
  author =	 "A. Helal and S. Moore and B. Ramachandran",
  title =	 "Drishti: {A}n {I}ntergrated {N}avigation {S}ystem
                  for {V}isually {I}mpaired and {D}isabled",
  booktitle =	 "Proceedings of the 5th International Symposium on
                  Wearable Computer",
  year =	 2000,
  month =	 "October",
  address =	 "Zurich,Switzerland",
  url =		 "http://harris.cise.ufl.edu/projects/navsystem.htm",
  pdf =		 "pdf/Drishti.pdf"
}

@InProceedings{Helal01,
  author =	 {A. Helal and S. Moore and B. Ramachandra},
  title =	 {Drishti: An Integrated Navigation System for
                  Visually Impaired and Disable},
  booktitle =	 {Proceedings of the 5th International Symposium on
                  Wearable Computer},
  year =	 2001,
  month =	 {October}
}

@Article{Helman85siam,
  author =	 {P. Helman and A. Rosenthal},
  title =	 {A comprehensive model of dynamic programming},
  journal =	 {SIAM J. on Algebraic and Discrete Methods},
  year =	 1985,
  volume =	 6,
  number =	 3,
  r-Helman89jacm ={The formalism developed in \cite{Helma89jacm} is an
                  outgrowth of the model of dynamic programming
                  presented in \cite{Helman85siam}. That model is
                  based on the enumeration of conjuncts,
                  nonassociative counterparts of strings.},
}

@article{Helman89jacm,
  author =	 {P. Helman},
  fullauthor =	 {Paul Helman},
  title =	 {A common schema for dynamic programming and branch
                  and bound algorithms},
  journal =	 {J. ACM},
  volume =	 36,
  number =	 1,
  year =	 1989,
  issn =	 {0004-5411},
  pages =	 {97--128},
  doi =		 {http://doi.acm.org/10.1145/58562.59304},
  publisher =	 {ACM Press},
  address =	 {New York, NY, USA},
  abstract =	 {A new model for dynamic programming and branch and
                  bound algorithms is presented. The model views these
                  algorithms as utilizing computationally feasible
                  dominance relations to infer the orderings of
                  application objects, thereby implicitly enumerating
                  a finite solution space. The formalism is broad
                  enough to apply the computational strategies of
                  dynamic programming and branch and bound to problems
                  with nonassociative objects, and can model both
                  oblivious and nonoblivious algorithms, as well as
                  parallel algorithms. The model is used to classify
                  computations based, in part, on the types of
                  computationally feasible dominances that they
                  employ. It is demonstrated that the model is
                  computationally precise enough to support the
                  derivation of lower bounds on the number of
                  operations required to solve various types of
                  problems.},
  c-dellaert =	 {\citet{Helman89jacm} develops a formal model based
                  on "non-associative conjuncts" that incorporates DP
                  and Branch and Bound. Pretty dense, and not cited
                  often.}
}

@InProceedings{Herath06iros,
  author =	 {D.C. Herath and S. Kodagoda and G. Dissanayake},
  title =	 {Simultaneous Localisation and Mapping: A Stereo
                  Vision Based Approach},
  booktitle =	 IROS,
  location =	 {Beijing, China},
  month =	 {Oct},
  year =	 2006,
  abstract =	 {With limited dynamic range and poor noise
                  performance, cameras still pose considerable
                  challenges in the application of range sensors in
                  the context of robotic navigation, especially in the
                  implementation of Simultaneous Localisation and
                  Mapping (SLAM) with sparse features. This paper
                  presents a combination of methods in solving the
                  SLAM problem in a constricted indoor environment
                  using small baseline stereo vision. Main
                  contributions include a feature selection and
                  tracking algorithm, a stereo noise filter, a robust
                  feature validation algorithm and a multiple
                  hypotheses adaptive window positioning method in
                  "closing the loop". These methods take a novel
                  approach in that information from the image
                  processing and robotic navigation domains are used
                  in tandem to augment each other. Experimental
                  results including a real-time implementation in an
                  office-like environment are also presented.},
  c-kaess =	 {Uses KLT feature tracker (about 20 features per
                  frame). Removes noisy features based on histogram
                  over disparity of neighborhood. Uses a RANSAC
                  inspired algorithm (read: heuristic) for "feature
                  validation". Loop closing by multiple hypotheses -
                  restricted view point variations due to use of
                  KLT. Claims to show that EKF is consistent based on
                  results from one test run. Real-time implementation
                  only without loop closing. Claims statistically
                  reliable results, but only states that "we have
                  observed large absolute errors (>3\%)" (read: it
                  doesn't work).},
}

@Article{Herman77,
  author =	 {G.T. Herman and A. Lent},
  title =	 {A computer implementation of a {B}ayesian analysis
                  of image reconstruction},
  journal =	 {Inform. Contr.},
  year =	 1977,
  volume =	 31,
  pages =	 {364-384},
}

@InProceedings{Hernandez07iccv,
  author =	 {Hernandez, C. and Vogiatzis, G. and Brostow,
                  G. J. and Stenger, B. and Cipolla, R.},
  title =	 {Non-Rigid Photometric Stereo with Colored Lights},
  booktitle =	 ICCV,
  year =	 2007,
}

@article{Higdon98,
  author =	 {D. M. Higdon},
  title =	 {Auxiliary Variable Methods for {M}arkov Chain
                  {M}onte {C}arlo with Applications},
  journal =	 {Journal of American Statistical Association},
  volume =	 93,
  pages =	 {585--595},
  year =	 1998,
}

@misc{Hine98,
  author =	 "J. Hine and A. Nooralahiyan",
  title =	 "Improving {M}obility and {I}ndependence for
                  {E}lderly and {B}lind and {V}isually {I}mpaired
                  {P}eople",
  year =	 1998,
  url =
                  "http://www.dinf.org/tide98/128/hine_nooralahiyan.html"
}

@article{Hinton06,
  author =	 {G.E. Hinton and S. Osindero and Y. Teh},
  title =	 {A fast learning algorithm for deep belief nets},
  journal =	 {Neural Computation},
  volume =	 18,
  pages =	 {1527--1554},
  year =	 2006,
}

@InProceedings{Hirata92,
  author =	 "S. Hirata and Y. Shirai and M. Asada",
  title =	 "Scene Interpretation Using 3-D Information Extracted
                  from Monocular Color Images",
  pages =	 1603,
  booktitle =	 IROS,
  year =	 1992,
  address =	 "Raleigh, NC",
  month =	 "July",
}

@InProceedings{Hirschmuller02icarcv,
  author =	 {H. Hirschm\"uller and P.R. Innocent and
                  J.M. Garibaldi},
  title =	 {Fast, Unconstrained Camera Motion Estimation from
                  Stereo without Tracking and Robust Statistics},
  booktitle =	 {Proc. of the Intl. Conf. on Control, Automation,
                  Robotics and Vision},
  pages =	 {1099-1104},
  year =	 2002,
  abstract =	 {Camera motion estimation is useful for a range of
                  applications. Usually, feature tracking is performed
                  through the sequence of images to determine
                  correspondences. Furthermore, robust statistical
                  techniques are normally used to handle large number
                  of outliers in correspondences. This paper proposes
                  a new method that avoids both. Motion is calculated
                  between two consecutive stereo images without any
                  pre-knowledge or prediction about feature location
                  or the possibly large camera movement. This permits
                  a lower frame rate and almost arbitrary
                  movements. Euclidean constraints are used to
                  incrementally select inliers from a set of initial
                  correspondences, instead of using robust statistics
                  that has to handle all inliers and outliers
                  together. These constraints are so strong that the
                  set of initial correspondences can contain several
                  times more outliers than inliers. Experiments on a
                  worst-case stereo sequence show that the method is
                  robust, accurate and can be used in real-time.},
}

@ARTICLE{Hoegh08Science,
  title =	 {Coral Reefs Under Rapid Climate Change and Ocean
                  Acidification},
  author =	 {Hoegh-Guldberg, O. and Mumby, P. J. and Hooten,
                  A. J. and Steneck, R. S. and Greenfield and Gomez,
                  P. E. and Harvell, C. D. and Sale, P. F. and
                  Edwards, A. J. and Caldeira, K. and Knowlton, N. and
                  Eakin, C. M.},
  journal =	 {Science},
  year =	 2008,
  volume =	 14,
  number =	 {318 (5857)},
  pages =	 {1737-1742.},
}

@InProceedings{Hoffman99sigir,
  author =	 {Thomas Hofmann},
  title =	 {Probabilistic latent semantic indexing},
  journal =	 SIGIR,
  pages =	 {50--57},
  year =	 1999,
}

@inproceedings{Hoiem05iccv,
  author =	 "Derek Hoiem and Alexei A. Efros and Martial Hebert",
  title =	 "Geometric Context from a Single Image",
  booktitle =	 "International Conference of Computer Vision (ICCV)",
  month =	 "October",
  year =	 2005,
  publisher =	 "IEEE"
}

@inproceedings{Hoiem05siggraph,
  author =	 "Derek Hoiem and Alexei A. Efros and Martial Hebert",
  title =	 "Automatic Photo Pop-up",
  booktitle =	 "ACM SIGGRAPH",
  month =	 "August",
  year =	 2005,
  note =	 "AVI Video available at:
                  http://www.cs.cmu.edu/~dhoiem/projects/popup/popup_movie_912_500_DivX.avi"
}

@inproceedings{Hoiem06cvpr,
  author =	 "Derek Hoiem and Alexei A. Efros and Martial Hebert",
  title =	 "Putting Objects in Perspective",
  booktitle =	 CVPR,
  year =	 2006,
  pages =	 "2137--2144"
}

@article{Hong04,
  author =	 {Wei Hong, Allen Yang Yang, Kun Huang and Yi Ma},
  title =	 {On Symmetry and Multiple View Geometry: Structure,
                  Pose and Calibration from a Single Image},
  journal =	 IJCV,
  voulume =	 60,
  number =	 3,
  year =	 2004
}

@article{Hongeng04cviu,
  author =	 {S. Hongeng and R. Nevatia and F. Bremond},
  title =	 {{Video-based event recognition : activity
                  representation and probabilistic recognition
                  mothods}},
  journal =	 CVIU,
  volume =	 96,
  number =	 2,
  pages =	 "129--162",
  month =	 "Nov.",
  year =	 2004,
  keywords =	 {video surveillance, activity recognition,
                  probabilistic modeling},
}

@article{Hopfield85,
  author =	 "J. J. Hopfield and D. W. Tank",
  title =	 "Neural Computation of Decisions in Optimization
                  Problems",
  journal =	 "Biological Cybernetics",
  volume =	 52,
  pages =	 "147--152",
  year =	 1985
}

@article{Hoppe94,
  author =	 "Hugues Hoppe and Tony DeRose and Tom Duchamp and
                  Mark Halstead and Hubert Jin and John McDonald and
                  Jean Schweitzer and Werner Stuetzle",
  title =	 "Piecewise Smooth Surface Reconstruction",
  journal =	 "Computer Graphics",
  volume =	 28,
  number =	 "{Annual Conference Series}",
  pages =	 "295--302",
  year =	 1994,
  url =		 "citeseer.nj.nec.com/hoppe94piecewise.html"
}

@article{Horaud87,
  author =	 "R. Horaud",
  title =	 "New Methods for Matching 3-D Objects with Single
                  Perspective Views",
  journal =	 PAMI,
  volume =	 9,
  number =	 3,
  pages =	 "401--412",
  year =	 1987
}

@article{Horaud89,
  author =	 {Radu Horaud, Thomas Skordas},
  title =	 {Stereo Correspondence Through Feature Grouping and
                  Maximal Cliques},
  journal =	 {Pattern Anaylysis and Machine Intelligence},
  volume =	 2,
  number =	 2,
  pages =	 {1168-1180},
  year =	 1989
}

@Book{Horn86,
  author =	 {B.K.P. Horn},
  title =	 {Robot {V}ision},
  publisher =	 MIT,
  year =	 1986,
}

@Article{Horn88,
  author =	 "Berthold k P Horn and E J Weldon",
  title =	 "Direct Methods for Recovering Motion",
  journal =	 IJCV,
  year =	 1988,
  volume =	 1,
  number =	 2,
  pages =	 "51-76",
}

@InProceedings{Hornegger97,
  author =	 "J. Hornegger",
  title =	 "Statistical Modeling of Relations for {3-D} Object
                  Recognition",
  volume =	 4,
  pages =	 "3173-3176",
  booktitle =	 ICASSP,
  year =	 1997,
  address =	 "Munich",
  month =	 "April",
}

@InProceedings{Horprasert99frame,
  author =	 {T. Horprasert and D. Harwood and L.S. Davis},
  title =	 {A Statistical Approach for Real-time Robust
                  Background Subtraction and Shadow Detection},
  booktitle =	 {{ICCV} Workshop on FRAME-RATE},
  year =	 1999,
  abstract =	 {This paper presents a novel algorithm for detecting
                  moving objects from a static background scene that
                  contains shading and shadows using color images. We
                  develop a robust and e ciently computed background
                  subtraction algorithm that is able to cope with
                  local illumination changes, such as shadows and
                  highlights, as well as global illumination
                  changes. The algorithm is based on a proposed
                  computational color model which separates the
                  brightness from the chromaticity component. We have
                  applied this method to real image sequences of both
                  indoor and outdoor scenes. The results, which
                  demonstrate the system's performance, and some speed
                  up techniques we employed in our implementation are
                  also shown.},
  c-houdan =	 {Similar scheme proposed in Elgammal00eccv: RGB color
                  space is separeted to brightness and chromaticity. A
                  pixel is judged as foreground if it has similar
                  chromaticity but lower brightness than those the
                  same pixel in the background},
}

@InProceedings{Horswill92,
  author =	 {I. Horswill},
  title =	 {Polly: a vision-based artificial agent},
  crossref =	 {_AAAI92},
  pages =	 {824-829},
}

@Article{Hou78,
  author =	 {H.H.~Hou and H.C.~A.s},
  title =	 {Cubic Splines for Image Interpolation and Digital
                  Filtering},
  journal =	 ASSP,
  year =	 1978,
  volume =	 26,
  number =	 6,
  pages =	 {508--517}
}

@inproceedings{Howard01iros,
  author =	 "A. Howard and M.J. Matari\'{c} and G.S. Sukhatme",
  fullauthor =	 "Andrew Howard and Maja J. Matari\'{c} and Gaurav
                  S. Sukhatme",
  title =	 "Relaxation on a mesh: a formalism for generalized
                  localization",
  booktitle =	 IROS,
  pages =	 "1055 - 1060",
  address =	 "Wailea, Hawaii",
  month =	 "Oct",
  year =	 2001,
}

@InProceedings{Howard01iros2,
  author =	 {A. Howard H. Seraji and E. Tunstel},
  fullauthor =	 {Ayanna Howard, Homayoun Seraji, and Edward Tunstel},
  title =	 {A Rule-Based Fuzzy Traversability Index for Mobile
                  Robot Navigation},
  booktitle =	 ICRA,
  year =	 2001,
  pages =	 {3067-3071}
}

@InProceedings{Howard02iros,
  author =	 {A. Howard and M.J. Matari\'{c} and G.S. Sukhatme},
  fullauthor =	 {Andrew Howard and Maja J. Matari\'{c} and Gaurav
                  S. Sukhatme},
  title =	 {Localization for Mobile Robot Teams Using Maximum
                  Likelihood Estimation},
  booktitle =	 IROS,
  pages =	 "434-459",
  address =	 "Lausanne, Switzerland",
  month =	 "Oct",
  year =	 2002,
  url =
                  "http://cres.usc.edu/cgi-bin/print_pub_details.pl?pubid=50"
}

@inproceedings{Howard02iros2,
  author =	 "Andrew Howard and Maja J. Matari\'{c} and Gaurav
                  S. Sukhatme",
  title =	 "An Incremental Deployment Algorithm for Mobile Robot
                  Teams",
  booktitle =	 IROS,
  pages =	 "2849-2854",
  address =	 "Lausanne, Switzerland",
  month =	 "Oct",
  year =	 2002,
  Abstract =	 {This paper describes an algorithm for deploying the
                  members of a mobile robot team into an unknown
                  environment. The algorithm deploys robots
                  one-at-a-time, with each robot making use of
                  information gathered by the previous robots to
                  determine the next deployment location. The
                  deployment pattern is designed to maximize the area
                  covered by the robots's sensors, while
                  simultaneously ensuring that the robots maintain
                  line-of-sight contact with one another. This paper
                  describes the basic algorithm and presents results
                  obtained from a series of experiments conducted
                  using both real and simulated robots.},
  r-Burgard05tro ={Recently Howard et al. [this] presented an
                  incremental deployment approach that is similar to
                  the technique described here. Whereas their approach
                  explicitly deals with obstructions, i.e., situations
                  in which the path of one robot is blocked by
                  another, they do not consider the problem of limited
                  communication.},
}

@incollection{Howard03er,
  author =	 {A. Howard and M.J. Matari\'{c} and G.S. Sukhatme},
  fullauthor =	 {Andrew Howard and Maja J. Matari\'{c} and Gaurav
                  S. Sukhatme},
  title =	 "Localization for Mobile Robot Teams: A Distributed
                  {MLE} Approach",
  booktitle =	 "Experimental Robotics VIII",
  editor =	 "Bruno Siciliano and Paulo Dario",
  publisher =	 "Springer-Verlag",
  series =	 "Advanced Robotics Series",
  pages =	 "146--155",
  year =	 "2003",
}

@inproceedings{Howard04icra,
  author =	 "Andrew Howard",
  title =	 "Multi-Robot Mapping using Manifold Representations",
  booktitle =	 "IEEE International Conference on Robotics and
                  Automation",
  pages =	 "4198--4203",
  address =	 "New Orleans, Louisiana",
  month =	 "Apr",
  year =	 "2004",
}

@inproceedings{Howard04iser,
  author =	 "A. Howard and L.E. Parker and G.S. Sukhatme",
  fullauthor =	 "Andrew Howard and Lynne E. Parker and Gaurav
                  S. Sukhatme",
  title =	 "The SDR Experience: Experiments with a Large-Scale
                  Heterogenous Mobile Robot Team",
  booktitle =	 "9th International Symposium on Experimental Robotics
                  2004",
  address =	 "Singapore",
  month =	 "Jun",
  year =	 2004,
  Abstract =	 "This paper reports on experiments conducted as part
                  of the DARPA SDR (Software for Distributed Robotics)
                  program. The core challenge for this program is to
                  develop a system capable of carrying out
                  'locate-and-protect' missions: the system must be
                  able to deploy a large number of robots into an
                  unexplored building, map the building interior,
                  locate a valued object, detect and track intruders,
                  and transmit all of the above information to a
                  remote observer/operator. To satisfy these
                  requirements, we have developed a large
                  heterogeneous robot team consisting of approximately
                  80 robots. This paper sketches the key technical
                  elements of this system, and presents selected
                  results from externally supervised experiments
                  conducted in a 600 m2 indoor environment.",
  r-Fox06ieee =	 {To estimate relative locations, Howard and
                  colleagues rely on the robots' ability to detect
                  each other [this]. Here, all robots explore
                  independently of each other until one coincidentally
                  detects another robot. The robots use such
                  detections to determine their relative location,
                  based on which they combine their maps. While such
                  an approach scales well in the number of robots, it
                  can result in inefcient exploration, since it can
                  take arbitrarily long until robots coincidentally
                  detect each other.}
}

@InProceedings{Howard04uai,
  author =	 {A. Howard and T. Jebara},
  title =	 {Dynamical Systems Trees},
  crossref =	 {_UAI04},
  pages =	 {260-267},
}

@article{Howard06ieee,
  author =	 "Andrew Howard and Gaurav S. Sukhatme and Maja
                  J. Matari\'{c}",
  title =	 "Multi-Robot Mapping using Manifold Representations",
  journal =	 "Proceedings of the IEEE - Special Issue on
                  Multi-robot Systems",
  volume =	 94,
  number =	 9,
  pages =	 "1360 - 1369",
  month =	 "Jul",
  year =	 2006,
  abstract =	 {This paper describes a novel representation for
                  two-dimensional maps, and shows how this
                  representation may be applied to the problem of
                  multirobot simultaneous localization and mapping. We
                  are inspired by the notion of a manifold, which
                  takes maps out of the two-dimensional plane and onto
                  a surface embedded in a higher-dimensional
                  space. The key advantage of the manifold
                  representation is selfconsistency: when closing
                  loops, manifold maps do not suffer from the "cross
                  over" problem exhibited in planar maps. This
                  self-consistency, in turn, facilitates a number of
                  important capabilities, including autonomous
                  exploration, search, and retro-traverse. It also
                  supports a very robust form of loop closure, in
                  which pairs of robots act collectively to confirm or
                  reject possible correspondence points. In this
                  paper, we develop the basic formalism of the
                  manifold representation, show how this may be
                  applied to the multirobot simultaneous localization
                  and mapping problem, and present experimental
                  results obtained from teams of up to four robots in
                  environments ranging in size from 400 to 900 m2.},
  c-dellaert =	 {},
}

@InProceedings{Huang03,
  author =	 {Kun Huang, Wei Hong and Yi Ma},
  title =	 {Symmetry-Based Photoediting},
  booktitle =	 "Proceedings of the IEEE 1st International Workshop
                  on Higher-Level Knowledge in {3D} Modeling and
                  Motion Analysis",
  publisher =	 "IEEE Computer Society",
  address =	 "Nice, France",
  isbn =	 "0-7695-2049-9",
  year =	 2003
}

@InProceedings{Huang08icra,
  fullauthor =	 {Shoudong Huang and Zhan Wang and Gamini Dissanayake},
  author =	 {S. Huang and Z. Wang and G. Dissanayake},
  title =	 {Exact state and covariance sub-matrix recovery for
                  submap based sparse EIF SLAM algorithm},
  pages =	 {1868-1873},
  month =	 {May},
  year =	 2008,
  abstract =	 {This paper provides a novel state vector and
                  covariance sub-matrix recovery algorithm for a
                  recently developed submap based exactly sparse
                  Extended Information Filter (EIF) SLAM algorithm --
                  Sparse Local Submap Joining Filter (SLSJF). The
                  algorithm achieves exact recovery instead of
                  approximate recovery. The recovery algorithm is very
                  efficient because of an incremental Cholesky
                  factorization approach and a natural reordering of
                  the global state vector. Simulation results show
                  that the computation cost of the SLSJF is much lower
                  as compared with the sequential map joining
                  algorithm using Extended Kalman Filter (EKF). The
                  SLSJF with the proposed recovery algorithm is also
                  successfully applied to the Victoria Park data set.},
}

@Article{Huang84,
  author =	 {T.S.~Huang and R.~Tsai},
  title =	 {Multi-Frame Image Restoration and Registration},
  journal =	 {Advances in Computer Vision and Image Processing},
  year =	 1984,
  volume =	 1,
  pages =	 {317--339}
}

@Article{Huang89,
  author =	 {Huang, T.S. and Lee, C.H.},
  title =	 {Motion and structure from orthographic projections},
  journal =	 PAMI,
  year =	 1989,
  pages =	 {536--540},
  month =	 {may}
}

@InProceedings{Huang97,
  author =	 "T. Huang and S. Russell",
  title =	 "Object identification in a {B}ayesian context",
  booktitle =	 IJCAI,
  year =	 1997,
  month =	 "August",
  address =	 "Nagoya, Japan"
}

@Article{Huang98,
  author =	 "T. Huang and S. Russell",
  title =	 "Object identification: {A} {B}ayesian analysis with
                  application to traffic surveillance",
  journal =	 "Artificial Intelligence",
  year =	 1998,
  volume =	 103,
  pages =	 "1--17",
}

@Article{HuangJ99,
  author =	 {Huang, J. and Supaongprapa, T. and Terakura, I. and
                  Wang, F. and Ohnishi, I. and Sugie, N.},
  title =	 {A Model Based Sound Localization System and Its
                  Application to Robot Navigation"},
  journal =	 RAS,
  year =	 1999,
  volume =	 27,
  pages =	 {199-209},
}

@Book{Huber81,
  author =	 {P. Huber},
  title =	 {Robust Statistics},
  publisher =	 Wiley,
  year =	 1981,
}

@Article{Huber85,
  author =	 {P.J. Huber},
  title =	 {Projection pursuit},
  journal =	 {The Annals of Statistics},
  year =	 1985,
  volume =	 13,
  number =	 2,
  pages =	 {435--475},
}

@InProceedings{Huber95icra,
  title =	 {Using stereo vision to pursue moving agents with a
                  mobile robot},
  author =	 {Huber, E. and Kortenkamp, D.},
  booktitle =	 {Robotics and Automation, 1995. Proceedings., 1995
                  IEEE International Conference on},
  year =	 1995,
  month =	 {May},
  volume =	 3,
  pages =	 {2340--2346},
  abstract =	 {To interact effectively with humans, mobile robots
                  will need certain skills. One particularly important
                  skill is the ability to pursue moving agents. To do
                  this, the robot needs a robust visual tracking
                  algorithm and an effective obstacle avoidance
                  algorithm, plus a means of integrating these two
                  behaviors in a seamless manner. In this paper, we
                  introduce the proximity space method as a means for
                  performing real-time, behavior-based control of
                  visual gaze. We then show how this method is
                  integrated with robot motion using an intelligent
                  control architecture that can automatically
                  reconfigure the robot's behaviors in response to
                  environmental changes. The resulting implementation
                  pursues people and other robots around our
                  laboratory for extended periods of time},
  r-Davison98thesis ={At NASA, \citet{Huber95icra} implemented a
                  behaviour-based active vision approach which enab1ed
                  a robot to track and follow a moving target (usually
                  a person). Correllation-based tracking was triggered
                  after a period of active searching for movement, and
                  extra vision modules helped the tracking to be
                  stable. The system was not truly an active vision
                  navigation system however since sonar sensors were
                  used for obstac1e detection and path phnning.},
  c-dellaert =	 {As Davison says, active vision part restricted to
                  person tracking.}
}

@article{Hue02a,
  Author =	 {Hue, C. and Le Cadre, J.-P. and Perez, P.},
  Title =	 {Sequential Monte Carlo methods for multiple target
                  tracking and data fusion},
  Journal =	 SP,
  Volume =	 {50},
  Number =	 {2},
  Pages =	 {309--325},
  Month =	 {February},
  Year =	 {2002}
}

@article{Hue02d,
  Author =	 {Hue, C. and Le Cadre, J.-P. and Perez, P.},
  Title =	 {Tracking multiple objects with particle filtering},
  Journal =	 AES,
  Volume =	 { 38},
  Number =	 3,
  Pages =	 {791--812},
  Month =	 {July},
  Year =	 2002
}

@article{Huebner07ar,
  journal =	 AR,
  year =	 2007,
  volume =	 23,
  pages =	 {183--196},
  title =	 {Metric embedding of view-graphs: A vision and
                  odometry-based approach to cognitive mapping},
  author =	 {W. H\"{u}bner and H.A. Mallot},
  fullauthor =	 {Wolfgang H\"{u}bner and Hanspeter A. Mallot},
  abstract =	 {Most recent robotic systems, capable of exploring
                  unknown environments, use topological structures
                  (graphs) as a spatial representation. Localization
                  can be done by deriving an estimate of the global
                  pose from landmark information. In this case
                  navigation is tightly coupled to metric knowledge,
                  and hence the derived control method is mainly
                  pose-based. Alternative to continuous metric
                  localization, it is also possible to base
                  localization methods on weaker constraints, e.g. the
                  similarity between images capturing the appearance
                  of places or landmarks. In this case navigation can
                  be controlled by a homing algorithm. Similarity
                  based localization can be scaled to continuous
                  metric localization by adding additional
                  constraints, such as alignment of depth
                  estimates. We present a method to scale a similarity
                  based navigation system (the view-graph-model) to
                  continuous metric localization. Instead of changing
                  the landmark model, we embed the graph into the
                  three dimensional pose space. Therefore,
                  recalibration of the path integrator is only
                  possible at discrete locations in the
                  environment. The navigation behavior of the robot is
                  controlled by a homing algorithm which combines
                  three local navigation capabilities, obstacle
                  avoidance, path integration, and scene based
                  homing. This homing scheme allows automated
                  adaptation to the environment. It is further used to
                  compensate for path integration errors, and
                  therefore allows to derive globally consistent pose
                  estimates based on ?eak?metric knowledge,
                  i.e. knowledge solely derived from odometry. The
                  system performance is tested with a robotic setup
                  and with a simulated agent which explores a large,
                  open, and cluttered environment.},
  quotes =	 {In the following we extend the view graph model from
                  topological information to survey knowledge by
                  embedding the graph into the three dimensional pose
                  space.},
  c-dellaert =	 {View graph + Lu and Milios. Same small town from 10
                  years back. Sigh. But, pretty cool, large graphs.},
}

@InProceedings{Huertas05,
  Author =	 {A. Huertas and L. Matthies and A. Rankin},
  fullauthor =	 {Andres Huertas, Larry Matthies, Arturo Rankin},
  title =	 {Stereo-Based Tree Traversability Analysis for
                  Autonomous Off-Road Navigation},
  booktitle =	 {IEEE Work-shop on Applications of Computer Vision},
  year =	 {2005}
}

@Article{Hunter83,
  author =	 {J.S Hunter and J.C.Hung},
  title =	 {Development of low-cost multifunction sensors for
                  lightweight fire and forget antitank weapon system},
  journal =	 {IEEE Trans. Industrial Electronics},
  year =	 1983,
  volume =	 {IE-30},
  number =	 1,
  pages =	 {7-10}
}

@Article{Hutchins95,
  author =	 "E. Hutchins",
  title =	 "How the cockpit remembers its speed",
  journal =	 "Cognitive Science",
  year =	 1995,
  volume =	 19,
  pages =	 "265-288",
}

@Article{Hutchinson96,
  author =	 {S. Hutchinson and G. Hager and P. Corke},
  title =	 {A Tutorial on Visual Servo Control},
  journal =	 TRA,
  year =	 1996,
  volume =	 12,
  number =	 5,
  pages =	 {651-671},
}

@article{Huttenlocher90,
  AUTHOR =	 "Huttenlocher, D.P. and Ullman, S.",
  TITLE =	 "Recognizing Solid Objects by Alignment with an
                  Image",
  JOURNAL =	 IJCV,
  VOLUME =	 5,
  YEAR =	 1990,
  NUMBER =	 2,
  MONTH =	 "November",
  PAGES =	 "195-212"
}

@Article{Huttenlocher93,
  author =	 {Huttenlocher, D.P. and Klanderman, G.A. and
                  Rucklidge, W.J.},
  title =	 {Comparing images using the {Hausdorff} distance},
  journal =	 PAMI,
  year =	 1993,
  volume =	 15,
  number =	 9,
  pages =	 {850--863},
  month =	 {September},
}

@article        {IRANI96B,
  key =		 "Irani",
  author =	 "Irani, M. and Anandan, P. and Bergen, J. and Kumar,
                  R. and Hsu, S.",
  title =	 "Efficient Representations of Video Sequences and
                  Their Applications",
  journal =	 "Signal Processing: Image Communication",
  volume =	 8,
  year =	 1996,
  pages =	 "327-351",
  keywords =	 "video mosaics, image compression",
  perused =	 "no (cite in Siggraph'97 face paper reviewer 5)",
  bibdate =	 "Wed 01/14/1998 9:16a"
}

@Article{Iba01,
  author =	 {Y. Iba},
  title =	 {Extended Ensemble {M}onte {C}arlo},
  journal =	 {International Journal of Modern Physics},
  year =	 2001,
  volume =	 {C12},
  pages =	 {623-656},
}

@InProceedings{Ihler04ipsn,
  author =	 {A. T. Ihler and J. W. {Fisher~III} and R. L. Moses
                  and A. S. Willsky},
  year =	 2004,
  title =	 {Nonparametric Belief Propagation for
                  Self-Calibration in Sensor Networks},
  booktitle =	 IPSN,
  abstract =	 {Automatic self-calibration of ad-hoc sensor networks
                  is a critical need for their use in military or
                  civilian applications. In general, self-calibration
                  involves the combination of absolute location
                  information (e.g. GPS) with relative calibration
                  information (e.g. time delay or received signal
                  strength between sensors) over regions of the
                  network. Furthermore, it is generally desirable to
                  distribute the computational burden across the
                  network and minimize the amount of inter-sensor
                  communication. We demonstrate that the information
                  used for sensor calibration is fundamentally local
                  with regard to the network topology and use this
                  observation to reformulate the problem within a
                  graphical model framework. We then demonstrate the
                  utility of nonparametric belief propagation (NBP), a
                  recent generalization of particle filtering, for
                  both estimating sensor locations and representing
                  location uncertainties. NBP has the advantage that
                  it is easily implemented in a distributed fashion,
                  admits a wide variety of statistical models, and can
                  represent multi-modal uncertainty. We illustrate the
                  performance of NBP on several example networks while
                  comparing to a previously published nonlinear least
                  squares method.},
  c-Upcroft06iser ={Non-Gaussian distributed algorithms for sensor
                  calibration have previously been developed by Ihler
                  et al. Correlated estimation errors due to common
                  information communicated between nodes in the past
                  (also known as data incest) [Bar-Shalom] were not
                  considered. Accounting for data incest in
                  decentralised architectures is the key problem in
                  ensuring mathematically consistent and convergent
                  solutions.},
  c-dellaert =	 {pretty cool, auto-localization of nodes in network}
}

@Article{Ihler05jsac,
  author =	 {A. T. Ihler and J. W. Fisher and R. L. Moses and
                  A. S. Willsky},
  fullauthor =	 {Alexander T. Ihler and John W. Fisher and Randolph
                  L. Moses and Alan S. Willsky},
  title =	 {Nonparametric Belief Propagation for
                  Self-Localization of Sensor Networks},
  journal =	 JSAC,
  year =	 2005,
  month =	 "April",
  volume =	 23,
  number =	 4,
  pages =	 {809-819},
}

@inproceedings{Intanagonwiwat00mobicom,
  author =	 {C. Intanagonwiwat and R. Govindan and D. Estrin},
  title =	 {Directed diffusion: a scalable and robust
                  communication paradigm for sensor networks},
  booktitle =	 {MobiCom '00: Proc. 6th Ann. Intl. Conf. on Mobile
                  Computing and Networking},
  year =	 2000,
  pages =	 {56--67},
  location =	 {Boston, Massachusetts, United States},
  doi =		 {http://doi.acm.org/10.1145/345910.345920},
  publisher =	 {ACM Press},
  address =	 {New York, NY, USA},
  abstract =	 {Advances in processor, memory and radio technology
                  will enable small and cheap nodes capable of
                  sensing, communication and computation. Networks of
                  such nodes can coordinate to perform distributed
                  sensing of environmental phenomena. In this paper,
                  we explore the directed diffusion paradigm for such
                  coordination. Directed diffusion is datacentric in
                  that all communication is for named data. All nodes
                  in a directed diffusion-based network are
                  application-aware. This enables diffusion to achieve
                  energy savings by selecting empirically good paths
                  and by caching and processing data in-network. We
                  explore and evaluate the use of directed diffusion
                  for a simple remote-surveillance sensor network.},
  r-Zhao03ieee = {Directed diffusion routes sensor data in a network
                  to minimize communication distance between data
                  sources and data sinks [this]. This is an
                  interesting way of organizing a network to allow
                  publish-and-subscribe to occur at a very
                  fine-grained level.},
}

@misc{Interagency,
  author =	 {Interagency GPS Executive Board},
  title =	 {{E}nd of {S}elective {A}vailability {D}eclaration
                  {W}ebsite},
  month =	 {May 1},
  year =	 2000,
  url =		 {http://www.igeb.gov/sa/}
}

@Article{Intille01cviu,
  author =	 {S.S. Intille and A.F. Bobick},
  fullauthor =	 {Stephen S. Intille and Aaron F. Bobick},
  title =	 {{Recognizing Planned, Multiperson Action}},
  journal =	 CVIU,
  year =	 2001,
  month =	 "March",
  volume =	 81,
  number =	 3,
  pages =	 {414-445},
}

@InProceedings{Irani90,
  author =	 {M. Irani and S. Peleg},
  title =	 {Super Resolution From Image Sequences},
  booktitle =	 ICIP,
  year =	 1990,
  pages =	 {115-120},
}

@article{Irani91,
  author =	 {M. Irani and S. Peleg},
  TITLE =	 "Improving Resolution by Image Registration",
  JOURNAL =	 GMIP,
  VOLUME =	 53,
  YEAR =	 1991,
  PAGES =	 "231-239"
}

@inproceedings{Irani92,
  author =	 {M. Irani and S. Peleg},
  TITLE =	 "Image Sequence Enhancement Using Multiple Motions
                  Analysis",
  BOOKTITLE =	 CVPR,
  YEAR =	 1992,
  PAGES =	 "216-222"
}

@article{Irani93,
  author =	 {M. Irani and S. Peleg},
  TITLE =	 "Motion Analysis for Image Enhancement: Resolution,
                  Occlusion, and Transparency",
  JOURNAL =	 JVCIR,
  VOLUME =	 4,
  number =	 4,
  YEAR =	 1993,
  PAGES =	 "324-335"
}

@inproceedings{Irani94,
  AUTHOR =	 "Irani, M. and Rousso, B. and Peleg, S.",
  TITLE =	 "Recovery of Ego-Motion Using Image Stabilization",
  BOOKTITLE =	 CVPR,
  YEAR =	 1994,
  PAGES =	 "454-460"
}

@inproceedings{Irani99,
  AUTHOR =	 "Irani, M.",
  TITLE =	 "Multi-Frame Optical Flow Estimation using Subspace
                  Constraints",
  BOOKTITLE =	 ICCV,
  YEAR =	 1999,
  PAGES =	 "626-633"
}

@inproceedings{Irani99va,
  author =	 {M. Irani and P. Anandan},
  title =	 {About Direct Methods},
  pages =	 {267--277},
  booktitle =	 {Vision Algorithms: Theory and Practice},
  editor =	 {B. Triggs and A. Zisserman and R. Szeliski},
  publisher =	 {Springer-Verlag},
  series =	 {LNCS},
  number =	 1883,
  address =	 {Corfu, Greece},
  month =	 sep,
  year =	 1999
}

@InProceedings{Isard01,
  author =	 {M. Isard and J. MacCormick},
  title =	 {{BraMBLe}: A {Bayesian} Multiple-Blob Tracker},
  booktitle =	 ICCV,
  pages =	 {34-41},
  year =	 2001,
}

@TechReport{Isard05,
  author =	 "M. Isard and J. MacCormick",
  title =	 "Dense Motion and Disparity Estimation via Loopy
                  Belief Propagation",
  institution =	 "Microsoft Research",
  year =	 2005,
  number =	 "MSR-TR-2005-163"
}

@InProceedings{Isard96,
  author =	 {M. Isard and A. Blake},
  title =	 {Contour tracking by stochastic propagation of
                  conditional density},
  booktitle =	 ECCV,
  pages =	 {343-356},
  year =	 1996,
}

@Article{Isard98,
  author =	 "M. Isard and A. Blake",
  title =	 "Condensation -- conditional density propagation for
                  visual tracking",
  journal =	 IJCV,
  year =	 1998,
  volume =	 29,
  number =	 1,
  pages =	 "5-28",
}

@InProceedings{Isard98b,
  author =	 {M. Isard and A. Blake},
  title =	 {A mixed-state {C}ondensation tracker with automatic
                  model-switching},
  booktitle =	 ICCV,
  year =	 1998,
}

@article{Ishiguro03,
  author =	 {H. Ishiguro and K. C. Ng and R. Capella and
                  M. M. Trivedi},
  title =	 {Omnidirectional image-based modeling: three
                  approaches to approximated plenoptic
                  representations},
  journal =	 {Machine Vision and Applications},
  volume =	 14,
  number =	 2,
  year =	 2003,
  pages =	 {94--102}
}

@Article{Ishiguro92,
  author =	 {H. Ishiguro and M. Yamamoto and S. Tsuji},
  title =	 {Omnidirectional stereo},
  journal =	 PAMI,
  year =	 1992,
  volume =	 14,
  number =	 {257-262},
}

@InProceedings{Ishiguro93icra,
  author =	 {Ishiguro, H. and Ueda, K. and Tsuji, S.},
  title =	 {Omnidirectional visual information for navigating a
                  mobile robot},
  booktitle =	 ICRA,
  pages =	 {799--804},
  year =	 1993,
}

@Inproceedings{Ishiguro96,
  author =	 {H. Ishiguro and S. Tsuji},
  title =	 {Image-Based Memory of Environment},
  booktitle =	 IROS,
  year =	 1996,
}

@article{Ishwaran03ss,
  author =	 {H. Ishwaran and L. F. James},
  title =	 {Generalized weighted Chinese restaurant processes
                  for species sampling mixture models},
  booktitle =	 {Statistica Sinica},
  volume =	 13,
  pages =	 {1211-1235}
}

@Inproceedings{Itti05cvpr,
  author =	 {L. Itti and P. Baldi},
  title =	 {A Principled Approach to Detecting Surprising Events
                  in Video},
  booktitle =	 CVPR,
  pages =	 {631-637},
  year =	 2005,
}

@inproceedings{Itti06nips,
  title =	 {Bayesian Surprise Attracts Human Attention},
  author =	 {L. Itti and P. Baldi},
  year =	 2006,
  publisher =	 {MIT Press},
  address =	 {Cambridge, MA},
  booktitle =	 NIPS,
  pages =	 {1-8},
  file =
                  {http://ilab.usc.edu/publications/doc/Itti_Baldi06nips.pdf},
}

@article{Ivanov00,
  author =	 "Y.A. Ivanov and A.F. Bobick",
  title =	 "Recognition of visual activities and interactions by
                  stochastic parsing",
  journal =	 "PAMI",
  volume =	 22,
  number =	 8,
  pages =	 "852-872",
  month =	 aug,
  year =	 2000,
}

@article{Iyengar03imm,
  Author =	 {Iyengar, S. S. and Sastry, S. and Balakrishnan, N.},
  Journal =	 {Instrumentation \& Measurement Magazine, IEEE},
  Number =	 4,
  Pages =	 {35--41},
  Title =	 {Foundations of data fusion for automation},
  Ty =		 {JOUR},
  Volume =	 6,
  Year =	 2003,
  Abstract =	 {This article discusses about the developing
                  paradigms of data for sensor-actuator networks that
                  perform engineering tasks. We provide a new
                  foundation for data fusion based on two concepts: a
                  conceptual framework and the goal-seeking
                  paradigm. The conceptual framework emphasizes the
                  dominant structures in the system. The goal-seeking
                  paradigm is a mechanism for representing system
                  evolution that explicitly manages uncertainty. The
                  goal-seeking formulation for data fusion helps to
                  distinguish between subjective decisions that can be
                  executed by computers. These notions are useful for
                  critical tasks, such as security management in
                  large-scale distributed systems. Investigations in
                  this area, and further refinement of the
                  goal-seeking formulation for instrumentation and
                  measurement applications, are likely to future
                  systems that facilitate holistic user decision
                  making.},
  c-dellaert =	 {Weakly relevant. Focused on automation systems. Not
                  that Sastry !!},
}

@inproceedings{Jacobs97,
  AUTHOR =	 "Jacobs, D.W.",
  TITLE =	 "Linear Fitting with Missing Data: Applications to
                  Structure from Motion and to Characterizing
                  Intensity Images",
  BOOKTITLE =	 CVPR,
  YEAR =	 1997,
  PAGES =	 "206-212"
}

@Article{Jacobson98,
  author =	 {Jacobson, R.D.},
  year =	 1998,
  title =	 {Cognitive mapping without sight: Four preliminary
                  studies of spatial learning},
  journal =	 {Journal of Environmental Psychology},
  volume =	 18,
  pages =	 {289-305},
}

@misc{Jacobson99,
  author =	 "Dan Jacobson",
  title =	 "Haptic {S}oundscapes {P}ublication",
  year =	 1999,
  url =
                  "http://garnet.acns.fsu.edu/~djacobso/haptic/hapticmain.html"
}

@Article{Jacquemod92,
  author =	 {G. Jacquemod and C. Odet and R. Gouette},
  title =	 {Image resolution enhancement using subpixel camera
                  displacement},
  journal =	 SP,
  year =	 1992,
  volume =	 26,
  pages =	 {139-146},
}

@TechReport{Jacyna98,
  author =	 {G.M. Jacyna and S.W. Pawlukiewicz},
  title =	 {Minimum origin uncertainty state estimation
                  ({MOUSE}) algorithm performance bounds},
  institution =	 {MITRE},
  year =	 1998,
  month =	 {March},
}

@InProceedings{Jaillon94,
  author =	 {P. Jaillon and A. Montanvert},
  title =	 {Image mosaicking applied to three-dimensional
                  surfaces},
  booktitle =	 ICPR,
  pages =	 {253-257},
  year =	 1994,
}

@article{Jain04jcgs,
  author =	 "S. Jain and R. Neal",
  title =	 {A Split-Merge {Markov} Chain {Monte} {Carlo}
                  Procedure for the Dirichlet Process Mixture Model},
  journal =	 { Journal of Computational and Graphical Statistics},
  month =	 {March},
  year =	 2004,
  volume =	 13,
  number =	 1,
  pages =	 {158-182}
}

@book{Janevski03book,
  author =	 "Toni Janevski",
  title =	 {{Traffic Analysis and Design of Wireless IP
                  Networks}},
  publisher =	 {Artech House},
}

@InProceedings{Jarvis88issr,
  author =	 {R.A. Jarvis and J.C. Byrne},
  title =	 {An automated guided vehicle with map building and
                  path finding capabilities},
  booktitle =	 {4th Intl. Symp. on Robotics Research},
  pages =	 {497-504},
  year =	 1998,
}

@InProceedings{Javed02motion,
  author =	 {O. Javed and K. Shafique and M. Shah},
  title =	 {A Hierarchical Approach to Robust Background
                  Subtraction using Color and Gradient Information},
  booktitle =	 {Workshop on Motion and Video Computing},
  year =	 2002,
  abstract =	 {We present a background subtraction method that uses
                  multiple cues to robustly detect objects in adverse
                  conditions. The algorithm consists of three distinct
                  levels i.e pixel level, region level and frame
                  level. At the pixel level, statistical models of
                  gradients and color are separately used to classify
                  each pixel as belonging to background or
                  foreground. In region level, foreground pixels
                  obtained from the color based subtraction are
                  grouped into regions and gradient based sub-
                  traction is then used to make inferences about the
                  validity of these regions. Pixel based models are
                  updated based on decisions made at the region
                  level. Finally frame level analysis is performed to
                  detect global illumination changes. Our method
                  provides the solution to some of the common prob-
                  lems that are not addressed by most background
                  subtraction algorithms such as quick illumination
                  changes, repositioning of static background objects,
                  and initialization of background model with moving
                  objects present in the scene.},
  c-houdan =	 {good idea that uses gradients to validate color
                  background segmentation results, since foreground
                  objects always have edges on its boundaries},
}

@book{Jazwinsky70,
  author =	 "A. Jazwinsky",
  title =	 "Stochastic Processes and Filtering Theory",
  publisher =	 "Academic Press",
  address =	 "New York",
  year =	 "1970"
}

@Article{Jeffress48,
  author =	 "L.A. Jeffress",
  title =	 "A place theory of sound localization",
  journal =	 {Journal of Comp. Physiol. Psychol.},
  volume =	 41,
  pages =	 {34--39},
  year =	 1948,
}

@article{Jelinek01pami,
  Abstract =	 {This paper deals with the problem of recovering the
                  dimensions of an object and its pose from a single
                  image acquired with a camera of unknown focal
                  length. It is assumed that the object in question
                  can be modeled as a polyhedron where the coordinates
                  of the vertices can be expressed as a linear
                  function of a dimension vector. The reconstruction
                  program takes as input, a set of correspondences
                  between features in the model and features in the
                  image. From this information, the program determines
                  an appropriate projection model for the camera, the
                  dimensions of the object, its pose relative to the
                  camera and, in the case of perspective projection,
                  the focal length of the camera. This paper describes
                  how the reconstruction problem can be framed as an
                  optimization over a compact set with low dimension
                  (no more than four). This optimization problem can
                  be solved efficiently by coupling standard nonlinear
                  optimization techniques with a multistart
                  method. The result is an efficient, reliable
                  solution system that does not require initial
                  estimates for any of the parameters being estimated},
  Author =	 {Jelinek, D. and Taylor, C. J.},
  Journal =	 PAMI,
  Number =	 7,
  Pages =	 {767--773},
  Title =	 {Reconstruction of linearly parameterized models from
                  single images with a camera of unknown focal length},
  Volume =	 23,
  Year =	 2001,
  r-Kosecka05cviu ={Camera pose recovery from a single view can be
                  solved very efficiently.},
}

@inproceedings{Jelinek02eccv,
  author =	 {D. Jelinek and C. J. Taylor},
  fullauthor =	 {David Jelinek and Camillo J. Taylor},
  title =	 {View Synthesis with Occlusion Reasoning Using
                  Quasi-Sparse Feature Correspondences},
  booktitle =	 ECCV,
  year =	 2002,
  isbn =	 {3-540-43744-4},
  pages =	 {463--478},
}

@InProceedings{Jennings99icra,
  author =	 {Jennings, C. and Murray, D. and Little, J.J.},
  title =	 {Cooperative robot localization with vision-based
                  mapping},
  booktitle =	 ICRA,
  pages =	 {2659-2665},
  year =	 1999,
}

@Article{Jensen90csq,
  author =	 {F.V. Jensen and S.L. Lauritzen and K.G. Olesen},
  title =	 {Bayesian updating in causal probabilistic networks
                  by local computations},
  journal =	 {Computat. Statist. Quart.},
  year =	 1990,
  volume =	 4,
  r-Kask05ai =	 {Tree clustering schemes have been widely used for
                  constraint processing, probabilistic reasoning and
                  for graphical models in general. The most popular
                  variants are join-tree clustering algorithms, also
                  called junction-trees. The schemes vary somewhat in
                  their graph definitions as well as in the way
                  tree-decompositions are processed \cite{Maier83book,
                  Dechter89ai, Jensen90csq, Lauritzen97amai,
                  Shenoy96uai, Gottlob00ai}. However, they all involve
                  a decomposition of a hyper-graph into a hyper-tree.},
}

@INPROCEEDINGS{Jensen94uai,
  AUTHOR =	 "F. Jensen and F. Jensen",
  FULLAUTHOR =	 "Finn Jensen and Frank Jensen",
  TITLE =	 "Optimal Junction Trees",
  crossref =	 {_UAI94},
  PAGES =	 "360-36",
  abstract =	 {The paper deals with updating of beliefs in
                  networks. First it is shown that any exact
                  propagation scheme must contain a triangulation of
                  the network, and therefore essentially is a message
                  passing scheme over a junction tree. In the second
                  part of the paper we give a simple algorithm for
                  constructing an optimal junction tree from a
                  triangulated network.},
  c-dellaert =	 {\cite{Jensen94uai} ascribes the junction tree
                  propagation method to \citet{Luritzen88jrssb} and
                  \citet{Jensen90csq}. Also realizes minimum
                  triangulation is NP-complete as stated by
                  \cite{Arnborg87siam}}
}

@InProceedings{Jensfelt02slam,
  author =	 {P. Jensfelt and H.I. Christensen and G. Zunino},
  title =	 {Integrated systems for Mapping and Localization},
  booktitle =	 {ICRA-02 SLAM Workshop},
  publisher =	 {IEEE},
  year =	 2002,
  editor =	 {J. Leonard and H. Durrant-Whyte},
  month =	 {May},
}

@InProceedings{Jensfelt99,
  author =	 {P. Jensfelt and S. Kristensen},
  title =	 {Active global localisation for a mobile robot using
                  multiple hypothesis tracking},
  booktitle =	 IJCAI,
  pages =	 {13-22},
  year =	 1999,
}

@InProceedings{Jepson01,
  author =	 {Allan D. Jepson and David J. Fleet and Thomas
                  F. El-Maraghi},
  title =	 {Robust Online Appearance Models for Visual Tracking},
  booktitle =	 CVPR,
  year =	 2001,
  pages =	 {415-422},
  volume =	 1,
}

@InProceedings{Jepson95,
  author =	 {W. Jepson and R. Liggett and S. Friedman},
  title =	 {An Environment for Real-time Urban Visualization},
  booktitle =	 {Proceedings of the Symposium on Interactive {3D}
                  Graphics},
  year =	 1995,
  address =	 {Monterey, California},
  month =	 {April},
}

@Article{Jerrum89,
  author =	 "M. Jerrum and A. Sinclair",
  title =	 "Approximating the permanent",
  journal =	 "SIAM Journal on Computing",
  volume =	 18,
  number =	 6,
  pages =	 "1149--1178",
  year =	 1989
}

@InCollection{Jerrum97,
  author =	 "M. Jerrum and A. Sinclair",
  title =	 "The {M}arkov chain {M}onte {C}arlo method: An
                  Approach to Approximate Counting and Integration",
  chapter =	 12,
  booktitle =	 "Approximation Algorithms for NP-hard Problems",
  publisher =	 "PWS Publishing",
  year =	 1997,
  editor =	 "D.S. Hochbaum",
  address =	 "Boston, MA",
}

@InProceedings{Jin00cvpr,
  author =	 {H. Jin and P. Favaro and S. Soatto},
  title =	 {Real-time {3-D} motion and structure from point
                  features: a front-end system for vision-based
                  control and interaction},
  crossref =	 {_CVPR00},
  volume =	 {2},
  pages =	 {778-779},
  abstract =	 {We present a system that consists of one camera
                  connected to a personal computer that can (a) select
                  and track a number of high-contrast point features
                  on a sequence of images, (b) estimate their
                  three-dimensional motion and position relative to an
                  inertial reference frame, assuming rigidity, (c)
                  handle occlusions that cause point-features to
                  disappear as well as new features to appear. The
                  system can also (d) perform partial self-calibration
                  and (e) check for consistency of the rigidity
                  assumption, although these features are not
                  implemented in the current release. All of this is
                  done automatically and in real-time (30 Hz) for
                  40-50 point features using commercial off-the-shelf
                  hardware. The system is based on an algorithm
                  presented by Chiuso et al. (2000), the properties of
                  which have been analyzed by Chiuso and Soatto
                  (2000). In particular, the algorithm is provably
                  observable, provably minimal and provably stable-
                  under suitable conditions. The core of the system,
                  consisting of C++ code ready to interface with a
                  frame grabber as well as Matlab code for
                  development, is available at
                  http://ee.wustl.edu/-soatto/research.html. We
                  demonstrate the system by showing its use as (1) an
                  ego-motion estimator, (2) an object tracker, and (3)
                  an interactive input device, all without any
                  modification of the system settings},
  c-dellaert =	 {2-page abstract of a CVPR demo, probably more detail
                  in Chiuso02pami, notable: real time at 30hz with
                  40-50 features in 2000}
}

@InProceedings{Jin01iccv,
  author =	 {H. Jin and P. Favaro and S. Soatto},
  title =	 {Real-time Feature Tracking and Outlier Rejection
                  with Changes in Illumination},
  booktitle =	 ICCV,
  year =	 2001,
  pages =	 {684-689}
}

@InProceedings{Jochem95iros,
  author =	 {T. M. Jochem and D. A. Pomerleau and C. E. Thorpe},
  fullauthor =	 {Todd M. Jochem and Dean A. Pomerleau and Charles
                  E. Thorpe},
  title =	 {Vision-based neural network road and intersection
                  detection and traversal},
  booktitle =	 IROS,
  year =	 1995,
  pages =	 {344-349}
}

@Article{Jochem96,
  author =	 "Todd Jochem and Dean Pomerleau",
  title =	 "Life in the Fast Lane",
  journal =	 "AI Magazine",
  year =	 1996,
  volume =	 17,
  number =	 2,
  pages =	 "11-50",
  month =	 "Summer",
}

@InProceedings{Jogan00,
  author =	 {M. Jogan and A. Leonardis},
  title =	 {Robust Localization Using Panoramic View-Based
                  Recognition},
  booktitle =	 ICPR,
  year =	 2000,
  pages =	 {136-- 139},
}

@book{Johnson02,
  author =	 {R. A. Johnson and D. W. Wichern},
  title =	 {Applied Multivariate Statistical Analysis, Fifth
                  Edition},
  publisher =	 {Prentice Hall},
  year =	 2002
}

@book{Johnson77,
  author =	 {N. L. Johnson and S. Kotz},
  title =	 {Urn Models and their Applications},
  publisher =	 {John Wiley and Sons},
  year =	 1977
}

@Article{Johnson96ivc,
  author =	 "N. Johnson and D. Hogg",
  fullauthor =	 "Neil Johnson and David Hogg",
  title =	 {Learning the distribution of object trajectories for
                  event recognition},
  journal =	 IVC,
  year =	 1996,
  volume =	 14,
  number =	 8,
  pages =	 "589-599",
  keywords =	 {path detection, surveillence, unsupervised activity
                  learning, activity classifiction},
  c-sangmin =	 {collect data of position and velocity. Then, use
                  competetive neural net to generate quantized code
                  books of the data. Then, again use competetive
                  neural net to learn time-stacked representation of
                  the code book sequences which is similar to
                  Bobick01pami with the trick of licking neurons. nice
                  early work. }
}

@InProceedings{Jojic00cvpr,
  author =	 {N. Jojic, N. Petrovic, B. Frey and T. S. Huang},
  fullauthor =	 {Nebojsa Jojic, Nemanja Petrovic, Brendan Frey and
                  Thomas S. Huang},
  title =	 {{Transformed Hidden Markov Models: Estimating
                  Mixture Models of Images and Inferring Spatial
                  Transformation in Video Sequences}},
  booktitle =	 CVPR,
  year =	 2000,
  c-sangmin =	 {The authors propose a generative graphical model for
                  video modeling where one foreground objects
                  undergoing appearance changes on changing
                  backgrounds (backgrounds not considered in the
                  modeling). The changing appearances are represented
                  as multiple classes of Gaussian mean images where
                  only one class is allowed per step. Then, there are
                  hidden variables in the model which capture the
                  translation/shifts of the mean images within each
                  frame. In their model, the possible motions :
                  translations are pre-defined as unknown discrete
                  variables where each variable cause permutation
                  matrix to re-order the columns and rows of the image
                  so that the model can capture moving foreground. The
                  authors capture the time-varying discretized hidden
                  appearances and translations by using HMM. The
                  authors show experimental results where they extract
                  multiple representative appearances of a single
                  foreground objects, and the ability to perform
                  tracking in the severe noise (such as black bar
                  artifacts in the image by showing the re-constructed
                  image without noise. The main un-addressed issue of
                  their approach is the missing handling of multiple
                  foreground objects, and inability to figure out
                  background model. The initialization may be
                  important, but not presented in the paper. },
}

@InProceedings{Jojic01cvpr,
  author =	 {Nebojsa Jojic and Brendan Frey},
  title =	 {{Learning Flexible Sprites in Video Layers}},
  booktitle =	 CVPR,
  year =	 2001,
  c-sangmin =	 {The authors propose a generative graphical model for
                  layered video modeling where the hidden variables
                  are (multiple)! sprite(foreground, fg) appearance,
                  fg masks, and bg which are pixelwisely
                  modeled. Multiple layers/bg modeling were not
                  addressed in Jojic00cvpr. The model is layered model
                  in that it assumes that the image is generated by
                  overlapping the bg image with the fg'son top of one
                  another with appropriate translations. The possible
                  tranlations (motions) are predefined as discrete
                  variables as in their Jojic00cvpr work. The authors
                  then solve the learning problem which involves the
                  learning of fgs/bg model+masks and motions in each
                  image through variational-EM in the maximum
                  likelihood frameowrkbecause the problem got coupled
                  severely between variables and exact EM is not
                  feasible anymore. Unlike their HMM work in
                  Jojic00cvpr, they do not have put frame ordering
                  constraints in their model and allow all the
                  translations to be equally likely. This would
                  suggest that a clever way of using such dynamic
                  constraints which is partly studied in Jojic00cvpr
                  by using HMMs as a way to have motion model can
                  improve the learning results. It is my impression
                  that this is very hard to solve the problems with
                  dynamic constraints in case of multiple layers. That
                  would be the reason why Jojic and Frey are using a
                  static model that does not consider the video
                  ordering for this work. They successfully learn the
                  fgs/bg model from the unordered images, and show fg
                  subtraction, removal of a second fg selectively from
                  the video, person appearance enhancements. One main
                  advantage of their works would be the use of mask
                  which seems to be rather unintuitive, but can
                  capture the non-rigid appearance of arbitrary
                  objects},
}

@InProceedings{Jojic06cvpr,
  author =	 {Nebojsa Jojic and John Winn and Larry Zitnick},
  title =	 {Escaping local minima through hierarchical model
                  selection:Automatic object discovery, segmentation,
                  and tracking in video},
  booktitle =	 CVPR,
  year =	 2006,
}

@book{Jolliffe86,
  author =	 {Jolliffe, I. T.},
  title =	 {Principal Component Analysis},
  year =	 1986,
  publisher =	 {Springer}
}

@Article{Jonker87comp,
  author =	 {R. Jonker and A. Volgenant},
  title =	 {A shortest augmenting path algorithm for dense and
                  sparse linear assignment problems},
  journal =	 {Computing},
  year =	 1987,
  volume =	 38,
  number =	 4,
  pages =	 {325-340},
}

@Unpublished{Jordan02book,
  author =	 {M.I. Jordan},
  title =	 {An Introduction to Probabilistic Graphical Models},
  note =	 {Unpublished Lecture Notes},
  month =	 {November},
  year =	 {2002},
}

@Article{Jordan94nc,
  author =	 {M.I. Jordan and R.A. Jacobs},
  title =	 {Hierarchical mixtures of experts and the {EM}
                  algorithm},
  journal =	 {Neural Computation},
  year =	 1994,
  volume =	 6,
  pages =	 {181-214},
}

@Article{Jordan99ml,
  author =	 "M.I. Jordan and Z. Ghahramani and T.S. Jaakkola and
                  L.K. Saul",
  title =	 "An Introduction to Variational Methods for Graphical
                  Models",
  journal =	 ML,
  year =	 1999,
  volume =	 37,
  pages =	 "183-233",
}

@ARTICLE{Judd98nature,
  author =	 {{Judd}, S.~P.~D. and {Collett}, T.~S.},
  title =	 "{Multiple stored views and landmark guidance in
                  ants}",
  journal =	 {Nature},
  volume =	 392,
  pages =	 {710-714},
  month =	 apr,
  year =	 1998,
}

@InProceedings{Julier01icra,
  author =	 {Julier, S.J. and Uhlmann, J.K.},
  title =	 {A counter example to the theory of simultaneous
                  localization and map building},
  booktitle =	 ICRA,
  pages =	 {4238-4243},
  year =	 2001,
  volume =	 4,
  abstract =	 {This paper analyzes the properties of the full
                  covariance simultaneous map building problem
                  (SLAM). We prove that, even for the special case of
                  a stationary vehicle (with no process noise) which
                  uses a range-bearing sensor and has non-zero angular
                  uncertainty, the full-covariance SLAM algorithm
                  always yields an inconsistent map. We also show,
                  through simulations, that these conclusions appear
                  to extend to a moving vehicle with process
                  noise. However, these inconsistencies only become
                  apparent after several hundred beacon updates.},
  r-DurrantWhyte06ram ={Non-linearity can be a significant problem in
                  EKF-SLAM and leads to inevitable, and sometimes
                  dramatic, inconsistency in solutions [this].},
  c-Alireza =	 {They show that: 1- It is questionable that if the
                  EKF framework is a general, robust and rigorous
                  solution to SLAM. 2- The consistency of any map
                  building algorithm cannot be fully assessed by
                  experimental results of short duration. }
}

@InProceedings{Julier01iros,
  author =	 {Julier, S.J.},
  title =	 {A sparse weight {K}alman filter approach to
                  simultaneous localisation and map building},
  booktitle =	 IROS,
  pages =	 {1251 - 1256},
  volume =	 3,
  year =	 2001
}

@InProceedings{Julier03iros,
  author =	 {Simon J. Julier and Jeffrey K. Uhlmann},
  title =	 {Using Multiple {SLAM} Algorithms},
  booktitle =	 IROS,
  year =	 2003,
}

@InProceedings{Julier97acc,
  author =	 {Julier, S.J. and Uhlmann, J.K.},
  title =	 {A non-divergent estimation algorithm in the presence
                  of unknown correlations},
  booktitle =	 ACC,
  pages =	 {2369-73},
  year =	 1997,
}

@InProceedings{JulierUhlman01iros,
  author =	 {S.J. Julier and J.K. Uhlmann},
  title =	 {Simultaneous localisation and map building using
                  split covariance intersection},
  booktitle =	 IROS,
  pages =	 {1257-62},
  year =	 2001,
  volume =	 3,
}

@InProceedings{Junejo04icpr,
  author =	 {I.N. Junejo, O. Javed, M. Shah},
  fullauthor =	 {Imran N. Junejo, Omar Javed, Mubarak Shah},
  title =	 {{Multi Feature Path Modeling for Video
                  Surveillance}},
  booktitle =	 ICIP,
  pages =	 {716-719},
  year =	 2004,
  volume =	 2,
  keywords =	 {surveillence, path detection, pedestrian analysis},
}

@InProceedings{Kaelbling96,
  author =	 "L.P. Kaelbling and A.R. Cassandra and J.A. Kurien",
  title =	 "Acting Under Uncertainty: Discrete {B}ayesian Models
                  for Mobile-Robot Navigation",
  booktitle =	 IROS,
  year =	 1996,
  c-ananth =	 { Other examples of HMM-based work include
                  [Kaelbling96][Gutierrez-Osuna96] and [Aycard97]
                  where a second order HMM is used to model the
                  environment.},
}

@Article{Kaelbling96jair,
  author =	 "L.P. Kaelbling and M.L. Littman and A.W. Moore",
  title =	 "Reinforcement Learning: A Survey",
  journal =	 JAIR,
  year =	 1996,
  volume =	 4,
  pages =	 "237-285",
}

@InProceedings{Kaess03hlk,
  author =	 {M. Kaess and F. Dellaert},
  fullauthor =	 {Michael Kaess and Frank Dellaert},
  title =	 {Reconstruction of Objects with Jagged Edges through
                  {R}ao-{B}lackwellized Fitting of Piecewise Smooth
                  Subdivision Curves},
  booktitle =	 {Proceedings of the IEEE 1st International Workshop
                  on Higher-Level Knowledge in {3D} Modeling and
                  Motion Analysis},
  pages =	 {39-47},
  publisher =	 {IEEE Computer Society},
  address =	 {Nice, France},
  isbn =	 {0-7695-2049-9},
  year =	 2003,
  abstract =	 {In some applications objects are known to have
                  nonsmooth or "jagged" edges, which are not well
                  approximated by smooth curves. We use subdivision
                  curves as a simple but flexible curve
                  representation, which allows tagging corners to
                  model non-smooth features along otherwise smooth
                  curves. A Markov chain Monte Carlo approach yields
                  an approximate posterior distribution over tags,
                  while Rao-Blackwellization allows us to integrate
                  out the control point locations by an
                  approximation. We apply this general methodology to
                  multi-view reconstruction of piecewise smooth curves
                  from multiple calibrated views in which the object
                  has been segmented from the background. Results are
                  shown for multiple images of two pot shards as would
                  be encountered in archaeological applications.},
}

@InProceedings{Kaess03icar,
  author =	 {M. Kaess and R.C. Arkin and J. Rossignac},
  fullauthor =	 {Michael Kaess and Ronald C. Arkin and Jarek
                  Rossignac},
  title =	 {Compact Encoding of Robot-Generated 3{D} Maps for
                  Efficient Wireless Transmission},
  booktitle =	 {IEEE Intl. Conf. on Advanced Robotics (ICAR)},
  address =	 {Coimbra, Portugal},
  pages =	 {324-331},
  year =	 2003,
  abstract =	 {This work focuses on real-time compression of laser
                  data on board a mobile robot platform. Data is
                  transmitted from the robot over low-bandwidth
                  channels or incrementally in short bursts to a host,
                  where it can be further processed for
                  visualization. For compression purposes, the data is
                  represented as a gray scale depth image. Considered
                  are existing lossless image and file compression
                  schemes (Unix compress, gzip, bzip2, PNG, Jpeg-LS),
                  as well as wavelet transforma- tions tailored to the
                  specific nature of the data. Test- ing is done on
                  several sets of indoor data acquired by a robot
                  moving through rooms and hallways. The results show
                  that Jpeg-LS compression performs best in this
                  setting.},
}

@InProceedings{Kaess04eccv,
  author =	 {M. Kaess and R. Zboinski and F. Dellaert},
  fullauthor =	 {Michael Kaess and Rafal Zboinski and Frank Dellaert},
  title =	 {{MCMC}-based Multiview Reconstruction of Piecewise
                  Smooth Subdivision Curves with a Variable Number of
                  Control Points},
  booktitle =	 ECCV,
  pages =	 {329-341},
  publisher =	 {Springer},
  address =	 {Prague, Czech Republic},
  series =	 {Lecture Notes in Computer Science},
  volume =	 3023,
  isbn =	 {3-540-21982-X},
  year =	 2004,
  abstract =	 {We investigate the automated reconstruction of
                  piecewise smooth 3D curves, using subdivision curves
                  as a simple but flexible curve representation. This
                  representation allows tagging corners to model
                  non-smooth features along otherwise smooth
                  curves. We present a reversible jump Markov chain
                  Monte Carlo approach which obtains an approximate
                  posterior distribution over the number of control
                  points and tags. In a Rao-Blackwellization scheme,
                  we integrate out the control point locations,
                  reducing the variance of the resulting sampler. We
                  apply this general methodology to the reconstruction
                  of piecewise smooth curves from multiple calibrated
                  views, in which the object is segmented from the
                  background using a Markov random field
                  approach. Results are shown for multiple images of
                  two pot shards as would be encountered in
                  archaeological applications.},
}

@InProceedings{Kaess05icra,
  author =	 {M. Kaess and F. Dellaert},
  fullauthor =	 {Michael Kaess and Frank Dellaert},
  title =	 {A {M}arkov Chain {M}onte {C}arlo Approach to Closing
                  the Loop in {SLAM}},
  booktitle =	 ICRA,
  address =	 {Barcelona, Spain},
  pages =	 {645-650},
  month =	 {April},
  year =	 2005,
  abstract =	 {The problem of simultaneous localization and mapping
                  has received much attention over the last
                  years. Especially large scale environments, where
                  the robot trajectory loops back on itself, are a
                  challenge. In this paper we introduce a new solution
                  to this problem of closing the loop. Our algorithm
                  is EM-based, but differs from previous work. The key
                  is a probability distribution over partitions of
                  feature tracks that is determined in the E-step,
                  based on the current estimate of the motion. This
                  virtual structure is then used in the M-step to
                  obtain a better estimate for the motion. We
                  demonstrate the success of our algorithm in
                  experiments on real laser data.},
}

@TechReport{Kaess06tr,
  author =	 {M. Kaess and F. Dellaert},
  fullauthor =	 {Michael Kaess and Frank Dellaert},
  title =	 {Visual {SLAM} with a Multi-Camera Rig},
  institution =	 {Georgia Institute of Technology},
  number =	 {GIT-GVU-06-06},
  month =	 {Feb},
  year =	 2006,
  abstract =	 {Camera-based simultaneous localization and mapping
                  or visual SLAM has received much attention
                  recently. Typically single cameras, multiple cameras
                  in a stereo setup or omni-directional cameras are
                  used. We propose a different approach, where
                  multiple cameras can be mounted on a robot in an
                  arbitrary configuration. Allowing the cameras to
                  face in different directions yields better
                  constraints than single cameras or stereo setups can
                  provide, simplifying the reconstruction of
                  large-scale environments. And in contrast to
                  omni-directional sensors, the available resolution
                  can be focused on areas of interest depending on the
                  application. We describe a sparse SLAM approach that
                  is suitable for real-time reconstruction from such
                  multi-camera configurations. We have implemented the
                  system and show experimental results in a
                  large-scale environment, using a custom made
                  eight-camera rig.},
  c-kaess =	 {multi-camera, vision+odometry, trifocal tensor,
                  fixed-lag smoothing},
}

@InProceedings{Kaess07icra,
  author =	 {M. Kaess and A. Ranganathan and F. Dellaert},
  fullauthor =	 {Michael Kaess and Ananth Ranganathan and Frank
                  Dellaert},
  title =	 {{iSAM}: Fast Incremental Smoothing and Mapping with
                  Efficient Data Association},
  booktitle =	 ICRA,
  address =	 {Rome, Italy},
  doi =		 {10.1109/ROBOT.2007.363563},
  issn =	 {1050-4729},
  isbn =	 {1-4244-0601-3},
  pages =	 {1670-1677},
  month =	 {April},
  year =	 2007,
  abstract =	 {We introduce incremental smoothing and mapping
                  (iSAM), a novel approach to the problem of
                  simultaneous localization and mapping (SLAM) that
                  addresses the data association problem and allows
                  real-time application in large-scale
                  environments. We employ smoothing to obtain the
                  complete trajectory and map without the need for any
                  approximations, exploiting the natural sparsity of
                  the smoothing information matrix. A QR-factorization
                  of this information matrix is at the heart of our
                  approach. It provides efficient access to the exact
                  covariances as well as to conservative estimates
                  that are used for online data association. It also
                  allows recovery of the exact trajectory and map at
                  any given time by back-substitution. Instead of
                  refactoring in each step, we update the
                  QR-factorization whenever a new measurement
                  arrives. We analyze the effect of loops, and show
                  how our approach extends to the non-linear
                  case. Finally, we provide experimental validation of
                  the overall non-linear algorithm based on the
                  standard Victoria Park data set with unknown
                  correspondences.},
}

@InProceedings{Kaess07ijcai,
  author =	 {M. Kaess and A. Ranganathan and F. Dellaert},
  fullauthor =	 {Michael Kaess and Ananth Ranganathan and Frank
                  Dellaert},
  title =	 {Fast Incremental Square Root Information Smoothing},
  booktitle =	 IJCAI,
  address =	 {Hyderabad, India},
  pages =	 {2129-2134},
  year =	 {2007},
  abstract =	 {We propose a novel approach to the problem of
                  simultaneous localization and mapping (SLAM) based
                  on incremental smoothing, that is suitable for
                  real-time applications in large-scale
                  environments. The main advantages over filter-based
                  algorithms are that we solve the full SLAM problem
                  without the need for any approximations, and that we
                  do not suffer from linearization errors. We achieve
                  efficiency by updating the square-root information
                  matrix, a factored version of the naturally sparse
                  smoothing information matrix. We can efficiently
                  recover the exact trajectory and map at any given
                  time by back-substitution. Furthermore, our approach
                  allows access to the exact covariances, as it does
                  not suffer from under-estimation of uncertainties,
                  which is another problem inherent to filters. We
                  present simulation-based results for the linear
                  case, showing constant time updates for exploration
                  tasks. We further evaluate the behavior in the
                  presence of loops, and discuss how our approach
                  extends to the non-linear case. Finally, we evaluate
                  the overall non-linear algorithm on the standard
                  Victoria Park data set.},
}

@Article{Kaess08tro,
  author =	 {M. Kaess and A. Ranganathan and F. Dellaert},
  fullauthor =	 {Michael Kaess and Ananth Ranganathan and Frank
                  Dellaert},
  title =	 {{iSAM}: Incremental Smoothing and Mapping},
  journal =	 TRO,
  volume =	 24,
  number =	 6,
  pages =	 {1365-1378},
  month =	 {Dec},
  year =	 2008,
  abstract =	 {We present incremental smoothing and mapping (iSAM),
                  a novel approach to the simultaneous localization
                  and mapping problem that is based on fast
                  incremental matrix factorization. iSAM provides an
                  efficient and exact solution by updating a QR
                  factorization of the naturally sparse smoothing
                  information matrix, therefore recalculating only the
                  matrix entries that actually change. iSAM is
                  efficient even for robot trajectories with many
                  loops as it avoids unnecessary fill-in in the factor
                  matrix by periodic variable reordering. Also, to
                  enable data association in real-time, we provide
                  efficient algorithms to access the estimation
                  uncertainties of interest based on the factored
                  information matrix. We systematically evaluate the
                  different components of iSAM as well as the overall
                  algorithm using various simulated and real-world
                  datasets for both landmark and pose-only settings.},
}

@InProceedings{Kaess09icra,
  author =	 {M. Kaess and K. Ni and F Dellaert},
  fullauthor =	 {Michael Kaess and Kai Ni and Frank Dellaert},
  title =	 {Flow Separation for Fast and Robust Stereo Odometry},
  booktitle =	 ICRA,
  year =	 2009,
  url =		 {http://frank.dellaert.com/pub/Kaess09icra.pdf}
}

@Article{Kaess09ras,
  author =       {M. Kaess and F. Dellaert},
  fullauthor =   {Michael Kaess and Frank Dellaert},
  title =        {Covariance Recovery from a Square Root Information
                  Matrix for Data Association},
  doi =          {10.1016/j.robot.2009.06.008},
  journal =      RAS,
  year =         2009,
  note =         {. In print},
  abstract =     {Data association is one of the core problems of
                  simultaneous localization and mapping (SLAM), and it
                  requires knowledge about the uncertainties of the
                  estimation problem in the form of marginal
                  covariances. However, it is often difficult to
                  access these quantities without calculating the full
                  and dense covariance matrix, which is prohibitively
                  expensive.  We present a dynamic programming
                  algorithm for efficient recovery of the marginal
                  covariances needed for data association. As input we
                  use a square root information matrix as maintained
                  by our incremental smoothing and mapping (iSAM)
                  algorithm.  The contributions beyond our previous
                  work are an improved algorithm for recovering the
                  marginal covariances and a more thorough treatment
                  of data association now including the joint
                  compatibility branch and bound (JCBB) algorithm. We
                  further show how to make information theoretic
                  decisions about measurements before actually taking
                  the measurement, therefore allowing a reduction in
                  estimation complexity by omitting uninformative
                  measurements. We evaluate our work on simulated and
                  real-world data.},
}

@article{Kahn90,
  AUTHOR =	 "P. Kahn and L. Kitchen and E.M. Riseman",
  TITLE =	 "A Fast Line Finder for Vision-Guided Robot
                  Navigation",
  JOURNAL =	 PAMI,
  VOLUME =	 12,
  YEAR =	 1990,
  NUMBER =	 11,
  MONTH =	 "Nov",
  PAGES =	 "1098-1102"
}

@Article{Kailath80it,
  author =	 {T. Kailath},
  title =	 {Review of '{F}actorization Methods for Discrete
                  Sequential Estimation' ({B}ierman, {G}erald
                  {J}.;1977)},
  journal =	 IT,
  year =	 1980,
  pages =	 {130-131},
  volume =	 26,
  number =	 1,
  month =	 {Jan},
}

@ARTICLE{Kalman60,
  AUTHOR =	 {Kalman, R. E.},
  TITLE =	 {A new Approach to Linear Filtering and Prediction
                  Problems},
  JOURNAL =	 {Trans. ASME, Journal of Basic Engineering},
  YEAR =	 1960,
  VOLUME =	 82,
  PAGES =	 {35-45}
}

@InProceedings{Kaltenbacher96,
  author =	 "E. Kaltenbacher and R.C. Hardie",
  title =	 "High-resolution infrared image reconstruction using
                  multiple low-resolution aliased frames",
  booktitle =	 "Proc. IEEE Nat. Aerospace Electronics Conf.",
  year =	 1996,
  month =	 "May",
}

@inproceedings{Kambhatla94fast,
  author =	 "N. Kambhatla and T. K. Leen",
  title =	 "Fast non-linear dimension reduction",
  pages =	 "152--159",
  year =	 1994,
  booktitle =	 NIPS,
  url =		 "citeseer.nj.nec.com/kambhatla94fast.html"
}

@InProceedings{Kaminski01,
  author =	 "J.Y. Kaminski and M. Fryers and A. Shashua and
                  M. Teicher",
  title =	 "Multiple View Geometry of Non-planar Algebraic
                  Curves",
  booktitle =	 "ICCV",
  pages =	 "181-186",
  volume =	 2,
  year =	 2001,
}

@InProceedings{Kanade98,
  author =	 {T. Kanade and R. Collins and A. Lipton and P. Burt
                  and L. Wixson},
  title =	 {Advances in Cooperative Multi-Sensor Video
                  Surveillance},
  booktitle =	 IUW,
  pages =	 {3-24},
  year =	 1998,
}

@InProceedings{Kanaya00,
  author =	 "I. Kanaya and Q. Chen and Y. Kanemoto and
                  K. Chihara",
  title =	 "Three-Dimensional Modeling for Virtual Relic
                  Restoration",
  booktitle =	 "MultiMedia IEEE",
  volume =	 7,
  pages =	 "42-44",
  year =	 2000,
}

@InProceedings{Kanazawa95,
  author =	 "K. Kanazawa and D. Koller and S.J. Russell",
  title =	 "Stochastic simulation algorithms for dynamic
                  probabilistic networks",
  crossref =	 {_UAI95},
}

@InProceedings{Kanbara01,
  author =	 {M.Kanbara and H.Fujii and H.Takemura and N.Yokoya},
  title =	 {A Stereo Vision-Based Mixed Reality System with
                  Natural Feature Point Tracking},
  booktitle =	 {ISMR},
  year =	 2001,
}

@Book{Kaneff69,
  author =	 {S. Kaneff},
  title =	 {Picture Language Machines},
  publisher =	 {Academic Press},
  year =	 1969,
}

@InProceedings{Kang04,
  author =	 {Kang, E. and Cohen, I. and Medioni, G.},
  title =	 {Non-Iterative Approach to Multiple 2D Motion
                  Estimation},
  year =	 2004,
  booktitle =	 ICPR
}

@Article{Kang04ijcv,
  author =	 {S.B. Kang and R. Szeliski},
  title =	 {Extracting view-dependent depth maps from a
                  collection of images},
  journal =	 IJCV,
  year =	 2004,
  volume =	 58,
  number =	 2,
  pages =	 {139-163},
  month =	 {July},
  r-kang06ftcgv ={For the unstructured Lumigraph work, Buehler et
                  al. [8] apply a more principled way of blending
                  textures based on relative angular position,
                  resolution, and field-of-view. Kang and Szeliski
                  [47] use not just view-dependent textures, but
                  view-dependent geometries as well. This is to
                  account for the fact that stereo is only locally
                  valid for scenes with non-Lambertian
                  properties. They blend warped depth images (depth
                  maps and textures) to produce new views, as shown in
                  Figure 36.},
}

@Article{Kang97,
  author =	 {S.B. Kang and R. Szeliski},
  title =	 {{3-D} scene data recovery using omnidirectional
                  multibaseline stereo},
  journal =	 IJCV,
  year =	 1997,
  volume =	 25,
  number =	 2,
  pages =	 {167--183},
  month =	 {November},
}

@InProceedings{Kantor02,
  author =	 {G. Kantor and S. Singh},
  title =	 {Preliminary results in range-only localization and
                  mapping},
  booktitle =	 ICRA,
  pages =	 {1818 -1823},
  year =	 2002,
}

@Article{Karayiannis91,
  author =	 {N.B.~Karayiannis and A.N.~Venetsanopolous},
  title =	 {Image Interpolation based on Variational Principles},
  journal =	 {Signal Processing},
  year =	 1991,
  volume =	 25,
  number =	 3,
  pages =	 {259--288}
}

@InProceedings{Karczmarczuk02padl,
  author =	 {Jerzy Karczmarczuk},
  title =	 {Functional Approach to Texture Generation},
  booktitle =	 {Practical Aspects of Declarative Languages, 4th
                  International Symposium},
  year =	 2002,
  pages =	 {225-242},
}

@InProceedings{Karczmarczuk98icfp,
  author =	 {Jerzy Karczmarczuk},
  title =	 {Functional Differentiation of Computer Programs},
  booktitle =	 ICFP,
  year =	 1998,
  pages =	 {195-203},
}

@TechReport{Karl92tr,
  author =	 {W.C. Karl and G.C. Verghese and Alan S. Willsky},
  title =	 {Reconstructing ellipsoids from projections},
  institution =	 {Laboratory for Information and Decision Systems,
                  Massachusetts Institute of Technology},
  year =	 1992,
  number =	 {LIDS-P ; 2141},
}

@InProceedings{Karlsson00,
  author =	 {R. Karlsson and F. Gustafsson},
  title =	 {Monte Carlo data association for multiple target
                  tracking},
  booktitle =	 {IEE Workshop on Target Tracking},
  pages =	 {247-254},
  year =	 2000,
}

@InProceedings{Karlsson05,
  author =	 {N. Karlsson and E.D. Bernardo and J. Ostrowski and
                  L. Goncalves and P. Pirjanian and M.E. Munich},
  title =	 {The {vSLAM} Algorithm for Robust Localization and
                  Mapping},
  booktitle =	 ICRA,
  pages =	 {24-29},
  year =	 2005,
}

@InProceedings{Karlsson05icra,
  author =	 {N. Karlsson and E.D. Bernardo and J. Ostrowski and
                  L. Goncalves and P. Pirjanian and M.E. Munich},
  fullauthor =	 {Niklas Karlsson and Enrico Di Bernardo and Jim
                  Ostrowski and Luis Goncalves and Paolo Pirjanian and
                  Mario E. Munich},
  title =	 {The {vSLAM} Algorithm for Robust Localization and
                  Mapping},
  booktitle =	 ICRA,
  pages =	 {24-29},
  location =	 {Barcelona, Spain},
  month =	 {Apr},
  year =	 2005,
  abstract =	 {This paper presents the Visual Simultaneous
                  Localization and Mapping (vSLAM) algorithm, a novel
                  algorithm for simultaneous localization and mapping
                  (SLAM). The algorithm is vision- and odometry-based,
                  and enables lowcost navigation in cluttered and
                  populated environments. No initial map is required,
                  and it satisfactorily handles dynamic changes in the
                  environment, for example, lighting changes, moving
                  objects and/or people. Typically, vSLAM recovers
                  quickly from dramatic disturbances, such as
                  "kidnapping".},
  r-Davison07pami ={The commercial vSLAM system [this] also uses SIFT
                  features, though within a SLAM algorithm which
                  relies significantly on odometry to build a
                  connected map of recognizable locations rather than
                  fully continuous accurate localization.},
  r-Elinas06icra ={... [this] uses a particle filter with a single
                  camera and robot odometry to map small indoor
                  environments. They construct topological maps and
                  identify visual landmarks using SIFT.},
  r-Elinas06icra ={In contrast, [this] uses a mixture proposal that
                  combines hypotheses from the motion and observation
                  models weighted according to either the motion or
                  observation models... However, computing the
                  particle weights according to two different models
                  generates an inconsistent set of hypotheses that in
                  [this] is not treated in a principled way.},
  c-kaess =	 {Features are compared with previously created
                  landmarks. Match yields a measurement of the
                  relative robot pose with respect to the pose at
                  which the landmark was created. Basically FastSLAM
                  with a mixture proposal distribution: uses samples
                  from motion model and samples from measurement
                  model. For frontend see Goncalves05icra.},
}

@TechReport{Karner02tr,
  author =	 {K. Karner and J. Bauer and A. Klaus and
                  K. Schindler},
  fullauthor =	 {Konrad Karner and Joachim Bauer and Andreas Klaus
                  and K. Schindler},
  title =	 {Metropogis: A city information system},
  institution =	 {Research Center for Virtual Reality and
                  Visualization (VRVis)},
  year =	 2002,
  number =	 {2002-030},
}

@Article{Karp67siam,
  author =	 {R.M. Karp and M. Held},
  title =	 {Finite-state processes and dynamic programming},
  journal =	 {SIAM J. Appl. Math},
  year =	 1967,
  volume =	 15,
  pages =	 {693--718},
  r-Helman89jacm ={Because conjunct combinations need not be
                  associative, the model has a far broader scope than
                  the classic, string-based models \cite{Karp67siam}.}
}

@TechReport{Karypis94tr,
  author =	 {G. Karypis and V. Kumar},
  fullauthor =	 {George Karypis and Vipin Kumar},
  title =	 {High Performance Sparse Cholesky Factorization
                  Algorithm for Scalable Parallel Computers},
  institution =	 {U. of Minnesota},
  year =	 1994,
  number =	 {94-41},
}

@inproceedings{Karypis98,
  author =	 {G. Karypis and V. Kumar},
  fullauthor =	 {George Karypis and Vipin Kumar},
  title =	 {Multilevel algorithms for multi-constraint graph
                  partitioning},
  booktitle =	 {Supercomputing '98: Proceedings of the 1998 ACM/IEEE
                  conference on Supercomputing (CDROM)},
  year =	 1998,
  isbn =	 {0-89791-984-X},
  pages =	 {1--13},
  location =	 {San Jose, CA},
  publisher =	 {IEEE Computer Society},
  address =	 {Washington, DC, USA},
}

@Article{Kask05ai,
  author =	 {K. Kask and R. Dechter and J. Larrosa and
                  A. Dechter},
  fullauthor =	 {Kalev Kask and Rina Dechter and Javier Larrosa and
                  Avi Dechter},
  title =	 {Unifying tree decompositions for reasoning in
                  graphical models},
  journal =	 AI,
  year =	 2005,
  volume =	 166,
  number =	 {1-2},
  pages =	 {165--193},
  month =	 {August},
  abstract =	 {The paper provides a unifying perspective of
                  tree-decomposition algorithms appearing in various
                  automated reasoning areas such as join-tree
                  clustering for constraint-satisfaction and the
                  clique-tree algorithm for probabilistic
                  reasoning. Within this framework, we introduce a new
                  algorithm, called bucket-tree elimination (BTE),
                  that extends Bucket Elimination (BE) to trees, and
                  show that it can provide a speed-up of n over BE for
                  various reasoning tasks. Time-space tradeoffs of
                  tree-decomposition processing are analyzed.},
  quotes =	 {The idea of embedding a database that consists of a
                  collection of functions or relations in a tree
                  structure and, subsequently, processing it
                  effectively by a tree-processing algorithm, has been
                  discovered and rediscovered in different
                  contexts. ... The aim of this paper is to present
                  the central concepts and properties of cluster-tree
                  decomposition techniques by way of a single, unified
                  framework for the purpose of making it more
                  accessible to researchers in diverse areas and
                  facilitating the transfer of this methodology among
                  these areas. Specifically, we demonstrate that
                  join-tree clustering, junction-tree decomposition,
                  and hyper-tree decomposition that, as mentioned
                  above, were developed in different contexts and for
                  different applications, are all instances of our
                  unified scheme. Also, as we show, variable
                  elimination algorithms can be viewed as processing
                  specific cluster-tree decompositions. ... Our work
                  expands on \cite{Shafer90uai} in several
                  ways. First, we use a graph-based language,
                  connecting our approach explicitly to graphical
                  models and using graph-based parameters for
                  capturing algorithmic principles. In particular, we
                  provide graph-based complexity analysis that focuses
                  on the time vs. space issue. Second, we emphasize
                  the distinction between the generation of a
                  structural tree-decomposition and the
                  tree-processing algorithms that are enabled by the
                  decomposition. Third, we show that variable
                  elimination algorithms can be viewed as a specific
                  tree-processing schemes that can be generalized to
                  full processing along special tree-decompositions
                  called bucket trees. Finally, we note how different
                  tree-decompositions of a given problem yield a
                  spectrum of time-space complexity characteristics
                  using superbuckets. ... Join-trees correspond to
                  minimal tree-decompositions. This restriction
                  exclude the super-bucket methods that accommodates
                  time-space trade-offs. ... We present these classes
                  of algorithms by harnessing the formal notation
                  appearing in \cite{Gottlob00ai} (which is restricted
                  there to constraint satisfaction). This allows
                  separating tree-structuring from tree-processing.},
  c-dellaert =	 {Bucket-tree = Bayes-tree ? Defines elimination
                  operators, directed graph, hyper-graph = symbolic
                  factor graph, primal graph = MRF = A'A, dual graph =
                  similar projection of factor-graph but now factors
                  are nodes, i.e. AA' ?, hyper-tree = acyclic
                  hyper-graph, induced width \cite{Dechter97ai},
                  graphical model (finite domains only), reasoning
                  problem. All very similar to and-or paper. Algorithm
                  cluster-tree elimination (CTE) is a message passing
                  algorithm in both directions. Building of cluster
                  tree and CTE are separated. Improved CTE (ICTE)
                  precomputes intermediate functions for each vertex
                  \cite{Shenoy96uai}. Bucket elimination, Bucket-tree,
                  points towards root, separators, Bucket-tree
                  elimination: top-down, bottom up. Superbuckets =
                  non-minimal merged cliques. ... Interesting
                  development: tree-decomposition includes junction
                  trees, certain hyper-tree decompositions}
}


@Article{Kass87ijcv,
  author =	 "M. Kass and A. Witkin and D. Terzopoulos",
  title =	 "Snakes: Active Contour Models",
  journal =	 IJCV,
  year =	 1987,
  pages =	 "321-331",
  volume =	 1,
  number =	 4,
}

@inproceedings{Kato99iros,
  Author =	 {Kato, K. and Ishiguro, H. and Barth, M.},
  Booktitle =	 IROS,
  Pages =	 {966--971 vol.2},
  Title =	 {Identifying and localizing robots in a multi-robot
                  system environment},
  Volume =	 2,
  Year =	 1999,
  Abstract =	 {Development of multiple robot systems which solve
                  complex and dynamic problems in parallel and
                  distributed manners is one of the key issues in
                  robotics research. The multiple robot systems
                  require robust methods to identify robots for
                  collaborative behaviors. This paper proposes a
                  method using omnidirectional vision sensors for the
                  identification between the robots. In addition to
                  the several advantages of the omnidirectional vision
                  sensor as a vision of a mobile robot, the
                  omnidirectional vision sensor brings a significant
                  benefit for realizing collaborative behaviors in
                  multiple robot systems. After discussing on the
                  algorithm, this paper shows several simulation
                  results and real experimental results in a real
                  environment},
}

@Article{Kavraki96tra,
  author =	 "L.E. Kavraki and P. Svestka and J.-C. Latombe and
                  M.H. Overmars",
  title =	 "Probabilistic Roadmaps for Path Planning in
                  High-Dimensional Configuration Spaces",
  journal =	 TRA,
  year =	 1996,
  volume =	 12,
  number =	 4,
  pages =	 "566-580",
}

@InProceedings{Kay97,
  author =	 {J. Kay and C. Thorpe},
  title =	 {An Examination of the {STRIPE} Vehicle teleoperation
                  System},
  booktitle =	 IROS,
  year =	 1997,
}

@Article{Kelly73obhp,
  author =	 {Kelly, III, C.W. and S. Barclay},
  title =	 {A general {Bayesian} model for hierarchical
                  inference},
  journal =	 {Organizational Behavior and Human Performance},
  year =	 1973,
  volume =	 10,
  pages =	 {388--403},
  abstract =	 {An inductive inference problem will often be
                  structured so that the target variable (hypotheses)
                  are logically distant from the observable events
                  (data). In this situation it may be difficult or
                  impossible to assess the probabilistic connection
                  between them, but it may be possible to decompose
                  the problem through the use of intermediate or
                  explanatory variables. That is, it will often be
                  possible to assess the likelihood of the observed
                  data given some intermediate variable, and the
                  likelihood of that intermediate variable given
                  another, and so on, until the hypotheses of interest
                  are reached. Inferences which incorporate one or
                  more intermediate variables are called hierarchical,
                  cascaded, or multistage inferences. The present
                  paper presents a normative model for the solution of
                  the general hierarchical inference problem. The
                  formulation begins with a formal description of the
                  hierarchical inference tree, including a discussion
                  of various simplifying conditional independence
                  assumptions. The solution is first derived for three
                  special case models of differing structure, and then
                  the algorithm for the general solution is given for
                  two cases: one in which the conditional independence
                  assumptions have been made and one in which they
                  have not.},
  r-Lauritzen88jrssb ={Kelly and Barclay (1973) and Pearl (1982)
                  consider 'trees' in which each node has at most one
                  parent and there are no 'loops'.},
  r-Shafer90amai ={The basic algorithms we describe in sections 7 and
                  8 do not go beyond the algorithms of
                  \citet{Kelly73obhp}, \citet{Cannings78aap},
                  \citet{Pearl86ai}, and \citet{Lauritzen88jrssb} in
                  what they accomplish, but they do show that the
                  accomplishment is simpler than sometimes thought.},
  c-dellaert =	 {This is our very own Clint Kelly, from SAIC},
}

@InProceedings{Keren88,
  author =	 {D.~Keren and S.~Peleg and R.~Brada},
  title =	 {Image Sequence Enhancement using Sub-Pixel
                  Displacements},
  booktitle =	 CVPR,
  year =	 1988,
  month =	 {June},
  pages =	 {742-746}
}

@Article{Kernigham70,
  author =	 "B.W. Kernighan and S. Lin",
  title =	 "An efficient heuristic procedure for partitioning
                  graphs",
  journal =	 "The Bell System Technical Journal",
  year =	 1970,
  volume =	 49,
  number =	 2,
  pages =	 "291-307"
}

@Article{Keys81,
  author =	 {R.G.~Keys},
  title =	 {Cubic Convolution Interpolation for Digital Image
                  Processing},
  journal =	 ASSP,
  year =	 1981,
  volume =	 29,
  number =	 6,
  pages =	 {1153--1160}
}

@InProceedings{Khan03,
  AUTHOR =	 {Khan, Z. and Balch, T. and Dellaert, F.},
  TITLE =	 {Efficient Particle Filter-Based Tracking of Multiple
                  Interacting Targets Using an {MRF}-based Motion
                  Model},
  BOOKTITLE =	 IROS,
  YEAR =	 2003,
  ADDRESS =	 {Las Vegas}
}

@Article{Khan03pami,
  author =	 {S. Khan and M. Shah},
  fullauthor =	 {Sohaib Khan and Mubarak Shah},
  title =	 {Consistent Labeling of Tracked Objects in Multiple
                  Cameras with Overlapping Fields of View},
  journal =	 PAMI,
  year =	 2003,
  month =	 "October",
  volume =	 25,
  number =	 10,
  pages =	 {1355-1360},
  keywords =	 {surveillance, multi camera, data association},
  c-sangmin =	 {detailed methodologies on target association with
                  multiple cameras with overlapping views},
}

@TechReport{Khan03tr,
  author =	 {Z. Khan and T. Balch and F. Dellaert},
  title =	 {An {MCMC}-based Particle Filter for Tracking
                  Multiple Interacting Targets},
  institution =	 {GVU Center, College of Computing, Georgia Tech},
  year =	 2003,
  number =	 {GIT-GVU-03-25},
}

@InProceedings{Khan04cvpr,
  author =	 {Khan, Z. and Balch, T. and Dellaert, F.},
  title =	 {A {Rao-Blackwellized} Particle Filter for
                  {EigenTracking}},
  booktitle =	 CVPR,
  volume =	 2,
  pages =	 "980-986",
  year =	 2004,
}

@InProceedings{Khan04eccv,
  author =	 {Khan, Z. and Balch, T. and Dellaert, F.},
  title =	 {An {MCMC}-based Particle Filter for Tracking
                  Multiple Interacting Targets},
  year =	 2004,
  booktitle =	 ECCV,
}

@TechReport{Khan04tr,
  author =	 {Z. Khan and and F. Dellaert},
  title =	 {Robust Generative Subspace Modeling: The Subspace t
                  Distribution},
  institution =	 {GVU Center, College of Computing, Georgia Tech},
  year =	 2004,
  number =	 {GIT-GVU-04-11},
}

@Article{Khan05brm,
  author =	 {Z. Khan and R. A. Herman and K. Wallen and T. Balch},
  title =	 {A 3-d Visual Tracking System for the Study of
                  Spatial Navigation and Memory in {Rhesus} Monkeys},
  journal =	 {Behavior Research Methods, Instruments \& Computers},
  year =	 2005,
  note =	 {In Press},
}

@journal{Kinderman1980mrf,
  title =	 {Markov Random Fields and Their Applications},
  author =	 {Kinderman, R. and Snell, J.L.},
  journal =	 {American Mathematical Soc},
  Address =	 {Providence, RI},
  year =	 {1980},
  r-Frey03uai =	 {Seminal ref for MRF},
}

@InProceedings{Khan05cvpr,
  author =	 {Khan, Z. and Balch, T. and Dellaert, F.},
  title =	 {Multitarget Tracking with Split and Merged
                  Measurements},
  booktitle =	 CVPR,
  year =	 2005,
}

@Article{Khan05pami,
  author =	 {Khan, Z. and Balch, T. and Dellaert, F.},
  title =	 {{MCMC}-Based Particle Filtering for Tracking a
                  Variable Number of Interacting Targets},
  journal =	 PAMI,
  year =	 2005,
  volume =	 27,
  number =	 11,
  pages =	 {1805--1918},
  month =	 {November},
}

@Article{Khan06pami,
  author =	 {Khan, Z. and Balch, T. and Dellaert, F.},
  title =	 {{MCMC} Data Association and Sparse Factorization
                  Updating for Real Time Multitarget Tracking with
                  Merged and Multiple Measurements},
  journal =	 PAMI,
  year =	 2006,
  volume =	 28,
  number =	 12,
  pages =	 {1960--1972},
  month =	 {December},
}

@Article{Kikinis95,
  title =	 "Integral computer scanning system",
  journal =	 "United States Patent 5,416,610",
  author =	 "D. Kikinis",
  year =	 1995,
  month =	 "May",
}

@InProceedings{Kim01iros,
  author =	 {J. Kim and M. Chung},
  fullauthor =	 {Jae-Hean Kim and Myung-Jin Chung},
  title =	 {Map generation from unknown planar motion using
                  omni-directional vision},
  booktitle =	 IROS,
  pages =	 {889-894},
  year =	 2001,
  volume =	 2,
}

@inproceedings{Kim03icra,
  author =	 {J. H. Kim and S. Sukkarieh},
  title =	 {Airborne simultaneous localisation and map building},
  booktitle =	 ICRA,
  year =	 {2003}
}

@InProceedings{Kim03icra,
  author =	 {J. H. Kim and S. Sukkarieh},
  title =	 {Airborne simultaneous localisation and map building},
  booktitle =	 ICRA,
  year =	 {2003}
}

@Article{Kim05press,
  author =	 {K. Kim and T.H. Chalidabhongse and D. Harwood and
                  L. Davis},
  title =	 {Real-time foreground-background segmentation using
                  codebook model},
  journal =	 {PRESS},
  year =	 2005,
  abstract =	 {We present a real-time algorithm for
                  foreground-background segmentation. Sample
                  background values at each pixel are quantized into
                  codebooks which represent a compressed form of
                  background model for a long image sequence. This
                  allows us to capture structural background variation
                  due to periodic-like motion over a long period of
                  time under limited memory. The codebook
                  representation is efficient in memory and speed
                  compared with other background modeling
                  techniques. Our method can handle scenes containing
                  moving backgrounds or illumination variations, and
                  it achieves robust detection for different types of
                  videos. We compared our method with other multimode
                  modeling techniques. In addition to the basic
                  algorithm, two features improving the algorithm are
                  presented-layered modeling/detection and adaptive
                  codebook updating. For performance evaluation, we
                  have applied perturbation detection rate analysis to
                  four background subtraction algorithms and two
                  videos of different types of scenes.},
  c-houdan =	 {It's a new way using codebook to segment background,
                  experimental results are as good as MOG and KDE
                  approach and the speed is faster},
}

@InProceedings{Kim06icra,
  author =	 {D. Kim and J. Sun and S. M. Oh and J. M. Rehg and
                  A. F. Bobick},
  fullauthor =	 {Dongshin Kim and Jie Sun and Sang Min Oh and James
                  M. Rehg and Aaron F. Bobick},
  title =	 {Traversability Classification using Unsupervised
                  On-line Visual Learning},
  booktitle =	 ICRA,
  year =	 {2006},
}

@Article{Kim06jmlr,
  author =	 {S. Kim and P. Smyth},
  fullauthor =	 {Seyoung Kim and Padhraic Smyth},
  title =	 {Segmental {H}idden {M}arkov {M}odels with {R}andom
                  {E}ffects for {W}aveform {M}odeling},
  journal =	 JMLR,
  year =	 2006,
  volume =	 7,
  month =	 {October},
  pages =	 {945-969}
}

@InProceedings{Kim07iros,
  author =	 {D. Kim and S. M. Oh and J. M. Rehg},
  fullauthor =	 {Dongshin Kim and Sang Min Oh and James
                  M. Rehg},
  title =	 {Traversability Classication for UGV Navigation : A Comparison of Patch and Superpixel 
Representation},
  booktitle =	 IROS,
  year =	 {2007},
}

@inproceedings{Kim09chiea,
  author =	 {Kim, Tanyoung and Hong, Hwajung and Magerko, Brian},
  title =	 {Coralog: use-aware visualization connecting human
                  micro-activities to environmental change},
  booktitle =	 {CHI EA '09: Proceedings of the 27th international
                  conference extended abstracts on Human factors in
                  computing systems},
  year =	 2009,
  isbn =	 {978-1-60558-247-4},
  pages =	 {4303--4308},
  location =	 {Boston, MA, USA},
  doi =		 {http://doi.acm.org/10.1145/1520340.1520657},
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
}

@Article{Kim90,
  author =	 {S.P. Kim and N.~Bose and H.~Valenzuela},
  title =	 {Recursive Reconstruction of High Resolution Image
                  from Noisy Undersampled Multiframes},
  journal =	 ASSP,
  year =	 1990,
  volume =	 38,
  month =	 {June},
  pages =	 {1013--1027}
}

@Article{Kim91,
  author =	 {Kim, W.-Y. and Kak, A.C.},
  title =	 {{3-D} object recognition using bipartite matching
                  embedded in discrete relaxation},
  journal =	 PAMI,
  year =	 1991,
  volume =	 13,
  number =	 3,
  month =	 {March},
  pages =	 {224 -251},
}

@Article{Kim93,
  author =	 {S.P. Kim and W.-Y.~Su},
  title =	 {Recursive High-Resolution Reconstruction of Blurred
                  Multiframe Images},
  journal =	 IP,
  year =	 1993,
  volume =	 2,
  month =	 {October},
  pages =	 {534--539}
}

@InProceedings{Kim93b,
  author =	 {D. Kim and R. Nevatia},
  title =	 {Indoor navigation without a specific map},
  booktitle =	 {Proc. Int. Conf. Intelligent Autonomous Systems},
  pages =	 {268-277},
  year =	 1993,
}

@PhdThesis{Kim94,
  author =	 {S.P. Kim},
  title =	 {High-resolution reconstruction from undersampled
                  multiframes},
  school =	 {Pennsylvania State University},
  year =	 1994,
}

@Article{Kim94a,
  author =	 {C.-J. Kim},
  title =	 {Dynamic linear models with {M}arkov-switching},
  journal =	 {Journal of Econometrics},
  year =	 1994,
  volume =	 60,
  number =	 "1-2",
  pages =	 "1-22",
}

@article{Kim99ep,
  Author =	 {Kim, Nam-Gyoon and Turvey, M. T.},
  ISSN =	 {1040-7413},
  Journal =	 {Ecological Psychology},
  Number =	 3,
  Pages =	 {233--248},
  Title =	 {Eye movements and a rule for perceiving direction of
                  heading.},
  Volume =	 11,
  Year =	 1999,
  abstract =	 {The basis of visually guided locomotion is the
                  ambient optical flow. Because animals with frontal
                  eyes can sample only a portion of the flow field,
                  they must continuously scan in order to be aware of
                  their surroundings. Such scanning introduces
                  additional transformations of the retinal image,
                  apparently complicating the extraction from retinal
                  flow of the information in optical flow. In this
                  study, the authors conducted computer simulations of
                  eye movement graphically. These simulations revealed
                  that when gaze direction coincides with heading
                  direction on curvilinear paths, velocity vectors in
                  the image plane become linearized. The active
                  rotation of the eyes is, in effect, an essential
                  mechanism for extracting the self-movement
                  information contained in optical flow from flow
                  patterns on the retinas. Strategically positioning
                  the eyes renders a nonlinear flow linear and,
                  thereby, converts a complicated information pickup
                  problem into a considerably simpler problem. Based
                  on these simulations, the authors contend that
                  heading direction is specified by the
                  perpendicularly aligned vectors.},
  quotes =	 {A possible resolution is suggested, however, by a
                  simulation of the retinal flow when the eyes are
                  directed at a point lying on the locomotory
                  path. For this field of view, all the image
                  trajectories are linearized. The vector directions
                  in Figure 3e are the same over successive
                  frames. Each velocity vector [] lies in the
                  direction tangent to the corresponding flow line
                  (i.e., the trajectory that a surface element
                  traces). Curves formed by connecting the velocity
                  vectors with the same direction define streamlines
                  of a flow field (Sutton, 1957). .. In contrast to
                  the complexities suggested by the preceding remarks,
                  there seems to be a simple rule for identifying the
                  path of locomotion regardless of its nature, that
                  is, linear or circular: Move the eyes until the
                  image trajectories on the retina are rendered
                  linear; then you are looking in the direction in
                  which you are heading, and the trajectory defined by
                  the perpendicular image vectors is your path of
                  locomotion. .. To conclude, why do we rotate the
                  eyes if, as often argued, rotation serves only to
                  induce ambiguity? Based on the arguments presented
                  here, the active rotation of the eyes is, in effect,
                  an essential mechanism for extracting the
                  self-movement information contained in optical flow
                  from flow patterns on the retinas. Strategically
                  positioning the eyes renders a nonlinear flow linear
                  and, thereby, converts a complicated information
                  pickup problem into a considerably simpler problem.},
  r-Wilkie03jov ={It has been proposed that the rotation introduced
                  into retinal flow by eye-movements can actually
                  simplify the steering task (Kim & Turvey, 1999; Wann
                  & Swapp, 2000).},
  c-dellaert =	 {Very hard to understand. Talks about a simple rule:
                  move until retinal flow "linear" then the
                  streamlines give your path of locomotion. Hmm.},
}

@InProceedings{King90,
  author =	 {King, S. and Weiman, C.},
  title =	 {Helpmate autonomous mobile robot navigation system},
  booktitle =	 {Proceedings of the SPIE Conference on Mobile Robots},
  year =	 1990,
  volume =	 2352,
}

@article{Kirby90,
  AUTHOR =	 "Kirby, M. and Sirovich, L.",
  TITLE =	 "Application of the Karhunen-Loeve Procedure for the
                  Characterization of Human Faces",
  JOURNAL =	 PAMI,
  VOLUME =	 12,
  YEAR =	 1990,
  NUMBER =	 1,
  MONTH =	 "January",
  PAGES =	 "103-108"
}

@Article{Kirsch64,
  title =	 {Computer interpretation of English text and picture
                  patterns},
  author =	 {R.A. Kirsch},
  journal =	 {Trans. IEEE EC},
  volume =	 13,
  pages =	 {363-376},
  month =	 "August",
  year =	 1964,
}

@Article{Kirubarajan01,
  author =	 {Kirubarajan, T. and Bar-Shalom, Y. and Pattipati,
                  K.R.},
  title =	 {Multiassignment for tracking a large number of
                  overlapping objects [and application to fibroblast
                  cells]},
  journal =	 AES,
  year =	 2001,
  volume =	 37,
  number =	 1,
  pages =	 {2-21},
  month =	 {January},
}

@Article{Kitagawa96,
  author =	 {G. Kitagawa},
  title =	 {Monte {C}arlo Filter and Smoother for non-Gaussian
                  Nonlinear State Space Models},
  journal =	 {J. of Computational and Graphical Statistics},
  year =	 1996,
  volume =	 5,
  number =	 1,
  pages =	 "1-25",
}

@InProceedings{Klass05uai,
  author =	 {M. Klaas, N. de Freitas, A. Doucet},
  fullauthor =	 {Mike Klass, Nando de Freitas, Arnaud Doucet},
  title =	 {Towards {P}ractical {N}2 {M}onte {C}arlo : The
                  {M}arginal {P}article {F}ilter},
  booktitle =	 {UAI},
  year =	 2005,
}

@InProceedings{Klass06icml,
  author =	 {M. Klaas, M. Briers, N. de Freitas, A. Doucet,
                  S. Maskell, D. Lang},
  fullauthor =	 {Mike Klass, Mark Briers, Nando de Freitas, Arnaud
                  Doucet,Simon Maskell,Dustin Lang},
  title =	 {Fast Particle Smoothing: If I Had a Million
                  Particles},
  booktitle =	 {ICML},
  year =	 2006,
}

@InProceedings{Klein03,
  author =	 {G. Klein and T. Drummond},
  title =	 {Robust Visual Tracking for Non-Instrumented
                  Augmented Reality},
  booktitle =	 {ISMAR},
  year =	 2003,
}

@InProceedings{Klein07ismar,
  Author =	 {G. Klein and D. Murray},
  Title =	 {Parallel Tracking and Mapping for Small {AR}
                  Workspaces},
  BookTitle =	 ismar,
  fullauthor =	 {Georg Klein and David Murray},
  month =	 {November},
  address =	 {Nara, Japan},
  year =	 2007,
  abstract =	 {The ability to localise a camera moving in a
                  previously unknown environment is desirable for a
                  wide range of applications. In computer vision this
                  problem is studied as monocular SLAM. Recent years
                  have seen improvements to the usability and
                  scalability of monocular SLAMsystems to the point
                  that they may soon find uses outside of laboratory
                  conditions. However, the robustness of these systems
                  to rapid camera motions (we refer to this quality as
                  agility) still lags behind that of tracking systems
                  which use known object models. In this paper we
                  attempt to remedy this. We present two approaches to
                  improving the agility of a keyframe-based SLAM
                  system: Firstly, we add edge features to the map and
                  exploit their resilience to motion blur to improve
                  tracking under fast motion. Secondly, we implement a
                  very simple inter-frame rotation estimator to aid
                  tracking when the camera is rapidly panning  and
                  demonstrate that this method also enables a
                  trivially simple yet effective relocalisation
                  method. Results show that a SLAM system combining
                  points, edge features and motion initialisation
                  allows highly agile tracking at a moderate increase
                  in processing time.  }
}

@Article{Knapp76,
  author =	 {C. Knapp and G. Carter},
  title =	 {The generalized correlatoon method for estimation of
                  time delay},
  journal =	 ASSP,
  year =	 1976,
  volume =	 24,
  number =	 4,
}

@InProceedings{Knight01iros,
  author =	 {J. Knight and A. Davison and I. Reid},
  title =	 {Towards constant time {SLAM} using postponement},
  booktitle =	 IROS,
  pages =	 {405-413},
  year =	 2001,
  c-Alireza =	 {The idea is to be able to postpone the observations
                  made in last frames, to a time that there is process
                  avilable for a full update of the state. The
                  solution is exact and gives the same result as
                  updating the whole map in every frame. Their
                  algorithm is still O(m^2) but it provides the
                  capability to run the full map update in the
                  background, and be able to collect more features and
                  do data association real time. The difference of
                  this paper with previous papers that use submaps and
                  postponement, is that the submap in previous papers
                  is provided geographically, while in this paper, the
                  submap is the set of recently visited features. }
}

@Article{Knight89,
  author =	 {T.W. Knight},
  title =	 {Color grammars: designing with lines and colors},
  journal =	 {Environment and Planning B: Planning and Design},
  year =	 1989,
  volume =	 16,
  pages =	 {417-449 },
}

@Article{Knight99,
  author =	 {T.W. Knight},
  title =	 {Shape grammars: six types},
  journal =	 {Environment and Planning B: Planning and Design},
  year =	 1999,
  volume =	 26,
  pages =	 {15-31 },
}

@Article{Knight99a,
  author =	 {T.W. Knight},
  title =	 {Shape grammars: five questions},
  journal =	 {Environment and Planning B: Planning and Design},
  year =	 1999,
  volume =	 26,
  pages =	 {477-501 },
}

@Article{Knuth68,
  author =	 {D.E. Knuth},
  title =	 {Semantics of context-free languages},
  journal =	 {Math. Sys. Theory},
  year =	 1968,
  volume =	 2,
  pages =	 {127-146}
}

@techreport{Koch84tr,
  author =	 {C. Koch and S. Ullman},
  fullauthor =	 {Christof Koch and Shimon Ullman},
  title =	 {Selecting One Among the Many: A Simple Network
                  Implementing Shifts in Selective Visual Attention},
  year =	 1984,
  institution =	 {Massachusetts Institute of Technology},
  address =	 {Cambridge, MA, USA},
  abstract =	 {This study addresses the question of how simple
                  networks can account for a variety of phenomena
                  associated with the shift of a specialized
                  processing focus across the visual scene. We address
                  in particular aspects of the dichotomy between the
                  preattentive-parallel and the attentive-serial modes
                  of visual perception and their hypothetical neuronal
                  implementations. Specifically, we propose the
                  following: (1) A number of elementary features, such
                  as color, orientation, direction of movement,
                  disparity etc. are represented in parallel in
                  different topographical maps, called the early
                  representation. (2) There exists a selective mapping
                  from this early representation into a more central
                  representation, such that at any instant the central
                  representation contains the properties of only a
                  single location in the visual scene, the {\it
                  selected} location. (3) We discuss some selection
                  rules that determine which location will be mapped
                  into the central representation. The major rule,
                  using the saliency or conspicuity of locations in
                  the early representation, is implemented using a
                  so-called Winner-Take-All network. A hierarchical
                  pyramid--like architecture is proposed for this
                  network. We suggest possible implementations in
                  neuronal hardware, including a possible role for the
                  extensive back-projection form the cortex to the
                  LGN.},
}

@article{Koch93pami,
  title =	 {{Dynamic 3-D scene analysis through synthesis
                  feedback control}},
  author =	 {Koch, R.},
  journal =	 PAMI,
  volume =	 {15},
  number =	 {6},
  pages =	 {556--568},
  year =	 {1993}
}

@InProceedings{Koch95iccv,
  author =	 {R. Koch},
  title =	 {3-D Surface Reconstruction from Stereoscopic Image
                  Sequences},
  booktitle =	 ICCV,
  year =	 1995,
  month =	 {June},
}

@Article{Koch97,
  author =	 {W. Koch and G. van Keuk},
  title =	 {Multiple Hypothesis Track Maintenance with Possibly
                  Unresolved Measurements},
  journal =	 AES,
  year =	 1997,
  volume =	 33,
  number =	 3,
  pages =	 {589--601},
}

@InProceedings{Koch98eccv,
  author =	 "R. Koch and M. Pollefeys and L. Van Gool",
  title =	 {Multi viewpoint stereo from uncalibrated video
                  sequences},
  booktitle =	 ECCV,
  year =	 1998,
  pages =	 "55-71",
}

@InProceedings{Kodaka08iros,
  author =	 {Kenri Kodaka and Haruhiko Niwa and Yoshihiro
                  Sakamoto and Masaumi Otake and Yuki Kanemori and
                  Shigeki Sugano},
  title =	 {Pose Estimation of a Mobile Robot on a Lattice of
                  RFID Tags},
  booktitle =	 IROS,
  year =	 {2008},
  added-by =	 {Alireza}
}

@InProceedings{Kodaka08iros,
  author = {Kenri Kodaka and Haruhiko Niwa and Yoshihiro Sakamoto and Masaumi Otake and Yuki Kanemori and Shigeki Sugano},
  title = {Pose Estimation of a Mobile Robot on a Lattice of RFID Tags},
  booktitle = IROS,
  year = {2008},
  added-by = {Alireza}
}

@article{Koenderink91,
  AUTHOR =	 "Koenderink, J.J. and vanDoorn, A.J.",
  TITLE =	 "Affine Structure from Motion",
  JOURNAL =	 "Journal of the Optical Society of America A",
  VOLUME =	 8,
  YEAR =	 1991,
  NUMBER =	 2,
  PAGES =	 "377-385"
}

@InProceedings{Koenig02icra,
  author =	 {Sven Koenig and Maxim Likhachev},
  title =	 {Improved Fast Replanning for Robot Navigation in
                  Unknown Terrain},
  booktitle =	 ICRA,
  year =	 2002,
}

@inproceedings{Kohli05iccv,
  author =	 {P. Kohli and P. H. S. Torr},
  TITLE =	 {Efficiently Solving Dynamic Markov Random Fields
                  using Graph Cuts},
  BOOKTITLE =	 ICCV,
  YEAR =	 2005,
  PAGES =	 {922--929},
}

@Article{Kolaitis00css,
  author =	 {P.G. Kolaitis and M.Y. Vardi},
  fullauthor =	 {Phokion G. Kolaitis and Moshe Y. Vardi},
  title =	 {Conjunctive-Query Containment and Constraint
                  Satisfaction},
  journal =	 {Journal of Computer and System Sciences},
  year =	 2000,
  volume =	 61,
  number =	 2,
  pages =	 {302--332},
  month =	 {October},
  r-Gottlob00ai ={Evaluating Boolean conjunctive queries, and deciding
                  constraint satisfaction can be also recast as the
                  same fundamental algebraic problem of deciding
                  whether, given two finite relational structures A
                  and B , there exists a homomorphism f : A -> B},
}

@Article{Koller93,
  author =	 "D Koller and K Daniilidis and H.-H. Nagel",
  title =	 "Model-Based Object Tracking in Monocular Image
                  Sequences of Road Traffic Scenes",
  journal =	 IJCV,
  year =	 1993,
  volume =	 10,
  number =	 3,
  pages =	 "257-281",
}

@InProceedings{Koller94,
  author =	 "D. Koller and Joseph W. Weber and Jitendra Malik",
  booktitle =	 ECCV,
  title =	 "Robust Multiple Car Tracking with Occlusion
                  Reasoning",
  year =	 1994,
  url =
                  "http://robotics.eecs.berkeley.edu/~ftp/pub/koller/eccv-94.ps.Z",
  month =	 May,
  pages =	 "189--196",
  publisher =	 "LNCS 800, Springer-Verlag",
  scope =	 "model",
}

@InProceedings{Koller94icpr,
  author =	 {D. Koller and J. Weber and T. Huang and J. Malik and
                  G. Ogasawara and B. Rao and S. Russell},
  title =	 {Towards Robust Automatic Traffic Scene Analysis in
                  Real-Time},
  booktitle =	 ICPR,
  pages =	 {126-131},
  year =	 1994,
  abstract =	 { Automatic symbolic traffic scene analysis is essen-
                  tial to many areas of IVHS (Intelligent Vehicle
                  High- way Systems). Traffic scene information can be
                  used to optimize traffic flow during busy periods,
                  identify stalled vehicles and accidents, and aid the
                  decision- making of an autonomous vehicle
                  controller. Improve- ments in technologies for
                  machine vision-based surveil- lance and high-level
                  symbolic reasoning have enabled us to develop a
                  system for detailed, reliable traffic scene
                  analysis. The machine vision component of our system
                  employs a contour tracker and an affine motion model
                  based on Kalman filters to extract vehicle
                  trajectories over a sequence of traffic scene
                  images. The symbolic reasoning component uses a
                  dynamic belief network to make inferences about
                  traffic events such as vehicle lane changes and
                  stalls. In this paper, we discuss the key tasks of
                  the vision and reasoning components as well as their
                  integration into a working prototype. Prelim- inary
                  results of an implementation on special purpose
                  hardware using C-40 Digital Signal Processors show
                  that near real-time performance can be achieved
                  with- out further improvements.},
  c-houdan =	 {Kalman filter-based adaptive background model}
}

@inproceedings{Koller97realtime,
  author =	 "D. Koller and G. Klinker and E. Rose and D. Breen
                  and R. Whitaker and M. Tuceryan",
  title =	 "Real-time {Vision-Based} {C}amera {T}racking for
                  {A}ugmented {R}eality {A}pplications",
  booktitle =	 "{ACM} Symposium on Virtual Reality Software and
                  Technology",
  publisher =	 "ACM Press",
  address =	 "New York, NY",
  editor =	 "Daniel Thalmann",
  year =	 1997,
  url =		 "citeseer.nj.nec.com/koller97realtime.html"
}

@Book{Koller??book,
  author =	 {D. Koller and N. Friedman},
  fullauthor =	 {Daphne Koller and Nir Friedman},
  title =	 {Bayesian Networks and Beyond},
  publisher =	 {?},
  year =	 {?},
  note =	 {Unpublished draft},
  quotes =	 { In fact, for a long time there was a widely held
                  misconception that the line between poly- trees and
                  other networks was a sharp cutoff, so that only
                  inference in polytrees was tractable. ... Thus, if
                  we find a chordal graph that contains the moralized
                  graph , we can use it as the basis for inference on
                  . The process of turning a graph into a chordal
                  graph is also called
                  triangulation. ... Historically, largely due to the
                  initial popularity of the polytree algorithm, the
                  conditioning approach has been mostly used in the
                  case where the transformed network is a
                  polytree. ... one might wonder why anyone bothers
                  with the con- ditioning algorithm. There are two
                  main reasons. First, variable elimination gains its
                  computational savings from caching factors computed
                  as intermediate results. The second reason for using
                  conditioning is that it forms the basis for a useful
                  approximate inference algorithm.},
  c-dellaert =	 {ch 8: fill edges and induced raph resulting from
                  elimination. They define the width of an induced
                  graph to be the number of nodes in the largest
                  clique in the graph minus 1. Every induced graph is
                  chordal (no ref). Any choral graph admits a PEO. MCS
                  as a (not so good) heuristic. Many heuristics:
                  minimum fill/discrepancy/size/weight. Conditioning
                  as an alternative to elimination. Making use of
                  structure e.g. noisy OR on many variables, trees, or
                  rules. },
}

@InProceedings{Kolmogorov02b,
  author =	 {V. Kolmogorov and R. Zabih},
  title =	 {Multi-camera Scene Reconstruction via Graph Cuts},
  booktitle =	 ECCV,
  year =	 2002,
}

@InProceedings{Kolmogorov02eccv,
  author =	 {V. Kolmogorov and R. Zabih,},
  title =	 {What energy functions can be minimized via graph
                  cuts ?},
  booktitle =	 ECCV,
  year =	 2002,
}

@InCollection{Kolodner96,
  author =	 "J.L. Kolodner and D.B. Leake",
  title =	 "A Tutorial Introduction to Case-Based Reasoning",
  booktitle =	 "Case-Based Reasoning: Experiences, Lessons, and
                  Future Directions",
  year =	 1996,
  editor =	 "D.B. Leake",
  publisher =	 MIT,
}

@inproceedings{Koltun00,
  author =	 {Vladlen Koltun and Yiorgos Chrysanthou and Daniel
                  Cohen-Or},
  title =	 {Virtual Occluders: An Efficient Intermediate PVS
                  Representation.},
  booktitle =	 {Rendering Techniques},
  year =	 2000,
  pages =	 {59-70},
  crossref =	 {DBLP:conf/rt/2000},
  bibsource =	 {DBLP, http://dblp.uni-trier.de}
}

@Article{Kong94,
  author =	 {A. Kong and J. S. Liu and W. H. Wong},
  title =	 {Sequential imputations and {Bayesian} missing data
                  problems},
  journal =	 {Journal of the American Statistical Association},
  year =	 1994,
  volume =	 {89(425)},
  pages =	 {278-288},
}

@Article{Koning81,
  author =	 {H. Koning and J. Eizenberg},
  title =	 {The language of the prairie: {F}rank {L}loyd
                  {W}right's prairie houses},
  journal =	 {Environment and Planning B},
  year =	 1981,
  volume =	 8,
  pages =	 {295-323},
}

@InProceedings{Konolige04aaai,
  author =	 {K. Konolige},
  title =	 {Large-scale map-making},
  crossref =	 {_AAAI04},
}

@InProceedings{Konolige04iser,
  author =	 {K. Konolige and D. Fox and C. Ortiz and A. Agno and
                  M. Eriksen and B. Limketai and J. Ko and B. Morriset
                  and D. Schulz and R. Vincent},
  title =	 {Centibots: Very large scale distributed robotic
                  teams},
  booktitle =	 {Proceedings of the International Symposium on
                  Experimental Robotics},
  address =	 {Singapore},
  year =	 2004,
}

@InProceedings{Konolige06iser,
  author =	 {K. Konolige and M. Agrawal and R.C. Bolles and
                  C. Cowan and M. Fischler and B.P. Gerkey},
  fullauthor =	 {Kurt Konolige and Motilal Agrawal and Robert
                  C. Bolles and Cregg Cowan and Martin Fischler and
                  Brian P. Gerkey},
  title =	 {Outdoor Mapping and Navigation using Stereo Vision},
  booktitle =	 ISER,
  location =	 {Rio de Janeiro, Brazil},
  month =	 {Jul},
  year =	 2006,
  abstract =	 {none},
  quotes =	 {The most important geometric analysis is finding the
                  ground plane.},
  c-kaess =	 {Overview and results of SRIs DARPA LAGR software,
                  including visual odometry and mapping;},
}

@InProceedings{Konolige07icra,
  author =	 {K. Konolige and M. Agrawal},
  fullauthor =	 {Kurt Konolige and Motilal Agrawal},
  title =	 {Frame-Frame Matching for Realtime Consistent Visual
                  Mapping},
  booktitle =	 ICRA,
  location =	 {Rome, Italy},
  pages =	 {2803-2810},
  month =	 {Apr},
  year =	 2007,
  abstract =	 {Many successful indoor mapping techniques employ
                  frame-to-frame matching of laser scans to produce
                  detailed local maps, as well as closing large
                  loops. In this paper, we propose a framework for
                  applying the same techniques to visual imagery,
                  matching visual frames with large numbers of point
                  features. The relationship between frames is kept as
                  a nonlinear measurement, and can be used to solve
                  large loop closures quickly. Both monocular
                  (bearing-only) and binocular vision can be used to
                  generate matches. Other advantages of our system are
                  that no special landmark initialization is required,
                  and large loops can be solved very quickly.},
  c-kaess =	 {Uses frame to frame matching similar to
                  scan-matching in laser-based mapping to obtain a
                  sparse optimization problems without landmarks, and
                  uses sparse bundle adjustment to fully optimize the
                  result. No automatic loop closing yet, but can be
                  incorporated when using better features.},
}

@InProceedings{Konolige07vslam,
  author =	 {K. Konolige and M. Agrawal and J. Sola},
  fullauthor =	 {Kurt Konolige and Motilal Agrawal and Joan Sola},
  title =	 {Large Scale Visual Odometry for Rough Terrain},
  booktitle =	 {IROS visual SLAM workshop},
  location =	 {San Diego},
  month =	 {Oct},
  year =	 2007,
  abstract =	 {Motion estimation from imagery, sometimes called
                  visual odometry, is a well-known process. However,
                  it is difficult to achieve good performance using
                  standard techniques. In this paper, we present the
                  results of several years of work on an integrated
                  system to localize a mobile robot in rough outdoor
                  terrain using visual odometry, with an increasing
                  degree of precision. We discuss issues that are
                  important for realtime, high-precision performance:
                  choice of features, matching strategies, incremental
                  bundle adjustment, and filtering with inertial
                  measurement sensors. Using data with ground truth
                  from an RTK GPS system, we show experimentally that
                  our algorithms can track motion, in off-road
                  terrain, over distances of 10 km, with an error of
                  less than 10 m (0.1\%).},
  c-kaess =	 {Uses stereo and IMU. Incremental sparse bundle
                  adjustment, basically fixed-lag smoothing. Claims
                  less than 10 meters error over 10km!},
}

@InProceedings{Konolige99,
  author =	 {Konolige, K. and Gutmann, J.-S.},
  title =	 {Incremental Mapping of Large Cyclic Environments},
  booktitle =	 {International Symposium on Computational
                  Intelligence in Robotics and Automation (CIRA'99)},
  year =	 1999
}

@InProceedings{Konolige99ijcai,
  author =	 {K. Konolige},
  title =	 {Markov localization using correlation},
  booktitle =	 IJCAI,
  year =	 1999,
}

@InProceedings{Kortenkamp94aaai,
  author =	 {Kortenkamp, D. and Weymouth, T.},
  title =	 {Topological mapping for mobile robots using a
                  combination of sonar and vision sensing},
  booktitle =	 {Proceedings of the Twelfth National Conference on
                  Artificial Intelligence},
  pages =	 {979--984},
  year =	 1994,
}

@InProceedings{Kortenkamp94nasa,
  author =	 {D. Kortenkamp},
  title =	 {Perception for mobile robot navigation: a survey of
                  the state of the art},
  booktitle =	 {Proc. NASA dual-use space technology transfer
                  conference},
  year =	 1994,
}

@PhdThesis{Kortenkamp94thesis,
  author =	 {D. Kortenkamp},
  title =	 {Cognitive maps for mobile robots: {A} representation
                  for mapping and navigation},
  school =	 {University of Michigan},
  year =	 1993,
}

@PROCEEDINGS{Kortenkamp97book,
  TITLE =	 {{AI}-based Mobile Robots: Case studies of successful
                  robot systems},
  EDITOR =	 {Kortenkamp, D. and Bonasso, R.P. and Murphy, R.},
  PUBLISHER =	 MIT,
  YEAR =	 1998
}

@Article{Kosaka92,
  author =	 {A. Kosaka and A. Kak},
  title =	 {Fast vision-guided mobile robot navigation using
                  model-based reasoning and prediction of
                  uncertainties},
  journal =	 CVIU,
  year =	 1992,
  volume =	 56,
  number =	 3,
  pages =	 {271-329},
}

@InProceedings{Kosaka95,
  author =	 {A. Kosaka and J. Pan},
  title =	 {Purdue experiments in model-based vision for hallway
                  navigation},
  booktitle =	 {Workshop on Vision for Robotics at IROS 95},
  year =	 1995,
}

@article{Kosecka02eccv,
  author =	 "J. Kosecka and W. Zhang",
  title =	 "Video {C}ompass",
  journal =	 ECCV,
  year =	 2002,
  pages =	 "476--491"
}

@InProceedings{Kosecka04,
  author =	 {J. Kosecka and F. Li},
  title =	 {Vision Based Markov Localization},
  booktitle =	 {ICRA},
  year =	 2004,
}

@inproceedings{Kosecka04course,
  author =	 {J. Kosecka and Y. Ma and S. Soatto and R. Vidal},
  title =	 {Multiple-view geometry for image-based modeling},
  booktitle =	 {ACM SIGGRAPH 2004 Course Notes},
  year =	 2004,
  location =	 {Los Angeles, CA},
  doi =		 {http://doi.acm.org/10.1145/1103900.1103909},
  publisher =	 {ACM Press},
  address =	 {New York, NY, USA},
}

@Article{Kosecka05cviu,
  author =	 {J. Kosecka and W. Zhang},
  fullauthor =	 {Jana Kosecka and Wei Zhang},
  title =	 {Extraction, matching, and pose recovery based on
                  dominant rectangular structures},
  journal =	 CVIU,
  year =	 2005,
  volume =	 100,
  number =	 3,
  pages =	 {274--293},
  month =	 {December},
  abstract =	 {Man-made environments possess many regularities
                  which can be efficiently exploited for image based
                  rendering as well as robotic navigation and
                  localization tasks. In this paper we present an
                  approach for automatic extraction of dominant
                  rectangular structures from a single view and show
                  how they facilitate the recovery of camera pose,
                  planar structure and matching across widely
                  separated views. In the presented approach the
                  rectangular hypothesis formation is based on a
                  higher level information encoded by the presence of
                  orthogonal vanishing directions, the dominant
                  rectangular structures can be detected and matched
                  despite the presence of multiple repetitive
                  structures often encountered in a variety of
                  buildings. Different stages of the approach are
                  demonstrated on various examples of images of
                  indoors and outdoors structured environments.},
  c-dellaert =	 {extracts vp, rectangular structure extraction (line
                  segment merging, hypothesis generation,
                  verification), camera pose recovery (f, homography
                  R,t), match rectangular structures (warp into
                  canonical view, geometric consistency), then find
                  relative pose wrpt other piece of plane. So, they
                  basically do the same as out ICCV submission,
                  except: we have automatic texture segmentation, we
                  do wallpaper groups, match based on motifs, find
                  repeated poses, intersect poses, work against a
                  known 3D model for geotagging},
}

@article{Kosowsky94,
  author =	 "Kosowsky, J. J. and Yuille, A. L.",
  title =	 "The Invisible Hand Algorithm - Solving the
                  Assignment Problem with Statistical Physics",
  journal =	 "Neural Networks",
  volume =	 "7",
  number =	 "3",
  pages =	 "477-490",
  year =	 "1994"
}

@Article{Kostelec00,
  author =	 {P. Kostelec and D. Maslen and D. Rockmore and
                  D. Healy},
  title =	 {Computational Harmonic Analysis for Tensor Fields on
                  the Two-Sphere},
  journal =	 {J. Computational Physics},
  year =	 2000,
  volume =	 162,
  pages =	 {514 - 535},
}

@TechReport{Kostelec07soft,
  author =	 {P. Kostelec and D. Rockmore},
  title =	 {{SOFT}: {SO(3)} {Fourier} Transforms},
  institution =	 {Department of Mathematics, Darthmouth College},
  year =	 2007,
}

@Article{Kostelec07soft,
  journal =	 {J. Computational Physics},
  year =	 2000,
  volume =	 162,
  pages =	 {514 - 535},
}

@INPROCEEDINGS{Kouzoubov04,
  AUTHOR =	 {K. Kouzoubov and D. Austin},
  TITLE =	 {Hybrid Topological/Metric Approach to {SLAM}},
  BOOKTITLE =	 ICRA,
  PAGES =	 {872--877},
  YEAR =	 2004,
}

@Book{Kozen91,
  author =	 "Dexter C. Kozen",
  title =	 "The design and analysis of algorithms",
  publisher =	 "Springer-Verlag",
  year =	 1991,
}

@InProceedings{Krauthausen06rss,
  author =	 {P. Krauthausen and F. Dellaert and A. Kipp},
  fullauthor =	 {Peter Krauthausen and Frank Dellaert and Alexander
                  Kipp},
  title =	 {Exploiting Locality by Nested Dissection For Square
                  Root Smoothing and Mapping},
  booktitle =	 RSS,
  year =	 2006,
  abstract =	 {The computational complexity of SLAM is dominated by
                  the cost of factorizing a matrix derived from the
                  measurements into a square root form, which has
                  cubic complexity in the worst case. However, the
                  matrices associated with the full SLAM problem are
                  typically very sparse, as opposed to the dense
                  problems one obtains in a filtering context. Hence
                  much faster, sparse factorization algorithms can be
                  used. Furthermore, the cost can be further reduced
                  by choosing a good order in which to eliminate
                  variables during the factorization process, leading
                  to more or less fill-in. In particular, in this
                  paper we investigate how a nested dissection
                  ordering method can provably improve the performance
                  of the full SLAM algorithm. We show that the
                  computational complexity for the factorization of a
                  large class of measurement matrices occurring in the
                  SLAM problem can be tightly bound under reasonable
                  assumptions.},
  c-kaess =	 {This paper analyzes the complexity of planar SLAM
                  based on nested dissection. A quick comparison for
                  planar SLAM examples shows only a marginal advantage
                  of AMD ordering over nested dissection, but the
                  latter is easier to analyze. Based on existing
                  theorems, it is shown that planar SLAM with nested
                  dissection has fill-in O(n log n) and time
                  complexity O(n^1.5), but with potentially large
                  constant factors. While SLAM graphs even in planar
                  environments are not exactly planar, they can be
                  "compressed" (graph theory) into a meta graph that
                  is exactly planar. An urban map serves as
                  example. Special cases with linear complexity are
                  environments of bounded size (first eliminate all
                  poses - Schur complement trick), exploration without
                  loop closure, and fixed sensor networks (first
                  eliminate all structure).},
}

@Book{Kreher99,
  author =	 {D.L. Kreher and D.R. Stinson},
  title =	 {Combinatorial Algorithms: Generation, Enumeration,
                  and Search},
  publisher =	 {CRC Press},
  year =	 {1999},
}

@InCollection{KriegBrueckner98sc,
  author =	 {Krieg-Br\"{u}ckner B. and R\"{o}fer T. and Carmesin
                  H.-O. and M\"{u}ller R.},
  title =	 {A taxonomy of spatial knowledge for navigation and
                  its application to the {Bremen} autonomous
                  wheelchair},
  booktitle =	 {Symposium on Spatial cognition : an
                  interdisciplinary approach to representing and
                  processing spatial knowledge},
  pages =	 {372--397},
  year =	 1998,
  volume =	 1404,
  number =	 489,
  series =	 {Lecture notes in computer science},
  address =	 {Trier},
  Abstract =	 {A new taxonomy is proposed that relates different
                  navigational behaviors in a hierarchical and
                  compositional way. Elementary navigation tactics are
                  combined to tactical navigation in routes; landmarks
                  in space are contrasted to routemarks in networks of
                  passages. Survey knowledge comes in at the level of
                  strategic navigation. The Bremen Autonomous
                  Wheelchair is then presented as a vehicle for
                  experimentation in robotics, both to model
                  biologically plausible navigational behaviors and to
                  develop efficient navigational mechanisms for a
                  technical application. The implementation on the
                  autonomous system is based on the use of basic
                  behaviors and the identification of routemarks. The
                  actual recognition of artificial routemarks is
                  described and early results of the current work on
                  the identification of natural 3-D marks are
                  presented.},
  c-dellaert =	 {Should read more carefully},
}

@InProceedings{Kriegman87,
  author =	 {D.J. Kriegman and E. Triedl and T. Binford},
  title =	 {A mobile robot: sensing, planning and locomotion},
  booktitle =	 ICRA,
  year =	 1987,
  pages =	 {402-408},
}

@Article{Kriegman89,
  author =	 {D.J. Kriegman and E. Triendl and T.O. Binford},
  title =	 {Stereo Vision and Navigation in Buildings for Mobile
                  Robots},
  journal =	 TRA,
  year =	 1989,
  volume =	 5,
  number =	 6,
  pages =	 {792-803},
  r-Dailey06icarcv ={Early VSLAM systems did use sparse features, but
                  they typically compressed the map to 2D. For
                  example, Kriegman, Triendl, and Binford? system
                  [this] uses a stereo sensor to extract vertical
                  lines from the environment. Observed lines are used
                  to reduce odometric uncertainty using an extended
                  Kalman filter (EKF), then the observations are in
                  turn used to update an environment map containing 2D
                  point features representing the observed vertical
                  lines. },
}

@Article{Kriegman89,
  author =	 {D.J. Kriegman and E. Triendl and T.O. Binford},
  title =	 {Stereo vision and navigation in buildings for mobile
                  robots},
  journal =	 TRA,
  year =	 1989,
  volume =	 5,
  number =	 6,
  pages =	 {792-803},
}

@Article{Krishnamurti80,
  author =	 {R. Krishnamurti},
  title =	 {The Arithmetic of Shapes},
  journal =	 {Environment and Planning B: Planning and Design},
  year =	 1980,
  volume =	 7,
  pages =	 {463-484 },
}

@Article{Krishnamurti92,
  author =	 {R. Krishnamurti and C.F. Earl},
  title =	 {Shape Recognition in Three Dimensions},
  journal =	 {Environment and Planning B: Planning and Design},
  year =	 1992,
  volume =	 19,
  pages =	 {585-603 },
}

@article{Krose01,
  author =	 {B.J.A. Krse and N. Vlassis and R. Bunschoten and
                  Y. Motomura},
  title =	 {A probabilistic model for appearance-based robot
                  localization},
  journal =	 {Image and Vision Computing},
  volume =	 19,
  number =	 6,
  pages =	 {381--391},
  year =	 2001,
}

@Article{Krose04ram,
  author =	 {Kr{\"o}se, B. and Bunschoten, R. and Hagen ST and
                  Terwijn, B. and Vlassis, N.},
  title =	 {Household robots look and learn: environment
                  modeling and localization from an omnidirectional
                  vision system},
  journal =	 {Robotics \& Automation Magazine},
  year =	 2004,
  volume =	 11,
  number =	 4,
  pages =	 {45-52},
  month =	 {Dec},
  note =	 {Special Issue on Panoramic Robotics}
}

@InProceedings{Krose99,
  author =	 {B.J.A. Kr{\"o}se and R. Bunschoten},
  title =	 {Probabilistic localization by appearance models and
                  active vision},
  booktitle =	 ICRA,
  pages =	 {2911-2916},
  year =	 1999,
  month =	 {May},
  organization = {IEEE},
}

@InProceedings{Krotkov89,
  author =	 {E. Krotkov},
  title =	 {Mobile robot localization using a single image},
  booktitle =	 ICRA,
  year =	 1989,
}

@article{Kschischang01it,
  author =	 "F.R. Kschischang and B.J. Frey and H-A. Loeliger",
  title =	 "Factor Graphs and the Sum-Product Algorithm",
  journal =	 IT,
  volume =	 47,
  number =	 2,
  month =	 "February",
  year =	 2001,
  abstract =	 {Algorithms that must deal with complicated global
                  functions of many variables often exploit the manner
                  in which the given functions factor as a product of
                  `local' functions, each of which depends on a subset
                  of the variables. Such a factorization can be
                  visualized with a bipartite graph that we call a
                  factor graph. In this tutorial paper, we present a
                  generic message-passing algorithm, the sum-product
                  algorithm, that operates in a factor
                  graph. Following a single, simple computational
                  rule, the sum-product algorithm computes---either
                  exactly or approximately---various marginal
                  functions derived from the global function. A wide
                  variety of algorithms developed in artificial
                  intelligence, signal processing, and digital
                  communications can be derived as specific instances
                  of the sum-product algorithm, including the
                  forward/backward algorithm, the Viterbi algorithm,
                  the iterative `turbo' decoding algorithm, Pearl's
                  belief propagation algorithm for Bayesian networks,
                  the Kalman filter, and certain fast Fourier
                  transform (FFT) algorithms.},
  quotes =	 {Wiberg \cite{Wiberg96thesis} introduced "hidden"
                  (latent) state variables and also suggested
                  applications beyond coding. Factor graphs take these
                  graph-theoretic models one step further, by applying
                  them to functions. From the factor-graph perspective
                  (as we will describe in Section III-A), a Tanner
                  graph for a code represents a particular
                  factorization of the characteristic (indicator)
                  function of the code.},
  c-dellaert =	 {No connection with linear algebra, CSP
                  etc. Application examples include behavioral
                  modeling, linear codes, trellises, state-space
                  models, a posteriori distributions, Markov chains,
                  and hidden Markov models. Algorithms are
                  forward/backward, Viterbi, and Kalman filtering, and
                  various coding schemes. There is a nice section on
                  graph transformations, including one that yields the
                  FFT (by factorizing the n and k indices in terms of
                  auxiliary variables).}
}

@Article{Kschischang03spm,
  author =	 {F.R. Kschischang},
  title =	 {Codes defined on graphs},
  journal =	 {IEEE Signal Proc. Mag.},
  year =	 {2003},
  volume =	 {41},
  pages =	 {118-125},
  month =	 {Aug.},
  r-Loeliger04spm ={The later introduction of factor graphs
                  \citep{Frey97ccc,Kschischang03spm} may be viewed as
                  a further elaboration of the ideas by Wiberg et
                  al. In the present article, we will use Forney-style
                  factor graphs (FFGs), which were introduced in
                  \citep{Forney01it} (and there called "normal
                  graphs").}
}

@article{Kuipers00ai,
  author =	 {B.J. Kuipers},
  year =	 2000,
  title =	 {The {S}patial {S}emantic {H}ierarchy},
  journal =	 {Artificial {I}ntelligence},
  volume =	 119,
  pages =	 {191--233},
  Abstract =	 {The Spatial Semantic Hierarchy is a model of
                  knowledge of large-scale space consisting of
                  multiple interacting representations, both
                  qualitative and quantitative. The SSH is inspired by
                  the properties of the human cognitive map, and is
                  intended to serve both as a model of the human
                  cognitive map and as a method for robot exploration
                  and map-building. The multiple levels of the SSH
                  express states of partial knowledge, and thus enable
                  the human or robotic agent to deal robustly with
                  uncertainty during both learning and
                  problem-solving. The control level represents useful
                  patterns of sensorimotor interaction with the world
                  in the form of trajectory-following and
                  hill-climbing control laws leading to locally
                  distinctive states. Local geometric maps in local
                  frames of reference can be constructed at the
                  control level to serve as observers for control laws
                  in particular neighborhoods. The causal level
                  abstracts continuous behavior among distinctive
                  states into a discrete model consisting of states
                  linked by actions. The topological level introduces
                  the external ontology of places, paths and regions
                  by abduction, to explain the observed pattern of
                  states and actions at the causal level. Quantitative
                  knowledge at the control, causal and topological
                  levels supports a ?atchworkmap?of local geometric
                  frames of reference linked by causal and topological
                  connections. The patchwork map can be merged into a
                  single global frame of reference at the metrical
                  level when sufficient information and computational
                  resources are available. We describe the assumptions
                  and guarantees behind the generality of the SSH
                  across environments and sensorimotor
                  systems. Evidence is presented from several partial
                  implementations of the SSH on simulated and physical
                  robots.},
  quotes =	 {This paper focuses primarily on large-scale space,
                  which is defined as space whose structure is at a
                  much larger scale than the sensory horizon of the
                  agent. .. Human knowledge of large-scale space is
                  sometimes called the cognitive map, though it is in
                  many ways not map-like \cite{Kuipers82eb}. .. We
                  propose that knowledge of large-scale space consists
                  of several distinct but interacting representations,
                  each with its own ontology, collectively known as
                  the Spatial Semantic Hierarchy (SSH)... The sensory
                  level is the interface to the agent? sensory
                  system. .. The control level describes the world in
                  terms of continuous control laws that bind the agent
                  and its environment into a dynamical system .. The
                  causal level abstracts the continuous world, and the
                  agent? behavior within it, to a discrete model
                  described in terms of sensory views, actions, and
                  the causal relations among them. .. The topological
                  level introduces the ontology of places, paths and
                  regions, and their connectivity, order and
                  containment relations .. The metrical level
                  represents a global geometric map of the environment
                  in a single frame of reference, which may be useful
                  but is seldom essential.},
  c-dellaert =	 {Ben's seminal paper},
}

@inproceedings{Kuipers02aaai,
  author =	 {B. Kuipers and P. Beeson},
  title =	 {Bootstrap learning for place recognition},
  crossref =	 {_AAAI02},
  pages =	 {174--180},
  c-ananth =	 {Kuipers and Beeson [Kuipers02aaai] apply a
                  clustering algorithm to the measurements to identify
                  distinctive places, thus providing a
                  maximum-likelihood solution to resolving ambiguity.},
}

@InProceedings{Kuipers04icra,
  author =	 {B.J. Kuipers and J. Modayil and P. Beeson and
                  M. MacMahon and F. Savelli},
  fullauthor =	 {Benjamin Kuipers and Joseph Modayil and Patrick
                  Beeson and Matt MacMahon and Francesco Savelli},
  year =	 2004,
  title =	 {Local metrical and global topological maps in the
                  Hybrid Spatial Semantic Hierarchy},
  booktitle =	 ICRA,
  abstract =	 {Topological and metrical methods for representing
                  spatial knowledge have complementary strengths. We
                  present a hybrid extension to the Spatial Semantic
                  Hierarchy that combines their strengths and avoids
                  their weaknesses. Metrical SLAM methods are used to
                  build local maps of small-scale space within the
                  sensory horizon of the agent, while topological
                  methods are used to represent the structure of
                  large-scale space. We describe how a local
                  perceptual map is analyzed to identify a local
                  topology description and is abstracted to a
                  topological place. The mapbuilding method creates a
                  set of topological map hypotheses that are
                  consistent with travel experience. The set of maps
                  is guaranteed under reasonable assumptions to
                  include the correct map. We demonstrate the method
                  on a real environment with multiple nested
                  large-scale loops.},
  quotes =	 {We use the term local perceptual map (LPM) for the
                  metrical map resulting from applying an online SLAM
                  method to a simple local region. .. The hybrid SSH
                  has several advantages that aid online
                  mapbuilding. First, local metrical motion planning
                  and obstacle avoidance can take place within the
                  LPM. Second, metrical localization can be done
                  quickly after entering a place neighborhood, rather
                  than requiring physical hill-climbing to a
                  distinctive pose. If resources needed for metrical
                  localization become unavailable, navigation can fall
                  back on hill-climbing as in the basic SSH. Third,
                  structural ambiguity due to large loops or false
                  positive place matches can be represented compactly
                  by a set of alternative topological maps, some of
                  which may be discarded by future observations. .. A
                  gateway is a boundary between qualitatively
                  different regions of the environment: in the basic
                  SSH, the boundary between trajectory-following and
                  hill-climbing applicability.},
  r-Kuipers08chapter ={Having defined large-scale space as space whose
                  structure is larger than the sensory horizon, it is
                  natural to define small-scale space as space whose
                  structure is within the sensory horizon. Small-scale
                  space is described by a local perceptual map that is
                  metrically accurate and is constructed directly from
                  sensory input. Recently developed SLAM methods are
                  well suited for creating such a local
                  perceptualmap.We avoid the problem of closing large
                  loops by confining the map to the agent? local
                  perceptual surround, where we can apply the
                  strengths of existing SLAM methods. When reasoning
                  about small-scale space, we are concerned only with
                  the frame of reference of the local perceptual map,
                  and not with its inevitable drift with respect to
                  the world frame of reference. We call the resulting
                  combined model of large-scale and small-scale space,
                  the hybrid SSH.},
  c-dellaert =	 {Interesting, did not read all details of
                  constructing the topological map. Our work maintains
                  sample and hence avoids making choices.},
}

@InCollection{Kuipers08chapter,
  author =	 {B.J. Kuipers},
  fullauthor =	 {Benjamin Kuipers},
  title =	 {An intellectual history of the spatial semantic
                  hierarchy},
  booktitle =	 {Robot and Cognitive Approaches to Spatial Mapping},
  year =	 {2008},
  publisher =	 {Springer Verlag},
  quotes =	 {Motion among distinctive states avoids the problem
                  of cumulative error that typically plagues robot
                  mapping. There is no attempt to maintain an accurate
                  location in a single global frame of
                  reference. Rather, the purpose of an action is to
                  move reliably from one distinctive state to another
                  one. Any error that accumulates during
                  trajectory-following is eliminated by the
                  hill-climbing step, as long as the error is not so
                  large as to miss entirely the basin of attraction of
                  the destination distinctive state.},
  quotes =	 {The focus of the TOUR model was primarily on the
                  role of topological knowledge of space. The focus of
                  the Basic SSH was on the role of control laws and
                  dynamical systems. The focus of the Hybrid SSH is on
                  the role of metrical knowledge and perception.},
  c-dellaert =	 {Cool overview, fairly self-referential obviously},
}

@PhdThesis{Kuipers77thesis,
  author =	 {B.J. Kuipers},
  year =	 1977,
  title =	 {Representing Knowledge of Large-Scale Space},
  school =	 {Massachusetts Institute of Technology},
  address =	 {Cambridge, Massachusetts},
  note =	 {Published as MIT Artificial Intelligence Laboratory
                  TR 418, 1977.},
  abstract =	 {This dissertation presents a model of the knowledge
                  a person has about the spatial structure of a
                  large-scale environment: the ``cognitive map.'' The
                  functions of the cognitive map are to assimilate new
                  information about the environment, to represent the
                  current position, and to answer route-finding and
                  relative-position problems. This model (called the
                  TOUR model) analyzes the cognitive map in terms of
                  symbolic descriptions of the environment and
                  operations on those descriptions. Knowledge about a
                  particular environment is represented in terms of
                  route descriptions, a topological network of paths
                  and places, multiple frames of reference for
                  relative positions, dividing boundaries, and a
                  structure of containing regions. The current
                  position is described by the ``You Are Here''
                  pointer, which acts as a working memory and a focus
                  of attention. Operations on the cognitive map are
                  performed by inference rules which act to transfer
                  information among different descriptions and the
                  ``You Are Here'' pointer. The TOUR model shows how
                  the particular descriptions chosen to represent
                  spatial knowledge support assimilation of new
                  information from local observations into the
                  cognitive map, and how the cognitive map solves
                  route-finding and relative-position problems. A
                  central theme of this research is that the states of
                  partial knowledge supported by a representation are
                  responsible for its ability to function with limited
                  information or computational resources. The
                  representations in the TOUR model provide a rich
                  collection of states of partial knowledge, and
                  therefore exhibit flexible, ``common-sense''
                  behavior. },
  r-Kuipers08chapter ={One problem with the original TOUR model is
                  that the procedural level too thoroughly abstracts
                  away the agent? sensory input from the
                  environment. The route-direction-like input
                  representation was unable to express either gaps in
                  the sequence of experience or perceptual aliasing
                  (different places that look the same). .. A second
                  problem with the original TOUR model is that it
                  presupposes that the continuous experience of the
                  agent has already been abstracted to a discrete
                  sequence of states and transitions.},
  c-dellaert =	 {Very GOFAI, but very well thought-out. Must read in
                  depth one day :-)},
}


@article{Kuipers78cs,
  author =	 {B.J. Kuipers},
  title =	 {Modeling spatial knowledge},
  journal =	 {Cognitive Science},
  volume =	 2,
  pages =	 {129--153},
  year =	 1978,
  c-dellaert =	 {TOUR model}
}

@inproceedings{Kuipers79ijcai,
  author =	 {B. J. Kuipers},
  year =	 1979,
  title =	 {Commonsense knowledge of space: learning from
                  experience},
  booktitle =	 IJCAI,
  abstract =	 {The TOUR model is a computational model of human
                  commonsense knowledge of large-scale space. It shows
                  how observations are assimilated into a description,
                  from multiple perspectives of the spatial
                  environment. In this paper we propose a
                  representation for sensory events at a level suited
                  to this investigation, and an inference strategy by
                  which these sensory events are assimilated into
                  descriptions of spatial structure. We also discuss
                  the states of partial knowledge that occur during
                  the learning process and show that the
                  representation exhibits graceful degradation of
                  performance under resource limitations},
  r-Kuipers08chapter ={Part of solving this was to provide an explicit
                  representation for sensory experience [25]. A view
                  is an abstracted description of the sensory image
                  experienced by the agent at a particular state
                  (i.e., place, path, and direction).},
  c-dellaert =	 {View -action-> view "schema". Places as equivalence
                  classes of views under "rotate". Path is equivalence
                  class under "travel". Schema support (a) landmark
                  recognition, (b) Self-guided travel, (c) Mental
                  rehearsal. },
}

@article{Kuipers82eb,
  journal =	 {Environment and Behavior},
  Volume =	 14,
  Number =	 2,
  pages =	 {202-220},
  year =	 1982,
  title =	 {The "Map in the Head" Metaphor},
  author =	 {B.J. Kuipers},
  fullauthor =	 {Benjamin Kuipers},
  abstract =	 {The "Map in the Head" metaphor states that knowledge
                  of large-scale space is isomorphic to the
                  information stored in a graphical map: That is,
                  corresponding operations are used to store and
                  retrieve information. The purpose of this essay is
                  to look carefully at the "Map in the Head" metaphor
                  to see the limits of its applicability. There are
                  two types of experimental results that are difficult
                  to accommodate within this metaphor. First, instead
                  of being integrated into a single map, spatial
                  knowledge can fall into disconnected components,
                  with little or no relation between the
                  components. Second, knowledge of routes (and other
                  spatial facts) may be represented asymmetrically, so
                  that a route can be followed in one direction but
                  not in the other. The first set of results leads us
                  to replace the simple "Map in the Head" with a more
                  complex and sophisticated metaphor including
                  separate metrical and topological components. The
                  second set of results suggests that even the more
                  sophisticated "Map in the Head" is built from
                  computational structures that occasionally reveal
                  their nonmaplike properties. A computational model
                  is presented for assimilating observations gathered
                  during travel, first into a description of the
                  particular route, then into representations for the
                  topological and metrical features of the
                  environment.},
  c-dellaert =	 {Criticism of map in the head metaphor},
}



@InCollection{Kuipers83cognitive,
  author =	 {B. Kuipers},
  title =	 {The Cognitive Map: Could It Have Been Any Other
                  Way?},
  booktitle =	 "Spatial Orientation: Theory, Research, and
                  Application",
  publisher =	 "Plenum Press",
  year =	 1983,
  editor =	 "H. L. Pick Jr. and L. P. Acredolo",
  address =	 "New York",
  c-dellaert =	 {Very nice paper with argument from design. Approach:
                  design a robot. Start with "Map in head". Does not
                  work as odometry noisy, expensive to correct. Map
                  cannot express partial knowledge. Maybe "Atlas in
                  the head": multiple frames of reference? Add edges
                  to indicate connectivity. Must be separate from
                  metric info, as can be either/and/none. We can now
                  plan fast, metric provides heuristic. Then add a
                  containment hierarchy. Still need to bridge gap to
                  views/actions.},
  c-ananth =	 {Kuipers and his group have been the pioneers in
                  bringing the cognitive map view of topological maps
                  into robotics}
}

@article{Kuipers88aim,
  author =	 {B.J. Kuipers and T.S. Levitt},
  title =	 {Navigation and mapping in large-scale space},
  journal =	 {AI Magazine},
  volume =	 9,
  number =	 2,
  year =	 1988,
  pages =	 {25--43},
  Levitt90ai =	 {Kuipers clearly defined the concept of "place" as a
                  set of relative visual events, and has pioneered the
                  development of computational models of spatial
                  memory based on local sets of commonly visible
                  landmarks and topological relationships between
                  visual separated regions. His representations were
                  proven efficacious by showing that they gave rise to
                  workable techniques for navigation and guidance.},
  c-dellaert =	 {4 level semantic hierarchy: sensorimotor,
                  procedural, topological, metric. Reviews in this
                  light the three programs for mapping and navigation:
                  TOUR, QualNav (with Levitt & Lawton), NX Robot (with
                  Byun).},
}

@incollection{Kuipers90asr,
  author =	 {B. Kuipers},
  title =	 {Modeling Spatial Knowledge},
  year =	 1990,
  publisher =	 "The University of Chicago Press",
  booktitle =	 {Advances in Spatial Reasoning (Volume 2)},
  editor =	 {S. Chen},
  pages =	 {171-198},
  c-ananth =	 {Reprint of \cite{Kuipers78cs}}
}

@Article{Kuipers91ras,
  author =	 "B.J. Kuipers and Y.-T. Byun",
  title =	 "A Robot Exploration and Mapping Strategy Based on a
                  Semantic Hierarchy of Spatial Representations",
  journal =	 RAS,
  year =	 1991,
  volume =	 8,
  pages =	 "47--63",
  r-Kuipers08chapter ={This basic idea, of letting the attractors of
                  continuous control laws define the topological
                  features of large-scale space, led to several
                  influential papers, including [29, 30].},
  r-Franz98ar =	 {Motivated by the findings of vertebrate ethology,
                  researchers have started to investigate topological
                  representations for robot navigation (e.g.,
                  \cite(Kuipers91ras,Mataric91sab)},
  c-dellaert =	 {Introduces the notion of hill-climbing to
                  distinctive places in topological mapping.},
}

@Book{Kullback59,
  author =	 "S. Kullback",
  title =	 "Information theory and statistics",
  publisher =	 "New York,Wiley",
  year =	 1959,
}

@InProceedings{Kum03acm,
  author =	 {S.-U. Kum and K. Mayer-Patel and H. Fuchs},
  title =	 {Real-time compression for dynamic {3D} environments},
  booktitle =	 {ACM Multimedia},
  year =	 2003,
}

@InProceedings{Kumar89cvpr,
  author =	 {R. V. R. Kumar and A. Tirumalai and R. C. Jain},
  title =	 {A non-linear optimization algorithm for the
                  estimation of structure and motion parameters},
  booktitle =	 CVPR,
  pages =	 {136-143},
  year =	 1989,
  month =	 {June},
}

@InProceedings{Kumar94,
  author =	 {R. Kumar and P. Anandan and K. Hanna},
  title =	 {Direct recovery of shape from multiple views: a
                  parallax based approach},
  booktitle =	 ICPR,
  pages =	 {685-688},
  year =	 1994,
}

@InProceedings{Kumar94ics,
  author =	 {B. Kumar and P. Sadayappan and C.-H. Huang},
  title =	 {On sparse matrix reordering for parallel
                  factorization},
  booktitle =	 {ICS '94: Proceedings of the 8th international
                  conference on Supercomputing},
  year =	 1994,
  isbn =	 {0-89791-665-4},
  pages =	 {431--438},
  location =	 {Manchester, England},
  publisher =	 {ACM Press},
  address =	 {New York, NY, USA},
}

@inproceedings{Kumar95,
  AUTHOR =	 "Kumar, R. and Anandan, P. and Irani, M. and Bergen,
                  J. and Hanna, K.",
  TITLE =	 "Representation of Scenes from Collections of Images",
  BOOKTITLE =	 RVS95,
  YEAR =	 1995,
}

@inproceedings{Kurata99,
  AUTHOR =	 "T. Kurata and J. Fujiki and M. Kourogi and
                  K. Sakaue",
  TITLE =	 "A Robust Recursive Factorization Method for
                  Recovering Structure and Motion from Live Video
                  Frames",
  BOOKTITLE =	 "1999 ICCV Workshop on Frame Rate processing, Corfu,
                  Greece",
  YEAR =	 1999,
}

@Article{Kurazume00ar,
  author =	 {R. Kurazume and S. Hirose},
  title =	 {An Experimental Study of a Cooperative Positioning
                  System},
  journal =	 AR,
  year =	 2000,
  volume =	 8,
  number =	 1,
  pages =	 {43-52},
  month =	 {January},
}

@InProceedings{Kurazume94icra,
  author =	 {R. Kurazume and S. Nagata and S. Hirose},
  title =	 {Cooperative Positioning with Multiple Robots},
  booktitle =	 ICRA,
  pages =	 {1250-1257},
  volume =	 2,
  year =	 1994,
  abstract =	 {A number of positioning identification techniques
                  have been used for mobile robots. Dead reckoning is
                  a popular method, but is not reliable when a robot
                  travels long distances or over an uneven surface
                  because of variations in wheel diameter and wheel
                  slippage. The landmark method, which estimates the
                  current position relative to landmarks, cannot be
                  used in an uncharted environment. The authors
                  propose a new method called ?cooperative
                  positioning with multiple robots?? For cooperative
                  positioning, the authors divide the robots into two
                  groups, A and B. One group, say A, remains
                  stationary and acts as a landmark while group B
                  moves. The moving group B then stops and acts as a
                  landmark for group A. This ?dance??is repeated
                  until the target robot position are
                  reached. Cooperative positioning has a far lower
                  accumulated positioning error than dead reckoning,
                  and can work in three-dimensions which is not
                  possible with dead reckoning. Also, this method has
                  inherent landmarks and therefore works in uncharted
                  environments. This paper discusses the positioning
                  accuracy of the authors' method with error variances
                  for an example with three mobile robots},
  r-Burgard05tro ={Whenever one robot moves, the other robots are kept
                  stationary and observe the moving robot, a strategy
                  similar to the presented by Kurazume and Shigemi
                  [this].},
}

@Article{Kurth94,
  author =	 {W. Kurth},
  title =	 {Growth Grammar Interpreter GROGRA 2.4: A software
                  tool for the 3-dimensional interpretation of
                  stochastic, sensitive growth grammars in the context
                  of plant modelling. Introduction and Reference
                  Manual},
  journal =	 {Berichte des Forschungszentrums Waldkosysteme der
                  Universitt Gttingen, Ser. B},
  year =	 {1994},
  volume =	 {38},
}

@Article{Kutulakos00ijcv,
  author =	 "K.N. Kutulakos and S.M. Seitz",
  title =	 "A Theory of Shape by Space Carving",
  journal =	 IJCV,
  year =	 2000,
  pages =	 "199-218",
  volume =	 38,
  number =	 3,
}

@inproceedings{Kutulakos99iccv,
  author =	 "K.N. Kutulakos and S.M. Seitz",
  title =	 "A Theory of Shape by Space Carving",
  booktitle =	 ICCV,
  year =	 1999,
  pages =	 {307-314}
}

@inproceedings{Kwok02,
  author =	 "C. Kowk and D. Fox and M. Meil\u{a}",
  fullauthor =	 "Cody Kowk and Dieter Fox and Marina Meil\u{a}",
  title =	 "Real-time Particle Filters",
  booktitle =	 NIPS,
  year =	 2002,
}

@inproceedings{Kwok03,
  author =	 "C. Kowk and D. Fox and M. Meil\u{a}",
  fullauthor =	 "Cody Kowk and Dieter Fox and Marina Meil\u{a}",
  title =	 "Adaptive Real-time Particle Filters for Robot
                  Localization",
  booktitle =	 ICRA,
  year =	 2003,
}

@inproceedings{Kwok03acra,
  author =	 {N. Kowk and G. Dissanayake},
  title =	 {Bearing-only {SLAM} in Indoor Environments using a
                  Modified Particle Filter},
  booktitle =	 {Proc. of the Australasian Conf. on Robotics and
                  Automation (ACRA)},
  location =	 {Brisbane, Australia},
  month =	 {Dec},
  year =	 2003,
  abstract =	 {The implementation of a particle filter (PF) for
                  vision-based simultaneous localisation and mapping
                  (SLAM) for a mobile robot in an unstructured indoor
                  environment is presented in this paper. Variations
                  to standard PF are proposed to remedy the sample
                  impoverishment problem in bearing-only SLAM. A CCD
                  camera mounted on the robot is used as the measuring
                  device and image quality is incorporated into data
                  association, PF update and map management. A passive
                  path control strategy to maintain the accuracy of
                  the SLAM process is also illustrated. Experimental
                  results from an implementation using real-life data
                  acquired from a Pioneer robot are included to
                  demonstrate the effectiveness of our approach.},
  r-Eade06cvpr = {Kwok and Dissanayake [this] use a modified particle
                  filter to perform SLAM in a planar world by
                  observing vertical edges with a camera. The system
                  uses particle clouds to describe the probability
                  distributions of landmarks in the world as well as
                  robot pose. In contrast to FastSLAM, this approach
                  fails to take advantage of the probabilistic
                  independence of landmarks given camera pose. Results
                  are shown for only 33 landmarks, using 10,000
                  particles. The running time and scaling complexity
                  of the system is not reported.},
}

@inproceedings{Kwok03acra,
  author =	 {N. Kwok and G. Dissanayake},
  title =	 {Bearing-only {SLAM} in Indoor Environments using a
                  Modified Particle Filter},
  booktitle =	 {Proc. of the Australasian Conf. on Robotics and
                  Automation (ACRA)},
  location =	 {Brisbane, Australia},
  month =	 {Dec},
  year =	 2003,
  abstract =	 {The implementation of a particle filter (PF) for
                  vision-based simultaneous localisation and mapping
                  (SLAM) for a mobile robot in an unstructured indoor
                  environment is presented in this paper. Variations
                  to standard PF are proposed to remedy the sample
                  impoverishment problem in bearing-only SLAM. A CCD
                  camera mounted on the robot is used as the measuring
                  device and image quality is incorporated into data
                  association, PF update and map management. A passive
                  path control strategy to maintain the accuracy of
                  the SLAM process is also illustrated. Experimental
                  results from an implementation using real-life data
                  acquired from a Pioneer robot are included to
                  demonstrate the effectiveness of our approach.},
  r-Eade06cvpr = {Kwok and Dissanayake [this] use a modified particle
                  filter to perform SLAM in a planar world by
                  observing vertical edges with a camera. The system
                  uses particle clouds to describe the probability
                  distributions of landmarks in the world as well as
                  robot pose. In contrast to FastSLAM, this approach
                  fails to take advantage of the probabilistic
                  independence of landmarks given camera pose. Results
                  are shown for only 33 landmarks, using 10,000
                  particles. The running time and scaling complexity
                  of the system is not reported.},
}

@InProceedings{Kwok04iros,
  author =	 {N.M. Kwok and G. Dissanayake},
  title =	 {An efficient multiple hypothesis filter for
                  bearing-only SLAM},
  booktitle =	 IROS,
  location =	 {Sendai, Japan},
  pages =	 {736-741},
  month =	 {Sep},
  year =	 2004,
  abstract =	 {This paper presents a multiple hypothesis approach
                  to solve the simultaneous localisation and mapping
                  (SLAM) problem with a bearing-only sensor. The main
                  contribution of the paper is to provide a remedy for
                  the landmark initialisation problem that occurs due
                  to the absence of range information, in a
                  computationally efficient manner. Each landmark is
                  initialised in the form of multiple hypotheses
                  distributed along the direction of the bearing
                  measurement. Using subsequent measurements, the
                  validity of the hypotheses is evaluated based on the
                  sequential probability ratio test
                  (SPRT). Consequently, the best approximation to the
                  landmark location is maintained. This approach
                  enables an extended Kalman filler (EKF) to be used
                  for bearing-only SLAM providing a computational
                  efficient solution. Simulation and experimental
                  results, from using a camera as the bearing-only
                  sensor mounted on a Pioneer robot are included to
                  demonstrate the effectiveness of the proposed
                  technique.},
}

@misc{LAGR,
  title =	 "http://www.darpa.mil/ipto/Programs/lagr/vision.htm",
  author =	 "{Learning Applied to Ground Robots (LAGR)}",
}

@InProceedings{LaCascia98,
  author =	 "M. {La Cascia} and J. Isidoro and S. Sclaroff",
  title =	 "Head Tracking via Robust Registration in Texture Map
                  Images",
  booktitle =	 CVPR,
  year =	 1998,
  address =	 "Santa Barbara, CA",
  month =	 "June",
}

@InProceedings{LaCascia99,
  author =	 "M. {La Cascia} and S. Sclaroff",
  title =	 "Fast, Reliable Head Tracking under Varying
                  Illumination",
  booktitle =	 CVPR,
  year =	 1999,
  address =	 "Fort Collins, CO",
  month =	 "June",
}

@InProceedings{LaMarca05pc,
  author =	 {A. LaMarca and Y. Chawathe and S. Consolvo and
                  J. Hightower and I.J. Smith and J. Scott and T. Sohn
                  and J. Howard and J. Hughes and F. Potter and
                  J. Tabert and P. Powledge and G. Borriello and
                  B. Schilit},
  title =	 {PlaceLab: {D}evice positioning using radio beacons
                  in the wild},
  booktitle =	 {International Conference on Pervasive Computing},
  year =	 2005,
}

@misc{Lacey,
  author =	 "Gerard Lacey and Kenneth M. Dawson-Howe",
  title =	 "Personal {A}daptive {M}obility {A}id ({PAM-AID}) for
                  the {I}nfirm and {E}lderly {B}lind",
  pdf =		 "pdf/pamaid.pdf",
  year =	 "199?",
}

@article{Lacey98ras,
  author =	 "G. Lacey and K. Dawson-Howe",
  title =	 "The Application of Robotics to a Mobility Aid for
                  the Elderly Blind",
  journal =	 "Robotics and Auton. Systems",
  volume =	 23,
  pages =	 "245-252",
  year =	 1998,
  url =		 "http://www.cs.tcd.ie/PAMAID/",
}

@inproceedings{Lafferty01icml,
  Author =	 {John Lafferty and Andrew McCallum, and Fernando
                  Pereira},
  Title =	 {Conditional random fields: Probabilistic models for
                  segmenting and labeling sequence data},
  Booktitle =	 ICML,
  Year =	 {2001},
  Keywords =	 {crf},
}

@Book{Lagendijk91,
  author =	 {E.L. Lagendijk and J. Biemond},
  title =	 {Iterative Identification and Restoration of Images},
  publisher =	 kluwer,
  year =	 1991,
  address =	 {Boston,MA},
}

@Article{Laird82,
  author =	 "N.M. Laird and J.H. Ware",
  fullauthor =	 "Nan M. Laird and James H. Ware",
  title =	 "Random-Effects Models for Longitudinal Data",
  journal =	 "Biometrika",
  year =	 1982,
  volume =	 38,
  number =	 4,
  pages =	 "963-974",
}

@Article{Laird87,
  author =	 "J. Laird and A. Newell and P. Rosenbloom",
  title =	 "SOAR: An Architecture for General Intelligence",
  journal =	 AI,
  year =	 1987,
  volume =	 33,
  pages =	 "1-64",
}

@InProceedings{Lakshmanan94,
  author =	 {S. Lakshmanan and A.K. jain and Yu Zhong},
  title =	 {Multi-resolution image representation using {M}arkov
                  random fields},
  booktitle =	 ICIP,
  pages =	 {855-860},
  year =	 1994,
}

@article{Land01vr,
  title =	 {In what ways do eye movements contribute to everyday
                  activities?},
  author =	 {Michael F. Land and Mary Hayhoe},
  journal =	 {Vision Research},
  volume =	 41,
  year =	 2001,
  pages =	 {3559--3565},
  abstract =	 {Two recent studies have investigated the relations
                  of eye and hand movements in extended food
                  preparation tasks, and here the results are
                  compared. The tasks could be divided into a series
                  of actions performed on objects. The eyes usually
                  reached the next object in the sequence before any
                  sign of manipulative action, indicating that eye
                  movements are planned into the motor pattern and
                  lead each action. The eyes usually fixated the same
                  object throughout the action upon it, although they
                  often moved on to the next object in the sequence
                  before completion of the preceding action. The
                  specific roles of individual fixations could be
                  identified as locating (establishing the locations
                  of objects for future use), directing (establishing
                  target direction prior to contact), guiding
                  (supervising the relative movements of two or three
                  objects) and checking (establishing whether some
                  particular condition is met, prior to the
                  termination of an action). It is argued that, at the
                  beginning of each action, the oculomotor system is
                  supplied with the identity of the required object,
                  information about its location, and instructions
                  about the nature of the monitoring required during
                  the action. The eye movements during this kind of
                  task are nearly all to task-relevant objects, and
                  thus their control is seen as primarily ?op-down?
                  and influenced very little by the ?ntrinsic
                  salience?of objects.},
  quotes =	 {The impression one obtains from the records is that
                  vision is a scarce and valuable resource, and it is
                  disengaged from a particular aspect of an action as
                  soon as another sense is available to take
                  over. .. Object localization is often a two-stage
                  process, with place memory being used to get the
                  eyes close enough for direct object detection. In
                  some cases, where an object has not been located
                  previously, a simple scanning strategy was also
                  invoked, but this was fairly uncommon. .. Our
                  studies lend no support to the idea that the visual
                  system builds up a detailed model of the
                  surroundings and operates from that. Most
                  information is obtained from the scene as it is
                  needed.},
  c-dellaert =	 {Very surprising !}
}

@article{Land92nature,
  journal =	 {Nature},
  volume =	 359,
  pages =	 {318--320},
  month =	 {September},
  year =	 1992,
  title =	 {Predictable eye-head coordination during driving},
  author =	 {M.F. Land},
  fullauthor =	 {Michael F. Land},
  abstract =	 {Large changes in the direction of gaze are made with
                  a combination of fast saccadic eye movements and
                  rather slower head movements. Since the first study
                  on freely moving subjects, most authors have agreed
                  that the head movement component of gaze is very
                  variable, with a high 'volitional' component. But in
                  some circumstances head and eye movements can be
                  quite predictable, for example when a subject is
                  asked to shift gaze as quickly as possible. Under
                  these conditions, laboratory studies have shown that
                  the eye and head motor-systems both receive
                  gaze-change commands, although they execute them in
                  rather different ways. Here I reconsider the way
                  gaze direction is changed during free movement, but
                  in the performance of a task where the subject is
                  too busy to exert conscious control over head or eye
                  movements. Using a new portable and inexpensive
                  method for recording head and eye movements, I
                  examine the oculomotor behaviour of car drivers,
                  particularly during the large gaze changes made at
                  road junctions. The results show that the pattern of
                  eye and head movements is highly preditable, given
                  only the sequence of gaze targets.},
  c-dellaert =	 {Did not read beyond abstract, bottom line: eye and
                  head movements are highly predictable.}
}

@article{Land94nature,
  journal =	 {Nature},
  volume =	 369,
  pages =	 {742--744},
  month =	 {June},
  year =	 1994,
  title =	 {Where we look when we steer},
  author =	 {M. F. Land and D. N. Lee},
  abstract =	 {Steering a car requires visual information from the
                  changing pattern of the road ahead. There are many
                  theories about what features a driver might use, and
                  recent attempts to engineer self-steering vehicles
                  have sharpened interest in the mechanisms
                  involved. However, there is little direct
                  information linking steering performance to the
                  driver's direction of gaze. We have made
                  simultaneous recordings of steering-wheel angle and
                  drivers' gaze direction during a series of drives
                  along a tortuous road. We found that drivers rely
                  particularly on the 'tangent point' on the inside of
                  each curve, seeking this point 1? s before each bend
                  and returning to it throughout the bend. The
                  direction of this point relative to the car's
                  heading predicts the curvature of the road ahead,
                  and we examine the way this information is used.},
  r-Murray96bmvc ={Steering a motor vehicle around a winding but
                  otherwise uncluttered road has been observed by
                  \citet{Land94nature} to involve repeated periods of
                  visual fixation upon the tangent point of the inside
                  of each bend. },
  r-Kim99ep =	 {Land and Lee (1994) reported that drivers rely on
                  the tangent point on the inside of a curve, a
                  strategy similar to the one depicted in Figure
                  2c. The utility of this point appears to be
                  maximized at 1 sec into a bend (> 75\% of the time
                  is spent at fixating this point), after which it
                  degrades rapidly (only 50\% after 2 sec). Donges
                  (1978) suggesed that, for successful steering,
                  drivers need not only information about the
                  curvature of the desired path but information about
                  the vehicle's current position. In a laboratory
                  study based on Land and Lee, Land and Horwood (1995)
                  observed that the crucial portion of the road for
                  successful steering is not the distant part but a
                  portion about 4 to 60 below the horizon of the
                  road. Note that the distant part is where the
                  tangent point is clearly visible, whereas the
                  optimum portion lacks such a point. The results are
                  consistent with Gibson's (1966, 1979/1986) notion of
                  visual kinethesis, the information about the
                  movement of the observer with respect to the
                  environment, provided in optical flow. That is,
                  optical flow contains information about the
                  observer, which in tum is used to correct his or her
                  locomotion (i.e., not only the future path but
                  position in the road).},
  c-dellaert =	 {Seminal paper that describes the use of the
                  "tangent-point" by human drivers to determine the
                  curvature of the road while in a turn.},
}

@article{Land99jcp,
  author =	 {M.F. Land},
  title =	 {Motion and vision: why animals move their eyes},
  journal =	 {J. Comparative Physiology A: Neuroethology, Sensory,
                  Neural, and Behavioral Physiology},
  Volume =	 185,
  Number =	 4,
  month =	 {October},
  year =	 1999,
  Abstract =	 {Nearly all animals with good vision have a
                  repertoire of eye movements. The majority show a
                  pattern of stable fixations with fast saccades that
                  shift the direction of gaze. These movements may be
                  made by the eyes themselves, or the head, or in some
                  insects the whole body. The main reason for keeping
                  gaze still during fixations is the need to avoid the
                  blur that results from the long response time of the
                  photoreceptors. Blur begins to degrade the image at
                  a retinal velocity of about 1 receptor acceptance
                  angle per response time. Some insects
                  (e.g. hoverflies) stabilise their gaze much more
                  rigidly than this rule implies, and it is suggested
                  that the need to see the motion of small objects
                  against a background imposes even more stringent
                  conditions on image motion. A third reason for
                  preventing rotational image motion is to prevent
                  contamination of the translational flow-field, by
                  which a moving animal can judge its heading and the
                  distances of objects. Some animals do let their eyes
                  rotate smoothly, and these include some heteropod
                  molluscs, mantis shrimps and jumping spiders, all of
                  which have narrow linear retinae which scan across
                  the surroundings. Hymenopteran insects also rotate
                  during orientation flights at speeds of
                  100?00?s. This is just consistent with a blur-free
                  image, as are the scanning speeds of the animals
                  with linear retinae.},
  c-dellaert =	 {non-attentional movement, here}
}

@article{Land99perception,
  author =	 {Land, M. and Mennie, N. and Rusted, J.},
  year =	 1999,
  title =	 {The roles of vision and eye movements in the control
                  of activities of daily living},
  journal =	 {Perception},
  volume =	 28,
  number =	 11,
  pages =	 {1311--1328},
  quotes =	 {Roughly a third of all fixations on objects could be
                  definitely identified with one of four monitoring
                  functions: locating objects used later in the
                  process, directing the hand or object in the hand to
                  a new location, guiding the approach of one object
                  to another (eg kettle and lid), and checking the
                  state of some variable (eg water level).},
  c-dellaert =	 {Cool movies, unconscious eye movements most of the
                  time, to guide behavior.},
}

@Article{Lange89,
  author =	 {K. L. Lange and R. J. A. Little and J. M. G. Taylor},
  title =	 {Robust Statistical Modeling Using the $t$
                  Distribution},
  journal =	 {Journal of the American Statistical Association},
  year =	 1989,
  volume =	 84,
  number =	 408,
  pages =	 {881-896},
}

@InProceedings{Langelaan05ac,
  author =	 "Jack Langelaan and Steve Rock",
  title =	 "Passive {GPS}-Free Navigation for Small {UAVs}",
  booktitle =	 AC,
  year =	 2005,
  added-by =	 {richard},
}

@InProceedings{Langer96,
  author =	 "Dirk Langer",
  title =	 "An Integrated MMW Radar System for Outdoor
                  Navigation",
  booktitle =	 ICRA,
  year =	 1996,
  address =	 "Minneapolis, MN",
  month =	 "April",
}

@TechReport{Langer97,
  author =	 "Dirk Langer",
  title =	 "An Integrated MMW Radar System for Outdoor
                  Navigation",
  institution =	 "Carnegie Mellon",
  year =	 1997,
  type =	 "PhD Dissertation",
  number =	 "CMU-RI-TR-97-03",
  month =	 "January",
}

@InCollection{Lappalainen00,
  author =	 "H. Lappalainen and J. W. Miskin",
  title =	 "Ensemble Learning",
  booktitle =	 "Advances in Independent Component Analysis",
  publisher =	 "Springer-Verlag",
  year =	 2000,
  editor =	 "M. Girolami",
  pages =	 "76--92",
}

@TechReport{Larsen03,
  author =	 "J. Larsen",
  title =	 "Gaussian Integrals",
  year =	 2003,
  month =	 "jan",
  keywords =	 "multidimensional gaussian integrals",
  institution =	 "Informatics and Mathematical Modelling, {DTU}",
  address =	 "Richard Petersens Plads, Buliding 321",
  url =		 "http://www.imm.dtu.dk/pubdb/p.php?1522"
}

@UnPublished{Lau06,
  author =	 {J. W. Lau and P. J. Green},
  fullauthor =	 {John W. Lau and Peter J. Green},
  title =	 {Bayesian model based clustering procedures},
  note =	 {Under review},
  year =	 2006,
  abstract =	 {This paper establishes a general framework for
                  Bayesian model-based clustering, in which subset
                  labels are exchangeable, and items are also
                  exchangeable, possibly up to covariate effects. It
                  is rich enough to encompass a variety of existing
                  procedures, including some recently discussed
                  methodologies involving stochastic search or
                  hierarchical clustering, but more importantly allows
                  the formulation of clustering procedures that are
                  optimal with respect to a specified loss
                  function. Our focus is on loss functions based on
                  pairwise coincidences, that is, whether pairs of
                  items are clustered into the same subset or
                  not. Optimisation of the posterior expected loss
                  function can be formulated as a binary integer
                  programming problem, which can be readily solved,
                  for example by the simplex method, when clustering a
                  modest number of items, but quickly becomes
                  impractical as problem scale increases. To combat
                  this, a new heuristic item-swapping algorithm is
                  introduced. This performs well in our numerical
                  experiments, on both simulated and real data
                  examples. The paper includes a comparison of the
                  statistical performance of the (approximate) optimal
                  clustering with earlier methods that are model-based
                  but ad hoc in their detailed definition.}
}

@InProceedings{Launay02icra,
  author =	 {F. Launay and A. Ohya and and S. Yuta},
  title =	 {A corridors lights based navigation system including
                  path definition using a topologically corrected map
                  for indoor mobile robots},
  booktitle =	 ICRA,
  year =	 {2002}
}

@InProceedings{Launay02icra,
  author = {F. Launay and A. Ohya and and S. Yuta},
  title = {A corridors lights based navigation system including path definition using a topologically corrected map for indoor mobile robots},
  booktitle = ICRA,
  year = {2002}
}

@Article{Lauritzen88jrssb,
  author =	 {S. L. Lauritzen and D. J. Spiegelhalter},
  title =	 {Local Computations with Probabilities on Graphical
                  Structures and Their Application to Expert Systems},
  journal =	 {Journal of the Royal Statistical Society. Series B
                  (Methodological)},
  year =	 {1988},
  volume =	 {50},
  number =	 {2},
  pages =	 {157--224},
  r-Kask05ai =	 {In the area of belief networks, junction-tree
                  clustering emerged as the leading strategy for
                  performing probabilistic inference
                  \cite{Lauritzen88jrssb}},
  c-dellaert =	 {Origin of "Asia" network ?},
}

@Article{Lauritzen97amai,
  author =	 {S.L. Lauritzen and D.J. Spiegelhalter},
  title =	 {Local computation with valuations from commutative
                  semigroups},
  journal =	 {Annals of Mathematics and Artificial Intelligence},
  volume =	 21,
  pages =	 {51--69},
  year =	 1997,
  r-Kask05ai =	 {Tree clustering schemes have been widely used for
                  constraint processing, probabilistic reasoning and
                  for graphical models in general. The most popular
                  variants are join-tree clustering algorithms, also
                  called junction-trees. The schemes vary somewhat in
                  their graph definitions as well as in the way
                  tree-decompositions are processed \cite{Maier83book,
                  Dechter89ai, Jensen90csq, Shenoy96uai,
                  Lauritzen97amai, Gottlob00ai}. However, they all
                  involve a decomposition of a hyper-graph into a
                  hyper-tree.},
  r-Kask05ai =	 {In both the constraint satisfaction and the Bayesian
                  networks communities the common tree-clustering
                  methods, called join-tree (or junction-tree)
                  clustering \cite{Dechter89ai, Lauritzen97amai}, are
                  based on a triangulation algorithm that transforms
                  the primal graph G (V,E) of a problem instance P
                  into a chordal graph G'.},
}



@InProceedings{Lavest00eccv,
  author =	 {J.M. Lavest and G. Rives and J.T. Lapreste},
  title =	 {Underwater Camera Calibration},
  crossref =	 {_ECCV00}
}

@article{Laws80,
  author =	 {K. I. Laws},
  fullauthor =	 {Kenneth I. Laws},
  title =	 {Rapid Texture Identification},
  journal =	 SPIE,
  year =	 {1980},
  pages =	 {376-380}
}

@PhdThesis{Lay91,
  author =	 {K.T. Lay},
  title =	 {Maximum Likelihood Iterative Image Identification
                  and Restoration},
  school =	 {Northwestern University},
  year =	 1991,
}

@InProceedings{Lazebnik06cvpr, 
  author = {L. Lazebnik, C. Schmid, and J. Ponce},
  title = {Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories},
  booktitle = CVPR,
  year = {2006}
}

@InProceedings{LeMaster00,
  author =	 "LeMaster, E.A. and S.M. Rock",
  title =	 "Field test results for a self-calibrating pseudolite
                  array",
  booktitle =	 "Proceedings of Institue of Navigation GPS-2000
                  Conference",
  year =	 2000,
}

@InProceedings{Lebanon02,
  author =	 {G. Lebanon and J. Lafferty},
  title =	 {Conditional models on the ranking poset},
  booktitle =	 NIPS,
  year =	 2002,
}

@Article{Lee00pami,
  author =	 {L. Lee and R. Romano and G. Stein},
  title =	 {Monitoring Activities from Multiple Video Streams:
                  Establishing a Common Coordinate Frame},
  journal =	 PAMI,
  year =	 2000,
  volume =	 22,
  number =	 8,
  pages =	 {758-767},
}

@InProceedings{Lee03workshop,
  author =	 {Sung Chun Lee and Ram. Nevatia},
  title =	 {Interactive 3D building modeling using a
                  hierarchical representation},
  booktitle =	 {{IEEE} Signal Processing Workshop on Higher-Level
                  Knowledge in 3D Modeling and Motion Analysis},
  year =	 2003,
}

@InProceedings{Lee04,
  author =	 {M.W. Lee and I. Cohen},
  title =	 {Human Upper Body Pose Estimation in Static Images},
  booktitle =	 ECCV,
  year =	 2004,
}

@InProceedings{Lee04a,
  author =	 {M.W. Lee and I. Cohen},
  title =	 {Proposal Maps driven MCMC for Estimating Human Body
                  pose in Static Images},
  booktitle =	 CVPR,
  year =	 2004,
}

@InProceedings{Lee05,
  author =	 {M.W. Lee and Ramakant Nevatia},
  title =	 {Dynamic Human Pose Estimation using Markov chain
                  Monte Carlo Approach},
  booktitle =	 {IEEE workshop on Motion and Video Computing},
  year =	 2005,
}

@Article{Lee05pami,
  author =	 {D. Lee},
  title =	 {Effective Gaussian Mixture Learning for Video
                  Background Subtraction},
  journal =	 PAMI,
  year =	 2005,
  volume =	 27,
  number =	 5,
  pages =	 {827-832},
  month =	 {May},
  abstract =	 {Adaptive Gaussian mixtures have been used for
                  modeling nonstationary temporal distributions of
                  pixels in video surveillance applications. However,
                  a common problem for this approach is balancing
                  between model convergence speed and stability. This
                  paper proposes an effective scheme to improve the
                  convergence rate without compromising model
                  stability. This is achieved by replacing the global,
                  static retention factor with an adaptive learning
                  rate calculated for each Gaussian at every
                  frame. Significant improvements are shown on both
                  synthetic and real video data. Incorporating this
                  algorithm into a statistical framework for
                  background subtraction leads to an improved
                  segmentation performance compared to a standard
                  method. },
  c-houdan =	 {It provides an algorithm to combine fast convergence
                  and temporal adaptability in adaptive Gaussian
                  mixture background modeling},
}

@Article{Lee06pami,
  author =	 {M. W. Lee and I. Cohen},
  fullauthor =	 {Mun Wai Lee and Issac Cohen},
  title =	 {A Model-Based Approach for Estimating Human 3D Poses
                  in Static Images},
  journal =	 PAMI,
  year =	 2006,
  volume =	 28,
  number =	 6,
  pages =	 {905-916},
}

@InProceedings{Lee2005efa,
  author =	 {J.Lee and R.Machiraju and H.Pfister and B.Moghaddam},
  title =	 {Estimation of 3D Faces and Illumination from Single
                  Photographs Using a Bilinear Illumination Model},
  booktitle =	 {Eurographics Symposium on Rendering},
  year =	 2005,
}

@InProceedings{Lee2005efa,
  author =	 {J.Lee and R.Machiraju and H.Pfister and B.Moghaddam},
  title =	 {Estimation of 3D Faces and Illumination from Single
                  Photographs Using a Bilinear Illumination Model},
  booktitle =	 {Eurographics Symposium on Rendering},
  year =	 2005,
}

@InProceedings{Lee88,
  author =	 {C.H. Lee and T.S. Huang},
  title =	 {Finding point correspondences and determining motion
                  of a rigid object from two weak perspective views},
  booktitle =	 CVPR,
  pages =	 {398-403},
  year =	 1988,
}

@Article{Lee93,
  author =	 {C. Lee and A. Joshi},
  title =	 {Correspondence problem in image sequence analysis},
  journal =	 {Pattern Recognition},
  year =	 1993,
  volume =	 26,
  number =	 1,
  pages =	 {47-61},
}

@Article{LeeEom88,
  author =	 {K.H. Lee, K.B. Eom and R.L. Kashyap},
  title =	 {Character Recognition Using Attributed Grammar},
  journal =	 {IEEE},
  year =	 1988,
}

@inproceedings{Leibe07cvpr,
  title =	 {Dynamic {3D} Scene Analysis from a Moving Vehicle},
  author =	 {B. Leibe and N. Cornelis and K. Cornelis and L. Van
                  Gool},
  booktitle =	 CVPR,
  year =	 2007,
}

@Article{Lele92osa,
  author =	 {A.S. Lele and S.R.Kulkarni and A.S.Willsky},
  title =	 {Convex-polygon estimatin from support-line
                  measurements and applications to target
                  reconstruction from laser-radar data},
  journal =	 {J. Opt. Soc. Am. A},
  year =	 1992,
  volume =	 9,
  number =	 10,
  pages =	 1693,
  month =	 {October},
}

@inproceedings{Lenser00icra,
  Author =	 {Lenser, S. and Veloso, M.},
  booktitle =	 ICRA,
  Pages =	 {1225--1232},
  volume =	 2,
  Title =	 {Sensor resetting localization for poorly modelled
                  mobile robots},
  Year =	 2000,
  Abstract =	 {We present a new localization algorithm, called
                  sensor resetting localization, which is an extension
                  of Monte Carlo localization. The algorithm adds
                  sensor based re-sampling to Monte Carlo localization
                  when the robot is lost. Sensor resetting
                  localization (SRL) is robust to modelling errors
                  including unmodelled movements and systematic
                  errors. It can be used in real time on systems with
                  limited computational power. The algorithm has been
                  successfully used on autonomous legged robots in the
                  Sony legged league of the robotic soccer competition
                  RoboCup'99. We present results from the real robots
                  demonstrating the success of the algorithm and
                  results from simulation comparing SRL to Monte Carlo
                  localization},
}

@Article{Leonard01joe,
  author =	 {J.J. Leonard and H.J.S. Feder},
  title =	 {Decoupled Stochastic Mapping},
  journal =	 {IEEE Journal of Oceanic Engineering},
  year =	 2001,
  pages =	 {561-571},
  month =	 {October},
  c-Alireza =	 {They use local submaps. on page 9 they describe
                  different aspects that their algorithm should saisfy
                  to be an acceptable algorithm: Computation time,
                  theoretical consistency, empirical consistency,
                  temporal convergence, spatial convergence, data
                  assiciation complexity. They transfer the covariance
                  matrix from a previous local map to the next one
                  with some approximations. Although they get good
                  results, but their algorithm is not exactly
                  identical to full global SLAM optimization. }
}

@article{Leonard01r,
  author =	 {J. J. Leonard and R. Carpenter and H. J. S. Feder},
  title =	 {Stochatic mapping using forward look sonar},
  journal =	 {Robotica},
  year =	 {2001}
}

@InProceedings{Leonard01r,
  author =	 {J. J. Leonard and R. Carpenter and H. J. S. Feder},
  title =	 {Stochatic mapping using forward look sonar},
  booktitle =	 {Robotica},
  year =	 {2001}
}

@InProceedings{Leonard03ijcai,
  author =	 {J.J. Leonard and P.M. Newman},
  title =	 {Consistent, Convergent, and Constant-time {SLAM}},
  booktitle =	 IJCAI,
  year =	 2003,
  abstract =	 {This paper presents a new efcient algorithm for
                  simultaneous localization and mapping (SLAM), using
                  multiple overlapping submaps, each built with
                  respect to a local frame of reference dened by one
                  of the features in the submap. The global position
                  of each submap is estimated using information from
                  other submaps in an efcient, provably consistent
                  manner. For situations where the mobile robot is
                  able to make repeated visits to all regions of the
                  environment, the method achieves convergence to a
                  near-optimal result with O(1) time complexity while
                  maintaining consistent error bounds. Simulation
                  results demonstrate the ability of the technique to
                  converge to errors that are only slightly greater
                  than the full solution, while maintaining
                  consistency.},
}

@InProceedings{Leonard03ijcai,
  author =	 {J. J. Leonard and P. M. Newman},
  title =	 {Consistent, Convergent, and Constant-time {SLAM}},
  booktitle =	 IJCAI,
  year =	 2003,
}

@Article{Leonard91tra,
  author =	 {J.J. Leonard and H.F. Durrant-Whyte},
  title =	 {Mobile robot localization by tracking geometric
                  beacons},
  journal =	 TRA,
  year =	 1991,
  volume =	 7,
  number =	 3,
  pages =	 {376-382},
  c-dellaert =	 {Rotating sonar or 6 fixed sonars, but principle is
                  the same: no active sensing, simply sonar return
                  pre-processing to extract beacons, then EKF
                  localization using map with known beacon locations}
}

@InProceedings{Leonard91wirs,
  author =	 {J.J. Leonard and H.F. Durrant-Whyte},
  title =	 {Simultaneous map building and localization for an
                  autonomous mobile robot},
  booktitle =	 {IEEE Int. Workshop on Intelligent Robots and
                  Systems},
  pages =	 {1442-1447},
  year =	 1991,
}

@Book{Leonard92book,
  author =	 "J.J. Leonard and H.F. Durrant-Whyte",
  title =	 "Directed Sonar Sensing for Mobile Robot Navigation",
  publisher =	 "Kluwer Academic",
  year =	 1992,
  address =	 "Boston",
  quotes =	 {The aim of directed sensing is to separate the
                  correspondence problem from the subsequent
                  estimation and control problem, through the use of
                  tracking sonars. The basic low-level competence is
                  the focus of attention. This is used to maintain
                  correspondence with individual environment features
                  during the vehicle or sensor's motion. By focusing
                  attention on a feature, correspondence can be easily
                  maintained once it has been achieved. By tracking a
                  given environment feature, a high bandwidth stream
                  of correctly associated measurements to this feature
                  becomes available. .. We envision a robot that
                  maintains continuous map contact, almost
                  effortlessly gliding through its environment,
                  "grabbing hold" of corners, planes, and cylinders in
                  the environment, using them as handrails.},
  r-Davison98thesis ={They have developed tracking sonars, which
                  actively follow the relative motion of world
                  features as the robot moves.},
  c-dellaert =	 {Very cool handrail idea, does not really come out in
                  the actual work, but one chapter is devoted to the
                  idea. Orienteering analogy in tht chapter is nice.},
}

@Article{Leonard92ijrr,
  author =	 {J.J. Leonard and H.F. Durrant-Whyte and I.J. Cox},
  title =	 {Dynamic map building for an autonomous mobile robot},
  journal =	 IJRR,
  year =	 1992,
  volume =	 11,
  number =	 4,
  pages =	 {286-289},
  abstract =	 {This paper presents an algorithm for autonomous map
                  building and maintenance for a mobile robot. We
                  believe that mobile robot navigation can be treated
                  as a problem of tracking geometric features which
                  occur naturally in the environment. We represent
                  each feature in the map by a location estimate (the
                  feature state vector) and two distinct measures of
                  uncertainty: a covariance matrix to represent
                  uncertainty in feature location, and a credibility
                  measure to represent our belief in the validity of
                  the feature. During each position update cycle,
                  predicted measurements are generated for each
                  geometric feature in the map and compared to actual
                  sensor observations. Successful matches cause a
                  feature's credibility to be increased. Unpredicted
                  observations are used to initialize new geometric
                  features, while unobserved predictions result in a
                  geometric feature's credibility being decreased. We
                  describe experimental results obtained with the
                  algorithm that demonstrate successful map building
                  using real sonar data.}
}

@Unpublished{Leonard99,
  author =	 {J.J. Leonard and H.-J. S. Feder},
  title =	 {Decoupled {S}tochastic {M}apping, {P}art {I}:
                  {T}heory},
  note =	 {Submitted to IEEE Transactions on Robotics and
                  Automation},
}

@INPROCEEDINGS{Leonard99a,
  AUTHOR =	 {J.J. Leonard and H.J.S. Feder},
  TITLE =	 {A computationally efficient method for large-scale
                  concurrent mapping and localization},
  YEAR =	 1999,
  BOOKTITLE =	 {Proceedings of the Ninth International Symposium on
                  Robotics Research},
  EDITOR =	 {J. Hollerbach and D. Koditschek},
  ADDRESS =	 {Salt Lake City, Utah}
}

@InProceedings{Lepetit03,
  author =	 {V.Lepetit and L.Vacchetti and D.Thalmann and P.Fua},
  title =	 {Fully Automated and Stable Registration for
                  Augmented Reality Applications},
  booktitle =	 {ISMAR},
  year =	 2003,
}

@InProceedings{Lepetit05cvpr,
  author =	 {V. Lepetit and P. Lagger and P. Fua},
  title =	 {Randomized trees for real-time keypoint recognition},
  booktitle =	 CVPR,
  year =	 2005,
}

@InProceedings{Lerner00,
  author =	 {U. Lerner and R. Parr and D. Koller and G. Biswas},
  title =	 {Bayesian fault detection and diagnosis in dynamic
                  systems},
  crossref =	 {_AAAI00},
  pages =	 "531-537",
}

@InProceedings{Lerner01,
  author =	 {U. Lerner and R. Parr},
  title =	 {Inference in Hybrid Networks: Theoretical Limits and
                  Practical Algorithms},
  year = 2001,
  crossref =	 {_UAI01},
  pages =	 {310-318},
  c-sangmin =	 {formally prove why SLDSs are not tractable},
}

@InProceedings{Letchner05aaai,
  author =	 {J. Letchner, D. Fox, and A. LaMarce},
  title =	 {Large-Scale Localization from Wireless Signal
                  Strength},
  booktitle =	 AAAI,
  year =	 2005,
}

@InProceedings{Levin04cvpr,
  author =	 {A. Levin and R. Szeliski},
  title =	 {Visual Odometry and Map Correlation},
  booktitle =	 CVPR,
  year =	 2004,
}

@Article{Levinson86,
  author =	 {S. E. Levinson},
  title =	 {Continuously variable duration hidden {M}arkov
                  models for automatic speech recognition},
  journal =	 {Computer Speech and Language},
  year =	 1990,
  volume =	 1,
  number =	 1,
  pages =	 {29-45},
}

@Article{Levitt90ai,
  author =	 {T.S. Levitt and D.T. Lawton},
  title =	 {Qualitative navigation for mobile robots},
  journal =	 {Artificial Intelligence},
  year =	 1990,
  volume =	 44,
  number =	 3,
  quotes =	 {We have developed a multi-level theory of spatial
                  representation of the environment based upon the
                  observation and re-acquisition of distinctive visual
                  events, i.e., landmarks. The representation provides
                  the theoretical foundations for a visual memory
                  database that includes coordinate-free, topological
                  representation of relative spatial location, yet
                  smoothly integrates available metric knowledge of
                  relative or absolute angles and distances. .. A key
                  contribution of this work is the realization of true
                  local coordinate systems, and a theory that makes
                  them computationally useful to a sighted mobile
                  robot. Using visually-based local coordinate
                  systems, which we call viewframes, a robot can
                  navigate about its environment, determining its
                  relative location in the world with essentially a
                  constant error. In particular, there is no
                  multiplicative accumulation of error in
                  location. .. Furthermore, humans and animals perform
                  navigation and guidance tasks quite reliably with
                  extremely poor range estimates, and very coarse
                  angular information. .. the notion of a geographic
                  "place" is defined in terms of data about visible
                  landmarks. A place, as a point on the surface of the
                  ground, is defined by the landmarks and spatial
                  relationships between landmarks that can be observed
                  from a fixed location. More generally we can define
                  a place as a region in space, in which a fixed set
                  of landmarks can be observed from anywhere in the
                  region, and relationships between them do not change
                  in some appropriate qualitative sense. Data about
                  places is stored in structures called viewframes,
                  boundaries and orientation regions},
  r-Franz00ras = {Levitt and Lawton [37] define navigation as a
                  process answering the following three questions: (a)
                  ?here am I?? (b) ?here are other places with respect
                  to me?? (c) ?ow do I get to other places from
                  here??},
  c-dellaert =	 {Pretty interesting stuff. Should read in more
                  depth.},
}

@inproceedings{Levoy00siggraph,
  author =	 "M. Levoy and K. Pulli and B. Curless and
                  S. Rusinkiewicz and D. Koller and L. Pereira and
                  M. Ginzton and S. Anderson and J. Davis and
                  J. Ginsberg and J. Shade and D. Fulk",
  title =	 "The Digital Michelangelo Project: 3{D} Scanning of
                  Large Statues",
  booktitle =	 "Siggraph 2000, Computer Graphics Proceedings",
  publisher =	 "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
  editor =	 "Kurt Akeley",
  pages =	 "131--144",
  year =	 "2000",
  url =		 "citeseer.nj.nec.com/levoy00digital.html"
}

@InProceedings{Levoy96siggraph,
  author =	 {M. Levoy and P. Hanrahan},
  title =	 {Light field rendering},
  booktitle =	 SIGGRAPH,
  pages =	 {31-42},
  year =	 1996,
}

@Article{Lewis89siam,
  author =	 {J.G. Lewis and B.W. Peyton and A. Pothen},
  title =	 {A fast algorithm for reordering sparse matrices for
                  parallel factorization},
  journal =	 {SIAM J. Sci. Stat. Comput.},
  year =	 1989,
  volume =	 10,
  pages =	 {1156--1173},
  r-Blair93chapter ={The reader should consult \citet{Lewis89siam} for
                  details on how to compute a clique tree in the
                  course of solving a sparse positive definite linear
                  system. },
}

@Book{Leyton01,
  author =	 {M. Leyton},
  title =	 {A Generative Theory of Shape},
  publisher =	 springer,
  year =	 2001,
}

@inproceedings{Li02,
  author =	 "Y. Li and T. Wang and H-Y. Shum",
  title =	 "Motion Texture : A Two-Level Statistical Model for
                  Character Motion Synthesis",
  booktitle =	 SIGGRAPH,
  year =	 2002,
}

@inproceedings{Li03sensor,
  author =	 {Qun Li and Micheal DeRosa and Danila Rus},
  title =	 {Distributed Algorithms for Guiding Navigation Across
                  a Sensor Network},
  booktitle =	 {Proceedings of the 9th International Conference on
                  Mobile Computing and Networking},
  pages =	 {313--325},
  month =	 {September},
  year =	 {2003}
}

@InProceedings{Li06iros,
  author =	 {F. Li and J. Kosecka},
  title =	 {Probabilistic location recognition using reduced
                  feature set},
  booktitle =	 ICRA,
  year =	 2006,
}

@article{Li92,
  author =	 "Li, S.Z.",
  title =	 "Matching: Invariant To Translations, Rotations, And
                  Scale Changes",
  journal =	 PR,
  volume =	 25,
  year =	 1992,
  pages =	 "583-594"
}

@Book{Li95,
  author =	 {S.Z. Li},
  title =	 {Markov {R}andom {F}ield Modeling in Computer Vision},
  publisher =	 {Springer},
  year =	 1995,
}

@Article{Li96,
  author =	 {Li, X.R. and Bar-Shalom, Y.},
  title =	 {Tracking in clutter with nearest neighbor filters:
                  analysis and performance},
  journal =	 AES,
  year =	 1996,
  volume =	 32,
  number =	 3,
  pages =	 {995-1010},
  month =	 {July},
}

@InProceedings{Liao03iros,
  author =	 {L.Liao and D.Fox and J.Hightower and H.Kautz and
                  D.Schulz},
  title =	 {Voronoi Tracking: Location Estimation using Sparse
                  and Noisy Sensor Data},
  booktitle =	 {IROS},
  year =	 2003
}

@InProceedings{Liao04aaai,
  author =	 {L. Liao and D. Fox and H.A. Kautz},
  title =	 {{Learning and Inferring Transportation Routines}},
  crossref =	 {_AAAI04},
  pages =	 {348--353},
  c-sangmin =	 {Used AH(E)MM, see Bui02jair or Bui03ijcai, to model
                  the user plans of transportations given the user
                  goals using GPS sensor data. They addressed the
                  learning approach to learn the significant goals and
                  transportation routines from GPS data using a
                  two-level learning approach, where they first learn
                  the significant goals and some important structural
                  locations from GPS log-data, then estimate the
                  higher order parameters from GPS data. They show
                  that their model is able to predict the goals more
                  accurately and earlier than 2nd order Markov models
                  in Ashbrook03 or Patterson03ubicomp},
}

@InProceedings{Liao05ijcai,
  author =	 {L. Liao and D. Fox and H.A. Kautz},
  title =	 {{Location-Based Activity Recognition using
                  Relational Markov Networks}},
  booktitle =	 IJCAI,
  pages =	 {1471--1476},
  year =	 2005,
}

@Article{Liberman89,
  author =	 {Liberman, A.M. and Mattingly, I.G},
  title =	 {A specialization for speech perception},
  journal =	 {Science},
  year =	 1989,
  volume =	 243,
  pages =	 {489-494},
}

@Article{Lichtfuss06,
  title =	 "Scanner screen using computer monitor as external
                  light source",
  journal =	 "United States Patent 6,989,916",
  author =	 "H. Lichtfuss",
  year =	 2006,
  month =	 "January",
}

@InProceedings{Liebowitz99,
  author =	 "Liebowitz, D. and Criminisi, A. and Zisserman, A.",
  title =	 "Creating Architectural Models from Images",
  booktitle =	 "Proc. EuroGraphics",
  volume =	 18,
  pages =	 "39--50",
  year =	 1999,
  month =	 sep,
  url =		 "http://www.robots.ox.ac.uk/~vgg"
}

@inproceedings{Liebowitz99iccv,
  author =	 "David Liebowitz and Andrew Zisserman",
  title =	 "Combining Scene and Auto-Calibration Constraints",
  booktitle =	 ICCV,
  pages =	 "293-300",
  year =	 1999,
  url =		 "citeseer.nj.nec.com/liebowitz99combining.html"
}

@InProceedings{Liedtke95caip,
  author =	 {C.-E. Liedtke and O. Grau and S. Growe},
  title =	 {Use of Explicit Knowledge for the Reconstruction of
                  {3-D} Object Geometry},
  booktitle =	 {Computer Analysis of Images and Patterns (CAIP)},
  year =	 1995,
}

@InProceedings{Liedtke97,
  author =	 "C. Liedtke and J. Bckner and O. Grau and S. Growe
                  and R. Tonjes",
  title =	 "AIDA: A System for the Knowledge Based
                  Interpretation of Remote Sensing Data",
  booktitle =	 "3rd Int. Airborne Remote Sensing Conference \&
                  Exhibition, Copenhagen, Denmark",
  volume =	 "Vol II",
  pages =	 "313--320",
  month =	 "July",
  year =	 1997,
  url =		 "citeseer.nj.nec.com/liedtke97aida.html"
}

@article{Lien82jacm,
  author =	 {Y.E. Lien},
  fullauthor =	 {Y. Edmund Lien},
  title =	 {On the Equivalence of Database Models},
  journal =	 {J. ACM},
  volume =	 29,
  number =	 2,
  year =	 1982,
  issn =	 {0004-5411},
  pages =	 {333--362},
  doi =		 {http://doi.acm.org/10.1145/322307.322311},
  publisher =	 {ACM Press},
  address =	 {New York, NY, USA},
  c-dellaert =	 {Reference for Bachman diagrams}
}

@InProceedings{Likhachev02icra,
  author =	 {M. Likhachev and M. Kaess and R.C. Arkin},
  fullauthor =	 {Maxim Likhachev and Michael Kaess and Ronald
                  C. Arkin},
  title =	 {Learning Behavioral Parameterization Using
                  Spatio-Temporal Case-Based Reasoning},
  booktitle =	 ICRA,
  pages =	 {1282-1289},
  volume =	 2,
  isbn =	 {0-7803-7273-5},
  publisher =	 {IEEE},
  address =	 {Washington, DC},
  year =	 2002,
  abstract =	 {This paper presents an approach to learning an
                  optimal behavioral parameterization in the framework
                  of a Case-Based Reasoning methodology for autonomous
                  navigation tasks. It is based on our previous work
                  on a behavior-based robotic system that also
                  employed spatio-temporal case-based reasoning in the
                  selection of behavioral parameters but was not
                  capable of learning new parameterizations. The
                  present method extends the case-based reasoning
                  module by making it capable of learning new and
                  optimizing the existing cases where each case is a
                  set of behavioral parameters. The learning process
                  can either be a separate training process or be part
                  of the mission execution. In either case, the robot
                  learns an optimal parameterization of its behavior
                  for different environments it encounters. The goal
                  of this research is not only to automatically
                  optimize the performance of the robot but also to
                  avoid the manual configuration of behavioral
                  parameters and the initial configuration of a case
                  library, both of which require the user to possess
                  good knowledge of robot behavior and the performance
                  of numerous experiments. The presented method was
                  integrated within a hybrid robot architecture and
                  evaluated in extensive computer simulations, showing
                  a significant increase in the performance over a
                  nonadaptive system and a performance comparable to a
                  non-learning CBR system that uses a hand-coded case
                  library.},
}

@InProceedings{Limketkai05ijcai,
  author =	 {B. Limketkai and L. Liao and D. Fox},
  title =	 {Relational Object Maps for Mobile Robots},
  booktitle =	 IJCAI,
  pages =	 {1471--1476},
  year =	 2005,
  abstract =	 {Mobile robot map building is the task of generating
                  a model of an environment from sensor data. Most
                  existing approaches to mobile robot mapping either
                  build topological representations or generate
                  accurate, metric maps of an environment. In this
                  paper we introduce relational object maps, a novel
                  approach to building metric maps that represent
                  individual objects such as doors or walls. We show
                  how to extend relational Markov networks in order to
                  reason about a hierarchy of objects and the spatial
                  relationships between them. Markov chain Monte Carlo
                  is used for ef cient inference and to learn the
                  parameters of the model. We show that the spatial
                  constraints modeled by our mapping technique yield
                  drastic improvements for labeling line segments
                  extracted from laser rangefinders. },
}

@InProceedings{Lin03icra,
  author =	 {S.S. Lin and Bajcsy, R.},
  title =	 {High resolution catadioptric omni-directional stereo
                  sensor for robot vision},
  booktitle =	 ICRA,
  pages =	 {1694 - 1699},
  year =	 2003,
  volume =	 2,
}

@Article{Lin84,
  author =	 {W.C. Lin and K.S. Fu},
  title =	 {A syntactic approach to {3D} object representation},
  journal =	 PAMI,
  volume =	 6,
  year =	 1984,
  pages =	 {351-364},
}

@inproceedings{Lin86,
  AUTHOR =	 "Lin, Z.C. and Lee, H. and Huang, T.S.",
  TITLE =	 "Finding {3D} Point Correspondences in Motion
                  Estimation",
  BOOKTITLE =	 ICPR,
  YEAR =	 1986,
  PAGES =	 "303-305"
}

@INPROCEEDINGS{Lin97uai,
  AUTHOR =	 "Y. Lin and M. Druzdzel",
  FULLAUTHOR =	 "Yan Lin and Marek Druzdzel",
  TITLE =	 "Computational Advantages of Relevance Reasoning in
                  {Bayesian} Belief Networks",
  crossref =	 {_UAI97},
  PAGES =	 "342-35",
  abstract =	 {This paper introduces a computational framework for
                  reasoning in Bayesian belief networks that derives
                  significant advantages from focused inference and
                  relevance reasoning. This framework is based on d
                  -separation and other simple and computationally
                  efficient techniques for pruning irrelevant parts of
                  a network. Our main contribution is a technique that
                  we call relevance-based
                  decomposition. Relevance-based decomposition
                  approaches belief updating in large networks by
                  focusing on their parts and decomposing them into
                  partially overlapping subnetworks. This makes
                  reasoning in some intractable networks possible and,
                  in addition, often results in significant speedup,
                  as the total time taken to update all subnetworks is
                  in practice often considerably less than the time
                  taken to update the network as a whole. We report
                  results of empirical tests that demonstrate
                  practical significance of our approach.},
}

@Article{Linde80,
  author =	 {Y. Linde and A. Buzo and R. M. Gray},
  title =	 {An algorithm for vector quantizer design},
  journal =	 {IEEE Transactions on Communications},
  year =	 1980,
  volume =	 {COM-28},
  pages =	 {84-95},
}

@Article{Lindeberg97,
  author =	 {T. Lindberg and J. Garding},
  title =	 {Shape-adapted smoothing in estimation of 3-d shape
                  cues from affine deformations of local 2-d
                  brightness structure},
  journal =	 {IVC},
  year =	 1997,
  month =	 "June",
  volume =	 {15(6)},
  pages =	 {445-434},
}

@Article{Lindeberg98,
  author =	 {T. Lindberg},
  title =	 {Feature detection with automatic scale-invariant
                  features},
  journal =	 {International Journal of Computer Vision},
  year =	 1998,
  volume =	 {30(2)},
  pages =	 {79-116},
}

@Article{Ling91tsp,
  author =	 "F. Ling",
  title =	 "Givens Rotation Based Least Squares Lattice Related
                  Algorithms",
  journal =	 SP,
  month =	 "Jul",
  year =	 1991,
  volume =	 39,
  number =	 7,
  pages =	 "1541-1551",
}

@Article{Lipton79nd,
  author =	 {R.J. Lipton and R.E. Tarjan},
  title =	 {Generalized Nested Dissection},
  journal =	 {SIAM Journal on Applied Mathematics},
  volume =	 16,
  number =	 2,
  pages =	 {346-358},
  year =	 1979,
  abstract =	 {J. A. George \cite{George73siam} has discovered a
                  method, called nested dissection, for solving a
                  system of linear equations defined on an $n = k
                  \times k$ square grid in $O(n \log n)$ and space
                  $O(n^{3/2})$ time. We generalize this method without
                  degrading the time and space bounds so that it
                  applies to any system of equations defined on a
                  planar or almost-planar graph. Such systems arise in
                  the solution of two-dimensional finite element
                  problems. Our method uses the fact that planar
                  graphs have good separators. More generally, we show
                  that sparse Gaussian elimination is efficient for
                  any class of graphs which have good separators, and
                  conversely that graphs without good separators
                  (including "almost all" sparse graphs) are not
                  amenable to sparse Gaussian elimination.},
  r-MathSciNet = {The problem is one of numerical analysis, namely
                  saving time and space while solving sparse systems
                  of linear equations by elimination; the approach is
                  purely graph-theoretic. If the system has many zero
                  coefficients and they are appropriately distributed,
                  a convenient order of elimination might be found
                  such that not many new nonzero coefficients arise in
                  originally zero positions and so the number of
                  necessary multiplications is low. An important
                  aspect is that the numbering algorithm itself does
                  not require many operations. A. George
                  \cite{George73siam} has found an effective numbering
                  for the system whose graph is a planar square
                  grid. For such a system of $n$ equations the number
                  of multiplications is $O(n^{3/2})$. A planar grid of
                  $n$ nodes collapses when $O(n^{1/2})$ nodes are
                  removed. The authors show that this, and not the
                  sparsity itself, is the property that is sufficient,
                  and also necessary, for the existence of a numbering
                  that gives the $O(n^{3/2})$ multiplication
                  count. So, George's numbering may be applied to the
                  equation system arising from the finite elements
                  method for the two-dimensional problem, giving again
                  $O(n^{3/2})$ multiplications. For a
                  three-dimensional grid, the multiplication count is
                  $O(n^2)$. \{The remark after Theorem 6 should read
                  $\sigma=(d-1)/d$\}. The theorems and some proofs
                  give estimates for the coefficients in the $O()$
                  positions.}
}

@Article{Lipton79sep,
  author =	 {R.J. Lipton and R.E. Tarjan},
  title =	 {A separator theorem for planar graphs},
  journal =	 {SIAM Journal on Applied Mathematics},
  volume =	 36,
  number =	 2,
  pages =	 {177-189},
  month =	 {April},
  year =	 1979,
  r-MathSciNet = {It is shown that any planar graph can be partitioned
                  into two (very) roughly equal subgraphs by the
                  removal of fewer than $3\surd n$ vertices. An $O(n)$
                  (and practical) algorithm for finding the partition
                  follows as a consequence of this separator
                  theorem. These results have profound consequences in
                  the solution of a number of diverse problems. The
                  major one is a dramatic generalization of the nested
                  dissection technique of Alan George for the solution
                  of sparse positive-definite symmetric systems of
                  linear equations. Other areas of applications
                  include pebbling problems, data structure embeddings
                  and lower bounds on Boolean circuits. The results of
                  this paper are clearly among the most significant in
                  the area of efficient algorithm design in the past
                  few years.}
}

@InProceedings{Lipton98,
  author =	 {A. Lipton and H. Fujiyosh and R. Patil},
  title =	 {Moving Target Classification and Tracking from Real
                  Time Video},
  booktitle =	 WACV,
  pages =	 {8-14},
  year =	 1998,
}

@InProceedings {Liu00cvpr,
  Author =	 {Liu, Y. and Collins, R. T.},
  Title =	 {A {C}omputational {M}odel for {R}epeated {P}attern
                  {P}erception using {F}rieze and {W}allpaper
                  {G}roups},
  crossref =	 {_CVPR00},
  Pages =	 {537-544},
}

@Book{Liu01,
  author =	 {J. S. Liu},
  title =	 {Monte Carlo Strategies in Scientific Computing},
  publisher =	 {Springer-Verlag},
  year =	 2001,
  address =	 {New York},
}

@inproceedings{Liu01cvpr,
  Author =	 {Y. Liu and Collins, R. T.},
  FullAuthor =	 {Yanxi Liu and Collins, Robert T.},
  Date-Added =	 {2007-03-24 17:26:47 -0400},
  crossref =	 {_CVPR01},
  Pages =	 {872--879},
  Title =	 {Skewed symmetry groups},
  Volume =	 1,
  Year =	 2001,
  Abstract =	 {We introduce the term skewed symmetry groups and
                  provide a complete theoretical treatment for 2D
                  wallpaper groups under affine transformations. For
                  the first time, a given periodic pattern can be
                  classified not simply by its Euclidean symmetry
                  group but,by its highest
                  {\tt{}"{}}potential{\tt{}"{}} symmetry group under
                  affine deformation. A concise wallpaper group
                  migration map is constructed that separates the 17
                  affinely deformed wallpaper groups into small,
                  distinct orbits. The practical value of this result
                  includes a novel indexing and retrieval scheme for
                  regular patterns, and a maximal-symmetry-based
                  method for estimating shape and orientation from
                  texture under unknown views.},
}

@InProceedings{Liu01icml,
  author =	 {Y. Liu and R. Emery and D. Chakrabarti and
                  W. Burgard and S. Thrun},
  title =	 {Using EM to learn {3D} models with mobile robots},
  booktitle =	 ICML,
  year =	 2001,
}

@inproceedings{Liu01siggraph,
  author =	 "Z.Liu and Y.Shan and Z.Zhang",
  title =	 "Expressive expression mapping with ratio images",
  booktitle =	 SIGGRAPH,
  pages =	 "271-276",
  year =	 2001,
}

@misc{Liu02,
  author =	 "Y. Liu and S. Thrun",
  title =	 "Results for outdoor-SLAM using sparse extended
                  information filters",
  text =	 "Yufeng Liu and Sebastian Thrun. Results for
                  outdoor-SLAM using sparse extended information
                  filters. Submitted for publication, 2002.",
  year =	 2002,
}

@article{Liu04pami,
  author =	 "Y. Liu and R. Collins and Y. Tsin",
  title =	 "A Computational Model for Periodic Pattern
                  Perception Based on Frieze and Wallpaper Groups",
  journal =	 PAMI,
  month =	 "March",
  year =	 2004,
  volume =	 26,
  number =	 3,
  pages =	 "354 - 371"
}

@PhdThesis{Liu05thesis,
  author =	 {Y. Liu},
  title =	 "{Decision-Theoretic Planning Under Risk-Sensitive
                  Planning Objectives}",
  school =	 {College of Computing, Georgia Institute of
                  Technology},
  year =	 2005,
}

@inproceedings{Liu06,
  author =	 {Liu, L. and Stamos, I. and Yu, G. and Wolberg,
                  G. and Zokai, S.},
  title =	 {Multiview Geometry for Texture Mapping 2D Images
                  onto 3D Range Data},
  booktitle =	 CVPR,
  year =	 2006,
}

@InProceedings{Liu07icme,
  author =	 {Z.Liu and C.Zhang and Z.Zhang},
  title =	 {Learning-Based Perceptual Image Quality Improvement
                  for Video Conferencing},
  booktitle =	 ICME,
  year =	 2007,
}

@InProceedings{Liu09cvpr,
  author = {Jingen Liu and Jiebo Luo and Mubarak Shah},
  title = {Recognizing realistic actions from videos "in the wild"},
  booktitle = CVPR,
  year = {2009}
}

@article{Liu85toms,
  author =	 {J.W.H. Liu},
  fullauthor =	 {Joseph W. H. Liu},
  title =	 {Modification of the minimum-degree algorithm by
                  multiple elimination},
  journal =	 {ACM Trans. Math. Softw.},
  volume =	 11,
  number =	 2,
  year =	 1985,
  issn =	 {0098-3500},
  pages =	 {141--153},
  publisher =	 {ACM Press},
  address =	 {New York, NY, USA},
  abstract =	 {The most widely used ordering scheme to reduce fills
                  and operations in sparse matrix computation is the
                  minimum-degree algorithm. The notion of multiple
                  elimination is introduced here as a modification to
                  the conventional scheme. The motivation is discussed
                  using the $k\times k$ grid model
                  problem. Experimental results indicate that the
                  modified version retains the fill-reducing property
                  of (and is often better than) the original ordering
                  algorithm and yet requires less computer time. The
                  reduction in ordering time is problem dependent, and
                  for some problems the modified algorithm can run a
                  few times faster than existing implementations of
                  the minimum-degree algorithm. The use of external
                  degree in the algorithm is also introduced.},
  quotes =	 {In this paper we introduce the idea of multiple
                  elimination as a modification to the minimum-degree
                  ordering algorithm. It helps to reduce the number of
                  degree updates, which is the most time consuming
                  part in the overall scheme.},
}

@article{Liu89,
  author =	 {Joseph W. H. Liu},
  title =	 {A graph partitioning algorithm by node separators},
  journal =	 {ACM Trans. Math. Softw.},
  volume =	 15,
  number =	 3,
  year =	 1989,
  issn =	 {0098-3500},
  pages =	 {198--219},
  publisher =	 {ACM Press},
  address =	 {New York, NY, USA},
}

@Article{Liu89siam,
  author =	 {J. W-H. Liu and A. Mirzaian},
  title =	 {A linear reordering algorithm for parallel pivoting
                  of chordal graphs},
  journal =	 {SIAM J. Disc. Math.},
  year =	 1989,
  volume =	 2,
  pages =	 {lOO--107},
  r-Blair93chapter ={Of the many ways to represent a chordal graph, a
                  particularly useful and compact representation is
                  provided by clique trees
                  \cite{Liu89siam,Tarjan84siam}},
}

@Article{Liu92,
  author =	 {Joseph W. H. Liu},
  title =	 {The Multifrontal Method for Sparse Matrix Solution:
                  Theory and Practice},
  journal =	 {SIAM Review},
  year =	 1992,
  volume =	 34,
  pages =	 {82-109}
}

@Article{Liu97,
  author =	 {C. Liu},
  title =	 {{ML} Estimation of the Multivariate $t$ Distribution
                  and the {EM} Algorithm},
  journal =	 {Journal of Multivariate Analysis},
  year =	 1997,
  volume =	 63,
  pages =	 {296-312}
}

@inproceedings{Littman01nips,
  author =	 {M.L. Littman, R.S. Sutton, S. Singh},
  fullauthor =	 "Michael L. Littman, Richard S. Sutton, Satinder Singh",
  title =	 "Predictive representations of state",
  booktitle =	 "Advances in Neural Information Processing Systems 14
                  (NIPS 2001)",
  year =	 2002
}

@book{Ljung87book,
  author =	 "L. Ljung",
  title =	 "System Identification, Theory for the user",
  publisher =	 "Prentice Hall",
  address =	 "New Jersey",
  year =	 1987,
  url =		 "citeseer.ist.psu.edu/ljung95system.html"
}

@Article{Lobo03ras,
  author =	 {J. Lobo and C. Queiroz and J. Dias},
  fullauthor =	 {Jorge Lobo and Carlos Queiroz and Jorge Dias},
  title =	 {World feature detection and mapping using
                  stereovision and inertial sensors},
  journal =	 RAS,
  volume =	 44,
  number =	 1,
  pages =	 {69-81},
  month =	 {Jul},
  year =	 2003,
  abstract =	 {This paper explores the fusion of inertial
                  information with vision for 3D reconstruction. A
                  method is proposed for vertical line segment
                  detection and subsequent local geometric map
                  building. Visual and inertial sensing are two
                  sensory modalities that can be explored to give
                  robust solutions on image segmentation and recovery
                  of 3D structure from images, increasing the
                  capabilities of autonomous vehicles and enlarging
                  the application potential of vision systems. From
                  the inertial sensors, a camera stereo rig, and a few
                  system parameters we can recover the 3D parameters
                  of the ground plane and vertical lines. The
                  homography between stereo images of ground points
                  can be found. By detecting the vertical line
                  segments in each image, and using the homography of
                  ground points for the foot of each segment, the
                  lines can be matched and reconstructed in 3D. The
                  mobile robot then maps the detected vertical line
                  segments in a world map as it moves. To build this
                  map an outlier removal method is implemented and a
                  statistical approach used, so that a simplified
                  metric map can be obtained for robot navigation.},
}

@Article{Loeliger04spm,
  author =	 {H.-A. Loeliger},
  title =	 {An Introduction to Factor Graphs},
  journal =	 {IEEE Signal Processing Magazine},
  year =	 2004,
  month =	 {January},
  pages =	 {28--41},
  quotes =	 {The later introduction of factor graphs
                  \citep{Frey97ccc,Kschischang03spm} may be viewed as
                  a further elaboration of the ideas by Wiberg et
                  al. In the present article, we will use Forney-style
                  factor graphs (FFGs), which were introduced in
                  \citep{Forney01it} (and there called "normal
                  graphs").},
  c-dellaert =	 {Uses Forney-style graphs, which are a bit weird.}
}

@article{LonguetHiggins81,
  AUTHOR =	 "Longuet-Higgins, H.C.",
  TITLE =	 "A Computer Algorithm for Reconstructing a Scene from
                  Two Projections",
  JOURNAL =	 "Nature",
  VOLUME =	 293,
  YEAR =	 1981,
  MONTH =	 "September",
  PAGES =	 "133-135"
}

@article{Loomis90,
  author =	 {Loomis, J.M. and Hebert, C. and Cicinelli, J.G.},
  year =	 1990,
  title =	 {Active localization of virtual sounds},
  journal =	 {Journal of the Acoustical Society of America},
  volume =	 88,
  pages =	 {1757-1764},
}

@inproceedings{Loomis94,
  author =	 {J.M.Loomis and R.G.Golledge and R.L.Klatzky and
                  J.M.Speigle and J.Tietz},
  title =	 {Personal guidance system for the visually impaired},
  booktitle =	 {Proceedings of the first annual ACM conference on
                  Assistive technologies},
  month =	 {November},
  year =	 1994,
  pages =	 {85-91},
  address =	 {Marina Del Rey, CA, USA},
  url =		 {http://www.csun.edu/cod/93virt/Gsvi.html}
}

@inproceedings{Louw05,
  author =	 {Louw, M. and Nicolls, F.},
  title =	 {An approximate EM Homographical Iterative Closest
                  Point algorithm },
  year =	 2005,
  booktitle =	 PRASA,
  address =	 {Langebaan, Cape Town, South Africa},
  url =
                  {http://www.dip.ee.uct.ac.za/~nicolls/publish/ml05-prasa.pdf},
}

@misc{Lovasz96,
  author =	 "L. Lovasz",
  title =	 "Random Walks on Graphs - a Survey",
  text =	 "L. Lovasz, Random Walks on Graphs - a Survey, in:
                  Combinatorics, Paul Erdos is Eighty, Part 2
                  Ed. D. Miklos, V. T. Sos, T. Szony, Janos Bolyai
                  Mathmatical Society, Budapest, 1996, Vol. 2,
                  pp. 353-398.",
  year =	 1996
}

@article{Lowe04,
  author =	 {D.G. Lowe},
  title =	 {Distinctive Image Features from Scale-Invariant
                  Keypoints},
  journal =	 IJCV,
  volume =	 60,
  number =	 2,
  year =	 2004,
  pages =	 {91-110}
}

@article{Lowe91,
  AUTHOR =	 "Lowe, D.G.",
  TITLE =	 "Fitting Parameterized Three-Dimensional Models to
                  Images",
  JOURNAL =	 PAMI,
  VOLUME =	 13,
  YEAR =	 1991,
  NUMBER =	 5,
  MONTH =	 "May",
  PAGES =	 "441-450"
}

@Article{Lowe92ijcv,
  author =	 "Lowe, D.G.",
  title =	 "Robust Model-Based Motion Tracking Through The
                  Integration Of Search And Estimation",
  journal =	 IJCV,
  year =	 1992,
  volume =	 8,
  pages =	 "113-122",
}

@InProceedings{Lowe99iccv,
  author =	 {D.G. Lowe},
  title =	 {Object Recognition from Local Scale-Invariant
                  Features},
  booktitle =	 ICCV,
  year =	 1999,
  pages =	 {1150--1157},
}

@Article{Lu79,
  author =	 {S.Y. Lu and K.S. Fu},
  title =	 {Stochastic tree grammar inference for texture
                  synthesis and discrimination},
  journal =	 {CGIP},
  year =	 1979,
  volume =	 9,
  pages =	 {234-245 },
}

@inproceedings{Lu94,
  author =	 "C. Lu and E. Mjolsness",
  title =	 "Two-Dimensional Object Localization by
                  Coarse-to-Fine Correlation Matching",
  booktitle =	 NIPS,
  volume =	 6,
  publisher =	 "Morgan Kaufmann Publishers, Inc.",
  editor =	 "J.D. Cowan and G. Tesauro and J. Alspector",
  pages =	 "985--992",
  year =	 1994,
}

@article{Lu96siam,
  author =	 "Szu-Min Lu and Jesse L. Barlow",
  title =	 "Multifrontal Computation with the Orthogonal Factors
                  of Sparse Matrices",
  journal =	 "SIAM Journal on Matrix Analysis and Applications",
  volume =	 17,
  number =	 3,
  pages =	 "658--679",
  year =	 1996,
  url =		 "citeseer.ist.psu.edu/lu94multifrontal.html"
}

@Article{Lu97,
  author =	 {F. Lu and E. Milios},
  title =	 {Globally consistent range scan alignment for
                  environment mapping},
  year =	 1997,
  month =	 {Apr},
  journal =	 AR,
  voulume =	 4,
  pages =	 {333-349},
  abstract =	 {A robot exploring an unknown environment may need to
                  build a world model from sensor measurements. In
                  order to integrate all the frames of sensor data, it
                  is essential to align the data properly. An
                  incremental approach has been typically used in the
                  past, in which each local frame of data is aligned
                  to a cumulative global model, and then merged to the
                  model. Because dierent parts of the model are
                  updated independently while there are errors in the
                  registration, such an approach may result in an
                  inconsistent model. In this paper, we study the
                  problem of consistent registration of multiple
                  frames of measurements (range scans), together with
                  the related issues of representation and
                  manipulation of spatial uncertainties. Our approach
                  is to maintain all the local frames of data as well
                  as the relative spatial relationships between local
                  frames. These spatial relationships are modeled as
                  random variables and are derived from matching
                  pairwise scans or from odometry. Then we formulate a
                  procedure based on the maximum likelihood criterion
                  to optimally combine all the spatial
                  relations. Consistency is achieved by using all the
                  spatial relations as constraints to solve for the
                  data frame poses simultaneously. Experiments with
                  both simulated and real data will be presented.},
}

@Article{Lu97jirs,
  author =	 {F. Lu and E. Milios},
  title =	 {Robot pose estimation in unknown environments by
                  matching {2D} range scans},
  year =	 1997,
  month =	 {April},
  journal =	 {Journal of Intelligent and Robotic Systems},
  voulume =	 18,
  pages =	 {249:275},
}

@InProceedings {Lucas81,
  author =	 "B. D. Lucas and Takeo Kanade",
  title =	 "An iterative image registration technique with an
                  application in stereo vision",
  booktitle =	 IJCAI,
  year =	 1981,
  pages =	 "674-679",
}

@Book{Luenberger84,
  author =	 {D.G. Luenberger},
  title =	 {Linear and Nonlinear Programming},
  publisher =	 addison,
  year =	 1984,
}

@Article{Lund00,
  author =	 {Jens Lund and Mats Rudemo},
  title =	 {Models for point processes observed with noise},
  journal =	 {Biometrika},
  year =	 2000,
  volume =	 87,
  number =	 2,
  pages =	 {235-249},
}

@TechReport{Lund99,
  author =	 {Jens Lund and Antti Penttinen and Mats Rudemo},
  title =	 {Bayesian analysis of spatial point patterns from
                  noisy observations},
  institution =	 {Mathematical Statistics, Chalmers University of
                  technology},
  year =	 1999,
  number =	 {1999:57},
  annote =
                  {http://www.dina.dk/~jlund/publications/publications.html}
}

@Article{Luong96,
  author =	 {Q.-T. Luong and O.D. Faugeras},
  title =	 {The {Fundamental} matrix: theory, algorithms, and
                  stability analysis},
  journal =	 IJCV,
  year =	 1996,
  volume =	 17,
  number =	 1,
  pages =	 {43--76},
}

@article{Luong97,
  author =	 "Q. Luong and O. Faugeras",
  title =	 "Self-calibration of a moving camera from point
                  correspondences and fundamental matrices",
  journal =	 IJCV,
  volume =	 22,
  number =	 3,
  pages =	 {261--89},
  year =	 1997
}

@Book{Lynch60book,
  author =	 {K. Lynch},
  fullauthor =	 {Kevin Lynch},
  title =	 {The image of the city},
  publisher =	 {The MIT press},
  year =	 1960,
  r-Kuipers77thesis ={Kevin Lynch's delightful book [] was responsible
                  for the recent surge of interest in mental images of
                  the environment. One central point is that the
                  mental image can be decomposed into symbolic
                  elements, and is not necessarily pictorial in nature
                  or properties. He distinguishes between the
                  qualities of imageability and legibility of an
                  environment. Imageability concerns the sensory
                  aspects of the environment and how its landmarks
                  evoke strong reactions. Legibility concerns the
                  structural aspects of the environment and how a
                  traveler can find his way around in it. The
                  properties that determine legibility are the ones
                  addressed by this research. .. Lynch decomposed the
                  knowledge in the cognitive map into five elements:
                  landmarks, nodes, paths, edges, and districts. Their
                  functions and relation- ships correspond roughly
                  with those of places, paths, and regions in the TOUR
                  model.},
  c-dellaert =	 {Qualitative tract about how people navigate cities
                  and what type of models they use. Have only
                  skimmed.},
}

@Book{Lynch71book,
  author =	 {K. Lynch},
  publisher =	 {{MIT} Press},
  title =	 "{The Image of the City}",
  year =	 1971
}

@InProceedings{Lyons00icad,
  author =	 {Lyons, K. and Gandy, M. and Starner, T.},
  year =	 2000,
  title =	 {Guided by Voices: An audio augmented reality
                  system. },
  booktitle =	 {Proceedings of the International Conference on
                  Auditory Display ICAD 2000, April 2-5},
  pages =	 {57-62},
}

@Proceedings{MASI03,
  title =	 {Proceedings of the 2nd International Workshop on the
                  Mathematics and Algorithms of Social Insects},
  year =	 2003,
  editor =	 {Anderson, C. and Balch, T.},
  address =	 {Atlanta},
  month =	 {December},
}

@Book{Ma04book,
  author =	 {Y. Ma and S. Soatto and J. Kosecka and S.S. Sastry},
  title =	 {An Invitation to {3-D} Vision},
  publisher =	 {Springer},
  year =	 2004,
}

@inproceedings{Ma99iccv,
  Author =	 {Ma, Y. and Soatto, S. and Kosecka, J. and Sastry,
                  S.},
  Pages =	 {773--780},
  Title =	 {Euclidean reconstruction and reprojection up to
                  subgroups},
  Volume =	 2,
  crossref =	 {_ICCV99},
}

@InProceedings{MacCormick98,
  author =	 "John MacCormick and Andrew Blake",
  title =	 "Spatial dependence in the observation of visual
                  contours",
  pages =	 "765--781",
  booktitle =	 "ECCV",
  year =	 1998,
}

@inproceedings{MacCormick99,
  author =	 "J. {MacCormick} and A. Blake",
  title =	 "A Probabilistic Exclusion Principle for Tracking
                  Multiple Objects",
  booktitle =	 ICCV,
  year =	 1999,
  pages =	 "572--578"
}

@article{MacEachern94,
  author =	 {S. N. MacEachern},
  year =	 1994,
  title =	 {Estimating normal means with a conjugate style
                  Dirichlet process prior},
  journal =	 {Communications in Statistics Part B - Simulation and
                  Computation},
  volume =	 23,
  pages =	 {727-741}
}

@article{MacEachern98,
  author =	 "S. N. MacEachern and P. Muller",
  year =	 1998,
  title =	 "Estimating Mixture of Dirichlet Process Models",
  journal =	 "Journal of Computational and Graphical Statistics",
  volume =	 7,
  pages =	 "223--238",
}

@article{MacEachern99cjs,
  author =	 "S. N. MacEachern and M. Clyde and J.S.Liu",
  year =	 1999,
  title =	 "Sequential importance sampling for nonparametric
                  {Bayes} models:the next generation",
  journal =	 "Canadian Journal of Statistics",
  volume =	 27,
  pages =	 "251-267",
}

@Book{MacKay03book,
  author =	 {D.J.C. MacKay},
  title =	 {Information Theory, Inference, and Learning
                  Algorithms},
  publisher =	 {Cambridge University Press},
  year =	 2003,
}

@InCollection{MacKay99chapter,
  author =	 "D.J.C. MacKay",
  title =	 "Introduction to {M}onte {C}arlo methods",
  crossref =	 {_Jordan98book},
  pages =	 "175-204",
}

@InProceedings{Maciel00,
  author =	 {Joo Maciel and Joo Costeira},
  title =	 {Robust Point Correspondence by Concave Mininization},
  booktitle =	 BMVC,
  year =	 2000,
  month =	 {September},
}

@TechReport{Maciel00b,
  author =	 "J. Maciel and J. Costeira",
  title =	 "Robust Point Correspondence by Concave Minimization",
  institution =	 "Instituto de Sistemas e Robotica, IST",
  year =	 1999,
  number =	 "VISLAB-TR 11/99",
  month =	 "December",
  url =		 "http://www.isr.ist.utl.pt/~maciel/tr1199.ps.gz"
}

@Unpublished{Maciuca:preprint,
  author =	 {R. Maciuca and S.C. Zhu},
  title =	 {How Do Heuristics Expedite {M}arkov Chain Search?},
  note =	 {Preprint of Statistics, UCLA},
}


@InProceedings{Madigan93,
  author =	 "D. Madigan and A. Raftery and J. Bradshaw and
                  R. Almond",
  title =	 "Strategies for Graphical Model Selection",
  pages =	 "331--336",
  booktitle =	 " Proc. International Workshop on AI and Statistics",
  year =	 1993,
}

@article{Madigan95,
  author =	 "D. Madigan and J. York",
  title =	 "Bayesian graphical models for discrete data",
  journal =	 "International Statistical Review ",
  volume =	 63,
  pages =	 "215--232",
  year =	 1995
}

@inproceedings{Madsen05icml,
  title =	 {Modeling word burstiness using the Dirichlet
                  distribution},
  authors =	 {R.E. Madsen and D. Kauchak and C. Elkan},
  booktitle =	 ICML,
  year =	 2005,
  pages =	 {545--552},
}

@InProceedings{Maeda97,
  author =	 {Sakashi Maeda and Yoshinori Kuno and Yoshiaki
                  Shirai},
  title =	 {Active Navigation Vision Based on Eigenspace
                  Analysis},
  booktitle =	 IROS,
  year =	 1997,
}

@ARTICLE{Magerko09lmt,
  title =	 {The Potential for Scientific Collaboration in
                  Virtual Ecosystems},
  author =	 {Magerko, B.},
  journal =	 {Learning, Media and Technology: Special Issue on
                  Learning in Virtual Worlds},
  year =	 2009,
}

@article{Mahon08tro,
  fullauthor =	 {Ian Mahon and Stefan B. Williams and Oscar Pizarro
                  and Matthew Johnson-Roberson},
  author =	 {I. Mahon and S.B. Williams and O. Pizarro and
                  M. Johnson-Roberson},
  title =	 {Efficient View-Based {SLAM} Using Visual Loop
                  Closures},
  journal =	 TRO,
  volume =	 24,
  number =	 5,
  pages =	 {1002-1014},
  month =	 {Oct},
  year =	 2008,
  abstract =	 {This paper presents a simultaneous localization and
                  mapping algorithm suitable for large-scale visual
                  navigation. The estimation process is based on the
                  viewpoint augmented navigation (VAN) framework using
                  an extended information filter. Cholesky
                  factorization modifications are used to maintain a
                  factor of the VAN information matrix, enabling
                  efficient recovery of state estimates and
                  covariances. The algorithm is demonstrated using
                  data acquired by an autonomous underwater vehicle
                  performing a visual survey of sponge
                  beds. Loop-closure observations produced by a stereo
                  vision system are used to correct the estimated
                  vehicle trajectory produced by dead reckoning
                  sensors.},
}

@Book{Maier83book,
  author =	 {D. Maier},
  title =	 {The Theory of Relational Databases},
  publisher =	 {Computer Science Press},
  year =	 1983,
  address =	 {Rockville, MD},
  r-Dechter92chapter ={Several efficient procedures for identifying
                  and finding a representative join tree have been
                  described \cite{Maier83book}.},
  r-Kask05ai =	 {Database researchers observed, almost three decades
                  ago, that relational database schemes that
                  constitute join-trees enable efficient query
                  processing \cite{Maier83book}},
  r-Kask05ai =	 {Tree clustering schemes have been widely used for
                  constraint processing, probabilistic reasoning and
                  for graphical models in general. The most popular
                  variants are join-tree clustering algorithms, also
                  called junction-trees. The schemes vary somewhat in
                  their graph definitions as well as in the way
                  tree-decompositions are processed \cite{Maier83book,
                  Dechter89ai, Jensen90csq, Lauritzen97amai,
                  Shenoy96uai, Gottlob00ai}. However, they all involve
                  a decomposition of a hyper-graph into a hyper-tree.},
  r-Kask05ai =	 {A join-tree clustering is defined as a tree T =
                  (V,E), where V is a set of maximal cliques of [the
                  chordal graph] G' and E is a set of edges that form
                  a tree between cliques satisfying the connectedness
                  property \cite{Maier83book}.}
}

@InProceedings{Maji08cvpr,
  author = {S. Marji and A. Berg and J. Malik},
  title = {Classification using intersection kernel support vector machines is efficient},
  booktitle = CVPR,
  year = {2008}
}

@InProceedings{Makadia03cvpr,
  author =	 {A. Makadia and K. Daniilidis},
  author =	 {Ameesh Makadia and Kostas Daniilidis},
  title =	 {Direct 3D-Rotation Estimation from Spherical Images
                  via a Generalized Shift Theorem},
  booktitle =	 CVPR,
  year =	 2003,
}

@InProceedings{Makadia05cvpr,
  author =	 {A. Makadia and C. Geyer and K. Daniilidis},
  title =	 {Radon-based Structure from Motion Without
                  Correspondences},
  booktitle =	 CVPR,
  year =	 2005,
}

@InProceedings{Makadia05icra,
  title =	 {Correspondenceless Ego-Motion Estimation using an
                  {IMU}},
  author =	 {A. Makadia and K. Daniilidis},
  booktitle =	 {ICRA},
  place =	 {Barcelona},
  month =	 {April},
  year =	 2005,
}

@Unpublished{Makadia07,
  author =	 {A. Makadia and C. Geyer and K. Daniilidis},
  title =	 {Correspondenceless Structure From Motion},
  note =	 {To appear in IJCV},
  year =	 2007,
}

@InProceedings{Makarenko04fusion,
  author =	 {Makarenko, A. and H, Durrant-Whyte},
  title =	 {Decentralized Data Fusion and Control in Active
                  Sensor Networks},
  booktitle =	 {7th Intl. Conf. on Information Fusion (Fusion'04)},
  year =	 2004,
  address =	 {Stockholm},
  month =	 {June-July},
  abstract =	 {The paper presents an algorithm for Bayesian
                  decentralized data fusion (BDDF) and its extension
                  to information-theoretic control. The algorithm is
                  stated for a feature represented by a general
                  probability density function. Several specific
                  representations are then considered -- Gaussian,
                  discrete, Certainty Grid, and hybrid. Well known
                  algorithms for these representations are shown to
                  fit the general BDDF pattern. Stating the algorithms
                  in Bayesian terms has a practical advantage of
                  allowing a generic software implementation. It is
                  also hoped that a clear general formulation will
                  stimulate extensions to efficient non-parametric
                  representations of arbitrary distributions. The
                  algorithms are described in the context of the
                  Active Sensor Network architecture -- a modular
                  framework for decentralized cooperative data fusion
                  and control. The approach is illustrated with the
                  results of two deployment scenarios with an indoor
                  sensor network.},
  c-dellaert =	 {A bit complex, dominated by software-architecture,
                  hard to see main point. Key = Active sensor
                  networks, ASN = control + estimation in SN, Bayesian
                  not just Gaussian, application = distributed
                  information gathering (DIG)},
}

@Article{Makris02ivc,
  author =	 "D. Makris and T. Ellis",
  fullauthor =	 "Dimitrios Makris and Tim Ellis",
  title =	 {{Path detection in video surveillance}},
  journal =	 IVC,
  volume =	 20,
  number =	 12,
  month =	 "Oct.",
  year =	 "2002",
  pages =	 "895-903",
  keywords =	 {surveillence, path detection},
}

@Book{Mallat98,
  author =	 {S. Mallat},
  title =	 {A wavelet tour of signal processing},
  publisher =	 {Academic Press},
  year =	 1998,
}

@Article{Mallick97,
  author =	 "B. K. Mallick",
  title =	 "Bayesian curve estimation by polynomials of random
                  order",
  journal =	 "J. Statist. Plan. Inform.",
  volume =	 70,
  year =	 1997,
  pages =	 "91-109",
  url =		 "citeseer.nj.nec.com/mallick95bayesian.html",
}

@InProceedings{Malzbender06egr,
  author =	 "T. Malzbender and B. Wilburn and D. Gelb and
                  B. Ambrisco",
  title =	 "Surface enhancement using real-time photometric
                  stereo and reflectance transformation",
  booktitle =	 "Eurographics Symposium on Rendering",
  pages =	 {245--250},
  year =	 2006,
}

@inproceedings{Maneva05soda,
  author =	 {E. Maneva and E. Mossel and M.J. Wainwright},
  fullauthor =	 {Elitza Maneva and Elchanan Mossel and Martin
                  J. Wainwright},
  title =	 {A new look at survey propagation and its
                  generalizations},
  booktitle =	 {SODA '05: Proceedings of the sixteenth annual
                  ACM-SIAM symposium on Discrete algorithms},
  year =	 2005,
  isbn =	 {0-89871-585-7},
  pages =	 {1089--1098},
  location =	 {Vancouver, British Columbia},
  publisher =	 {Society for Industrial and Applied Mathematics},
  address =	 {Philadelphia, PA, USA},
  r-Tu06bsc =	 {A milestone in the understanding of SP in this
                  context is the work of \citep{Maneva05soda}. In
                  \citep{Maneva05soda}, the authors introduced a
                  combinatorial framework - a Markov Random Field
                  (MRF) formalism over the extended configuration
                  space (i.e., each variable alphabet includes the
                  additional joker symbol). Based on this formalism,
                  the authors of \citep{Maneva05soda} generalized SP
                  to a family of algorithms parameterized by a single
                  real number between 0 and 1, as a solver for k-SAT
                  problems. In addition, it is shown in
                  \citep{Maneva05soda} that this family of algorithms
                  may be interpreted as an instance of the well-known
                  sum-product (or belief-propagation) algorithm
                  \cite{Kschischang01it} on their MRF model.},
}

@InProceedings{Mann94,
  author =	 {S.~Mann and R.W.~Picard},
  title =	 {Virtual Bellows: {C}onstructing High Quality Stills
                  from Video},
  booktitle =	 ICIP,
  year =	 1994,
  address =	 {Austin, TX},
  month =	 {September},
  pages =	 {363--367}
}

@Article{Mann97,
  author =	 {S.~Mann and R.W.~Picard},
  title =	 {Video Orbits of the Projective Group: {A} Simple
                  Approach to Featureless Estimation of Parameters},
  journal =	 IP,
  year =	 1997,
  month =	 {September}
}

@Book{ManningSchutze01,
  author =	 {C.D. Manning and H. Schutze},
  title =	 {Foundations of Statistical Natural Language
                  Processing},
  publisher =	 MIT,
  year =	 2001,
}

@InProceedings{Mantzel04acssc,
  author =	 {W.E. Mantzel and H. Choi and R.G. Baraniuk},
  title =	 {Distributed Camera Network Localization},
  booktitle =	 {the 38th Asilomar Conference on Signals, Systems and
                  Computers (ACSSC)},
  year =	 2004,
  month =	 {November},
}

@inproceedings{Manyika92cdc,
  Author =	 {Manyika, J. M. and Durrant-Whyte, H. F.},
  booktitle =	 CDC,
  Pages =	 {3506--3507},
  volume =	 4,
  Title =	 {On sensor management in decentralized data fusion},
  Year =	 1992,
  Abstract =	 {A probabilistic framework for decentralized data
                  fusion and sensor management based on the notion of
                  Bayesian information value is presented. Use is made
                  of information as the expected utility of actions
                  within a framework of decentralized
                  decision-theory. Entropy is used as an information
                  metric. Some preliminary results justifying this
                  approach are shown},
  c-dellaert =	 {Manyika arrives on the scene, "Information" and
                  "DDF" terms are used (for the first
                  time?). Information gain from Bayes law:
                  P(x|z)=P(x)P(z|x)/P(z) =>
                  I[P(x|z)]=I[P(x)]+I[P(z|x)/P(z)], where I[p] = E[ln
                  p], i.e. I[p] = - H[p], where H is entropy. By
                  taking the log, probabilities are transformed in
                  negative energies, and these are additive. Quoting
                  the paper "Continuous and discrete data fusion
                  algrothms can be directly derived from Eqn. 3",
                  i.e. both the DKF and the DBI from
                  \citet{Rao91iros}. Manyika then continues to also
                  include decsision-making, but I don't quite follow
                  it from the terse description. This is just a
                  two-page abstract, but it illustrates the ideas are
                  becoming much more sophisticated and general.},
}

@Book{Manyika94book,
  author =	 {J. Manyika and H.F. Durrant-Whyte},
  title =	 {Data Fusion and Sensor Management: An
                  Information-Theoretic Approach.},
  publisher =	 {Prentice Hall},
  year =	 1994,
  r-Zhao03ieee = {The distributed information filter
                  \cite{Manyika94book} is a method of distributed
                  fusion in which nodes communicate any new
                  information contained in each measurement to other
                  nodes for fusion. Unlike IDSQ, it is not localized
                  to regions of high-information content, and thus may
                  suffer from higher communication requirements and
                  scalability problems.},
  c-dellaert =	 {see DurrantWhyte01fusion},
}

@INPROCEEDINGS{Mao04uai,
  AUTHOR =	 "Y. Mao and Frank Kschischang and Brendan Frey",
  FULLAUTHOR =	 "Yongyi Mao and Frank Kschischang and Brendan Frey",
  TITLE =	 "Convolutional Factor Graphs as Probabilistic Models",
  crossref =	 "_UAI04",
  PAGES =	 "374-38",
  abstract =	 {Based on a recent development in the area of error
                  control coding, we introduce the notion of
                  convolutional factor graphs (CFGs) as a new class of
                  probabilistic graphical models. In this context, the
                  conventional factor graphs are referred to as
                  multiplicative factor graphs (MFGs). This paper
                  shows that CFGs are natural models for probability
                  functions when summation of independent latent
                  random variables is involved. In particular, CFGs
                  capture a large class of linear models, where the
                  linearity is in the sense that the observed
                  variables are obtained as a linear transformation of
                  the latent variables taking arbitrary
                  distributions. We use Gaussian models and
                  independent factor models as examples to demonstrate
                  the use of CFGs. The requirement of a linear
                  transformation between latent variables (with
                  certain independence restriction) and the observed
                  variables, to an extent, limits the modelling
                  flexibility of CFGs. This structural restriction
                  however provides a powerful analytic tool to the
                  framework of CFGs; that is, upon taking the Fourier
                  transform of the function represented by the CFG,
                  the resulting function is represented by a MFG with
                  identical structure. This Fourier transform duality
                  allows inference problems on a CFG to be solved on
                  the corresponding dual MFG.},
  c-dellaert =	 {Introduce convolutional factor graphs.},
}

@Article{Mao05it,
  author =	 {Mao, Y. and Kschischang, F.R.},
  fullauthor =	 {Mao, Yongyi and Kschischang, Frank R.},
  title =	 {On factor graphs and the {Fourier} transform},
  journal =	 IT,
  year =	 {2005},
  volume =	 {51},
  number =	 {5},
  pages =	 {1635--1649},
  r-Loeliger04spm ={\citet{Forney01it} and \citet{Mao05it} showed that
                  the Fourier transform of a multi-variable function
                  can be carried out directly in the FFG (which may
                  have cycles) according to the following recipe... },
  r-Mao04uai =	 {The foundation of this paper is presented in
                  \cite{Mao05it}, where a generalized notion of
                  multi-variate convolution and the notion of CFGs
                  were presented in the context of error correction
                  coding. based on CFG models.},
  c-dellaert =	 {MatSciNet search on "factor graphs". Not read yet.},
}

@article{Mareschal03cognition,
  author =	 {D. Mareschal and M. H. Johnson},
  title =	 {The "what" and "where" of object representations in
                  infancy},
  journal =	 {Cognition},
  volume =	 88,
  number =	 3,
  pages =	 {259--276},
  year =	 2003,
}

@Article{Marinakis08tro,
  author =	 {D. Marinakis and G. Dudek},
  title =	 {Occam's Razor Applied to Network Topology Inference},
  journal =	 TRO,
  year =	 {2008},
  month =	 {April},
  volume =	 {24},
  number =	 {2},
  pages =	 {293--306}
}

@Book{Markman99book,
  author =	 {A.B. Markman},
  title =	 {Knowledge Representation},
  publisher =	 {Lawrence Erlbaum Associates},
  year =	 1999,
  address =	 {Mahwah, NJ},
}

@InProceedings{Marks07vslam,
  author =	 {T.K. Marks and A. Howard and M. Bajracharya and
                  G.W. Cottrell and L. Matthies},
  fullauthor =	 {Tim K. Marks and Andrew Howard and Max Bajracharya
                  and Garrison W. Cottrell and Larry Matthies},
  title =	 {Gamma-{SLAM}: Stereo Visual {SLAM} in Unstructured
                  Environments Using Variance Grid Maps},
  booktitle =	 {IROS visual SLAM workshop},
  location =	 {San Diego},
  month =	 {Oct},
  year =	 2007,
  abstract =	 {We introduce a new method for stereo visual SLAM
                  (simultaneous localization and mapping) that works
                  in unstructured, outdoor environments. Observations
                  use dense stereo vision to measure the variance of
                  the heights in each cell of a 2D grid. Unlike other
                  grid-based SLAM algorithms, which use occupancy grid
                  maps, our algorithm uses a new mapping technique
                  that maintains a posterior distribution over the
                  height variance in each cell. To obtain a joint
                  posterior over poses and maps, we use a
                  Rao-Blackwellized particle filter: the pose
                  distribution is estimated using a particle filter,
                  and each particle has its own map that is obtained
                  through exact filtering conditioned on the particle?
                  pose. For the particle filter over pose, visual
                  odometry (VO) provides good proposal
                  distributions. In the analytical (exact) filter for
                  the map, we update the sufficient statistics of a
                  gamma distribution over the precision (inverse
                  variance) of heights in each grid cell. We
                  demonstrate performance on two outdoor courses, and
                  verify the accuracy of the algorithm by comparing
                  with ground truth data obtained using electronic
                  surveying equipment.},
  c-kaess =	 {Combines FastSLAM-based SLAM with grid maps in the
                  context of the DARPA LAGR program. The FastSLAM part
                  is standard, but the maps are special in this
                  context: Based on dense stereo data, they capture
                  the variation in height, represented by a gamma
                  distribution. The mean of the Gaussian height
                  distribution is ignored. It is argued that the
                  height is difficult to determine and not very
                  meaningful given non-flat terrain. Resulting maps
                  for two environments are shown, comparing gamma SLAM
                  with visual odometry. While the maps seem very
                  accurate and useful for navigation, the terrain in
                  the tests is very flat, and no overhanging objects,
                  such as leaves are present. No timing results are
                  provided, but the evaluation seems to be performed
                  offline, as real-time application is mentioned as
                  future work.},
}

@InProceedings{Marks08icra,
  author =	 {T.K. Marks and A. Howard and M. Bajracharya and
                  G.W. Cottrell and L. Matthies},
  fullauthor =	 {Tim K. Marks and Andrew Howard and Max Bajracharya
                  and Garrison W. Cottrell and Larry Matthies},
  title =	 {Gamma-{SLAM}: Using Stereo Vision and Variance Grid
                  Maps for {SLAM} in Unstructured Envrionments},
  booktitle =	 ICRA,
  year =	 2008,
}

@Book{Marr83book,
  author =	 {D. Marr},
  title =	 {Vision: A Computational Investigation into the Human
                  Representation and Processing of Visual Information},
  publisher =	 {W.H. Freeman and Company},
  year =	 1983,
}

@InProceedings{Marschner97,
  author =	 {S.Marschner and D.Greenberg},
  title =	 {Inverse lighting for photography},
  booktitle =	 {IST/SID Fifth Colort Imaging Conference},
  year =	 1997,
}

@InProceedings{Marschner99,
  author =	 {S.Marschner and S.Westin and E.Lafortune and
                  K.Torrance and D.Greenberg},
  title =	 {Image-based BRDF Measurement Including Human Skin},
  booktitle =	 {10th Eurographics Workshop on Rendering},
  year =	 1999,
  pages =	 {139-152},
}

@InProceedings{Marshall06cbms,
  author =	 {A.H. Marshall and R. Donaghy},
  title =	 {Intelligent Patient Management using Dynamic Models
                  of Clinical Variables},
  booktitle =	 {IEEE International Symposium on Computer-Based
                  Medical Systems},
  year =	 2006,
  pages =	 {805--812},
}

@ARTICLE{Marsland01,
  AUTHOR =	 "{Marsland}, Stephen and {Nehmzow}, Ulrich and
                  {Duckett}, Tom",
  TITLE =	 "Learning to Select Distinctive Landmarks for Mobile
                  Robot Navigation",
  JOURNAL =	 "Robotics and Autonomous Systems",
  VOLUME =	 37,
  NUMBER =	 4,
  PAGES =	 {241--260},
  YEAR =	 2001
}

@InProceedings{Marszalek09cvpr,
  author = {M. Marszalek and I. Laptev and C. Schmid},
  title = {Actions in Context},
  booktitle = CVPR,
  year = {2009}
}

@InProceedings{Martel-Brisson05cvpr,
  author =	 {N. Martel-Brisson and A. Zaccarin},
  title =	 {Moving Cast Shadow Detection from a Gaussian Mixture
                  Shadow Model},
  booktitle =	 CVPR,
  year =	 2005,
  abstract =	 {Moving cast shadows are a major concern for
                  foreground detection algorithms. Processing of
                  foreground images in surveillance applications
                  typically requires that such shadows have been
                  identified and removed from the detected
                  foreground. This paper presents a novel pixel-based
                  statistical approach to model moving cast shadows of
                  non-uniform and varying intensity. This approach
                  uses the Gaussian mixture model (GMM) learning
                  ability to build statistical models describing
                  moving cast shadows on surfaces. This statistical
                  modeling can deal with scenes with complex and
                  time-varying illumination, and prevent false
                  detection in regions where shadows cannot be
                  detected. Gaussian mixture shadow models (GMSM) are
                  automatically constructed and updated over time, are
                  easily added to a GMM architecture for foreground
                  detection, and require only a small number of
                  parameters. Results obtained with different scene
                  types show the robustness of the approach. },
  c-houdan =	 {It uses Mixture of Gaussian to model shadowed
                  surfaces in YUV color space. The shadow properties
                  model used here is similar to Horprasert99frame},
}

@InProceedings{Marthi02,
  title =	 {Decayed {MCMC} filtering},
  author =	 {B. Marthi and H. Pasula and S. Russel and Y. Peres},
  crossref =	 {_UAI02},
}

@article{Martin04pami,
  author =	 "D. R. Martin and C. C. Fowlkes and J. Malik",
  title =	 "Learning to Detect Natural Image Boundaries Using
                  Local Brightness, Color, and Texture Cues",
  journal =	 PAMI,
  year =	 2004,
  volume =	 26,
  number =	 5,
  pages =	 "530-549",
}

@InProceedings{Martinec02eccv,
  author =	 {D. Martinec and T. Pajdla},
  title =	 {Structure from Many Perspective Images with
                  Occlusions},
  booktitle =	 ECCV,
  year =	 2002,
}

@InProceedings{Martinec05cvpr,
  author =	 {D. Martinec and T. Pajdla},
  title =	 {{3D} reconstruction by fitting low-rank matrices
                  with missing data},
  booktitle =	 CVPR,
  month =	 {June},
  year =	 2005,
}

@InProceedings{Martinec06_3dpvt,
  author =	 {D. Martinec and T. Pajdla},
  title =	 {{3D} Reconstruction by Gluing Pair-wise Euclidean
                  Reconstructions, or "How to Achieve a Good
                  Reconstruction from Bad Images"},
  booktitle =	 PVT,
  year =	 2006,
}

@TechReport{Martinson02mpl,
  author =	 {E.B. Martinson and F. Dellaert},
  title =	 {Marco {P}olo {L}ocalization},
  institution =	 CoC,
  year =	 2002,
  month =	 {September},
  note =	 {Also submitted as a regular paper to ICRA 2003}
}

@InProceedings{Martinson03icra,
  author =	 {E.B. Martinson and F. Dellaert},
  title =	 {Marco {P}olo {L}ocalization},
  booktitle =	 ICRA,
  year =	 2003,
  month =	 {May},
}

@Article{Masini83,
  author =	 {G. Masini and R. Mohr},
  title =	 {MIRABELLE, a system for structural analysis of line
                  drawings},
  journal =	 {Pattern Recognition},
  year =	 1983,
  volume =	 16,
  pages =	 {363-372},
}

@InProceedings{Maslen97generalized,
  author =	 {David K. Maslen and Daniel Rockmore},
  title =	 {Generalized {FFTs} - A Survey of some recent
                  results},
  booktitle =	 {Proceedings of the DIMACS Workshop on Groups and
                  Computation},
  pages =	 {183-237},
  year =	 1997
}

@Article{Maslen97separation,
  author =	 {D. Maslen and D. Rockmore},
  title =	 {Separation of Variables and the Computation of
                  {Fourier} Transforms on Finite Groups, {I}},
  journal =	 {Journal of the American Math Society},
  year =	 1997,
  volume =	 {1(10)},
  pages =	 {169-214},
}

@MastersThesis{Mataric90,
  author =	 {Matari\'{c}, M.~J.},
  title =	 {A distributed model for mobile robot
                  environment-learning and navigation},
  school =	 {MIT, Artificial Intelligence Laboratory, Cambridge},
  year =	 1990,
  month =	 {January},
  note =	 {Also available as MIT AI Lab Tech Report AITR1228}
}

@inproceedings{Mataric90sab,
  author =	 {Matari\'{c}, M.~J.},
  title =	 {Navigating with a rat brain: A
                  neurobiologically-inspired model for robot spatial
                  representation},
  year =	 1990,
  booktitle =	 {From Animals to Animats: First International
                  Conference on Simulation of Adaptive Behavior
                  (SAB-90)},
  editor =	 {J.-A.Meyer and S.W.Wilson},
  publisher =	 {MIT Press, Cambridge, MA.},
  r-Franz98ar =	 {Motivated by the findings of vertebrate ethology,
                  researchers have started to investigate topological
                  representations for robot navigation (e.g.,
                  \cite(Kuipers91ras,Mataric91sab)},
  r-Franz00ras = {Experiments on rat navigation motivated Mataric to
                  build a robot that concatenated different wall and
                  midline following behaviours to routes and
                  graphs. The robot was equipped with a ring of
                  ultrasonic sensors and a compass. It executed a
                  single behaviour as long as the sensory conditions
                  remained qualitatively the same, e.g., as long as
                  the robot? ultrasonic sensors detected a corridor
                  leading into the south. A new behaviour was
                  triggered by arriving at a distinctive place showing
                  a qualitative change of the immediate environment
                  such as a corner or a dead end. In contrast to the
                  other approaches, the recognition of these places
                  was only determined by their context, i.e., by the
                  sequence of actions preceding the current
                  action. Thus, the only information stored in the
                  graph representation were actions, not place
                  descriptions. In the graph, each action was labelled
                  by the type of the local environment and by the
                  navigation behaviour used to traverse it (e.g.,
                  follow left wall heading south). These features
                  allowed the robot to acquire routes autonomously by
                  simply following the walls of the experimental
                  room. Routes were integrated as soon as the robot
                  encountered a previously visited local environment
                  requiring the same local navigation behaviour. This
                  shows a limitation of Mataric? approach: The number
                  of uniquely identifiable combinations of wall type
                  and compass direction is small. In general
                  environments, the problem of perceptual aliasing
                  arises, i.e., distinct locations appear identical to
                  the robot? sensors [55]. Arriving at a new situation
                  identical to an already stored one, Mataric? robot
                  would perform a false route integration. Thus, the
                  navigable environment remained confined to rooms
                  with a uniquely identifiable wall configuration.},
  c-dellaert =	 {Taking place cells idea and trying to graft this on
                  Brooks subsumption architecture.},
}

@Article(Messier05photo,
  author =       {Messier, P.},
  fullauthor =   {Paul Messier},
  title =        {Notes on Dating Photographic Paper},
  journal =      {Topics in Photograph Preservation},
  volume =       11,
  year =         2005,
}

@InProceedings{Matas02bmvc,
  author =	 {J. Matas and O. Chum and M. Urban and T. Pajdla},
  title =	 {Robust Wide Baseline Stereo from Maximally Stable
                  Extremal Regions},
  booktitle =	 BMVC,
  pages =	 {414-431},
  year =	 {2002},
}

@InProceedings{Matas05iccv,
  author =	 {J. Matas and O. Chum},
  title =	 {Randomized {RANSAC} with Sequential Probability Ratio
                  Test},
  booktitle =	 ICCV,
  pages =	 {1727-1732},
  year =	 2005,
}

@InProceedings{Mateescu07ijcai,
  author =	 {R. Mateescu and R. Dechter},
  fullauthor =	 {Robert Mateescu and Rina Dechter},
  title =	 {A Comparison of Time-Space Schemes for Graphical
                  Models},
  booktitle =	 IJCAI,
  year =	 2007,
  c-dellaert =	 {AND/OR adaptive caching encompasses all other
                  algorithms. Fairly detailed, not amazingly
                  insightful.},
}

@Misc{Mathworld,
  year =	 2006,
  title =	 {MathWorld -- a {Wolfram} Web Resource},
  howpublished = {Web site: http://mathworld.wolfram.com},
}

@article{Matstoms94toms,
  author =	 {P. Matstoms},
  fullauthor =	 {Pontus Matstoms},
  title =	 {Sparse {QR} factorization in {MATLAB}},
  journal =	 {ACM Trans. Math. Softw.},
  volume =	 20,
  number =	 1,
  year =	 1994,
  issn =	 {0098-3500},
  pages =	 {136--159},
  doi =		 {http://doi.acm.org/10.1145/174603.174408},
  publisher =	 {ACM Press},
}

@InProceedings{Matsumoto00iros,
  author =	 {Y. Matsumoto and K. Ikeda and M. Inaba and H. Inoue},
  title =	 {Exploration and navigation in corridor environment
                  based on Omni-View sequence},
  booktitle =	 IROS,
  pages =	 {1505 - 1510},
  year =	 2000,
  volume =	 2,
}

@InProceedings{Matsumoto99,
  author =	 {Y. Matsumoto and K. Ikeda and M. Inaba and H. Inoue},
  title =	 {Exploration and Map Acquisition for View-Based
                  Navigation in Corridor Environment},
  booktitle =	 FSR,
  year =	 1999,
}

@Article{Matthies87,
  author =	 {L. Matthies and S.A. Shafer},
  title =	 {Error modeling in stereo navigation},
  journal =	 {Robotics and Automation},
  year =	 1987,
  volume =	 {RA-3},
  pages =	 {234-248},
}

@Article{Mau99,
  author =	 {B. Mau and M. A. Newton and B. Larget},
  title =	 {Bayesian phylogenetic inference via Markov chain
                  Monte Carlo methods},
  journal =	 {Biometrics},
  volume =	 5,
  pages =	 {1-12},
  year =	 1999,
}

@inproceedings{Maurer96,
  AUTHOR =	 "Maurer, M. and Behringer, R. and Fuerst, S. and
                  Thomanek, F. and Dickmanns, E.",
  TITLE =	 "A Compact Vision System for Road Vehicle Guidance",
  BOOKTITLE =	 ICPR,
  YEAR =	 1996,
  PAGES =	 "C7A.1"
}

@misc{MaxPlanck06pr,
  title =	 {Two Nerve Cells in Direct Contact},
  howpublished = {Max Planck Society Press Release},
  year =	 {2006},
  editor =	 {Andreas Trepte},
}

@Book{Maybeck79,
  author =	 "P. Maybeck",
  title =	 "Stochastic Models, Estimation and Control",
  address =	 "New York",
  publisher =	 "Academic Press",
  year =	 1979,
  volume =	 1,
}

@Book{Maybeck82,
  author =	 "P. Maybeck",
  title =	 "Stochastic Models, Estimation and Control",
  address =	 "New York",
  publisher =	 "Academic Press",
  year =	 1982,
  volume =	 2,
}

@inproceedings{McCallum96sab,
  author =	 {McCallum, R. Andrew},
  title =	 {Learning to Use Selective Attention and Short-Term
                  Memory in Sequential Tasks},
  booktitle =	 {From Animals to Animats, Fourth International
                  Conference on Simulation of Adaptive Behavior,
                  (SAB'96)},
  address =	 {Cape Cod, MA},
  month =	 {September},
  year =	 1996,
  r-Hayhoe00vc = {Thus, it is important to establish if the normal
                  range of visual behaviours is possible from limited
                  representations. One demonstration that this is
                  possible is in driving, where McCallum (1995)
                  demonstrated that a very limited set of sensory
                  information was sufficient to allow a simulated
                  vehicle to learn to drive successfully on a freeway,
                  passing slower cars in front and avoiding faster
                  cars behind. .. The work ofMcCallum (1995),
                  described earlier, shows that an autonomous agent
                  can learn a minimal set of perception?ction
                  sequences appropriate for freeway driving. This can
                  be modelled as a partially observable Markov
                  decision process, where the state transitions
                  reflect the behaviour and the underlying structure
                  of theMarkov process reflects the organization of
                  the driving schema.},
  c-dellaert =	 {I know this work well, as I tried implementing it
                  once. Highway driving simulator, gaze is important
                  state variable. Emphasis is on how to learn to deal
                  with Non-Markovian state spaces in RL, i.e., solving
                  a POMDP.}
}

@article{McDermottRobots,
  author =	 {McDermott},
  title =	 {Robots},
  journal =	 {Languages},
  year =	 {2001},
}

@Book{McFarland93Book,
  author =	 {D. McFarland},
  title =	 {Animal {B}ehaviour},
  publisher =	 {Longman Scientific and Technical},
  year =	 1993,
}

@Article{McKeague00,
  author =	 {McKeague, I. W. and Wefelmeyer, W.},
  title =	 {Markov Chain {M}onte {C}arlo and
                  {R}ao-{B}lackwellization},
  journal =	 {Statistical Planning and Inference},
  year =	 2000,
  volume =	 85,
  pages =	 {171-182},
}

@Book{McLachlan88,
  author =	 "G.J. McLachlan and K.E. Basford",
  title =	 "Mixture Models: Inference and Applications to
                  Clustering",
  publisher =	 "Marcel Dekker",
  year =	 1988,
  address =	 "New York",
}

@Book{McLachlan97,
  author =	 "G.J. McLachlan and T. Krishnan",
  title =	 "The {EM} algorithm and extensions",
  publisher =	 "John Wiley \& Sons",
  year =	 1997,
  series =	 "Wiley series in probability and statistics",
}

@InProceedings{McMillan95,
  author =	 {L. McMillan and G. Bishop},
  title =	 {Plenoptic Modeling: An image-based rendering system},
  booktitle =	 SIGGRAPH,
  pages =	 {39-46},
  year =	 1995,
}

@TechReport{McMillan97,
  author =	 "Leonard McMillan and Gary Bishop",
  title =	 "Shape as a Perturbation to Projective Mapping",
  institution =	 "Dept. of Computer Science, University of North
                  Carolina",
  year =	 1997,
}

@inproceedings{Mclauchlan00cvpr,
  author =	 "P. {McLauchlan}",
  title =	 "A Batch/Recursive Algorithm for {3D} Scene
                  Reconstruction",
  pages =	 "738--743",
  booktitle =	 CVPR,
  year =	 2000,
}

@inproceedings{Mclauchlan95,
  author =	 "P. McLauchlan and D. Murray",
  title =	 "A unifying framework for structure and motion
                  recovery from image sequences",
  booktitle =	 ICCV,
  pages =	 {314--320},
  montyh =	 {June},
  year =	 1995
}

@article{Mech96,
  author =	 "R. Mech and P. Prusinkiewicz",
  title =	 "Visual models of plants interacting with their
                  environment",
  journal =	 "Proceedings of the 23rd annual conference on
                  Computer graphics and interactive techniques",
  publisher =	 "ACM Press",
  pages =	 {397-410 },
  year =	 1996
}

@article{Meila00ml,
  author =	 "M. Meila and M.I. Jordan",
  fullauthor =	 "Marina Meila and Michael I. Jordan",
  title =	 "Learning with Mixtures of Trees",
  journal =	 "Journal of Machine Learning Research",
  volume =	 1,
  pages =	 "1-48",
  year =	 2000,
  url =		 "citeseer.nj.nec.com/meila-predoviciu00learning.html"
}

@InProceedings{Meila00nips,
  author =	 {M. Meila and J. Shi},
  title =	 {Learning Segmentation with Random Walk},
  booktitle =	 NIPS,
  year =	 2000,
}

@InProceedings{Meila01aistats,
  author =	 {M. Meila and J. Shi},
  title =	 {A Random Walks View of Spectral Segmentation},
  booktitle =	 {AI and STATISTICS 2001(AISTATS)},
  year =	 2001
}

@inproceedings{Meila99icml,
  author =	 "Marina Meila",
  title =	 "An accelerated Chow and Liu algorithm: fitting tree
                  distributions to high dimensional sparse data",
  booktitle =	 ICML,
  year =	 1999,
}

@TechReport{Mellinger02,
  author =	 {D.K. Mellinger },
  title =	 {Ishmael 1.0 User's Guide. ISHMAEL: Integrated System
                  for Holistic Multi-channel Acoustic Exploration and
                  Localization},
  institution =	 {NOAA Technical Memorandum},
  year =	 2002,
  number =	 {OAR PMEL-120},
}

@InProceedings{Meltzer04iros,
  author =	 {J. Meltzer and R. Gupta and M.-H. Yang and
                  S. Soatto},
  fullauthor =	 {Jason Meltzer and Rakesh Gupta and Ming-Hsuan Yang
                  and Stefano Soatto},
  title =	 {Simultaneous Localization and Mapping using Multiple
                  View Feature Descriptors},
  booktitle =	 IROS,
  location =	 {Sendai, Japan},
  month =	 {Sep},
  year =	 2004,
  abstract =	 {We propose a vision-based SLAM algorithm
                  incorporating feature descriptors derived from
                  multiple views of a scene, incorporating
                  illumination and viewpoint variations. These
                  descriptors are extracted from video and then
                  applied to the challenging task of wide baseline
                  matching across significant viewpoint changes. The
                  system incorporates a single camera on a mobile
                  robot in an extended Kalman filter framework to
                  develop a 3D map of the environment and determine
                  egomotion. At the same time, the feature descriptors
                  are generated from the video sequence, which can be
                  used to localize the robot when it returns to a
                  mapped location. The kidnapped robot problem is
                  addressed by matching descriptors without any
                  estimate of position, then determining the epipolar
                  geometry with respect to a known position in the
                  map.},
  c-kaess =	 {Interesting idea of viewpoint invariance by kernal
                  PCA over a set of patches for each feature. Uses EKF
                  with M-estimator for robust outlier handling, and
                  bundle adjustment across several viewpoints to
                  correct for drift "keeping the known structure
                  constant". Results shown for camera that moved in a
                  circle around an object. Not real-time. I have
                  difficulty interpreting the experimental results.},
}

@PhdThesis{Menegatti02thesis,
  author =	 {E. Menegatti},
  title =	 {Omnidirectional Vision for Mobile Robotics},
  school =	 {Department of Information Engineering, The
                  University of Padua},
  year =	 2002,
  month =	 {Dec},
}

@InProceedings{Menegatti03ecmr,
  fullauthor =	 {E. Menegatti and M. Zoccarato and E. P. and
                  H. Ishiguro},
  author =	 {Emanuele Menegatti and Mauro Zoccarato and Enrico
                  Pagello and Hiroshi Ishiguro},
  title =	 {Hierarchical Image-based Localisation for Mobile
                  Robots with Monte-Carlo Localisation},
  booktitle =	 {Proc. of 1st European Conference on Mobile Robots
                  (ECMR'03), Warsaw, Poland},
  pages =	 {13-20},
  year =	 2003,
  month =	 {September},
}

@inproceedings{Menegatti03iaai,
  author =	 {E. Menegatti and M. Zoccarato and E. Pagello and
                  H. Ishiguro},
  title =	 {Image-based {Monte-Carlo} Localisation without a
                  Map},
  booktitle =	 {Proc. of the 8th Conference of the Italian
                  Association for Artificial Intelligence},
  year =	 2003,
  month =	 "September",
}

@Article{Menegatti04ras1,
  author =	 {E. Menegatti and M. Zoccarato and E. Pagello and
                  H. Ishiguro},
  title =	 {Image-Based {Monte-Carlo} Localisation with
                  Omnidirectional Images},
  journal =	 RAS,
  year =	 2004,
  volume =	 48,
  number =	 1,
  pages =	 {17--30},
  month =	 {August},
}

@article{Menegatti04ras2,
  author =	 {E. Menegatti and T. Maeda and H. Ishiguro},
  title =	 {Image-based memory for robot navigation using
                  properties of the omnidirectional images},
  journal =	 RAS,
  volume =	 47,
  number =	 4,
  pages =	 {251--267},
  year =	 2004
}

@Article{Meredith90psy,
  author =	 {Meredith, W. and Tisak, J.},
  fullauthor =	 {Wiliam Meredith and John Tisak},
  title =	 {Latent curve analysis},
  journal =	 {Psychometrika},
  year =	 1990,
  volume =	 55,
  number =	 1,
  pages =	 {107-122},
}

@InProceedings{Messina03icme,
  author =	 {G. Messina and A. Castorina and S. Battiato and
                  A. Bosco},
  title =	 {Image quality improvement by adaptive exposure
                  correction techniques},
  booktitle =	 ICME,
  pages =	 {549-552},
  year =	 2003,
}

@InProceedings{Messina03icme,
  author =	 {G. Messina and A. Castorina and S. Battiato and
                  A. Bosco},
  title =	 {Image quality improvement by adaptive exposure
                  correction techniques},
  booktitle =	 ICME,
  pages =	 {549-552},
  year =	 2003,
}

@Article{Metoyer03tvc,
  author =	 {R. A. Metoyer and J. K. Hodgins},
  fullauthor =	 {Ronald A. Metoyer and Jessica K. Hodgins},
  title =	 {{Reactive Pedestrian Path Following from Examples}},
  journal =	 {The Visual Computer},
  month =	 {Dec.},
  year =	 2004,
  volume =	 20,
  number =	 10,
  pages =	 {635-349},
  keywords =	 {pedestrian, group, animation},
  c-sangmin =	 {uses behavior-based control rules, and additionally
                  provide reactive path-following behaviors
                  w.r.t. user-specified examples. For generalization,
                  use Naive Bayes learning and classification for
                  decision process},
}

@ARTICLE{Metropolis53,
  AUTHOR =	 {Metropolis, N. and Rosenbluth, A.W. and Rosenbluth,
                  M.N. and Teller, A.H. and Teller, E.},
  TITLE =	 {Equations of state calculations by fast computing
                  machine},
  JOURNAL =	 {Journal of Chemical Physics},
  VOLUME =	 21,
  YEAR =	 1953,
  PAGES =	 {1087--1091}
}

@Article{Meyer92,
  author =	 {K.Meyer and H.L. Applewhite and F.A.Biocca},
  title =	 {A Survey of Position Trackers},
  journal =	 {Presence: Teleoperators and Virtual Environments},
  year =	 1992,
  volume =	 1,
  number =	 2,
  pages =	 {173-- 200},
}

@Article{Mezard02science,
  author =	 {M. M\'{e}zard and G. Parisi and R. Zecchina},
  title =	 {Analytic and algorithmic solution of random
                  satisfiability problems},
  journal =	 {Science},
  year =	 2002,
  volume =	 297,
  pages =	 {812--815},
  r-Tu06bsc =	 {Survey propagation (SP) \citep{Mezard02science} is a
                  recent revolutionary algorithmic discovery in
                  solving a classical class of NP-complete problems,
                  the k-SAT problems. As a message-passing procedure
                  on the factor graph representation
                  \citep{Kschischang01it} of the problem instance, SP
                  has been shown to be effective even for very large
                  and difficult instances of k-SAT problems.},
}

@Article{Mezard03science,
  author =	 {Marc Mzard},
  title =	 {Passing Messages Between Disciplines},
  journal =	 {Science},
  year =	 2003,
  volume =	 301,
  number =	 5640,
  pages =	 {1685--1686},
  month =	 {September},
  quotes =	 {ethods from statistical physics have helped to
                  understand the performance and limitations of BP,
                  and have led to substantial improvements. The
                  threshold phenomena exhibited by the above
                  computational problems -- the satisfiability
                  threshold or Shannon's threshold -- are nothing but
                  phase transitions, typical of macroscopic materials
                  that switch abruptly from one phase to another as a
                  result of a small change in a control
                  parameter. This happens, for example, when ice
                  changes to water at temperatures above 0C. In
                  physics, phase diagrams are typically studied using
                  "mean field" or more accurate "Bethe" approximations
                  in which some correlations between variables are
                  neglected. It turns out that BP message passing is a
                  Bethe approximation.}
}

@Book{Mezard??book,
  author =	 {M. Mzard and. A. Montanari},
  title =	 {Constraint Satisfaction Networks in Physics and
                  Computation},
  publisher =	 {?},
  year =	 {?},
  note =	 {Unpublished draft},
  c-dellaert =	 {Very interesting, the 300-page book version of his
                  Science "Perspectives"},
}

@InProceedings{Michels05icml,
  author =	 {J. Michels and A. Saxena and A. Y. Ng},
  fullauthor =	 {Jeff Michels and Ashutosh Saxena and Andrew Y. Ng},
  title =	 {High Speed Obstacle Avoidance using Monocular Vision
                  and Reinforcement Learning},
  booktitle =	 ICML,
  year =	 2005,
}

@InProceedings{Micusik04accv,
  author =	 {B. Mi\v{c}u\v{s}\'{i}k and D. Martinec and
                  T. Pajdla},
  title =	 {{3D} Metric Reconstruction from Uncalibrated
                  Omnidirectional Images},
  booktitle =	 ACCV,
  year =	 2004,
}

@InProceedings{Mikolajczyk01,
  author =	 {K. Mikolajczyk and C. Schmid},
  title =	 {Indexing based on scale invariant interest points},
  booktitle =	 ICCV,
  year =	 2001,
}

@InProceedings{Mikolajczyk02eccv,
  author =	 {K. Mikolajczyk and C. Schmid},
  title =	 {An affine invariant interest point detector},
  booktitle =	 ECCV,
  pages =	 {128-142},
  volume =	 1,
  year =	 2002,
}

@article{Mikolajczyk05ijcv,
  title =	 {A comparison of affine region detectors},
  author =	 {K. Mikolajczyk and T. Tuytelaars and C. Schmid and
                  A. Zisserman and J. Matas and F. Schaffalitzky and
                  T. Kadir and L. Van Gool},
  journal =	 IJCV,
  volume =	 65,
  number =	 {1/2},
  pages =	 {43--72},
  year =	 2005,
}

@Article{Milanfar94cvgip,
  author =	 {P. Milanfar and W.C. Karl and Alan S. Willsky},
  title =	 {Reconstructing Binary Polygonal Objects From
                  Projections: A Statistical View},
  journal =	 {CVGIP: Graphical Models and Image Processing},
  year =	 1994,
  volume =	 56,
  number =	 5,
  pages =	 {371-391},
  month =	 {September},
}

@InProceedings{Milanfar94icip,
  author =	 {Milanfar, P. and Karl, W.C. and Willsky, A.S. and
                  Verghese, G.C},
  title =	 {Moment-based geometric image reconstruction},
  booktitle =	 ICIP,
  pages =	 {825-829},
  year =	 1994,
  volume =	 2,
  month =	 {November},
}

@Article{Milford08tro,
  author =	 {Michael J. Milford and Gordon F. Wyeth},
  title =	 {Mapping a Suburb With a Single Camera Using a Biologically Inspired {SLAM} System},
  journal =	 TRO,
  year =	 2008,
  volume =	 24,
  number =	 5,
  month =	 {October},
  pages = 	 {1038-1053},
  added-by =	 {richard},
}

@Article{Miller74,
  author =	 {P.L. Miller},
  title =	 {A locally organized parser for spoken input},
  journal =	 {Comm. ACM},
  year =	 1974,
  volume =	 17,
  pages =	 {621-630},
}

@InProceedings{Miller98aaai,
  author =	 {E.G. Miller and P.A. Viola},
  title =	 {Ambiguity and Constraint in Mathematical Expression
                  Recognition},
  booktitle =	 {_AAAI98},
}

@InProceedings{MillerShaw68,
  author =	 {W.F. Miller and A.C. Shaw},
  title =	 {Linguistic Methods in picture processing - a survey},
  booktitle =	 {Proc. AFIPS 1968 Fall Joint Computer Conference},
  pages =	 {279-290},
  year =	 1968,
  volume =	 33,
}

@Book{Milner97,
  author =	 {Robin Milner and Mads Tofte and Robert Harper and
                  David MacQueen},
  title =	 {The Definition of Standard ML (Revised)},
  publisher =	 MIT,
  year =	 1997,
}

@TechReport{Minka00,
  author =	 {Thomas P. Minka},
  title =	 {From Hidden Markov Models to Linear Dynamical
                  Systems},
  institution =	 {MIT Media Laboratory},
  year =	 2000,
  number =	 "VISMOD 531",
}

@PhdThesis{Minka01thesis,
  author =	 "T. Minka",
  title =	 "A family of algorithms for approximate Bayesian
                  inference",
  school =	 "MIT Media Lab, MIT",
  year =	 2001,
}

@InProceedings{Minka01uai,
  author =	 {Thomas P. Minka},
  title =	 {Expectation Propagation for approximate {B}ayesian
                  inference},
  crossref =	 {_UAI01},
  pages =	 {362-369},
}

@Unpublished{Minka03,
  author =	 {T.P. Minka},
  title =	 {Estimating a Dirichlet distribution},
  url =		 "www.stat.cmu.edu/~minka/papers/dirichlet",
  year =	 2003
}

@Unpublished{Minka98,
  author =	 {T.P. Minka},
  title =	 {Expectation-{M}aximization as lower bound
                  maximization},
  note =	 {Tutorial published on the web at
                  \url{http://research.microsoft.com/en-us/um/people/minka/papers/em.html}},
  month =	 {November},
  year =	 1998,
}

@inproceedings{Minnen03,
  author =	 "D. Minnen and I. Essa and T. Starner",
  title =	 "Expectation Grammars: Leveraging High-Level
                  Expectations for Activity Recognition",
  booktitle =	 CVPR,
  year =	 2003,
}

@inproceedings{Minnen06iswc,
  author =	 "D. Minnen and T. Starner and I. Essa and C.Isbell",
  title =	 "Discovering Characteristic Actions from On-Body
                  Sensor Data",
  booktitle =	 ISWC,
  year =	 2006,
}

@InCollection{Minsky75,
  author =	 "M. Minsky",
  title =	 "A Framework for Representing Knowledge",
  booktitle =	 "The Psychology of Computer Vision",
  publisher =	 "McGraw-Hill",
  year =	 1975,
  editor =	 "P.H. Winston",
}

@Book{Mirman95,
  author =	 {R. Mirman},
  title =	 {Group Theory: An Intuitive Approach},
  publisher =	 {World Scientific},
  year =	 1995,
  address =	 {River Edge, NJ},
}

@INPROCEEDINGS{Mitchell93icassp,
  author =	 {C. D. Mitchell and L. H. Jamieson},
  title =	 {{Modeling duration in a hidden Markov model with the
                  exponential family}},
  booktitle =	 ICASSP,
  year =	 {1993},
  pages =	 {331--334}
}

@BOOK{Mitchell97a,
  AUTHOR =	 {Mitchell, T.M.},
  TITLE =	 ML,
  PUBLISHER =	 {McGraw-Hill},
  YEAR =	 1997
}

@Article{Mittal03ijcv,
  author =	 {A. Mittal and L. S. Davis},
  fullauthor =	 {Anurag Mittal and Larry S. Davis},
  title =	 {{M2Tracker: A Multi-View Approach to Segmenting and
                  Tracking People in a Cluttered Scene}},
  booktitle =	 IJCV,
  month =	 {Feb.},
  year =	 2003,
  volume =	 51,
  number =	 3,
  pages =	 {189-203},
}

@InProceedings{Mittal04cvpr,
  author =	 {A. Mittal and N. Paragios},
  title =	 {Motion-Based Background Subtraction using Adaptive
                  Kernel Density Estimation},
  booktitle =	 CVPR,
  year =	 2004,
  abstract =	 {Background modeling is an important component of
                  many vision systems. Existing work in the area has
                  mostly addressed scenes that consist of static or
                  quasi-static structures. When the scene exhibits a
                  persistent dynamic behavior in time, such an
                  assumption is violated and detection performance
                  deteriorates. In this paper, we propose a new method
                  for the modeling and subtraction of such
                  scenes. Towards the modeling of the dynamic
                  characteristics, optical flow is computed and
                  utilized as a feature in a higher dimensional
                  space. Inherent ambiguities in the computation of
                  features are addressed by using a data-dependent
                  bandwidth for density estimation using
                  kernels. Extensive experiments demonstrate the
                  utility and performance of the proposed approach.},
  c-houdan =	 {KDE with variabel bandwidth, using optical flow +
                  normalized color as features. It has good results
                  for dynamic background},
}

@Article{Mitter79,
  author =	 "S. Mitter and A. Laub",
  title =	 "Factorization methods for discrete sequential
                  estimation",
  journal =	 "IEEE Transactions on Automatic Control",
  volume =	 24,
  number =	 6,
  pages =	 {990--992},
  year =	 1979,
}

@InProceedings{Miyazaki00,
  author =	 {D. Miyazaki and T. Ooishi and T. Nishikawa and
                  R. Sagawa and K. Nishino and T. Tomomatsu and
                  Y. Takase and K. Ikeuchi},
  title =	 {The {Great} {Buddha} Project: Modelling Cultural
                  Heritage through Observation},
  booktitle =	 {Proceedings of the Sixth International Conference on
                  Virtual Systems and MultiMedia (VSMM2000)},
  year =	 2000,
  address =	 {Gifu, Japan},
  pages =	 {138-145}
}

@Article{MoBIC96,
  author =	 {H. Petrie and V. Johnson and T. Strothotte and
                  A. Raab and S. Fritz and R. Michel },
  title =	 {MOBIC:Designing a Travel Aid for Blind and Elderly
                  People},
  journal =	 {Journal of Navigation},
  year =	 1996,
  pages =	 {45-52}
}

@Article{Moayer75,
  author =	 {B. Moayer and K.S. Fu},
  title =	 {A tree system approach for fingerprint pattern
                  recognition},
  journal =	 {IEEE Trans. on Computers},
  year =	 1975,
  volume =	 25,
}

@inproceedings{Modayil04,
  author =	 {J. Modayil and P. Beeson and B. Kuipers},
  year =	 2004,
  title =	 {Using the topological skeleton for scalable global
                  metrical map-building},
  booktitle =	 IROS,
  c-ananth =	 {Work by Modayil et. al. [Modayil04] generates an
                  ensemble of topological maps and uses them to
                  construct a global metric map. However, they do not
                  provide a probabilistic ordering to their ensemble
                  of maps as the posterior on topologies constructed
                  by our algorithm does.},
}

@article{Moffat98is,
  author =	 {A. Moffat and R.M. Neal and I.H. Witten},
  fullauthor =	 {Alistair Moffat and Radford M. Neal and Ian
                  H. Witten},
  title =	 {Arithmetic coding revisited},
  journal =	 {ACM Trans. Inf. Syst.},
  volume =	 16,
  number =	 3,
  year =	 1998,
  issn =	 {1046-8188},
  pages =	 {256--294},
  doi =		 {http://doi.acm.org/10.1145/290159.290162},
  publisher =	 {ACM Press},
  address =	 {New York, NY, USA},
}

@InProceedings{Mogh95,
  author =	 {Baback Moghaddam and Alex Pentland},
  title =	 {Probabilistic Visual learning for Object Detection},
  booktitle =	 ICCV,
  year =	 1995,
}

@InProceedings{Mogh98,
  author =	 {Baback Moghaddam and Wasiuddin Wahid and Alex
                  Pentland},
  title =	 {Beyond Eigenfaces: Probabilistic Matching for Face
                  Recognition},
  booktitle =	 {Proc of the 3d IEEE Int'l Conference on Automatic
                  Face and Gesture Recognition, Nara, Japan},
  year =	 1998,
  month =	 {April},
}

@PhdThesis{Moller00,
  author =	 {J. Moller},
  title =	 {Aspects of Spatial Statistics, Stochastic Geometry
                  and {M}arkov Chain {M}onte {C}arlo},
  school =	 {Faculty of Engineering and Science, Aalborg
                  University},
  year =	 2000,
}

@Article{Molnar98,
  author =	 {K.J. Molnar and J.W. Modestino},
  title =	 {Application of the {EM} Algorithm for the
                  Multitarget/Multisensor Tracking Problem},
  journal =	 SP,
  year =	 1998,
  volume =	 46,
  number =	 1,
  month =	 {January},
}

@InProceedings{Molton04bmvc,
  author =	 {N. Molton and I. Reid and A. Davison},
  title =	 {Locally planar patch features for real-time
                  structure from motion},
  booktitle =	 {Brit. Mach. Vision Conf.},
  year =	 {2004}
}

@InProceedings{Molton04bmvc,
  author = {N. Molton and I. Reid and A. Davison},
  title = {Locally planar patch features for real-time structure from motion},
  booktitle = {Brit. Mach. Vision Conf.},
  year = {2004}
}

@InProceedings{Monnet03iccv,
  author =	 {A. Monnet and A. Mittal and N. Paragios and
                  V. Ramesh},
  title =	 {Background Modeling and Subtraction of Dynamic
                  Scenes},
  booktitle =	 ICCV,
  year =	 2003,
  abstract =	 {Background modeling and subtraction is a core compo-
                  nent in motion analysis. The central idea behind
                  such module is to create a probabilistic
                  representation of the static scene that is compared
                  with the current input to perform subtraction. Such
                  approach is efficient when the scene to be modeled
                  refers to a static structure with limited
                  perturbation. In this paper, we address the problem
                  of modeling dynamic scenes where the assumption of a
                  static background is not valid. Waving trees,
                  beaches, escalators, natural scenes with rain or
                  snow are examples. We propose an on-line
                  auto-regressive model to capture and predict the
                  behavior of such scenes. Towards detection of events
                  we introduce a new metric that is based on a
                  state-driven comparison between the prediction and
                  the actual frame. Promising results demonstrate the
                  potentials of the proposed framework.},
  c-houdan =	 {A prediction-based on-line auto-regressive model of
                  dynamic scenes.},
}

@Article{Montanari74is,
  author =	 {U. Montanari},
  fullauthor =	 {Ugo Montanari},
  title =	 {Networks of constraints: Fundamental properties and
                  applications to picture processing},
  journal =	 {Information Sciences},
  year =	 {1974},
  volume =	 {7},
  pages =	 {95--132},
  abstract =	 {The problem of representation and handling of
                  constraints is here considered, mainly for picture
                  processing purposes. A systematic specification and
                  utilization of the available constraints could
                  significantly reduce the amount of search in picture
                  recognition. On the other hand, formally stated
                  constraints can be embedded in the syntactic
                  productions of picture languages. Only binary
                  constraints are treated here, but they are
                  represented in full generality as binary
                  relations. Constraints among more than two variables
                  are then represented as networks of simultaneous
                  binary relations. In general, more than one
                  equivalent (i.e., representing the same constraint)
                  network can be found: a minimal equivalent network
                  is shown to exist, and its computation is shown to
                  solve most practical problems about constraint
                  handling. No exact solution for this central problem
                  was found. Anyway, constraints are treated
                  algebraically, and the solution of a system of
                  linear equations in this algebra provides an
                  approximation of the minimal network. This solution
                  is then proved exact in special cases, e.g., for
                  tree-like and series-parallel networks and for
                  classes of relations for which a distributive
                  property holds. This latter condition is satisfied
                  in cases of practical interest.},
  r-Seidel81ijcai ={Montanari \cite{Montanari74is} showed that the
                  general CSP is NP-complete. ... Montanari
                  \cite{Montanari74is} pointed out that a CSP only
                  involving binary constraints can be represented by a
                  graph.},
  r-Kolaitis00css ={Starting with the pioneering work of Montanari
                  \cite{Montanari74is} researchers in artificial
                  intelligence have investigated a class of
                  combinatorial problems that became known as
                  constraint-satisfaction problems.},
  c-dellaert =	 {Mostly on complexity. Pretty dense.},
}

@InProceedings{Montemerlo02aaai,
  author =	 "M. Montemerlo and S. Thrun and D. Koller and
                  B. Wegbreit",
  title =	 "{FastSLAM}: A Factored Solution to the Simultaneous
                  Localization and Mapping Problem",
  crossref =	 {_AAAI02},
  abstract =	 {The ability to simultaneously localize a robot and
                  accurately map its surroundings is considered by
                  many to be a key prerequisite of truly autonomous
                  robots. However, few approaches to this problem
                  scale up to handle the very large number of
                  landmarks present in real environments. Kalman
                  filter-based algorithms, for example, require time
                  quadratic in the number of landmarks to incorporate
                  each sensor observation. This paper presents
                  FastSLAM, an algorithm that recursively estimates
                  the full posterior distribution over robot pose and
                  landmark locations, yet scales logarithmically with
                  the number of landmarks in the map. This algorithm
                  is based on an exact factorization of the posterior
                  into a product of conditional landmark distributions
                  and a distribution over robot paths. The algorithm
                  has been run successfully on as many as 50,000
                  landmarks, environments far beyond the reach of
                  previous approaches. Experimental results
                  demonstrate the advantages and limitations of the
                  FastSLAM algorithm on both simulated and realworld
                  data.},
}

@InProceedings{Montemerlo03icra,
  author =	 "M. Montemerlo and S. Thrun",
  title =	 "Simultaneous Localization and Mapping with Unknown
                  Data Association Using {FastSLAM}",
  booktitle =	 ICRA,
  year =	 2003,
}

@InProceedings{Montemerlo03ijcai,
  author =	 "M. Montemerlo and S. Thrun and D. Koller and
                  B. Wegbreit",
  title =	 "{FastSLAM} 2.0: An Improved Particle Filtering
                  Algorithm for Simultaneous Localization and Mapping
                  that Provably Converges",
  booktitle =	 IJCAI,
  year =	 2003,
}

@InProceedings{Montemerlo03iros,
  author =	 {M. Montemerlo and N. Roy and and S. Thrun},
  title =	 {Perspectives on Standardization in Mobile Robot
                  Programming: The {Carnegie} {Mellon} Navigation
                  ({CARMEN}) Toolkit},
  booktitle =	 IROS,
  Taddress =	 {Las Vegas},
  month =	 {October},
  year =	 2003
}

@InProceedings{Montemerlo2004,
  author =	 {M. Montemerlo and S. Thrun},
  title =	 {A multi-resolution pyramid for outdoor robot terrain
                  perception},
  crossref =	 {_AAAI04},
}

@inproceedings{Montesinos98,
  author =	 "P. Montesinos and V. Gouet and R. Deriche",
  title =	 "Differential Invariants for Color Images",
  booktitle =	 ICIP,
  year =	 1998,
}

@InProceedings{Montiel06rss,
  author =	 {J.M.M. Montiel and J. Civera and A.J. Davison},
  fullauthor =	 {Jose M.M. Montiel and Javier Civera and Andrew
                  J. Davison},
  title =	 {Unified Inverse Depth Parametrization for Monocular
                  {SLAM}},
  booktitle =	 RSS,
  location =	 {Philadelphia, PA},
  month =	 {Aug},
  year =	 2006,
  abstract =	 {Recent work has shown that the probabilistic SLAM
                  approach of explicit uncertainty propagation can
                  succeed in permitting repeatable 3D real-time
                  localization and mapping even in the 'pure vision'
                  domain of a single agile camera with no extra
                  sensing. An issue which has caused difficulty in
                  monocular SLAM however is the initialization of
                  features, since information from multiple images
                  acquired during motion must be combined to achieve
                  accurate depth estimates. This has led algorithms to
                  deviate from the desirable Gaussian uncertainty
                  representation of the EKF and related probabilistic
                  filters during special initialization steps. In this
                  paper we present a new unified parametrization for
                  point features within monocular SLAM which permits
                  efficient and accurate representation of uncertainty
                  during undelayed initialisation and beyond, all
                  within the standard EKF (Extended Kalman
                  Filter). The key concept is direct parametrization
                  of inverse depth, where there is a high degree of
                  linearity. Importantly, our parametrization can cope
                  with features which are so far from the camera that
                  they present little parallax during motion,
                  maintaining sufficient representative uncertainty
                  that these points retain the opportunity to 'come
                  in' from infinity if the camera makes larger
                  movements. We demonstrate the parametrization using
                  real image sequences of large-scale indoor and
                  outdoor scenes.},
  c-kaess =	 {Extension of Davison03iccv to allow initialization
                  of features at arbitrary depth, including infinity,
                  rather than just close to the camera. Uses Gaussian
                  distribution in inverse depth representation, rather
                  than particles. 6-dim parameterization by camera
                  center, orientation, and inverse depth.},
}

@InProceedings{Moore00uia,
  author =	 {A.W. Moore},
  title =	 {The Anchors Hierarchy: Using the Triangle Inequality
                  to Survive High-Dimensional Data},
  crossref =	 {_UAI00},
  Pages =	 {397--405},
}

@InProceedings{Moore01,
  author =	 {D. Moore and I. Essa},
  title =	 {Recognizing Multitasked Activities using Stochastic
                  Context-Free Grammar},
  booktitle =	 {Proceedings of Workshop on Models versus Exemplars
                  in Computer Vision},
  year =	 2001,
}

@InProceedings{Moore94,
  author =	 "A. W. Moore and Mary Soon Lee",
  title =	 "Efficient Algorithms for Minimizing Cross Validation
                  Error",
  booktitle =	 ICML,
  year =	 1994,
  publisher =	 "Morgan Kaufmann",
}

@Incollection{Moore94b,
  Author =	 "A. W. Moore and D. J. Hill and M. P. Johnson",
  Title =	 "{An Empirical Investigation of Brute Force to choose
                  Features, Smoothers and Function Approximators}",
  Editor =	 "S. Hanson and S. Judd and T. Petsche",
  Booktitle =	 "{Computational Learning Theory and Natural Learning
                  Systems, Volume 3}",
  Publisher =	 MIT,
  Year =	 1994
}

@Article{Moore97,
  author =	 "C. G. Atkeson and S. A. Schaal and A. W. Moore",
  title =	 "Locally Weighted Learning",
  journal =	 "AI Review",
  year =	 1997,
  volume =	 11,
  pages =	 "11-73",
}

@InProceedings{Moore97b,
  author =	 "A.W. Moore and J. Schneider and K. Deng",
  fullauthor =	 "Andrew W. Moore and Jeff Schneider and Kan Deng",
  title =	 "Efficient Locally Weighted Polynomial Regression
                  Predictions",
  booktitle =	 ICML,
  year =	 1997,
  publisher =	 "Morgan Kaufmann",
}

@Article{Moore98ai,
  author =	 {A.W. Moore and Mary Soon Lee},
  title =	 {Cached Sufficient Statistics for Efficient Machine
                  Learning with Large Datasets},
  Journal =	 JAIR,
  Volume =	 8,
  Month =	 {March},
  Year =	 1998,
  Pages =	 {67-91}
}

@InProceedings{Moore99nips,
  author =	 {A.W. Moore},
  title =	 {Very Fast {EM}-based Mixture Model Clustering Using
                  Multiresolution KD-trees},
  Booktitle =	 NIPS,
  Month =	 {April},
  Year =	 1999,
  Pages =	 {543--549},
  Editor =	 {M. Kearns and D. Cohn},
  Publisher =	 {Morgan Kaufman},
}

@Book{Moorshead2000,
  author =	 "Halvor Moorshead",
  title =	 "Dating Old Photographs 1840-1929",
  publisher =	 "Moorshead Magazines Ltd",
  year =	 2000,
}

@InProceedings{Moravec77,
  author =	 {H.P. Moravec},
  title =	 {Towards automatic visual obstacle avoidance},
  booktitle =	 IJCAI,
  pages =	 584,
  location =	 {Cambridge, MA},
  year =	 1977,
  month =	 {Aug},
}

@InProceedings{Moravec77,
  author =	 {H.P. Moravec},
  title =	 {Towards automatic visual obstacle avoidance},
  booktitle =	 IJCAI,
  pages =	 584,
  year =	 1977,
  month =	 {august},
}

@InProceedings{Moravec79,
  author =	 {H.P. Moravec},
  title =	 {Visual mapping by a robot rover},
  booktitle =	 IJCAI,
  pages =	 {599-601},
  location =	 {Tokyo, Japan},
  year =	 1979,
  month =	 {Aug},
  c-dellaert =	 {Seminal work in building visual maps from a moving
                  robot.},
}

@InProceedings{Moravec79,
  author =	 {H.P. Moravec},
  title =	 {Visual mapping by a robot rover},
  booktitle =	 IJCAI,
  pages =	 {599-601},
  year =	 1979,
  month =	 {august},
}

@InProceedings{Moravec81,
  author =	 {H.P. Moravec},
  title =	 {Rover visual obstacle avoidance},
  booktitle =	 IJCAI,
  pages =	 {785-790},
  year =	 1981,
  month =	 {august},
}

@Book{Moravec81b,
  author =	 {H.P. Moravec},
  title =	 {Robot Rover Visual Navigation},
  publisher =	 {UMI Research Press},
  year =	 1981,
  address =	 {Ann Arbor, MI},
}

@Article{Moravec83,
  author =	 {H.P. Moravec},
  title =	 {The {S}tanford Cart and the {CMU} Rover},
  journal =	 {Proceedings of the IEEE},
  year =	 1983,
  volume =	 71,
  number =	 7,
  pages =	 {872-884},
  month =	 {july},
}

@Article{Moravec88ai,
  author =	 {H.P. Moravec},
  title =	 {Sensor fusion in certainty grids for mobile robots},
  journal =	 {AI Magazine},
  year =	 1988,
  volume =	 9,
  pages =	 {61-74},
}

@TechReport{Moravec96,
  author =	 {H.P. Moravec},
  title =	 {Robot Spatial Perception by Stereoscopic Vision and
                  {3D} Evidence Grids},
  institution =	 {Carnegie Mellon},
  year =	 1996,
  number =	 {CMU-RI-TR-96-34},
  month =	 {September},
}

@article{Morefield77itac,
  author =	 "C. Morefield",
  title =	 "Application of 0-1 integer programming to
                  multitarget tracking problems",
  journal =	 ITAC,
  volume =	 22,
  number =	 3,
  pages =	 "302--312",
  year =	 1977
}

@article{Morency07ai,
  Author =	 {L.-P. Morency, C. Sidner, C. Lee, and T. Darrell},
  Title =	 {Head Gestures for Perceptual Interfaces: The Role of
                  Context in Improving Recognition},
  Journal =	 AI,
  Month =	 {June},
  Volume =	 {171},
  Number =	 {8-9},
  Pages =	 {568-585},
  Year =	 {2007},
}

@inproceedings{Morency07cvpr,
  Author =	 {Louis-Philippe Morency and Ariadna Quattoni and Trevor
                  Darrell},
  Title =	 {Latent-Dynamic Discriminative Models for Continuous
                  Gesture Recognition },
  Booktitle =	 CVPR,
  Year =	 {2007},
  Keywords =	 {crf, gesture recognition, continuous recognition},
  c-sangmin =	 {they introduce LD-CRF model, wehre each of the
                  concept class is modeled as a H-CRF model. then, the
                  set of H-CRF models are used to conduct 'continous
                  labeling' for visual gesture recognition. However,
                  each CRF possesses disjoint sets of hidden states,
                  which differ from [Wang2006cvpr] where they promote
                  hidden structure sharing. In fact, due to the
                  disjoint structure assumption, there is no explicit
                  high-level concept learning other than the fact that
                  the available labels are used in the training
                  process. However, their experimental results are
                  better than some of the other competing methods in
                  their domains. Still the number of classes are very
                  limited, only two classes foreground/background for
                  all three types of data.},
}

@InProceedings{Mori98,
  author =	 {H. Mori and S. Kotani},
  title =	 {Robotic Travel Aid for the Blind: HARUNOBU-6},
  booktitle =	 {Proc of the Second European Conference on
                  Disability, VirtualReality and Associated
                  Technologies},
  year =	 1998,
  month =	 {September},
}

@inproceedings{Morris00,
  author =	 "D. D. Morris and T. Kanade",
  fullauthor =	 "Daniel D. Morris and Takeo Kanade",
  title =	 "Image-Consistent Surface Triangulation",
  booktitle =	 CVPR,
  year =	 2000,
  volume =	 1,
  pages =	 "332-338",
}

@InProceedings{Morris98,
  author =	 "D.D. Morris and T. Kanade",
  title =	 "A unified factorization algorithm for points, line
                  segments and planes with uncertainty models",
  pages =	 "696-702",
  booktitle =	 ICCV,
  year =	 1998,
}

@InProceedings{Morris99,
  author =	 "D.D. Morris and K. Kanatani and T. Kanade",
  title =	 "Uncertainty Modeling for Optimal Structure from
                  Motion",
  booktitle =	 "ICCV Workshop on Vision Algorithms: Theory and
                  Practice",
  year =	 1999,
}

@InProceedings{Mort88,
  author =	 {M.S. Mort and M.D. Srinath},
  title =	 {Maximum Likelihood Image Registration with Subpixel
                  Accuracy},
  booktitle =	 SPIE,
  pages =	 {38-45},
  year =	 1988,
  volume =	 974,
}

@inproceedings{Motard07icra,
  title =	 {Incremental On-Line Topological Map Learning for A
                  Visual Homing Application},
  author =	 {E. Motard and B. Raducanu and V. Cadenat and
                  J. Vitri\`a},
  fullauthor =	 {Elvina Motard and Bogdan Raducanu and Viviane
                  Cadenat and Jordi Vitri`a},
  year =	 2007,
  booktitle =	 ICRA,
  Abstract =	 {In this paper we propose an on-line incremental
                  vision-based topological map learning for AIBO
                  robots. The topological map is represented through a
                  graph, where the vertices encode views from the
                  robot? environment and the edges the spatial
                  relationship between these views. The views are
                  represented through their SIFT keypoints. The
                  proposed map learning method has been successfully
                  applied to a homing application.},
  quotes =	 {A view graph G = (V,E) is defined as a topological
                  representation consisting of local views (vertices)
                  and their spatial relationship (edges). The proposed
                  method was used for a homing application, which
                  proved that AIBO is able to reach the recharging
                  station even when it is far away or its view
                  occluded by obstacles. The experimental results so
                  far are very encouraging, but they are conditioned
                  by the presence of distinct objects presenting a
                  rich texture.},
  video =
                  {http://www.cvc.uab.es/~bogdan/Videos/topol_vslam_icra07.mpg},
  c-dellaert =	 {Very interesting. Is really what I wanted to do, but
                  seems too trivial to work on for th next 4 years.},
}

@InProceedings{Mottaghi08icra,
  author =	 {R. Mottaghi and M. Kaess and A. Ranganathan and
                  R. Roberts and F. Dellaert},
  fullauthor =	 {Roozbeh Mottaghi and Michael Kaess and Ananth
                  Ranganathan and Richard Roberts and Frank Dellaert},
  title =	 {Place Recognition-based Fixed-Lag Smoothing for
                  Environments with Unreliable {GPS}},
  booktitle =	 ICRA,
  address =	 {Pasadena, CA},
  month =	 {May},
  year =	 2008,
  abstract =	 {Pose estimation of outdoor robots presents some
                  distinct challenges due to the various uncertainties
                  in the robot sensing and action. In particular,
                  global positioning sensors of outdoor robots do not
                  always work perfectly, causing large drift in the
                  location estimate of the robot. To overcome this
                  common problem, we propose a new approach for global
                  localization using place recognition. First, we
                  learn the location of some arbitrary key places
                  using odometry measurements and GPS measurements
                  only at the start and the end of the robot
                  trajectory. In subsequent runs, when the robot
                  perceives a key place, our fixed-lag smoother fuses
                  odometry measurements with the relative location to
                  the key place to improve its pose estimate. Outdoor
                  mobile robot experiments show that place recognition
                  measurements significantly improve the estimate of
                  the smoother in the absence of GPS measurements.},
}

@article{Mou06jeplmc,
  journal =	 JEPLMC,
  year =	 2006,
  month =	 {Nov},
  volume =	 32,
  number =	 6,
  pages =	 {1274-1290},
  title =	 {Roles of Egocentric and Allocentric Spatial
                  Representations in Locomotion and Reorientation},
  author =	 {Weimin Mou and Timothy P McNamara and Bj\"{o}rn Rump
                  and Chengli Xiao},
  abstract =	 {Four experiments investigated the nature of spatial
                  representations used in locomotion. Participants
                  learned the layout of several objects and then
                  pointed to the objects while blindfolded in 3
                  conditions: before turning (baseline), after turning
                  to a new heading (updating), and after
                  disorientation (disorientation). The internal
                  consistency of pointing in the disorientation
                  condition was relatively high and equivalent to that
                  in the baseline and updating conditions, when the
                  layout had salient intrinsic axes and the
                  participants learned the locations of the objects on
                  the periphery of the layout. The internal
                  consistency of pointing was disrupted by
                  disorientation when participants learned the
                  locations of objects while standing amid them and
                  the layout did not have salient intrinsic axes. It
                  was also observed that many participants retrieved
                  spatial relations after disorientation from the
                  original learning heading. These results indicate
                  that people form an allocentric representation of
                  object-to-object spatial relations when they learn
                  the layout of a novel environment and use that
                  representation to locate objects around
                  them. Egocentric representations may be used to
                  locate objects when allocentric representations are
                  not of high fidelity.},
}

@InProceedings{Mouragnon06cvpr,
  author =	 {E. Mouragnon and M. Lhuillier and M. Dhome and
                  F. Dekeyser and P. Sayd},
  title =	 {Real Time Localization and 3D Reconstruction},
  booktitle =	 CVPR,
  location =	 {New York, NY},
  month =	 {Jun},
  year =	 2006,
  abstract =	 {In this paper we describe a method that estimates
                  the motion of a calibrated camera (settled on an
                  experimental vehicle) and the tridimensional
                  geometry of the environment. The only data used is a
                  video input. In fact, interest points are tracked
                  and matched between frames at video rate. Robust
                  estimates of the camera motion are computed in
                  real-time, key-frames are selected and permit the
                  features 3D reconstruction. The algorithm is
                  particularly appropriate to the reconstruction of
                  long images sequences thanks to the introduction of
                  a fast and local bundle adjustment method that
                  ensures both good accuracy and consistency of the
                  estimated camera poses along the sequence. It also
                  largely reduces computational complexity compared to
                  a global bundle adjustment. Experiments on real data
                  were carried out to evaluate speed and robustness of
                  the method for a sequence of about one kilometer
                  long. Results are also compared to the ground truth
                  measured with a differential GPS.},
}

@InProceedings{Mouragnon06icra,
  author =	 {E. Mouragnon and M. Lhuillier and M. Dhome and
                  F. Dekeyser and P. Sayd},
  fullauthor =	 {Etienne Mouragnon and Maxime Lhuillier and Michel
                  Dhome and Fabien Dekeyser and Patrick Sayd},
  title =	 {3D reconstruction of complex structures with bundle
                  adjustment: an incremental approach},
  booktitle =	 ICRA,
  location =	 {Orlando, FL},
  pages =	 {3055-3061},
  month =	 {May},
  year =	 2006,
  abstract =	 {This paper introduces an incremental method for
                  "Structure From Motion" of complex scenes from a
                  video sequence. More precisely, we estimate the 3D
                  positions of the viewed points in images and the
                  camera positions and orientations through the
                  sequence. The method can be seen as a fast but
                  accurate alternative to classical reconstruction
                  methods that use bundle adjustment, and that can
                  become slow and computation time expensive for very
                  long scenes. Our results are compared to the
                  reconstruction obtained by the classical
                  hierarchical bundle adjustment method. They have
                  also been successfully used as a reference sequence
                  for the vision based localization of an autonomous
                  mobile robot.},
}

@InProceedings{Moutarlier89,
  author =	 {P. Moutarlier and R. Chatila},
  title =	 {Stochastic multisensor data fusion for mobile robot
                  location and environment modelling},
  booktitle =	 {5th Int. Symp. Robotics Research},
  year =	 1989,
}

@inproceedings{Moutarlier89iser,
  author =	 {P. Moutarlier and R. Chatila},
  fullauthor =	 {Philippe Moutarlier and Raja Chatila},
  title =	 {An Experimental System for Incremental Environment
                  Modelling by an Autonomous Mobile Robot.},
  booktitle =	 {Experimental Robotics I, The First International
                  Symposium, Montr{\'e}al, Canada, June 19-21, 1989},
  year =	 1989,
  pages =	 {327-346},
  bibsource =	 {DBLP, http://dblp.uni-trier.de}
}

@InProceedings{Mozos06iros,
  TITLE =	 {Supervised Learning of Topological Maps using
                  Semantic Information Extracted from Range Data},
  AUTHOR =	 {O. Mart\'{i}nez Mozos and W. Burgard},
  BOOKTITLE =	 IROS,
  PAGES =	 {2772-2777},
  YEAR =	 2006,
}

@InProceedings{Mozos06irosworkshop,
  TITLE =	 {Semantic Labeling of Places using Information
                  Extracted from Laser and Vision Sensor Data},
  AUTHOR =	 {O. Mart\'{i}nez Mozos and A. Rottmann and R. Triebel
                  and P. Jensfelt and W. Burgard},
  BOOKTITLE =	 {In Proc.~of the IEEE/RSJ IROS 2006 Workshop: From
                  Sensors to Human Spatial Concepts},
  YEAR =	 2006,
}

@InProceedings{Mozos07icraworkshop,
  title =	 {From Labels to Semantics: An Integrated System for
                  Conceptual Spatial Representations of Indoor
                  Environments for Mobile Robots},
  author =	 {\'{O}. Mart\'{i}nez Mozos and P. Jensfelt and
                  H. Zender and G-J. M. Kruijff and W. Burgard},
  booktitle =	 ICRA,
  year =	 2007,
}

@InProceedings{Mueller06vast,
  author =	 {P. Mueller and T. Vereenooghe and P. Wonka and
                  I. Paap and Luc Van Gool},
  title =	 {Procedural 3D Reconstruction of Puuc Buildings in
                  Xkipch},
  booktitle =	 {Eurographics Symposium on Virtual Reality,
                  Archaeology and Cultural Heritage (VAST)},
  pages =	 {139-146},
  year =	 2006,
}

@InProceedings{Mueller07siggraph,
  author =	 {P. Mueller and G. Zeng and P. Wonka and Luc Van
                  Gool},
  title =	 {Image-Based Procedural Modeling of Building
                  Facades.},
  booktitle =	 SIGGRAPH,
  year =	 2007,
  volume =	 26,
  number =	 3,
  publisher =	 {ACM Press},
  address =	 {New York, NY, USA},
}

@article{Mukherjee95philA,
  author =	 "D. Mukherjee and A. Zisserman and J. Brady",
  title =	 "Shape from symmetry---detecting and exploiting
                  symmetry in affine images",
  journal =	 "Phil. Trans. R. Soc. Lond. A",
  volume =	 351,
  pages =	 "77--106",
  year =	 1995,
}

@TechReport{Mulcahy,
  author =	 {C. Mulcahy and J. Rossi},
  title =	 {{ATLAST} -- a fresh approach to {S}ingular {V}alue
                  {D}ecomposition},
  institution =	 {Dept. of Mathematics, Spelman College},
  year =	 1996,
}

@Article{Mulcahy88,
  author =	 {C. Mulcahy and J. Rossi},
  title =	 {{ATLAST} - a fresh approach to {S}ingular {V}alue
                  {D}ecomposition},
  journal =	 {College Mathematics Journal},
  volume =	 29,
  number =	 3,
  pages =	 {199--207},
  year =	 1988,
}

@article{Murase81,
  author =	 "H Murase and F Kimura and M Yoshimura and Y Miyake",
  title =	 "An improvement of the Auto-Correlation Matrix in
                  Pattern Matching Method and its Application to
                  Handprinted {'HIRAGANA'}",
  JOURNAL =	 "Trans. IECE",
  VOLUME =	 "J64-D",
  YEAR =	 1981,
  NUMBER =	 3,
  PAGES =	 "276-283"
}

@article{Murase95,
  AUTHOR =	 "Murase, H. and Nayar, S.K.",
  TITLE =	 "Visual Learning And Recognition Of 3-D Objects From
                  Appearance",
  JOURNAL =	 IJCV,
  VOLUME =	 14,
  YEAR =	 1995,
  NUMBER =	 1,
  MONTH =	 "January",
  PAGES =	 "5-24"
}

@InCollection{Murphy01,
  author =	 {K. Murphy and S. Russell},
  title =	 {{Rao-Blackwellised} Particle Filtering for Dynamic
                  {Bayesian} Networks},
  booktitle =	 {Sequential {M}onte {C}arlo Methods in Practice},
  publisher =	 {Springer-Verlag},
  year =	 2001,
  editor =	 {A. Doucet and N. de Freitas and N. Gordon},
  address =	 {New York},
  month =	 {January},
}

@InProceedings{Murphy01nips,
  AUTHOR =	 "K. Murphy and M. A. Paskin",
  TITLE =	 {{Linear-time inference in Hierarchical HMMs}},
  booktitle =	 NIPS,
  YEAR =	 2001,
  c-sangmin =	 {introduce lienar time inference method for H-HHMs},
}

@PhdThesis{Murphy02phd,
  author =	 {K. P. Murphy},
  title =	 {Dynamic Bayesian Networks: Representation, Inference
                  and Learning},
  school =	 {University of California, Berkeley},
  year =	 2002,
}

@TechReport{Murphy99,
  author =	 "K. Murphy and S. Mian",
  title =	 "Modelling gene expression data using dynamic
                  {B}ayesian networks",
  institution =	 "Computer Science Division, University of California,
                  Berkeley",
  year =	 1999,
}

@InProceedings{Murphy99a,
  author =	 {K. Murphy},
  title =	 {Bayesian Map Learning in Dynamic Environments},
  booktitle =	 NIPS,
  year =	 1999,
}

@InCollection{Murphy08inbook,
  author =	 {Robin R. Murphy and Satoshi Tadokoro and Daniele Nardi and Adam Jacoff and Paolo Fiorini and Howie Choset and Aydan M. Erkmen},
  title =	 {Search and Rescue Robotics},
  booktitle =	 {Springer Handbook of Robotics},
  year = 	 2008,
  editor =	 {Bruno Siciliano and Oussama Khatib},
  pages =	 {1151-1171},
  publisher =	 SPRINGER,
}

@INPROCEEDINGS{Murray96bmvc,
  author =	 {David W. Murray and Ian D. Reid and Andrew
                  J. Davison},
  title =	 {Steering and navigation behaviours using fixation},
  booktitle =	 BMVC,
  address =	 {Edinburgh,UK},
  year =	 1996,
  pages =	 {635--644},
  abstract =	 {Steering a motor vehicle around a winding but
                  otherwise uncluttered road has been observed by
                  \citet{Land94nature} to involve repeated periods of
                  visual fixation upon the tangent point of the inside
                  of each bend. We demonstrate a similar use of
                  'active' fixation in the autonomous navigation of a
                  robot vehicle around an obstacle, and show how the
                  control law devised for steering in the robotic
                  example is applicable to the observed human
                  performance data. We discuss the merits of fixation
                  for mobile robot localization.},
  quotes =	 {We have shown that information very useful for
                  localization can be obtained from active fixation on
                  a world feature. Which features will be the best to
                  fixate on and when should a transition be made from
                  one to another? These are questions we hope to
                  address soon, but instinct suggests that given an
                  uncertainty in location, which can be thought of as
                  an ellipse surrounding the current estimate, an
                  observation at right angles to the major axis would
                  make the best use of the accurate angular
                  information available and reduce the uncertainty the
                  most.},
  c-dellaert =	 {Small robot with active stereo-head is driven around
                  an obstacle using a control law derived from the
                  robot's gaze angle, relative to the robot's heading,
                  reproducing the findings by \cite{Land94nature}. A
                  second element is the implementation of an EKF
                  localization algorithm a la \cite{Leonard92book}
                  (presumably by Andrew). The last sentence shows that
                  10 years before the 2005 ICCV paper Andrew was
                  already thinking about active feature selection.},
}

@InProceedings{Murray97icra,
  author =	 {Murray, D. and Jennings, C.},
  title =	 {Stereo vision based Mapping and Navigation for
                  Mobile Robots},
  booktitle =	 ICRA,
  pages =	 {1694-1699},
  location =	 {Albuquerque, NM},
  month =	 {Apr},
  year =	 1997,
  abstract =	 {This paper describes a visually guided robot that
                  can plan paths, construct maps and explore an indoor
                  environment. The robot uses a trinocular stereo
                  vision system to produce highly accurate depth
                  images at 2 Hz allowing it to safely travel through
                  the environment at 0.5 m/s. The algorithm integrates
                  stereo vision, occupancy grid mapping, and potential
                  field path planning techniques to form a robust and
                  cohesive robotic system for mapping and
                  navigation. Stereo vision is shown to be a viable
                  alternative to active sensing devices such as sonar
                  and laser range finders.},
  r-Meltzer04iros ={A stereo vision algorithm for mobile robot mapping
                  and navigation was proposed by Murray et. al. in
                  [this], where a 2D occupancy grid map was built from
                  the stereo data. However, odometry error was not
                  corrected, and hence the map could drift over time.},
}

@Article{Mutambara00ijrr,
  author =	 {A.G.O. Mutambara and H. Durrant-Whyte},
  title =	 {Fully decentralised estimation and control for a
                  modular wheeled mobile robot},
  journal =	 IJRR,
  year =	 2000,
  volume =	 19,
  number =	 6,
  abstract =	 {In this paper, the problem of fully decentralized
                  data fusion and control for a modular wheeled mobile
                  robot (WMR) is addressed. This is a vehicle system
                  with nonlinear kinematics, distributed multiple
                  sensors, and nonlinear sensor models. The problem is
                  solved by applying fully decentralized estimation
                  and control algorithms based on the extended
                  information filter. This is achieved by deriving a
                  modular, decentralized kinematic model by using
                  plane motion kinematics to obtain the forward and
                  inverse kinematics for a generalized simple wheeled
                  vehicle. This model is then used in the
                  decentralized estimation and control algorithms. WMR
                  estimation and control is thus obtained locally
                  using reduced order models with reduced
                  communication requirements, in a scalable network of
                  control nodes. If communication of information
                  between nodes is carried out after every measurement
                  (full rate communication), the estimates and control
                  signals obtained at each node are equivalent to
                  those obtained by a corresponding centralized
                  system. Transputer architecture is used as the basis
                  for hardware and software design as it supports the
                  extensive communication and concurrency requirements
                  that characterize modular and decentralized
                  systems. The advantages of a modular WMR vehicle
                  include scalability, application flexibility, low
                  prototyping costs, and high reliability.},
}

@InProceedings{Myatt02bmvc,
  author =	 {D.R. Myatt and P.H.S. Torr and S.J. Nasuto and
                  J.M. Bishop and R. Craddock},
  title =	 {NAPSAC: High Noise, High Dimensional Robust
                  Estimation - It's In The Bag},
  booktitle =	 BMVC,
  pages =	 {458--467},
  year =	 2002,
}

@article{Mykland95,
  author =	 {P. Mykland and L. Tierney and B. Yu},
  year =	 1995,
  title =	 {Regeneration in {M}arkov chain samplers},
  journal =	 {Journal of the {A}merican {S}tatistical
                  {A}ssociation},
  volume =	 90,
  pages =	 {233--241}
}

@Book{NRC2,
  author =	 "William H. Press and Brian P. Flannery and Saul
                  A. Teukolsky and William T. Vetterling",
  title =	 "Numerical Recipes: The Art of Scientific Computing",
  edition =	 "2nd",
  publisher =	 "Cambridge University Press",
  address =	 "Cambridge (UK) and New York",
  year =	 1992,
  isbn =	 "0-521-43064-X",
}

@article{Nadel91hippocampus,
  journal =	 {Hippocampus},
  volume =	 1,
  number =	 3,
  PAGES =	 {221--229},
  month =	 {July},
  year =	 1991,
  title =	 {The Hippocampus and Space Revisited},
  author =	 {Lynn Nadel},
  fullauthor =	 {L. Nadel},
  quotes =	 {I will concentrate on three major issues. First, I
                  will discuss at some length the fact that our theory
                  was about a spatial memory system, not simply a
                  ?patial?system. Second, I will discuss our
                  assumption that the spatial memory system we
                  allocated to the hippocampus was but one of many
                  spatial systems, and that the role of these various
                  systems can best be understood if one takes into
                  consideration an animal? behavior in its natural
                  habitat. Third, I will briefly discuss our view that
                  in the human hippocampus, at least in the left
                  hemisphere, the mapping system represents something
                  more abstract than physical space.},
  c-dellaert =	 {Looking back on seminal book, a bit of a rant for
                  insiders, not so useful.}
}

@InProceedings{Nakadai01,
  author =	 {K. Nakadai and K. Hidai and H.G. Okuno and
                  H. Kitano},
  title =	 {Epipolor Geometry Based Sound Localization and
                  Extraction for Humanoid Audition},
  booktitle =	 IROS,
  year =	 2001,
}

@InProceedings{Nakazawa94,
  author =	 {Y. Nakazawa and T. Saito and T. Komatsu and
                  K. Aizawa},
  title =	 {Two approaches for image-processing based
                  high-resolution image acquisition},
  booktitle =	 ICIP,
  pages =	 {147-151},
  year =	 1994,
}

@InProceedings{Nando02,
  author =	 {Nando de Freitas},
  title =	 {Rao-Blackwellised Particle Filtering for Fault
                  Diagnosis},
  booktitle =	 "IEEE Aerospace",
  year =	 2002,
}

@INPROCEEDINGS{Narasimhan05iccv,
  title =	 {Structured light in scattering media},
  author =	 {Narasimhan, S.G. and Nayar, S.K. and Bo Sun and
                  Koppal, S.J.},
  booktitle =	 {Computer Vision, (ICCV 2005). Tenth IEEE
                  International Conference on},
  year =	 2005,
  month =	 {Oct.},
  volume =	 1,
  pages =	 { 420-427 Vol. 1},
}

@INPROCEEDINGS{Narasimhan05oceans,
  title =	 {Structured light methods for underwater imaging:
                  light stripe scanning and photometric stereo},
  author =	 {Narasimhan, S.G. and Nayar, S.K.},
  pages =	 { 2610-2617 Vol. 3},
  crossref =	 {_Oceans05Washington},
  abstract =	 { Virtually all structured light methods in computer
                  vision assume that the scene and the sources are
                  immersed in pure air and that light is neither
                  scattered nor absorbed. Recently, however,
                  structured lighting has found growing application in
                  underwater and aerial imaging, where scattering
                  effects cannot be ignored. In this paper, we present
                  a comprehensive analysis of two representative
                  methods - light stripe range scanning and
                  photometric stereo - in the presence of
                  scattering. For both methods, we derive physical
                  models for the appearances of a surface immersed in
                  a scattering medium. Based on these models, we
                  present results on (a) the condition for object
                  detectability in light striping and (b) the number
                  of sources required for photometric stereo. In both
                  cases, we demonstrate that while traditional methods
                  fail when scattering is significant, our methods
                  accurately recover the scene (depths, normals,
                  albedos) as well as the properties of the
                  medium. These results are in turn used to restore
                  the appearances of scenes as if they were captured
                  in clear air. Although we have focused on light
                  striping and photometric stereo, our approach can
                  also be extended to other methods such as grid
                  coding, gated and active polarization imaging.},
}

@Article{Narasimhan66,
  author =	 {R. Narasimhan},
  title =	 {Syntax-directed interpretation of classes of
                  pictures},
  journal =	 {Comm. ACM},
  year =	 1966,
  volume =	 9,
  pages =	 {166-173 },
}

@Article{Nash00cse,
  author =	 {Nash, J.C.},
  title =	 {The ({Dantzig}) simplex method for linear
                  programming},
  pages =	 {29--31},
  crossref =	 {_CSE00Jan},
  journal =	 {Computing in Science \& Engineering},
  volume =	 2,
  number =	 1,
  month =	 {Jan.-Feb.},
  year =	 2000,
  note =	 {Special issue on the Top 10 Algorithms in {Science}
                  \& {Engineering}},
}

@InCollection{Nayar96,
  author =	 "S.K. Nayar and H. Murase and S.A. Nene",
  editor =	 "S.K. Nayar and T. Poggio",
  booktitle =	 "Early Visual Learning",
  title =	 "Parametric Appearance Representation",
  chapter =	 6,
  publisher =	 "Oxford University Press",
  year =	 1996,
  pages =	 "131-159",
}

@InProceedings{Neal03nips,
  author =	 {R.M. Neal and M.J. Beal and S.T. Roweis},
  fullauthor =	 {Radford M. Neal and Matthew J. Beal and Sam
                  T. Roweis},
  title =	 {Inferring {S}tate {S}equences for {N}on-linear
                  {S}ystems with {E}mbedded {H}idden {M}arkov
                  {M}odels},
  booktitle =	 NIPS,
  year =	 2003,
}

@TechReport{Neal93,
  author =	 "R.M. Neal",
  title =	 "Probabilistic inference using {M}arkov chain {M}onte
                  {C}arlo methods",
  institution =	 "Dept. of Computer Science, University of Toronto",
  year =	 1993,
  number =	 "CRG-TR-93-1",
}

@article{Neal96,
  author =	 {R. M. Neal},
  year =	 1996,
  title =	 {Sampling from multimodal distributions using
                  tempered transitions},
  journal =	 {Statistics and {C}omputing},
  volume =	 6,
  pages =	 {353-366}
}

@InCollection{Neal98a,
  AUTHOR =	 {Neal, R.M. and Hinton, G.E.},
  TITLE =	 {A view of the {EM} algorithm that justifies
                  incremental, sparse, and other variants},
  crossref =	 {_Jordan98book},
}

@ARTICLE{Negahdaripour03joe,
  title =	 {Stereovision imaging on submersible platforms for
                  3-D mapping of benthic habitats and sea-floor
                  structures},
  author =	 {Negahdaripour, S. and Madjidi, H.},
  journal =	 {Oceanic Engineering, IEEE Journal of},
  year =	 2003,
  month =	 {Oct.},
  volume =	 28,
  number =	 4,
  pages =	 { 625-650},
  abstract =	 { We investigate the deployment of a submersible
                  platform with stereovision imaging capability for
                  three-dimensional (3D) mapping of benthic habitats
                  and other sea-floor structures over local areas.  A
                  complete framework is studied, comprising: 1)
                  suitable trajectories to be executed for data
                  collection; 2) data processing for positioning and
                  trajectory followed by online frame-to-frame and
                  frame-to-mosaic registration of images, as well as
                  recursive global realignment of positions along the
                  path; and 3) 3D mapping by the fusion of various
                  visual cues, including motion and stereo within a
                  Kalman filter. The computational requirements of the
                  system are evaluated, formalizing how processing may
                  be achieved in real time. The proposed scenario is
                  simulated for testing with known ground truth to
                  assess the system performance, to quantify various
                  errors, and to identify how performance may be
                  improved. Experiments with underwater images are
                  also presented to verify the performance of various
                  components and the overall scheme.},
  c_viorela =	 {Suitable trajectories for data collection, Fused
                  data processing for navigation and
                  positioning. Frame -to.frame and frame-to-mosaic
                  registration. Motion and stereo to produce 3D.},
}

@INPROCEEDINGS{Negahdaripour08oceans,
  title =	 {Bundle adjustment for 3-{D} motion and structure
                  estimation from 2-{D} optical and sonar views},
  author =	 {Negahdaripour, S. and Taatian, A.},
  booktitle =	 {OCEANS 2008},
  year =	 2008,
  month =	 {Sept.},
  pages =	 {1-6},
  keywords =	 {image reconstruction, motion estimation,
                  oceanographic techniques, optical images, optical
                  radar, sonar imaging, underwater optics, underwater
                  sound2D optical image, 3D motion estimation, 3D
                  structure estimation, bundle adjustment, image
                  reconstruction, sonar imaging system, underwater
                  technique},
}

@Article{Neira01tra,
  author =	 {J. Neira and J.D. Tards},
  title =	 {Data Association in Stochastic Mapping Using the
                  Joint Compatibility Test},
  journal =	 TRA,
  volume =	 17,
  number =	 6,
  pages =	 {890-897},
  month =	 {December},
  year =	 2001,
  c-kaess =	 {Discusses Individual Compatiblity Nearest Neighbor
                  (ICNN) and shows a simple failure case. Introduces
                  Sequential Compatibility (SCNN) that selects the
                  best match for one feature, reestimates the state,
                  and continues with the next features. However, state
                  reestimation is expensive and the result can be
                  incorrect, one reason being that the resulting
                  hypothesis depends on the order in which the
                  features are considered. Finally proposes Joint
                  Compatibility Branch and Bound (JCBB) that performs
                  a search for the hypothesis that contains the
                  largest number of jointly compatible pairings, while
                  avoiding state reestimation. However, the joint
                  innovation test that is needed is potentially
                  expensive, and approximations are applied to allow
                  incremental evaluation. The search is bounded by the
                  monotonically nondecreasing quality measure of a
                  node by the number of nonnull pairings that can be
                  established from the node},
}

@InProceedings{Neira03icra,
  author =	 {J.Neira and J.D. Tards and J.A. Castellanos},
  title =	 {Linear time vehicle relocation in {SLAM}},
  booktitle =	 ICRA,
  year =	 2003,
}

@InProceedings{Neira97,
  author =	 {J. Neira and M.I. Rbeiro and J.D. Tard\'{o}s},
  fullauthor =	 {Jos\'{e} Neira and Mar\'{i}a Isabel Ribeiro and Juan
                  Domingo Tard\'{o}s},
  title =	 {Mobile Robot Localisation and Map Building using
                  Monocular Vision},
  booktitle =	 {Intl. Symp. on Intelligent Robotics Systems},
  location =	 {Stockholm, Sweden},
  month =	 {Jul},
  year =	 1997,
  abstract =	 {In this paper we analyze the fundamental aspects of
                  the construction of indoor maps suitable for their
                  use in navigation tasks by a mobile robot. We
                  highlight the limitations inherent to the use of a
                  priori maps. We show the fundamental problems
                  related to the simultaneous construction of the map
                  and the localization of the robot within this
                  map. We describe an experiment with the use of a
                  monocular vision system to build a vertical-based
                  environmental map for robot localization purposes
                  and discuss its results.},
  r-Davison07pami ={Neira et al. presented a simple system mapping
                  vertical line segments in 2D in a constrained indoor
                  environment [this]...},
}


@article{Nelson91bc,
  author =	 {R.C. Nelson},
  title =	 {Visual homing using an associative memory},
  journal =	 {Biological Cybernetics},
  volume =	 65,
  year =	 1991,
  pages =	 {281--291},
  abstract =	 {Homing is the process by which an autonomous system
                  guides itself to a particular location on the basis
                  of sensory input. In this paper, a method of visual
                  homing using an associative memory based on a simple
                  pattern classifier is described. Homing is
                  accomplished without the use of an explicit world
                  model by utilizing direct associations between
                  learned visual patterns and system motor
                  commands. The method is analyzed in terms of a
                  pattern space and conditions obtained that allow the
                  system performance to be predicted on the basis of
                  statistical measurements on the environment. Results
                  of experiments utilizing the method to guide a
                  robot-mounted camera in a three-dimensional
                  environment are presented.},
  r-Franz00ras = {Nelson presented a robot capable of a view
                  recognition-triggered response together with a
                  theoretical analysis of the associative memory used
                  in his approach. Instead of a mobile robot, Nelson
                  used a small camera mounted on a robot arm which
                  could move at a fixed height over a miniature city
                  called ?inytown? Places were recognized from the
                  bird? eye view of the camera. Each camera image of a
                  location was divided into a 5 ?5 grid of adjacent
                  subwindows in which the predominant edge direction
                  was determined. In the training phase, Nelson?
                  system learned associations between local edge
                  orientation patterns with directions towards the
                  goal in the town centre at 120 preselected places
                  covering Tinytown. Homing was accomplished by
                  comparing the currently perceived pattern against
                  all patterns stored in the associative memory, and
                  moving into the specified direction of the winning
                  pattern. Nelson? system was able to find the goal
                  from almost all places in Tinytown and thus
                  demonstrated the feasability of
                  recognition-triggered responses in robot
                  applications. However, his system relied on some
                  idealizations: pictures were taken in exactly the
                  same camera orientation, the system had to be
                  trained at all possible locations and could not
                  select places autonomously.},
  c-dellaert =	 {Could not find an online version. I met the author
                  at an NSF panel.}
}

@article{Nene97pami,
  author =	 "S.A. Nene and S.K. Nayar",
  title =	 "A Simple Algorithm for Nearest Neighbor Search in
                  High Dimensions",
  journal =	 PAMI,
  volume =	 "19",
  year =	 "1997",
  url =		 "citeseer.nj.nec.com/nene97simple.html"
}

@InProceedings{Nettleton00aerosense,
  author =	 {Nettleton, E.W. and P.W. Gibbens and
                  H.F. Durrant-Whyte},
  title =	 {Closed form solutions to the multiple platform
                  simultaneous localisation and map building ({SLAM})
                  problem},
  booktitle =	 {AeroSense},
  pages =	 {24-28},
  year =	 2000,
  address =	 {Orlando, FL},
  month =	 {April},
  abstract =	 {This paper presents a closed form solution to the
                  multiple platform simultaneous localisation and map
                  building (SLAM) problem. Closed form solutions are
                  presented in both state space and information based
                  forms. A key conclusion of this paper is that the
                  information-state based form offers many advantages
                  over the state space formulation in allowing the
                  SLAM algorithm to be decentralised across multiple
                  platforms. The benefits of operating SLAM in an
                  information form are numerous. The additive
                  properties of the information update make it
                  especially attractive, as does the ability to
                  predict estimates through any direction in
                  time. However, of paramount importance is the
                  well-known ability to decentralise the information
                  filter. A general form of the continuous time
                  inverse covariance matrix for the SLAM problem is
                  presented to determine such properties as the
                  initial and steady state conditions. These
                  properties are investigated to determine their
                  dependence and relationship to both the observation
                  and process noise. Examination of the structure of
                  the general form of the inverse covariance matrix
                  also gives an insight into what information should
                  be communicated between platforms in the
                  decentralised architecture and how it can be
                  managed. },
  c-Rosencrantz03uai ={In a recent result [this], it was shown that
                  scalable decentralized state estimation can be
                  achieved for static environments with Gaussian error
                  - that is, environments where the state does not
                  change over time and observations are
                  (approximately) linear functions of the state with
                  Gaussian error. The key insight in [this] is that in
                  static worlds, information can be accumulated at any
                  time and in any order, regardless of the time at
                  which it was acquired. Furthermore, because of the
                  simple form of the observations, there is a simple
                  algorithm for accumulating local evidence in the
                  form of additive information
                  matrices. Unfortunately, the "trick" of additive
                  information works only for distributions (such as
                  Gaussians) which are in the exponential family.},
  c-Nettleton03fsr ={The update of the information form is additive;
                  as a result, incremental new information can be
                  integrated across different vehicles with arbitrary
                  network latencies. However, our previous work
                  required communication bandwidths quadratic in the
                  size of the map.},
  c-Upcroft06iser ={robust decentralised data fusion have included
                  tracking artificial visual features with known
                  range},
}

@InCollection{Nettleton00chapter,
  author =	 {E. Nettleton and H. Durrant-Whyte and P. Gibbens},
  title =	 {Multiple platform localisation and map building},
  booktitle =	 {Sensor Fusion and Decentralised Control in Robotic
                  Stystems III},
  editor =	 {G.T. McKee and P.S. Schenker},
  volume =	 {4196},
  r-Thrun03isrr ={A number of papers addresses the problem under the
                  constraint that the initial pose of all robots
                  relative to each other is known exactly},
}

@InProceedings{Nettleton03fsr,
  author =	 {Nettleton, E. and Thrun, S. and Durrant-Whyte,
                  H. and Sukkarieh, S.},
  title =	 {Decentralised {SLAM} with Low-Bandwidth
                  Communication for Teams of Vehicles},
  booktitle =	 FSR,
  year =	 2003,
  address =	 {Japan},
  month =	 {July},
  abstract =	 {This paper addresses the problem of simultaneous
                  localization and mapping (SLAM) for teams of
                  collaborating vehicles where the communication
                  bandwidth is limited. We present a novel SLAM
                  algorithm that enables multiple vehicles to acquire
                  a joint map, but which can cope with arbitrary
                  latency and bandwidth limitations such as typically
                  found in airborne vehicle applications. The key idea
                  is to represent maps in information form (negative
                  log-likelihood), and to selectively communicate
                  subsets of the information tailored to the available
                  communication resources. We show that our
                  communication scheme preserves the consistency,
                  which has important ramifications for data
                  association problems. We also provide experimental
                  results that illustrate the effectiveness of our
                  approach in comparison with previous techniques.},
  quotes =	 {The ability to communicate maps of arbitrary size is
                  obtained by implementing a hybrid information
                  filter/ Covariance Intersect (CI) algorithm on each
                  communication link. This algorithm is implemented
                  separately from the SLAM filter and is used solely
                  to manage the inter-vehicle communication and ensure
                  that information vehicles have shared does not get
                  "double counted".},
}

@PhdThesis{Nettleton03thesis,
  author =	 {E. Nettleton},
  title =	 {Decentralised Architectures for Tracking and
                  Navigation with Multiple Flight Vehicles},
  school =	 {U. of Sydney},
  year =	 2003,
  c-Makarenko04fusion ={A decentralized algorithm for rebuilding a
                  tree network after a Node failure},
}

@misc{Nettletoon00boston,
  text =	 {Nettleton EW, Durrant-Whyte HF , Gibbens PW,
                  Goktogan AH "Multiple Platform Localisation and Map
                  Building". Sensor Fusion and Decentralized Control
                  in Robotic Systems III November 4-8, 2000, Boston,
                  Ma. vol 4196, pp 337-347, G. McKee, P. Schenker,
                  eds. SPIE Washington DC, 2000.}
}

@Article{Neumann99mm,
  author =	 {U. Neumann and S. You},
  title =	 {Natural Feature Tracking for Augmented Reality},
  journal =	 {IEEE Transactions on Multimedia},
  year =	 1999,
  volume =	 1,
  number =	 1,
  pages =	 {53-- 64},
}

@Book{Neuts81,
  author =	 {M. F. Neuts},
  title =	 {Matri-geometric solutions in stochastic models},
  year =	 1981,
  publisher =	 {The Johns Hopkins University Press},
}

@InProceedings{Nevado04ras,
  author =	 {M. M. Nevado and Jaime Gmez Garca-Bermejo and
                  Eduardo Zalama Casanova},
  title =	 {Obtaining 3D models of indoor environments with a
                  mobile robot by estimating local surface directions},
  booktitle =	 {Robot. Auton. Syst.},
  year =	 {2004}
}

@InProceedings{Nevado04ras,
  author = {M. M. Nevado and Jaime Gmez Garca-Bermejo and Eduardo Zalama Casanova},
  title = {Obtaining 3D models of indoor environments with a mobile robot by estimating local surface directions},
  booktitle = {Robot. Auton. Syst.},
  year = {2004}
}

@InProceedings{Newman02explore,
  author =	 {P.M. Newman and J.J. Leonard and J.Neira and
                  J.Tards},
  title =	 {Explore and Return: Experimental Validation of Real
                  Time Concurrent Mapping and Localization},
  booktitle =	 ICRA,
  pages =	 {1802--1809},
  year =	 2002,
  month =	 {May},
}


@InProceedings{Newman02icra,
  author =	 {P. Newman and J. Leonard},
  title =	 {Range-only subsea {c}oncurrent {M}apping and
                  {L}ocalization},
  booktitle =	 {ICRA Workshop on Concurrent Mapping and Localization
                  for Autonomous Mobile Robots},
  year =	 2002,
}

@InProceedings{Newman03ijcai,
  author =	 {Paul M. Newman and John J. Leonard},
  title =	 {Consistent Convergent Constant Time {SLAM}},
  booktitle =	 IJCAI,
  year =	 2003,
}

@InProceedings{Newman06icra,
  author =	 {P. Newman and D. Cole and K. Ho},
  title =	 {Outdoor {SLAM} using Visual Appearance and Laser
                  Ranging},
  booktitle =	 ICRA,
  year =	 2006,
  c-ananth =	 { Spectral clustering using the affinity matrix is
                  also performed by Newman et. al. [Newman06icra],
                  albeit for the loop closing problem in the context
                  of metric maps.}
}

@PhdThesis{Newman99thesis,
  author =	 {P. Newman},
  title =	 {On the Structure and Solution of the Simultaneous
                  Localisation and Map Building Problem},
  school =	 {The University of Sydney},
  year =	 1999,
  c-Alireza =	 {In this thesis he talks about the absolute maps
                  versus relative maps. He describes how linear and
                  non linear constraints can be used for addition to
                  relative maps to get the absolute map. Kalman filter
                  framework can be used to add constraints with
                  certainity defined using the covariance matrix. They
                  prove the three important characteristic of SLAM
                  framework for absolute map, like the one that says
                  the covariance decreases over time. }
}

@inproceedings{Ng02nips,
  Author =	 {Andrew Y Ng, Michael I Jordan},
  Title =	 {On Discriminative vs. Generative Classifiers: A
                  comparison of logistic regression and naive Bayes},
  Booktitle =	 NIPS,
  Year =	 {2002}
}

@InProceedings{Nguyen02icpr,
  author =	 {N. T. Nguyen and S. Venkatesh and G. West and
                  H. H. Bui},
  fullauthor =	 {Nam T.Nguyen and Svetha Venkatesh and Geoff West and
                  Hung H. Bui},
  title =	 {Hierarchical monitoring of people's behaviors in
                  complex environments using multiple cameras},
  booktitle =	 ICPR,
  year =	 2002,
  keywords =	 {activity recognition, hierarchical model,
                  surveillance},
}

@InProceedings{Nguyen03cvpr,
  author =	 {N. T. Nguyen and S. Venkatesh and G. West and
                  H. H. Bui},
  fullauthor =	 {Nam T.Nguyen and Svetha Venkatesh and Geoff West and
                  Hung H. Bui},
  title =	 {Recognising and monitoring high-level behaviors in
                  complex spatial environments},
  booktitle =	 CVPR,
  year =	 2003,
  keywords =	 {activity recognition, hierarchical model,
                  surveillance},
}

@InProceedings{Nguyen05bmvc,
  author =	 {N. Nguyen, S. Venkatesh},
  title =	 {Discovery of activity structures Using the
                  hierarchical hidden Markov model},
  booktitle =	 {BMVC},
  year =	 2005,
  keywords =	 {activity, hierarchical model, HMM},
}

@InProceedings{Nguyen06bmvc,
  author =	 {N. Nguyen, S. Venkatesh, and H. Bui},
  title =	 {Recognising behaviours of multiple people with
                  hierarchical probabilistic model and statistical
                  data association},
  booktitle =	 {BMVC},
  volme =	 3,
  pages =	 {1239-1248},
  year =	 2006,
  keywords =	 {activity, hierarchical model, HMM},
}

@Unpublished{Ni05iccv,
  author =	 {K. Ni and M. Kaess and F. Dellaert},
  title =	 {A Multi-view Feature-based Approach for Real-time
                  Localization},
  note =	 {Submitted to Intl. Conf. on Computer Vision (ICCV)
                  2005},
}

@InProceedings{Ni06icip,
  author =	 "K. Ni and F. Dellaert",
  fullauthor =	 "Kai Ni and Frank Dellaert",
  title =	 "Stereo Tracking and Three-Point/One-Point Algorithms
                  - A Robust Approach in Visual Odometry",
  booktitle =	 ICIP,
  year =	 2006,
}

@InProceedings{Ni06icip,
  author =	 {K. Ni and F. Dellaert},
  fullauthor =	 {Kai Ni and Frank Dellaert},
  title =	 {Stereo Tracking and Three-Point/One-Point Algorithms
                  - A Robust Approach in Visual Odometry},
  booktitle =	 ICIP,
  year =	 2006,
  url =
                  {http://www.cc.gatech.edu/~dellaert/pubs/Ni06icip.pdf}
}

@InProceedings{Ni07iccv,
  author =	 {K. Ni and D. Steedly and F. Dellaert},
  fullauthor =	 {Kai Ni and Drew Steedly and Frank Dellaert},
  title =	 {Out-of-Core Bundle Adjustment for Large-Scale {3D}
                  Reconstruction},
  booktitle =	 ICCV,
  address =	 {Rio de Janeiro},
  month =	 {October},
  year =	 2007,
  url =
                  {http://www.cc.gatech.edu/~dellaert/pubs/Ni07iccv.pdf}
}

@InProceedings{Ni07icra,
  author =	 {K. Ni and D. Steedly and F. Dellaert},
  fullauthor =	 {Kai Ni and Drew Steedly and Frank Dellaert},
  title =	 {Tectonic {SAM}: Exact; Out-of-Core; Submap-Based
                  {SLAM}},
  booktitle =	 ICRA,
  address =	 {Rome; Italy},
  month =	 {April},
  year =	 2007,
  url =
                  {http://www.cc.gatech.edu/~dellaert/pubs/Ni07icra.pdf}
}

@Article{Nickels99,
  author =	 "K. Nickels and S. Hutchinson",
  title =	 "Model-Based Tracking of Complex Articulated Objects",
  journal =	 TRA,
  year =	 1999,
}

@INPROCEEDINGS{Nicosevici08oceans,
  title =	 {Online Robust {3D} Mapping Using Structure from
                  Motion Cues},
  author =	 {Nicosevici, T. and Garcia, R.},
  booktitle =	 {OCEANS 2008 - MTS/IEEE Kobe Techno-Ocean},
  year =	 2008,
  month =	 {April},
  pages =	 {1-7},
}

@Inproceedings{Nielsen04,
  author =	 {C. W. Nielsen and B. Ricks and M. A. Goodrich and
                  D. Bruemmer and D. Few and M. Walton},
  title =	 {Snapshots for {S}emantic {M}aps},
  booktitle =	 {Proceedings of the 2004 IEEE Conference on Systems,
                  Man, and Cybernetics},
  year =	 2004,
}

@InProceedings{Nieto03icra,
  author =	 "J. Nieto and H. Guivant and E. Nebot and S. Thrun",
  title =	 "Real Time Data Association for {FastSLAM}",
  booktitle =	 ICRA,
  year =	 2003,
}

@InProceedings{Nieto04,
  author =	 "J. Nieto and J. Guivant and E. Nebot",
  title =	 "The hybrid metric maps (HYMMS): A novel map
                  representation for DenseSLAM",
  booktitle =	 "IEEE International Conference on Robotics and
                  Automation",
  year =	 2004,
}

@Book{Nijenhuis78,
  author =	 {A. Nijenhuis and H. Wilf},
  title =	 {Combinatorial Algorithms},
  publisher =	 ap,
  year =	 1978,
  edition =	 2,
}

@article{Nishino2004er,
  author =	 {K.Nishino and S.K.Nayar},
  title =	 {Eyes for relighting},
  journal =	 {ACM Transactions on Graphics},
  volume =	 23,
  number =	 3,
  pages =	 {704--711},
  year =	 2004,
}

@misc{NisongerMarine,
  author =	 {NisongerMarine},
  title =	 {In-Dash Fluxgate Compass - 21/2 inch cutout
                  {S}pecification and {P}rice {W}ebsite},
  url =		 {www.nisongermarine.com/3-gcid2.html}
}

@InProceedings{Nister00eccv,
  fullauthor =	 {David Nist\'er},
  author =	 {D. Nist\'er},
  title =	 {Reconstruction from Uncalibrated Sequences with a
                  Hierarchy of Trifocal Tensors},
  booktitle =	 {ECCV},
  year =	 2000,
}

@InProceedings{Nister03cvpr,
  fullauthor =	 {David Nist\'er},
  author =	 {D. Nist\'er},
  title =	 {An Efficient Solution to the Five-Point Relative
                  Pose Problem},
  booktitle =	 {CVPR},
  year =	 2003,
}

@InProceedings{Nister03iccv,
  author =	 {D. Nist\'er},
  fullauthor =	 {David Nist\'er},
  title =	 {Preemptive {RANSAC} for Live Structure and Motion
                  Estimation},
  booktitle =	 ICCV,
  pages =	 {199-206},
  location =	 {Nice, France},
  month =	 {Oct},
  year =	 2003,
  abstract =	 {A system capable of performing robust live
                  ego-motion estimation for perspective cameras is
                  presented. The system is powered by random sample
                  consensus with preemptive scoring of the motion
                  hypotheses. A general statement of the problem of
                  efficient preemptive scoring is given. Then a
                  theoretical investigation of preemptive scoring
                  under a simple inlier-outlier model is performed. A
                  practical preemption scheme is proposed and it is
                  shown that the preemption is powerful enough to
                  enable robust live structure and motion estimation.},
  r-Stasse06iros ={Although not a SLAM system capable of long-term
                  mapping a loop closure, the real-time visual
                  odometry system of Nister et al. [this] deserves
                  mention as it demonstrates the state of the art in
                  the use of frame-to-frame visual matching for highly
                  accurate motion estimation.},
  c-dellaert =	 {Has very impressive real-time structure from
                  motion.},
}

@InProceedings{Nister04cvpr,
  fullauthor =	 {David Nist\'er},
  author =	 {D. Nist\'er},
  title =	 {A Minimal solution to the generalised 3-point pose
                  problem},
  booktitle =	 CVPR,
  pages =	 {560-567},
  year =	 2004,
}

@InProceedings{Nister04cvpr2,
  author =	 {D. Nist\'er and O. Naroditsky and J. Bergen},
  fullauthor =	 {David Nist\'er and Oleg Naroditsky and James Bergen},
  title =	 {Visual Odometry},
  booktitle =	 CVPR,
  pages =	 {652-659},
  volume =	 1,
  location =	 {Washington, DC},
  month =	 {Jun},
  year =	 2004,
  abstract =	 {We present a system that estimates the motion of a
                  stereo head or a single moving camera based on video
                  input. The system operates in real-time with low
                  delay and the motion estimates are used for
                  navigational purposes. The front end of the system
                  is a feature tracker. Point features are matched
                  between pairs of frames and linked into image
                  trajectories at video rate. Robust estimates of the
                  camera motion are then produced from the feature
                  tracks using a geometric hypothesize-and-test
                  architecture. This generates what we call visual
                  odometry, i.e. motion estimates from visual input
                  alone. No prior knowledge of the scene nor the
                  motion is necessary. The visual odometry can also be
                  used in conjunction with information from other
                  sources such as GPS, inertia sensors, wheel
                  encoders, etc. The pose estimation method has been
                  applied successfully to video from aerial,
                  automotive and handheld platforms. We focus on
                  results with an autonomous ground vehicle. We give
                  examples of camera trajectories estimated purely
                  from images over previously unseen distances and
                  periods of time.},
  r-Davison07pami ={Nister [this] presented a real-time system based
                  very much on the standard structure from motion
                  methodology of frame-to-frame matching of large
                  numbers of point features which was able to recover
                  instantaneous motions impressively but again had no
                  ability to re-recognize features after periods of
                  neglect and therefore would lead inevitably to rapid
                  drift in augmented reality or localization.},
  c-kaess =	 {Estimates the motion of a single camera or stereo
                  head incrementally. Features are extracted using
                  Harris, and filtered by non-maximum supression and a
                  local, tile-based saturation using the quickselect
                  algorithm. Matching is performed based on normalized
                  correlation, using the mutual consistency
                  check. Details for efficient implementation are
                  provided. A robust estimation scheme is presented
                  that differs between monocular and stereo
                  setups. Preemptive RANSAC is used in connection with
                  the 5-point and 3-point algorithm,
                  respectively. Only image-based quantities are used
                  to prevent depth uncertainties from influencing the
                  result. In contrast to the monocular algorithm, the
                  stereo version exhibits no drift for a static
                  camera. Support is measured by a robust reprojection
                  error, assuming Cauchy distribution for the
                  reprojection errors. Results are shown for outdoor
                  sequences, comparing to DGPS and INS. An application
                  to mapping is shown.},
}

@InProceedings{Nister06cvpr,
  fullauthor =	 {D. Nist\'er and H. Stew\'enius},
  author =	 {D. Nist\'er and H. Stew\'enius},
  title =	 {Scalable Recognition with a Vocabulary Tree},
  booktitle =	 CVPR,
  year =	 2006,
}

@InProceedings{Nister06dss,
  author =	 {D. Nist\'er and C. Engels},
  fullauthor =	 {David Nist\'er and Christopher Engels},
  title =	 {Estimating Global Uncertainty in Epipolar Geometry
                  for Vehicle-Mounted Cameras},
  booktitle =	 {SPIE Defense and Security Symposium, Unmanned
                  Systems Technology VIII},
  month =	 {Apr},
  year =	 2006,
  abstract =	 {We present a method for estimating the global
                  uncertainty of epipolar geometry with applications
                  to autonomous vehicle navigation. Such uncertainty
                  information is necessary for making informed
                  decisions regarding the confidence of a motion
                  estimate, since we must otherwise accept the
                  estimate without any knowledge of the probability
                  that the estimate is in error. For example, we may
                  wish to fuse visual estimates with information from
                  GPS and inertial sensors, but without uncertainty
                  information, we have no principled way to do
                  so. Ideally, we would perform a full search over the
                  7-dimensional space of fundamental matrices to yield
                  an estimate and its related uncertainty. However,
                  searching this space is computationally
                  infeasible. As a compromise between fully
                  representing posterior likelihood over this space
                  and producing a single estimate, we represent the
                  uncertainty over the space of translation directions
                  in a calibrated framework. In contrast to finding a
                  single estimate, representing the posterior
                  likelihood is always a well-posed problem, albeit an
                  often computationally challenging one. Given the
                  posterior likelihood, we derive a confidence
                  interval around the motion estimate. We verify the
                  correctness of the confidence interval using
                  synthetic data and show examples of uncertainty
                  estimates using vehicle-mounted camera sequences.},
}

@Article{Nister06jfr,
  author =	 {D. Nist\'er and O. Naroditsky and J. Bergen},
  fullauthor =	 {David Nist\'er and Oleg Naroditsky and James Bergen},
  title =	 {Visual Odometry for Ground Vehicle Applications},
  journal =	 JFR,
  volume =	 23,
  number =	 1,
  month =	 {Jan},
  year =	 2006,
  abstract =	 {We present a system that estimates the motion of a
                  stereo head or a single moving camera based on video
                  input. The system operates in real-time with low
                  delay and the motion estimates are used for
                  navigational purposes. The front end of the system
                  is a feature tracker. Point features are matched
                  between pairs of frames and linked into image
                  trajectories at video rate. Robust estimates of the
                  camera motion are then produced from the feature
                  tracks using a geometric hypothesize-and-test
                  architecture. This generates motion estimates from
                  visual input alone. No prior knowledge of the scene
                  nor the motion is necessary. The visual estimates
                  can also be used in conjunction with information
                  from other sources such as GPS, inertia sensors,
                  wheel encoders, etc. The pose estimation method has
                  been applied successfully to video from aerial,
                  automotive and handheld platforms. We focus on
                  results obtained with a stereo-head mounted on an
                  autonomous ground vehicle. We give examples of
                  camera trajectories estimated in real-time purely
                  from images over previously unseen distances (600
                  meters) and periods of time.},
  c-kaess =	 {Visual Odometry for DARPA PerceptOR; mostly camera
                  trajectories in combination with other sensors, but
                  also shows a resulting obstacle map.},
}

@BOOK{Nocedal99,
  author =	 "Jorge Nocedal and Stephen J. Wright",
  year =	 1999,
  title =	 "Numerical Optimization",
  series =	 "Springer Series in Operations Research",
  publisher =	 "Springer-Verlag",
}

@InProceedings{Nodelman05uai,
  author =	 {U. Nodelman and C. R. Shelton and D. Koller},
  title =	 {{Expectation Maximization and Complex Duration
                  Distributions for Continuous Time Bayesian
                  Networks}},
  booktitle =	 UAI,
  year =	 2005,
  c-sangmin =	 {Presents more general coxian distribution
                  approximation for duration using E.M.},
}

@Article{North00pami,
  author =	 "B. North and A. Blake and M. Isard and J. Rottscher",
  title =	 "Learning and Classification of Complex Dynamics",
  journal =	 PAMI,
  year =	 2000,
  volume =	 22,
  number =	 9,
  pages =	 "1016-1034",
}

@InProceedings{Nourbakhsh03iros,
  author =	 {I. Nourbakhsh and C. Kunz and T. Willeke},
  title =	 {The {Mobot} Museum Robot Installations: A Five Year
                  Experiment},
  booktitle =	 IROS,
  year =	 2003,
}

@Article{Nourbakhsh95,
  AUTHOR =	 {Nourbakhsh, I. and Powers, R. and Birchfield,S.},
  TITLE =	 {{DERVISH} an Office-Navigating Robot},
  JOURNAL =	 {AI Magazine},
  YEAR =	 1995,
  MONTH =	 {Summer},
  VOLUME =	 16,
  NUMBER =	 2,
  PAGES =	 {53-60}
}

@Inproceedings{Nuchter03workshop,
  author =	 {A. N{\"u}chter and H. Surmann and K. Lingemann and
                  J. Hertzberg},
  title =	 {Semantic Scene Analysis of Scanned {3D} Indoor
                  Environments},
  booktitle =	 {Proceedings of the 8th International Fall Workshop
                  Vision, Modeling, and Visualization 2003},
  pages =	 {215--222},
  year =	 2003,
}

@InProceedings{Nuechter03,
  author =	 {A. Nchter and H. Surmann and J. Hertzberg},
  title =	 {Automatic Model Refinement for {3D} Reconstruction
                  with Mobile Robots},
  booktitle =	 _3DIM,
  pages =	 {394 - 401},
  year =	 2003,
}

@InProceedings{Nuechter05robocup,
  author =	 {A. Nchter and O. Wulf and K. Lingemann and
                  J. Hertzberg and B. Wagner and H. Surmann},
  title =	 {3D Mapping with Semantic Knowledge},
  booktitle =	 {RoboCup},
  pages =	 {335--346},
  year =	 2005,
}

@book{OKeefe78book,
  author =	 {J. O'Keefe and L. Nadel},
  year =	 1978,
  title =	 {The Hippocampus as a Cognitive Map},
  publisher =	 {Clarendon Press: Oxford},
  r-Franz98ar =	 {Higher vertebrates appear to construct
                  representations ?sometimes referred to as cognitive
                  maps ?which encode spatial relations between
                  relevant locations in their environment (see, O?eefe
                  and Nadel, 1978; Gallistel, 1990, for reviews).},
  r-Nadel91hippocampus ={It was our feeling in 1976, when we
                  terminated the review of the lesion literature,
                  which was ultimately published in The Hippocumpiis
                  CIS a Cognitive Map (O?eefe and Nadel, 1978), that
                  the spatial hypothesis successfully handled the vast
                  preponderance of these lesion studies as well as
                  what was then known about the physiology of the
                  hippocampal formation.},
  c-dellaert =	 {Don't have book.}
}

@article{ONeill91eb,
  journal =	 {Environment and Behavior},
  Volume =	 23,
  number =	 3,
  pages =	 {259--284},
  year =	 1991,
  title =	 {Evaluation of a Conceptual Model of Architectural
                  Legibility},
  author =	 {Michael J. O'Neill},
  abstract =	 {Architectural legibility is the degree to which the
                  designed features of the environment aid people in
                  creating an effective mental image, or "cognitive
                  map" of the spatial relationships within a building,
                  and the subsequent ease of wayfinding within the
                  environment. However, little research has attempted
                  to operationalize legibility by examining the
                  relationship between objective measures of the
                  physical environment, the cognitive map, and
                  observational measures of wayfinding
                  performance. This article empirically assesses the
                  effects of one environmental variable, topological
                  floor plan complexity, on the cognitive mapping and
                  wayfinding performance of 63 participants within
                  three building settings. The study finds that this
                  objective measure of floor plan complexity
                  significantly influences cognitive mapping and
                  observed wayfinding. Given these results, a
                  conceptual model of one aspect of architectural
                  legibility was developed and empirically
                  tested. Path analysis was used to assess the
                  relationship between topological plan configuration,
                  four convergent measures of the cognitive map, and
                  observational measures of human wayfinding
                  performance. Analysis of these data provide support
                  for the conceptual model. The model suggests that
                  the complexity of topological plan configuration
                  influences legibility. The evidence also indicates
                  that the relationship between plan configuration and
                  wayfinding is mediated by the accuracy of the
                  cognitive map.},
  r-Franz98ar =	 {Humans, for instance, are able to navigate in
                  unknown environments after presentation of sequences
                  of connected views (e.g., O?eill, 1991).},
  c-dellaert =	 {Not read. Complixity of topology makes navigation
                  more difficult.},
}

@article{ONeill91jep,
  title =	 {A biologically based model of spatial cognition and
                  wayfinding},
  author =	 {M. O'Neill},
  journal =	 {Journal of Environmental Psychology},
  volume =	 {11},
  pages =	 {299-320},
  year =	 {1991},
}

@InProceedings{Oh04cdc,
  author =	 {S. Oh and S. Russell and S. Sastry},
  title =	 {{M}arkov Chain {M}onte {C}arlo Data Association for
                  General Multiple Target Tracking Problems},
  booktitle =	 CDC,
  year =	 2004,
}

@InProceedings{Oh04iros,
  author =	 {S. M. Oh and S. Tariq and B. Walker and F. Dellaert},
  title =	 {Map-Based Priors for Localization},
  booktitle =	 IROS,
  year =	 2004,
}

@InProceedings{Oh05aaai,
  author =	 {S. M. Oh and J. M. Rehg and T. Balch and
                  F. Dellaert},
  title =	 {Data-{D}riven {MCMC} for {L}earning and {I}nference
                  in {S}witching {L}inear {D}ynamic {S}ystems},
  crossref =	 {_AAAI05},
  pages =	 {944-949},
}

@inproceedings{Oh05acc,
  author =	 {S. Oh and S. Sastry},
  title =	 {A Polynomial-Time Approximation Algorithm for Joint
                  Probabilistic Data Association},
  booktitle =	 ACC,
  address =	 {Portland, OR},
  month =	 {June},
  year =	 2005,
}

@InProceedings{Oh05iccv,
  author =	 {S. M. Oh and J. M. Rehg and T. Balch and
                  F. Dellaert},
  title =	 {Learning and {I}nference in {P}arametric {S}witching
                  {L}inear {D}ynamic {S}ystems},
  booktitle =	 ICCV,
  year =	 2005,
  volume =	 2,
  pages =	 {1161-1168},
}

@TechReport{Oh05tr,
  author =	 {S. M. Oh and A. Ranganathan and J.M. Rehg and
                  F. Dellaert},
  title =	 {A {V}ariational inference method for {S}witching
                  {L}inear {D}ynamic {S}ystems},
  number =	 {GIT-GVU-05-16},
  institution =	 {GVU Center, College of Computing, Georgia Institute
                  of Technology},
  year =	 2005,
}

@TechReport{Oh05tr2,
  author =	 {S. M. Oh and J.M. Rehg and F. Dellaert},
  title =	 {Segmental Switching Linear Dynamic Systems},
  number =	 {GIT-CC-05-13},
  institution =	 {College of Computing, Georgia Institute of
                  Technology},
  year =	 2005,
}

@InProceedings{Oh06cvpr,
  author =	 {S. M. Oh and J. M. Rehg and F. Dellaert},
  fullauthor =	 {Sang Min Oh and James M. Rehg and Frank Dellaert},
  title =	 {Parameterized duration modeling for {S}witching
                  lienar dynamic systems},
  booktitle =	 CVPR,
  year =	 2006,
}

@InProceedings{Oh06snowbird,
  author =	 {S. M. Oh and J. M. Rehg and F. Dellaert},
  fullauthor =	 {Sang Min Oh and James M. Rehg and Frank Dellaert},
  title =	 {On-line Learning of the Traversability of
                  Unstructured Terrain for Outdoor Robot Navigation},
  booktitle =	 {Snobird Learning Workshop},
  year =	 2006,
}

@TechReport{Oh06tr,
  author =	 {S. M. Oh and A. Ranganathan and J.M. Rehg and
                  F. Dellaert},
  title =	 {Learning and Inferring Motion Patterns using
                  Parametric Segmental Switching Linear Dynamic
                  Systems},
  number =	 {GIT-GVU-06-02},
  institution =	 {GVU Center, College of Computing, Georgia Institute
                  of Technology},
  year =	 2006,
}

@InProceedings{Oh06yif,
  fullauthor =	 {Sang Min Oh and Grant Schildler and Frank Dellaert
                  and Bruce N. Walker and Jefferety Lindsay},
  title =	 {Automatic Acquisition of 4D urban Models and
                  Proactive Auditory Service for Enhanced User
                  Experience},
  booktitle =	 {Young Investigators Forum in culture and Technology},
  year =	 2006,
}

@Article{Oh08ijcv,
  author =	 {S. M. Oh and J. M. Rehg and T. Balch and
                  F. Dellaert},
  title =	 {Learning and {I}nferring {M}otion {P}atterns using
                  {P}arametric {S}egmental {S}witching {L}inear
                  {D}ynamic {S}ystems},
  journal =	 IJCV,
  volume =	 77,
  number =	 "1-3",
  pages =	 "103-124",
  year =	 2008,
  month =	 "May",
}

@inproceedings{Ohara05icra,
  author =	 {Keith J. O'Hara and Victor Bigio and Shaun Whitt and
                  Daniel Walker and Tucker Balch},
  title =	 {Evaluation of a Large Scale Pervasive Embedded
                  Network for Robot Path Planning},
  booktitle =	 ICRA,
  year =	 {2006},
}

@ARTICLE{Ohara08tro,
  title =	 {Physical Path Planning Using a Pervasive Embedded
                  Network},
  author =	 {K.J. O'Hara and D.B. Walker and T.R. Balch},
  journal =	 TRO,
  year =	 {2008},
  month =	 {June},
  volume =	 {24},
  number =	 {3},
  pages =	 {741-746},
  doi =		 {10.1109/TRO.2008.919303}
}

@InProceedings{Ohta01iccv,
  author =	 {N. Ohta},
  title =	 {A Statistical Approach to Background Subtraction for
                  Surveillance Systems},
  booktitle =	 ICCV,
  year =	 2001,
  abstract =	 {Background subtraction is a commonly used process in
                  surveillance systems. One dificult problem when
                  using the process is maintaining a correct
                  background image against changing illumination
                  conditions. Most methods for maintaining the
                  background image are based on intuitive definitions
                  about the illumination change and are implemented as
                  somewhat ad hoc algorithms. In contrast, we first
                  define mathematical models representing the relation
                  between the illumination intensity, a rejection
                  index of objects and a pixel value. We also
                  mathematically define an assumption about
                  illumination, which requires that the distribution
                  of the illumination intensity in a small region does
                  not change Then we formalize the background
                  subtraction problem as a statistical test based on
                  the models and assunip tion. The experinients show
                  that our models appropriately express the imaging
                  process of a camera and our method' provides stable
                  detection performance for foreground objects.},
  c-houdan =	 {Focus on how to define models for changing
                  illumination, spatial distribution of illumination
                  and pixel noise.},
}

@Article{Ohtsuki76siam,
  author =	 {Ohtsuki, T.},
  title =	 {A fast algorithm for finding an optimal ordering for
                  vertex elimination on a graph},
  journal =	 {SIAM J. Comput.},
  year =	 {1976},
  key =		 {},
  volume =	 {5},
  number =	 {1},
  pages =	 {133--145},
  r-MathSciNet = {The author proves the following generalization of
                  results by D. J. Rose \cite{Rose72chapter}. Let $P$
                  be a proper subset of $V$ in a graph $G(V,E)$ such
                  that for every connected component $G(X)$ of
                  $G(V-P)$ there exists a $u,v$ chain in
                  $G(V-X-\text{Adj}(X)\cup\{u,v\})$ for any distinct
                  vertices $u,v\in\text{Adj}(X)$ (where
                  $\text{Adj}(X)$ denotes the set of vertices adjacent
                  to $X$); then there exists an optimal ordering of
                  $V$ such that the vertices of $P$ are ordered
                  last. From this result a "backward ordering scheme"
                  based on a depth first search is devised. An
                  algorithm for finding an optimal ordering in
                  $O(MN)$ time is presented. This algorithm is
                  different from the $O(MN)$ time algorithm for
                  finding minimal (optimal) orderings given by Rose,
                  R. E. Tarjan and G. S. Lueker [SIAM J. Comput. 5
                  (1976), no. 2, 266--283].},
  r-Heggernes06dm ={Since the problem of computing minimum
                  triangulations is NP-hard, the related polynomially
                  solvable problem of computing minimal triangulations
                  became interesting, and the first algorithms for it
                  appeared in 1976 \cite{Ohtsuki76siam,
                  Rose76siam}. The number of edges in a minimal
                  triangulation can be far from minimum.},
}

@InProceedings{Okuma04,
  author =	 {K. Okuma and A. Taleghani and N. de Freitas and
                  J. Little and D. Lowe},
  title =	 {A Boosted Particle Filter: Multitarget Detection and
                  Tracking},
  booktitle =	 ECCV,
  year =	 2004,
}

@Article{Okutomi93,
  author =	 {Okutomi, M. and Kanade, T.},
  title =	 {A multiple-baseline stereo algorithm},
  journal =	 PAMI,
  year =	 1993,
  volume =	 15,
  number =	 4,
  pages =	 {353--363},
}

@article{Oliver00pami,
  author =	 {N.M. Oliver and B. Rosario and A. Pentland},
  title =	 {A Bayesian Computer Vision System for Modeling Human
                  Interactions},
  journal =	 PAMI,
  volume =	 22,
  number =	 8,
  pages =	 {831-843},
  year =	 2000,
  url =		 {citeseer.nj.nec.com/oliver99bayesian.html},
  abstract =	 {We describe a real-time computer vision and machine
                  learning system for modeling and recognizing human
                  behaviors in a visual surveillance task. The system
                  is particularly concerned with detecting when
                  interactions between people occur and classifying
                  the type of interaction. Examples of interesting
                  interaction behaviors include following another
                  person, altering one's path to meet another, and so
                  forth. Our system combines top-down with bottom-up
                  information in a closed feedback loop, with both
                  components employing a statistical Bayesian
                  approach. We propose and compare two different
                  state-based learning architectures, namely, HMMs and
                  CHMMs for modeling behaviors and interactions. The
                  CHMM model is shown to work much more efficiently
                  and accurately. Finally, to deal with the problem of
                  limited training data, a synthetic Alife-style
                  training system is used to develop flexible prior
                  models for recognizing human interactions. We
                  demonstrate the ability to use these a priori models
                  to accurately classify real human behaviors and
                  interactions with no additional tuning or training.},
  c-houdan =	 {Eigenbackground subtraction using PCA. The author
                  reports it offers as good results as mixture
                  Gaussian method does},
}

@article{Oliver04cviu,
  author =	 {N. Oliver, A. Garg and E. Horvitz},
  fullauthor =	 {Nuria Oliver, Ashutosh Garg and Eric Horvitz},
  title =	 {{Layered representations for learning and inferring
                  office activity from multiple sensory channels}},
  journal =	 CVIU,
  volume =	 96,
  number =	 2,
  pages =	 {163--180},
  year =	 2004,
}

@InProceedings{Olivieri92,
  author =	 {P. Olivieri and M. Gatti and M. Straforini and
                  V. Torre},
  title =	 {A method for the {3D} reconstruction of indoor
                  scenes from monocular images},
  booktitle =	 ECCV,
  pages =	 {696-700},
  year =	 1992,
}

@InProceedings{Olson00,
  author =	 {Clark F. Olson},
  title =	 {Maximum-Likelihood Template Matching},
  booktitle =	 CVPR,
  pages =	 {52-57},
  year =	 2000,
}

@InProceedings{Olson00cvpr,
  author =	 "C.F. Olson and L.H. Matthies and M. Schoppers and
                  M.W. Maimone",
  fullauthor =	 "Clark F. Olson and Larry H. Matthies and Marcel
                  Schoppers and Mark W. Maimone",
  title =	 "Robust Stereo Ego-motion for Long Distance
                  Navigation",
  pages =	 "453-458",
  crossref =	 {_CVPR00},
}

@InProceedings{Olson01icra,
  author =	 {C.F. Olson},
  fullauthor =	 {Clark F. Olson},
  title =	 {Stereo Ego-motion Improvements for Robust Rover
                  Navigation},
  booktitle =	 ICRA,
  pages =	 {1099-1104},
  year =	 2001,
}

@inproceedings{Olson05rss,
  author =	 "E. Olson and M. Walther and J. Leonard and
                  S. Teller",
  fullauthor =	 "Edwin Olson and Matthew Walter and John Leonard and
                  Seth Teller",
  title =	 "Single-Cluster Spectral Graph Partitioning for
                  Robotics Applications",
  booktitle =	 RSS,
  year =	 2005,
  pages =	 "265--272"
}

@InProceedings{Olson06icra,
  author =	 {E. Olson and J. Leonard and S. Teller},
  fullauthor =	 {Edwin Olson and John Leonard and Seth Teller},
  title =	 {Fast Iterative Alignment of Pose Graphs with Poor
                  Initial Estimates},
  booktitle =	 ICRA,
  location =	 {Orlando, FL},
  month =	 {May},
  year =	 2006,
  abstract =	 {A robot exploring an environment can estimate its
                  own motion and the relative positions of features in
                  the environment. Simultaneous Localization and
                  Mapping (SLAM) algorithms attempt to fuse these
                  estimates to produce a map and a robot
                  trajectory. The constraints are generally
                  non-linear, thus SLAM can be viewed as a non-linear
                  optimization problem. The optimization can be
                  difficult, due to poor initial estimates arising
                  from odometry data, and due to the size of the state
                  space. We present a fast non-linear optimization
                  algorithm that rapidly recovers the robot
                  trajectory, even when given a poor initial
                  estimate. Our approach uses a variant of Stochastic
                  Gradient Descent on an alternative state-space
                  representation that has good stability and
                  computational properties.We compare our algorithm to
                  several others, using both real and synthetic data
                  sets.},
  c-kaess =	 {Solves a problem that only appears with iterative
                  batch solvers, such as stochastic gradient descent,
                  as pose graphs always seem to converge for direct
                  methods! Timing for LU decomposition seems to be for
                  dense matrix, could be way faster when correctly
                  implemented as in SAM. A key part of the algorithm
                  is that nodes are represented relative to their
                  successors along the trajectory, yielding simple
                  jacobians. See Grisetti07rss for improved version
                  based on spanning tree.},
}

@InProceedings{Olson07rss,
  author =	 {E. Olson and J. Leonard and S. Teller},
  fullauthor =	 {Edwin Olson and John Leonard and Seth Teller},
  title =	 {Spatially-Adaptive Learning Rates for Online
                  Incremental {SLAM}},
  booktitle =	 RSS,
  location =	 {Atlanta, GA},
  month =	 {Jun},
  year =	 {2007},
}

@InProceedings{Olson09gem,
  author =       {E. Olson and M. Kaess},
  fullauthor =   {Ed Olson and Michael Kaess},
  title =        {Evaluating the Performance of Robot Mapping Systems},
  booktitle =    {Workshop on Good Experimental Methodology in Robotics},
  year =         2009,
  abstract =     {Localization and mapping are essential capabilities
                  of virtually all mobile robots. These topics have
                  been the focus of a great deal of research, but it
                  is not always easy to tell which methods are
                  best. This paper discusses performance evaluation
                  for an important sub-problem of robot mapping, map
                  optimization. We explore aspects underlying the
                  evaluation of map optimization such as the quality
                  of the result and computational complexity.  For
                  each aspect we discuss evaluation metrics and
                  provide specific recommendations.},
}

@InProceedings{Omohundro91nips,
  author =	 {S. M. Omohundro},
  title =	 {Bumptrees for efficient function, constraint, and
                  classification learning},
  booktitle =	 NIPS,
  year =	 1991,
  publisher =	 {Morgan Kaufmann},
}

@article{Osogami06,
  author =	 {T. Osogami and M. Harchol-Balter},
  fullauthor =	 {Takayuki Osogami and Mor Harchol-Balter},
  year =	 2006,
  title =	 "Closed Form Solutions for Mapping General
                  Distributions to Minimal PH Distributions",
  journal =	 {Performance Evaluation},
  volume =	 63,
  number =	 6,
  pages =	 "524--552",
}

@article{Ostendorf96,
  author =	 "M. Ostendorf and V. V. Digalakis and O. A. Kimball",
  year =	 1996,
  title =	 "From {HMM}'s to {S}egment Models : A {U}nified
                  {V}iew of {S}tochastic {M}odeling for {S}peech
                  {R}ecognition",
  journal =	 "IEEE Transactions on Speech and Audio Processing",
  volume =	 4,
  number =	 5,
  pages =	 "360--378",
}

@Article{Ouriachi80,
  author =	 {K. Ouriachi},
  title =	 {Processus de Reconnaissance des Formes applicable a
                  un assemblage automatique},
  journal =	 {These de 3eme cycle, Universite des Sciences et
                  Techniques de Lille},
  year =	 1980,
}

@InProceedings{Ozuysal07cvpr,
  author =	 {M. Ozuysal and P. Fua and V. Lepetit},
  title =	 {Fast Keypoint Recognition in Ten Lines of Code},
  booktitle =	 CVPR,
  year =	 {2007},
}

@InProceedings{Pagnot95,
  author =	 {R. Pagnot and P. Grandjea},
  title =	 {Fast Cross-country Navigation on Fair Terrains},
  booktitle =	 ICRA,
  year =	 1995,
  pages =	 {2593-2598},
}

@InProceedings{Paletta01,
  author =	 {L.Paletta and S.Frintrop and J.Hertzberg},
  title =	 {Robust Localization Using Context in Omnidirectional
                  Imaging},
  booktitle =	 ICRA,
  year =	 2001,
}

@InProceedings{Paletta05scia,
  fullauthor =	 {Lucas Paletta and Gerald Fritz},
  author =	 {L. Paletta and G. Fritz},
  year =	 2005,
  title =	 {Urban object detection from mobile phone imagery
                  using informative sift descriptors},
  booktitle =	 {Scandinavian Conference on Image Analysis (SCIA)},
  r-Wang06_3dpvt ={In [7] the authors proposed to detect buildings
                  using SIFT descriptors combined with the
                  discriminative feature selection mechanism which
                  reduced the overall complexity of the
                  representation. Alternatively when dealing with
                  large databases, it is desirable to use a global
                  descriptor, to preselect small a number of
                  candidates before carrying out recognition based on
                  local features. For this stage color histograms were
                  used, because of their simplicity and robustness to
                  changes in object?s scale, orientation and to some
                  extent viewpoint.},
}

@Book{Palmer99book,
  author =	 "S.E. Palmer",
  title =	 "Vision science: from photons to phenomenology",
  publisher =	 MIT,
  year =	 1999,
}

@Book{Papadimitriou82,
  author =	 "C.H. Papadimitriou and K. Steiglitz",
  title =	 "Combinatorial Optimization: Algorithms and
                  Complexity",
  publisher =	 "Prentice-Hall",
  year =	 1982,
}

@Article{Papoulis77,
  author =	 {A. Papoulis},
  title =	 {Generalized sampling theorem},
  journal =	 {IEEE Trans. Circuits Syst.},
  year =	 1977,
  volume =	 {CAS-24},
  pages =	 {652-654},
}

@InProceedings{Parag06cvpr,
  author =	 {T. Parag and A. Elgammal and A. Mittal},
  title =	 {A Framework for Feature Selection for Background
                  Subtraction},
  booktitle =	 CVPR,
  year =	 2006,
  abstract =	 {Background subtraction is a widely used paradigm to
                  detect moving objects in video taken from a static
                  camera and is used for various important
                  applications such as video surveillance, human
                  motion analysis, etc. Various statistical approaches
                  have been proposed for modeling a given scene
                  background. However, there is no theoretical
                  framework for choosing which features to use to
                  model different regions of the scene background. In
                  this paper we introduce a novel framework for
                  feature selection for background modeling and
                  subtraction. A boosting algorithm, namely RealBoost,
                  is used to choose the best combination of features
                  at each pixel. Given the probability estimates from
                  a pool of features calculated by Kernel Density
                  Estimate (KDE) over a certain time period, the
                  algorithm selects the most useful ones to
                  discriminate foreground objects from the scene
                  background. The results show that the proposed
                  framework successfully selects appropriate features
                  for different parts of the image.},
  c-houdan =	 {A good paper of selecting features from RGB,
                  intensity, spatial gradients, temporal gradients,
                  optical flow, etc. for background modeling and
                  subtraction},
}

@InProceedings{Parikh07iccv,
  author =	 {D. Parikh and T. Chen},
  title =	 {Hierarchical Semantic of Objects (hSOs)},
  booktitle =	 ICCV,
  year =	 {2007},
  added-by =	 {Alireza},
}

@Article{Parish2001,
  author =	 {Y.I.H. Parish and P. Muller},
  title =	 {Procedural modeling of cities},
  journal =	 SIGGRAPH,
  year =	 {2001},
  pages =	 {301-308 },
}

@Article{Parker83,
  author =	 {J.A.~Parker and R.V.~Kenyon and D.E.~Troxel},
  title =	 {Comparison of Interpolating Methods for Image
                  Resampling},
  journal =	 {IEEE Transactions on Medical Imaging},
  year =	 1983,
  volume =	 2,
  number =	 1,
  pages =	 {31--39}
}

@Article{Parlett00cse,
  author =	 {Parlett, B.N.},
  title =	 {The {QR} algorithm},
  pages =	 {38--42},
  journal =	 {Computing in Science \& Engineering},
  volume =	 2,
  number =	 1,
  month =	 {Jan.-Feb.},
  year =	 2000,
  note =	 {Special issue on the Top 10 Algorithms in {Science}
                  \& {Engineering}},
}

@Article{Parter61siam,
  author =	 {S. Parter},
  fullauthor =	 {Seymour V. Parter},
  title =	 {The use of linear graphs in {Gauss} elimination},
  journal =	 {SIAM Rev.},
  year =	 1961,
  volume =	 3,
  number =	 2,
  pages =	 {119--130},
  month =	 {April},
  r-MathSciNet = {Recent interest in various block iterative methods
                  investigated by the author and the reviewer for
                  solving elliptic difference equations are based on
                  the ability to solve directly special systems of
                  linear equations. In this paper, the author first
                  gives (Theorem 1) an interpretation of Gaussian
                  elimination by means of the linear graph $G(A)$ of
                  the associated matrix $A$. Several interesting
                  examples, which make use of graphs, include
                  Laplace's difference equation and the two-line
                  biharmonic matrix. Finally, when the linear graph
                  $G(A)$ in a tree and Gaussian elimination is always
                  possible, an algorithm is given for choosing the
                  pivots in an elimination scheme.},
  quotes =	 {This is done by associating a ... "picture" with
                  each matrix A. In many problems the role of the
                  associated graph is completely apparent. For example
                  K. Friedrich (1930) made use of these concepts in
                  his work on the normal equations for Geodetic nets.},
  r-Rose70 =	 {S. V. Parter \cite{Parter61siam} discussed this
                  question when $M$ was represented by a tree, and he
                  showed that an ordering $P$ could be found which
                  resulted in a `perfect' elimination scheme. },
  r-Heggernes06dm ={Although we know today that minimal triangulations
                  are closely related to minimal separators, sparse
                  matrix compu- tations was the first field to study
                  different triangulations of a given graph
                  \cite{George81book, Parter61siam, Rose72chapter}.},
  r-Heggernes06dm ={ A graph algorithm, known as Elimination Game
                  \cite{Parter61siam}, was given in 1961, introducing
                  the connection between sparse matrix computations
                  and graphs. This algorithm simulates symmetric
                  Gaussian elimination on graphs by repeatedly
                  choosing a vertex v, adding edges to make the
                  neighborhood of v into a clique, and then removing v
                  from the graph.},
  c-dellaert =	 {Was at Cornell, now at Wisconsin. The paper seems to
                  be the first where matrices are analyzed using
                  graphs. Theorem II: one-term successive elimination
                  schemes exists if $G(A)$ is a tree.}
}

@TechReport{Paskin02,
  author =	 {M.A. Paskin},
  fullauthor =	 {Mark A. Paskin},
  title =	 {Thin Junction Tree Filters for Simultaneous
                  Localization and Mapping},
  institution =	 {University of California, Berkeley},
  year =	 2002,
  number =	 {UCB/CSD-02-1198},
}

@InProceedings{Paskin03ijcai,
  author =	 "M.A. Paskin",
  fullauthor =	 "Mark A. Paskin",
  title =	 "Thin Junction Tree Filters for Simultaneous
                  Localization and Mapping",
  booktitle =	 IJCAI,
  year =	 2003,
  abstract =	 {Simultaneous Localization and Mapping (SLAM) is a
                  fundamental problem in mobile robotics: while a
                  robot navigates in an unknown environment, it must
                  incrementally build a map of its surroundings and,
                  at the same time, localize itself within that
                  map. One popular solution is to treat SLAM as an
                  estimation problem and apply the Kalman filter; this
                  approach is elegant, but it does not scale well: the
                  size of the belief state and the time complexity of
                  the filter update both grow quadratically in the
                  number of landmarks in the map. This paper presents
                  a filtering technique that maintains a tractable
                  approximation of the belief state as a thin junction
                  tree. The junction tree grows under filter updates
                  and is periodically "thinned" via efficient maximum
                  likelihood projections so inference remains
                  tractable. When applied to the SLAM problem, these
                  thin junction tree filters have a linearspace belief
                  state and a linear-time filtering operation. Further
                  approximation yields a filtering operation that is
                  often constant-time. Experiments on a suite of SLAM
                  problems validate the approach.},
}

@techreport{Paskin03tr,
  Author =	 {Mark A. Paskin and Gregory D. Lawrence},
  Title =	 {Junction Tree Algorithms for Solving Sparse Linear
                  Systems},
  Institution =	 {EECS Department, University of California, Berkeley},
  Year =	 2003,
  Number =	 {UCB/CSD-03-1271}
}

@PhdThesis{Paskin04thesis,
  author =	 {M.A. Paskin},
  fullauthor =	 {Mark A. Paskin},
  title =	 {Exploiting Locality in Probabilistic Inference},
  school =	 {University of California, Berkeley},
  year =	 2004,
  month =	 {September},
}

@TechReport{Paskin04tr,
  author =	 {M.A. Paskin and C.E. Guestrin},
  title =	 {A Robust Architecture for Distributed Inference in
                  Sensor Networks},
  institution =	 {Intel Research},
  year =	 2004,
  number =	 {IRB-TR-03-039},
  c-Paskin04uai ={In a companion paper[this], we present an
                  architecture for distributed inference in which the
                  nodes of the network assemble themselves into a
                  network junction tree, where each network node has
                  an associated clique and set of factors. Our
                  architecture builds, maintains, and optimizes this
                  network junction tree robustly, addressing both
                  unreliable communication and node failures. Using
                  asynchronous message passing on this junction tree,
                  the nodes can solve the inference problem
                  efficiently and exactly.},
  c-Paskin05ipsn ={An extended version of this paper presents
                  additional background, details, and experimentsl }
}

@InProceedings{Paskin04uai,
  author =	 {M.A. Paskin and C.E. Guestrin},
  full.author =	 {Mark A. Paskin and Carlos E. Guestrin},
  title =	 {Robust Probabilistic Inference in Distributed
                  Systems},
  crossref =	 {_UAI04},
  abstract =	 {Probabilistic inference problems arise naturally in
                  distributed systems such as sensor networks and
                  teams of mobile robots. Inference algorithms that
                  use message passing are a natural fit for
                  distributed systems, but they must be robust to the
                  failure situations that arise in real-world
                  settings, such as unreliable communication and node
                  failures. Unfortunately, the popular sum-product
                  algorithm can yield very poor estimates in these
                  settings because the nodes' beliefs before
                  convergence can be arbitrarily different from the
                  correct posteriors. In this paper, we present a new
                  message passing algorithm for probabilistic
                  inference which provides several crucial guarantees
                  that the standard sum-product algorithm does
                  not. Not only does it converge to the correct
                  posteriors, but it is also guaranteed to yield a
                  principled approximation at any point before
                  convergence. In addition, the computational
                  complexity of the message passing updates depends
                  only upon the model, and is independent of the
                  network topology of the distributed system. We
                  demonstrate the approach with detailed experimental
                  results on a distributed sensor calibration task
                  using data from an actual sensor network
                  deployment.},
  r-Upcroft06iser ={robust decentralised data fusion have included
                  monitoring temperature},
  r-Paskin05ipsn ={For further detail on the application of our
                  architecture to probabilistic inference and
                  regression problems, see [this]},
  c-dellaert =	 {paskin04uai, Guestrin04ipsn, Paskin05ipsn all seem
                  to be the same thing},
}

@InProceedings{Paskin05ipsn,
  author =	 {M. Paskin and C. Guestrin and J. McFadden},
  title =	 {A Robust Architecture for Distributed Inference in
                  Sensor Networks},
  booktitle =	 IPSN,
  year =	 2005,
  abstract =	 {Many inference problems that arise in sensor
                  networks require the computation of a global
                  conclusion that is consistent with local information
                  known to each node. A large class of these problems
                  - including probabilistic inference, regression, and
                  control problems - can be solved by message passing
                  on a data structure called a junction tree. In this
                  paper, we present a distributed architecture for
                  solving these problems that is robust to unreliable
                  communication and node failures. In this
                  architecture, the nodes of the sensor network
                  assemble themselves into a junction tree and
                  exchange messages between neighbors to solve the
                  inference problem efficiently and exactly. A key
                  part of the architecture is an efficient distributed
                  algorithm for optimizing the choice of junction tree
                  to minimize the communication and computation
                  required by inference. We present experimental
                  results from a prototype implementation on a 97-node
                  Mica2 mote network, as well as simulation results
                  for three applications: distributed sensor
                  calibration, optimal control, and sensor field
                  modeling. These experiments demonstrate that our
                  distributed architecture can solve many important
                  inference problems exactly, efficiently, and
                  robustly.},
  quotes =	 {[Other] inference approaches are not as general as
                  ours, and more importantly, they do not fully
                  address the practical issues that arise in real
                  deployments: communication over wireless networks is
                  unreliable due to noise and packet collisions; the
                  wireless network topology changes over time; and,
                  nodes can fail for a number of reasons...To address
                  these robustness issues we propose a novel
                  architecture consisting of three layers: spanning
                  tree formation, junction tree formation, and message
                  passing.},
  c-dellaert =	 {Best Paper Award. paskin04uai, Guestrin04ipsn,
                  Paskin05ipsn all seem to be the same thing},
}

@InProceedings{Pasula99,
  author =	 "H. Pasula and S. Russell and M. Ostland and
                  Y. Ritov",
  title =	 "Tracking many objects with many sensors",
  booktitle =	 IJCAI,
  year =	 1999,
  address =	 "Stockholm",
}

@InProceedings{Patti94,
  author =	 {A. J. Patti and M. I. Sezan and A. M. Tekalp},
  title =	 {High-Resolution Image Reconstruction from a
                  Low-resolution Image Sequence in the Presence of
                  Time-varying Motion Blur},
  booktitle =	 ICIP,
  pages =	 {343-347},
  year =	 1994,
}

@InProceedings{Patti95,
  author =	 "A. J. Patti and M. I. Sezan and A. M. Tekalp",
  title =	 "High-resolution standards conversion of
                  low-resolution video",
  pages =	 "2197-2000",
  booktitle =	 ICASSP,
  year =	 1995,
}

@article{Patti97,
  AUTHOR =	 "Patti, A.J. and Sezan, M.I. and Tekalp, A.M.",
  TITLE =	 "Superresolution Video Reconstruction with Arbitrary
                  Sampling Lattices and Nonzero Aperture Time",
  JOURNAL =	 IP,
  VOLUME =	 6,
  YEAR =	 1997,
  NUMBER =	 8,
  MONTH =	 "August",
  PAGES =	 "1064-1076"
}

@InCollection{PattiPati90,
  author =	 {K.R. PattiPati and S. Deb and Y. Bar-Shalom},
  title =	 {Passive multisensor data association using a new
                  relaxation algorithm},
  booktitle =	 {Multitarget-Multisensor Tracking: Advanced
                  Applications},
  pages =	 {219-246},
  publisher =	 {Artech House},
  year =	 1990,
}

@Article{PattiPati92itac,
  author =	 {Pattipati, K.R. and Deb, S. and Bar-Shalom, Y. and
                  Washburn, R.B., Jr.},
  title =	 {A new relaxation algorithm and passive sensor data
                  association},
  journal =	 ITAC,
  year =	 1992,
  volume =	 37,
  number =	 2,
  pages =	 {198 -213},
  month =	 {February},
}

@Article{Paulus97,
  author =	 {D. Paulus and J. Hornegger and H. Niemann},
  title =	 {A Framework For Statistical 3-D Object Recognition},
  journal =	 PRL,
  year =	 1997,
  volume =	 18,
  pages =	 {1153-1157},
}

@Article{Pavlidis72,
  author =	 "T. Pavlidis",
  title =	 "Grammatical and graph theoretical analysis of
                  pictures",
  journal =	 "{Graphic Languages}",
  year =	 1972,
}

@article{Pavlidis76,
  author =	 "Horowitz, S.L. and Pavlidis, T.",
  title =	 "Picture Segmentation by a Tree Traversal Algorithm",
  journal =	 "JACM",
  volume =	 23,
  year =	 1976,
  number =	 2,
  month =	 "April",
  pages =	 "368-388"
}

@inproceedings  {Pavlovic00a,
  author =	 "V. Pavlovi\'{c} and J.M. Rehg",
  title =	 "Impact of {D}ynamic {M}odel {L}earning on
                  {C}lassification of {H}uman {M}otion",
  booktitle =	 CVPR,
  volume =	 1,
  pages =	 {788-795},
  year =	 2000,
  keywords =	 "SLDS, approximate inference, switching system",
}

@inproceedings  {Pavlovic00b,
  author =	 "V. Pavlovi\'{c} and J.M. Rehg and J. MacCormick",
  title =	 "Learning Switching Linear Models of Human Motion",
  booktitle =	 NIPS,
  year =	 2000,
  pages =	 "981-987",
  keywords =	 "SLDS, approximate inference, switching system",
}

@inproceedings  {Pavlovic99,
  author =	 "V. Pavlovi\'{c} and J.M. Rehg and T.-J. Cham and
                  K. Murphy",
  title =	 "A Dynamic {B}ayesian Network Approach to Figure
                  Tracking Using Learned Dynamic Models",
  booktitle =	 ICCV,
  volume =	 1,
  pages =	 {94-101},
  year =	 1999,
}

@article{Payton01autonomous,
  author =	 {David Payton and Mike Daily and Regina Estowski and
                  Mike Howard and Craig Lee},
  title =	 {Pheromone Robotics},
  journal =	 {Autonomous Robots},
  volume =	 {11},
  pages =	 {319--324},
  year =	 {2001}
}

@InProceedings{Paz07vslam,
  author =	 {L.M. Paz and P. Pinies and J.D. Tard\'{o}s and
                  J. Neira},
  title =	 {6{DOF} {SLAM} with Stereo-in-hand},
  booktitle =	 {IROS visual SLAM workshop},
  location =	 {San Diego},
  month =	 {Oct},
  year =	 2007,
  abstract =	 {In this paper we describe a system that carries out
                  SLAM using a stereo pair moving with 6DOF as the
                  only sensor. Textured point features are extracted
                  from the images and stored as 3D points if seen in
                  both images with sufficient disparity, or stored as
                  inverse 3D points otherwise. This allows the system
                  to make use of both near and far features that
                  provide distance and orientation, or orientation
                  information, respectively. Unlike other vision only
                  SLAM systems, stereo does not suffer from ?cale
                  drift?because of unobservability problems, and thus
                  no other information such as gyroscopes or
                  accelerometers is required. Our SLAM algorithm
                  generates sequences of conditionally independent
                  local maps that can share information related to the
                  camera motion and common features being tracked. The
                  system computes the full map using the Divide and
                  Conquer algorithm adapted for conditionally
                  independent local maps, allowing linear time
                  execution. We show experimental results in outdoor
                  urban environments that demonstrate the robustness
                  and scalability of our system.},
  c-kaess =	 {Stereo SLAM without additional sensors, includes
                  motion model into estimation. Uses Divide and
                  Conquer SLAM that builds conditionally independent
                  local maps, supposedly in linear
                  time. Differentiates between close and far points -
                  not sure why they cannot be treated uniformly as we
                  do.},
}

@Article{Paz08tro,
  author =	 {L. M. Paz and P. Pinies and J. D. Tards and
                  J. Neira},
  title =	 {Large Scale 6{DOF} {SLAM} with Stereo-in-hand},
  journal =	 {IEEE Transactions on Robotics},
  pages =        {946-957},
  year =	 2008,
  volume =	 24,
  number =	 5
}

@InProceedings{Pearl82aaai,
  author =	 {J. Pearl},
  title =	 {Reverend {Bayes} on inference engines: a distributed
                  hierarchical approach},
  crossref =	 {_AAAI82},
  pages =	 {133--136},
  r-Lauritzen88jrssb ={\cite{Kelly73obhp} and \citet{Pearl82aaai}
                  consider 'trees' in which each node has at most one
                  parent and there are no 'loops'.},
  c-dellaert =	 {2000 AAAI Classic Paper Award, for "revolutionizing
                  uncertain reasoning through the introduction of
                  efficient Bayesian inference methods". First paper
                  to show belief propagation in trees ? Apparently no
                  references to earlier work except applications or
                  negative refs.},
}

@Book{Pearl84book,
  author =	 {J. Pearl},
  title =	 {Heuristics: Intelligent Search Strategies for
                  Computer Problem Solving},
  publisher =	 {Addison-Wesley},
  year =	 1984,
}

@Article{Pearl86ai,
  author =	 {J. Pearl},
  title =	 {Fusion, propagation, and structuring in belief
                  networks},
  journal =	 AI,
  year =	 1986,
  volume =	 29,
  number =	 3,
  pages =	 {241--288},
  month =	 {September},
  r-Lauritzen88jrssb ={When loops are unavoidable, Pearl (1986a)
                  recommends conditioning on each value combination of
                  nodes that will decompose the graph into trees and
                  then averaging over the results... or restructuring
                  into a tree by introducing intermediate states that
                  'explain' dependencies.},
  r-Shafer90amai ={The basic algorithms we describe in sections 7 and
                  8 do not go beyond the algorithms of Kelly and
                  Barclay \cite{Kelly73obhp}, Cannings, Thompson and
                  Skolnick \cite{Cannings78aap}, Pearl
                  \cite{Pearl86ai}, and Lauritzen and Spiegelhalter
                  \cite{Lauritzen88jrssb} in what they accomplish, but
                  they do show that the accomplishment is simpler than
                  sometimes thought.},
}

@Book{Pearl88book,
  author =	 {J. Pearl},
  title =	 {Probabilistic Reasoning in Intelligent Systems:
                  Networks of Plausible Inference},
  publisher =	 {Morgan Kaufmann},
  year =	 1988,
  r-Dechter99ai ={Cutset-conditioning \cite{Dechter90ai, Pearl88book}
                  applies conditioning to a subset of variables that
                  cut all cycles of the interaction graph and solve
                  the resulting subproblem by bucket-elimination.}
}

@Article{Peel00,
  author =	 {D. Peel and G. J. McLachlan},
  title =	 {Robust mixture modelling using the $t$ distribution},
  journal =	 {Statistics and Computing},
  year =	 2000,
  volume =	 10,
  pages =	 {339-348}
}

@article{Peers2007,
  author =	 {P.Peers and N. Tamura and W.Matusik and P.Debevec},
  title =	 {Post-production facial performance relighting using
                  reflectance transfer},
  journal =	 {ACM Transactions on Graphics},
  volume =	 26,
  number =	 3,
  year =	 2007,
}

@InProceedings{Pegard96icra,
  author =	 {Pegard, C. and Mouaddib, E.M.;},
  title =	 {A mobile robot using a panoramic view},
  booktitle =	 ICRA,
  pages =	 {89-94},
  year =	 1996,
  volume =	 1,
}

@article{Peleg01pami,
  author =	 "S. Peleg and M. Ben-Ezra and Y. Pritch",
  fullauthor =	 "Shmuel Peleg and Moshe Ben-Ezra and Yael Pritch",
  title =	 "Omnistereo: Panoramic Stereo Imaging",
  journal =	 PAMI,
  volume =	 23,
  number =	 3,
  pages =	 "279-290",
  year =	 2001,
}

@Article{Peleg87,
  author =	 {S.~Peleg and D.~Keren and L.~Schweitzer},
  title =	 {Improve Image Resolution using Subpixel Motion},
  journal =	 {Pattern Recognition Letters},
  year =	 1987,
  pages =	 {223--226}
}

@inproceedings  {Peleg97,
  key =		 "Peleg",
  author =	 "Peleg, S. and Herman, J.",
  fullauthor =	 "S. Peleg and Joshua Herman",
  title =	 "Panoramic mosaics by manifold projection",
  booktitle =	 CVPR,
  address =	 "San Juan, Puerto Rico",
  month =	 "June",
  year =	 1997,
  pages =	 "338-343",
  keywords =	 "panoramic image construction",
  bibdate =	 "Mon 06/23/1997 11:08a"
}

@InProceedings{Perez02,
  author =	 {P. Perez and C. Hue and J. Vermaak and M. Gangnet},
  title =	 {Color-Based Probabilistic Tracking},
  booktitle =	 ECCV,
  pages =	 661675,
  year =	 2002
}

@inproceedings{Petrie96mobic,
  author =	 "H. Petrie and V. Johnson and T. Strothotte and
                  A. Raab and R. Michel and L. Reichert and A. Schalt",
  fullauthor =	 "Helen Petrie and Valerie Johnson and Thomas
                  Strothotte and Andreas Raab and Rainer Michel and
                  Lars Reichert and Axel Schalt",
  title =	 "Mo{BIC}: {A}n {A}id to {I}ncrease the {I}ndependent
                  {M}obility of {B}lind {T}ravellers",
  booktitle =	 "The British Journal of Visual Impairment Vol.15:2",
  year =	 1996,
  url =		 "http://www.qac.ac.uk/bjvi/vo115/bjvi152d.htm"
}

@PhdThesis{Peyton86thesis,
  author =	 {B.W. Peyton},
  title =	 {Some applications of clique trees to the solution of
                  sparse linear systems},
  school =	 {Dept. of Mathematical Sciences, Clemson University},
  year =	 1986,
  r-Blair93chapter ={However, chordal graphs and clique trees have
                  found a niche in more recent work in this area,
                  primarily due to various research questions
                  associated with advanced computer architectures. For
                  instance, the multifrontal method \cite{Duff83toms},
                  which was developed to obtain good performance on
                  vector supercomputers, can be expressed very
                  succinctly in terms of a clique tree representation
                  of the underlying chordal graph
                  \cite{Peyton86thesis, Pothen92siam}.},
}

@inproceedings{Pfingsthorn08lnai,
  title =	 {A Scalable Hybrid Multi-robot {SLAM} Method for
                  Highly Detailed Maps},
  fullauthor =	 {Pfingsthorn, Max and Slamet, Bayu and Visser,
                  Arnoud},
  author =	 {M. Pfingsthorn and B. Slamet and A. Visser},
  pages =	 {457--464},
  year =	 {2008},
  abstract =	 {Recent successful SLAM methods employ hybrid map
                  representations combining the strengths of
                  topological maps and occupancy grids. Such
                  representations often facilitate multi-agent
                  mapping. In this paper, a successful SLAM method is
                  presented, which is inspired by the manifold data
                  structure by Howard et al. This method maintains a
                  graph with sensor observations stored in vertices
                  and pose differences including uncertainty
                  information stored in edges. Through its graph
                  structure, updates are local and can be efficiently
                  communicated to peers. The graph links represent
                  known traversable space, and facilitate tasks like
                  path planning. We demonstrate that our SLAM method
                  produces very detailed maps without sacrificing
                  scalability. The presented method was used by the
                  UvA Rescue Virtual Robots team, which won the Best
                  Mapping Award in the RoboCup Rescue Virtual Robots
                  competition in 2006.},
  c-dellaert =	 {Interesting application of Howard},
  crossref =	 {_Robocup07},
}

@article{Pham96tsp,
  author =	 "D. Pham",
  title =	 "Blind Separation of Instantaneous Mixture of Sources
                  via an Independent Component Analysis",
  journal =	 SP,
  pages =	 "2668--2779",
  volume =	 44,
  number =	 11,
  year =	 1996,
}

@InCollection{Phillips96,
  author =	 "D.B. Phillips and A.F.M. Smith",
  title =	 "Bayesian model comparison via jump diffusion",
  crossref =	 "Gilks96",
}

@article{Phong95,
  author =	 "Phong, T.Q. and Horaud, R. and Yassine, A. and Tao,
                  P.D.",
  title =	 "Object Pose from {2-D} to {3-D} Point and Line
                  Correspondences",
  journal =	 IJCV,
  volume =	 15,
  number =	 3,
  month =	 "July",
  pages =	 "225-243",
  year =	 1995,
}

@misc{PhotoBooth,
  author =	 {Apple {C}omputer {I}nc.},
  title =	 {Photo {B}ooth},
  url =		 {http://www.apple.com/macbookpro/features.html},
  year =	 2005,
}

@Book{Piaget56book,
  author =	 {J. Piaget and B. Inhelder},
  year =	 1956,
  title =	 {The {C}hild's {C}onception of {S}pace},
  publisher =	 {London: Routledge \& Kegan Paul},
}

@Article{Piazzalunga98,
  author =	 {U. Piazzalunga and P.I. Fitzhorn},
  title =	 {Note on a three-dimensional shape grammar
                  interpreter},
  journal =	 {Environment and Planning B: Planning and Design},
  year =	 1998,
  volume =	 25,
  pages =	 {11-33 },
}

@InProceedings{Piccardi04icip,
  author =	 {M. Piccardi and T. Jan},
  title =	 {Mean-shift Background Image Modeling},
  booktitle =	 ICIP,
  pages =	 {3399-3402},
  year =	 2004,
  month =	 {October},
  abstract =	 {Background modeling is widely used in computer
                  vision for the detection of forcground objects in a
                  frame sequence. The more accurate the background
                  model, the more correct is the detection of the
                  foreground objects. In this paper, we present an
                  approach to background modeling based on a
                  mean-shift procedure. The mean shift vector
                  convergence properties enable the system to achieve
                  reliable background modeling. In addition,
                  histogram-based compulation and the new concept of
                  local basins of attraction allow us to meet the
                  stringent real-time requirements of video
                  processing.},
  c-houdan =	 {By detecting the modes, the PDF estimation requires
                  fas less computation that KDE method which applies a
                  kernel function for every point},
}

@InProceedings{Piccardi04icsmc,
  author =	 {M. Piccardi},
  title =	 {Background subtraction techniques: a review},
  booktitle =	 {International Conference on Systems, Man and
                  Cybernetics},
  pages =	 {3099-3104},
  year =	 2004,
  abstract =	 {Background subtraction is a widely used approoch for
                  detecting moving objects @om static cameras. Mony
                  different methods have been proposed over the recent
                  years and both the novice and the exprt can be
                  confused about iheir benefits and limitations. In
                  order to overcome this problem, this poper provides
                  a review o ihe main methods and an original f
                  categorisotion based on speed, memoy requirements
                  and accuracy, Such o review can effectively guide
                  ihe designer to select the most suitoble meihod for
                  a given application in a principled way. Methods
                  reviewed include parametric and non-porametric
                  background density estimates and spatial correlation
                  approaches.},
  c-houdan =	 {It makes quantified comparision of speed and memory
                  requirements, but doesn't make quantified accuracy
                  analysis among them.}
}

@article{Pierce97,
  author =	 "Pierce, D. and Kuipers, B.",
  title =	 "Map learning with uninterpreted sensors and
                  effectors",
  journal =	 "Artificial Intelligence",
  volume =	 "92",
  pages =	 "169-229",
  year =	 "1997",
  c-ananth =	 {A complete behavior-based learning system based on
                  the Spatial Semantic Hierarchy that learns at many
                  levels starting from low-level sensori-motor control
                  to topological and metric maps is described in
                  [Pierce97]. },
}

@inproceedings{Pilu97,
  AUTHOR =	 "Pilu, M.",
  TITLE =	 "A Direct Method for Stereo Correspondence Based on
                  Singular Value Decomposion",
  BOOKTITLE =	 CVPR,
  YEAR =	 1997,
  PAGES =	 "261-266"
}

@InProceedings{Ping09iccv,
  author = {Ping Wang and Gregory D. Abowd and James M. rehg},
  title = {Quasi-Periodic Event Analysis for Video Retrieval},
  booktitle = ICCV,
  year = {2009}
}

@Article{Pison03,
  author =	 {G. Pison. and P. J. Rousseeuw and P. Filzmoser and
                  C. Croux },
  title =	 {Robust factor analysis},
  journal =	 {Journal of Multivariate Analysis},
  year =	 2003,
  volume =	 84,
  number =	 1,
  pages =	 {145-172},
}

@InCollection{Pitman96,
  author =	 {J. Pitman},
  title =	 "Some developments of the {B}lackwell-{M}acQueen urn
                  scheme",
  booktitle =	 {Statistics, {P}robability and {G}ame {T}heory;
                  {P}apers in honor of {D}avid {B}lackwell},
  editor =	 {T. S. Ferguson and L. S. Shapley and J. B. MacQueen},
  series =	 {Lecture Notes-Monograph Series},
  volume =	 30,
  pages =	 {245-267},
  publisher =	 {Institute of {M}athematical {S}tatistics},
  year =	 1996
}

@article{Pitman97,
  author =	 "Pitman, J.",
  title =	 "Some Probabilistic Aspects of Set Partitions",
  journal =	 "The American Mathematical Monthly",
  year =	 1997,
  month =	 "March",
  volume =	 104,
  number =	 3,
  pages =	 "201-209",
}

@InCollection{Pitt01,
  author =	 {M. K. Pitt and N. Shephard},
  title =	 {Auxiliary Variable Based Particle Filters},
  booktitle =	 {Sequential {M}onte {C}arlo Methods in Practice},
  publisher =	 {Springer-Verlag},
  year =	 2001,
  editor =	 {Arnaud Doucet and Nando de Freitas and Neil Gordon},
  address =	 {New York}
}

@TechReport{Pitt97,
  author =	 {M. K Pitt and N. Shephard},
  title =	 {Filtering via Simulation: auxiliary particle
                  filters},
  institution =	 {Department of Mathematics, Imperial College, London},
  month =	 "October",
  year =	 1997,
}

@ARTICLE{Pizarro09joe,
  title =	 {Large Area 3-D Reconstructions From Underwater
                  Optical Surveys},
  author =	 {Pizarro, O. and Eustice, R.M. and Singh, H.},
  journal =	 {Oceanic Engineering, IEEE Journal of},
  year =	 2009,
  month =	 {April },
  volume =	 34,
  number =	 2,
  pages =	 {150-169},
  abstract =	 {Robotic underwater vehicles are regularly performing
                  vast optical surveys of the ocean floor. Scientists
                  value these surveys since optical images offer high
                  levels of detail and are easily interpreted by
                  humans. Unfortunately, the coverage of a single
                  image is limited by absorption and backscatter while
                  what is generally desired is an overall view of the
                  survey area. Recent works on underwater mosaics
                  assume planar scenes and are applicable only to
                  situations without much relief. We present a
                  complete and validated system for processing optical
                  images acquired from an underwater robotic vehicle
                  to form a 3D reconstruction of the ocean floor. Our
                  approach is designed for the most general conditions
                  of wide-baseline imagery (low overlap and presence
                  of significant 3D structure) and scales to hundreds
                  or thousands of images. We only assume a calibrated
                  camera system and a vehicle with uncertain and
                  possibly drifting pose information (e.g., a compass,
                  depth sensor, and a Doppler velocity log). Our
                  approach is based on a combination of techniques
                  from computer vision, photogrammetry, and
                  robotics. We use a local to global approach to
                  structure from motion, aided by the navigation
                  sensors on the vehicle to generate 3D
                  sub-maps. These sub-maps are then placed in a common
                  reference frame that is refined by matching
                  overlapping sub-maps. The final stage of processing
                  is a bundle adjustment that provides the 3D
                  structure, camera poses, and uncertainty estimates
                  in a consistent reference frame. We present results
                  with ground truth for structure as well as results
                  from an oceanographic survey over a coral reef.},
  c-dellaert =	 {At woods hole, affine invariant regions
                  (Tuytelaars00bmvc), Zernike moments descriptor, 2 or
                  3-view submaps then bundle-adjustment,
                  Delaunay-based trinagulation for dense height-map,
                  ground-truth obtained via laser.},
}

@article{Plantinga90,
  author =	 {Harry Plantinga and Charles R. Dyer},
  title =	 {Visibility, occlusion, and the aspect graph},
  journal =	 {Int. J. Comput. Vision},
  volume =	 5,
  number =	 2,
  year =	 1990,
  issn =	 {0920-5691},
  pages =	 {137--160},
  doi =		 {http://dx.doi.org/10.1007/BF00054919},
  publisher =	 {Kluwer Academic Publishers},
  address =	 {Hingham, MA, USA},
}

@article{Plarre04,
  author =	 {K. Plarre and P. R. Kumar},
  title =	 "Extended Message Passing Algorithm for Inference in
                  Loopy Gaussian Graphical Models",
  journal =	 {Ad Hoc Networks},
  volume =	 2,
  pages =	 {153--169},
  year =	 2004
}

@InProceedings{Pless03cvpr,
  author =	 {R. Pless},
  title =	 {Using Many Cameras as One},
  booktitle =	 CVPR,
  volume =	 2,
  pages =	 {587-593},
  year =	 2003
}

@inproceedings{Poelman94,
  AUTHOR =	 "Poelman, C.J. and Kanade, T.",
  TITLE =	 "A Paraperspective Factorization for Shape and Motion
                  Recovery",
  BOOKTITLE =	 ECCV,
  YEAR =	 1994,
  PAGES =	 "B:97-108"
}

@Article{Poelman97,
  author =	 "C. Poelman and T. Kanade",
  title =	 "A paraperspective factorization method for shape and
                  motion recovery",
  journal =	 PAMI,
  year =	 1997,
  volume =	 19,
  number =	 3,
  pages =	 "206-218",
  month =	 "March",
}

@article{Poggio90nature,
  journal =	 {Nature},
  volume =	 343,
  pages =	 {263--266},
  month =	 {January},
  year =	 1990,
  title =	 {A network that learns to recognize three-dimensional
                  objects},
  author =	 {T. Poggio and S. Edelman},
  abstract =	 {The visual recognition of three-dimensional (3-D)
                  objects on the basis of their shape poses at least
                  two difficult problems. First, there is the problem
                  of variable illumination, which can be addressed by
                  working with relatively stable features such as
                  intensity edges rather than the raw intensity
                  images. Second, there is the problem of the
                  initially unknown pose of the object relative to the
                  viewer. In one approach to this problem, a
                  hypothesis is first made about the viewpoint, then
                  the appearance of a model object from such a
                  viewpoint is computed and compared with the actual
                  image. Such recognition schemes generally employ 3-D
                  models of objects, but the automatic learning of 3-D
                  models is itself a difficult problem. To address
                  this problem in computational vision, we have
                  developed a scheme, based on the theory of
                  approximation of multivariate functions, that learns
                  from a small set of perspective views a function
                  mapping any viewpoint to a standard view. A network
                  equivalent to this scheme will thus 'recognize' the
                  object on which it was trained from any viewpoint.},
  c-dellaert =	 {Most cited paper by Edelman on view-based
                  recognition, network of broadly tuned views.}
}

@article{Pollefeys99,
  AUTHOR =	 "Pollefeys, M. and Koch, R. and L. {Van Gool}",
  TITLE =	 "Self-Calibration and Metric Reconstruction Inspite
                  of Varying and Unknown Intrinsic Camera Parameters",
  JOURNAL =	 IJCV,
  VOLUME =	 32,
  YEAR =	 1999,
  NUMBER =	 1,
  MONTH =	 "August",
  PAGES =	 "7-25"
}

@Book{Pols2002,
  author =	 "Robert Pols",
  title =	 "Family Photographs, 1860-1945: A Guide to
                  Researching, Dating and Contextuallising Family
                  Photographs",
  publisher =	 "Public Record Office Publications",
  year =	 2002,
}

@Book{Pomerleau94,
  author =	 "D. Pomerleau",
  title =	 "Neural Network Perception for Mobile Robot Guidance",
  publisher =	 "Kluwer Academic Publishing",
  address =	 "Boston, MA",
  year =	 1994
}

@Article{Pomerleau96,
  author =	 "Pomerleau, D. and T. Jochem",
  title =	 "Rapidly Adapting Machine Vision for Automated
                  Vehicle Steering",
  journal =	 "IEEE Expert",
  year =	 1996,
  volume =	 11,
  number =	 2,
  month =	 "April",
}

@inproceedings{Pons05cvpr,
  author =	 "J.P.Pons and R.Keriven and O.Faugeras",
  title =	 "Modelling Dynamic Scenes by Registering Multi-View
                  Image Sequences",
  booktitle =	 CVPR,
  year =	 2005,
  pages =	 "822--827"
}

@Book{Poole03,
  author =	 "David Poole",
  title =	 "Linear Algebra : A Modern Introduction",
  year =	 2003,
  isbn =	 "0-534-34174-8",
  publisher =	 "BROOKS/COLE",
}

@article{Popat97ip,
  author =	 "K. Popat and R. W. Picard",
  title =	 "Cluster based probability model and its application
                  to image and texture processing.",
  journal =	 IP,
  volume =	 6,
  number =	 2,
  pages =	 "268--284",
  year =	 1997,
  url =		 "citeseer.nj.nec.com/popat97clusterbased.html"
}

@Book{Popoli99,
  author =	 {Robert Popoli and Samuel S. Blackman},
  title =	 {Design and Analysis of Modern Tracking Systems},
  publisher =	 {Artech House Radar Library},
  year =	 1999,
  month =	 {August},
}

@InProceedings{Porikli05iccv,
  author =	 {F. Porikli and J. Thornton},
  title =	 {Shadow Flow: A Recursive Method to Learn Moving Cast
                  Shadows},
  booktitle =	 ICCV,
  year =	 2005,
  month =	 {October},
  abstract =	 {We present a novel algorithm to detect and remove
                  cast shadows in a video sequence by taking advantage
                  of the statistical prevalence of the shadowed
                  regions over the object regions. We model shadows
                  using multivariate Gaussians. We apply a weak
                  classifier as a prefilter. We project shadow models
                  into a quantized color space to update a shadow flow
                  function. We use shadow flow, background models, and
                  current frame to determine the shadow and object
                  regions. This method has several advantages: It does
                  not require a color space transformation. We pose
                  the problem in the RGB color space, and we can carry
                  out the same analysis in other Cartesian spaces as
                  well. It is data-driven and adapts to the changing
                  shadow conditions. In other words, accuracy of our
                  method is not limited by the preset
                  values. Furthermore, it does not assume any 3D
                  models for the target objects or tracking of the
                  cast shadows between frames. Our results show that
                  the detection performance is superior than the
                  benchmark method. },
  c-houdan =	 {Use mixture of Gaussian to model shadow as well as
                  background. Nice results for both heavy and light
                  shadow},
}

@inproceedings{Posner06,
  author =	 {I. Posner and D. Schroeter and P. Newman},
  title =	 {Using Scene Similarity for Place Labeling},
  booktitle =	 {International {S}ymposium of {E}xperimental
                  {R}obotics},
  year =	 {2006},
}

@inproceedings{Pothen92siam,
  author =	 {A. Pothen and C. Sun},
  title =	 {Distributed Multifrontal Factorization Using Clique
                  Trees},
  booktitle =	 {Proc. of the Fifth SIAM Conf. on Parallel Processing
                  for Scientific Computing},
  year =	 1992,
  isbn =	 {0-89871-303-X},
  pages =	 {34--40},
  publisher =	 {Society for Industrial and Applied Mathematics},
  r-Blair93chapter ={However, chordal graphs and clique trees have
                  found a niche in more recent work in this area,
                  primarily due to various research questions
                  associated with advanced computer architectures. For
                  instance, the multifrontal method \cite{Duff83toms},
                  which was developed to obtain good performance on
                  vector supercomputers, can be expressed very
                  succinctly in terms of a clique tree representation
                  of the underlying chordal graph
                  \cite{Peyton86thesis, Pothen92siam}.},
}

@Article{Pothen92siam2,
  author =	 {A. Pothen and F.L. Alvarado},
  title =	 {A fast reordering algorithm for parallel sparse
                  triangular solution},
  journal =	 {SIAM J. Sci. Stat. Comput},
  year =	 1992,
  volume =	 13,
  pages =	 {645-653},
}

@techreport{Pothen92tr,
  author =	 "{Pothen, A.} and {Simon, H.} and {Wang, L.}",
  title =	 "Spectral Nested Dissection",
  number =	 "CS-92-01",
  year =	 1992,
  institution =	 "Penn. State"
}

@InProceedings{Pothen93siam,
  author =	 {A. Pothen and C. Sun},
  title =	 {A mapping algorithm for parallel sparse {Cholesky}
                  factorization},
  journal =	 {SIAM J. Sci. Comput.},
  volume =	 14,
  number =	 5,
  year =	 1993,
  issn =	 {1064-8275},
  pages =	 {1253--1257},
  publisher =	 {Society for Industrial and Applied Mathematics},
}

@InProceedings{Power02ivcnz,
  author =	 {P.W. Power and J.A. Schoonees},
  title =	 {Understanding Background Mixture Models for
                  Foreground Segmentation},
  booktitle =	 {Image and Vision Computing New Zealand},
  year =	 2002,
  month =	 {November},
  abstract =	 {The seminal video surveillance papers on moving
                  object segmenta- tion through adaptive Gaussian
                  mixture models of the background image do not
                  provide adequate information for easy replication of
                  the work. They also do not explicitly base their
                  algorithms on the underlying statistical theory and
                  sometimes even suffer from errors of
                  derivation. This tutorial paper describes a
                  practical implementation of the Stauffer-Grimson
                  algorithm and provides values for all model
                  parameters. It also shows what approximations to the
                  theory were made and how to improve the standard
                  algorithm by redefining those approximations. },
  c-houdan =	 {describe the algorithm in Stauffer99cvpr in detail
                  and give out parameters for implementation in
                  practice},
}

@InProceedings{Prati01cvpr,
  author =	 {A. Prati and R. Cucchiara and I. Mikic and
                  M.M. Trivedi},
  title =	 {Anakysis and Detection of Shadows in Video Streams:
                  A Comparative Evaluation},
  booktitle =	 CVPR,
  pages =	 {571-576},
  year =	 2001,
  abstract =	 { Robustness to changes in illumination conditions as
                  well as viewing perspectives is an important
                  requirement for many computer vision
                  applications. One of the key factors in enhancing
                  the robustness of dynamic scene analysis is that of
                  accurate and reliable means for shadow
                  detection. Shadow detection is critical for correct
                  object detection in image sequences. Many algorithms
                  have been proposed in the literature that deal with
                  shadows. However, a comparative evaluation of the
                  existing approaches is still lacking. In this paper,
                  the full range of problems underlying the shadow
                  detection are identified and discussed. We classify
                  the proposed solutions to this problem using a
                  taxonomy of four main classes, called deterministic
                  model and non-model based and statistical parametric
                  and non- parametric. Novel quantitative (detection
                  and discrimination accuracy) and qualitative metrics
                  (scene and object independence, flexibility to
                  shadow situations and robustness to noise) are
                  proposed to evaluate these classes of algorithms on
                  a benchmark suite of indoor and outdoor video
                  sequences. },
  c-houdan =	 {the exactly same content as Prati03pami},
}

@Article{Prati03pami,
  author =	 {A. Prati and I. Mikic and M.M. Trivedi and
                  R. Cucchiara},
  title =	 {Detecting Moving Shadows: Algorithms and Evaluation},
  journal =	 PAMI,
  year =	 {2003},
  volume =	 {25},
  number =	 {7},
  pages =	 {918-923},
  month =	 {July},
  abstract =	 {Moving shadows need careful consideration in the
                  development of robust dynamic scene analysis
                  systems. Moving shadow detection is critical for
                  accurate object detection in video streams since
                  shadow points are often misclassified as object
                  points, causing errors in segmentation and
                  tracking. Many algorithms have been proposed in the
                  literature that deal with shadows. However, a
                  comparative evaluation of the existing approaches is
                  still lacking. In this paper, we present a
                  comprehensive survey of moving shadow detection
                  approaches. We organize contributions reported in
                  the literature in four classes two of them are
                  statistical and two are deterministic. We also
                  present a comparative empirical evaluation of
                  representative algorithms selected from these four
                  classes. Novel quantitative (detection and
                  discrimination rate) and qualitative metrics (scene
                  and object independence, flexibility to shadow
                  situations, and robustness to noise) are proposed to
                  evaluate these classes of algorithms on a benchmark
                  suite of indoor and outdoor video sequences. These
                  video sequences and associated groundtruth data are
                  made available at http://cvrr.ucsd.edu/aton/shadow
                  to allow for others in the community to experiment
                  with new algorithms and metrics. },
  c-houdan =	 {A good reference that make full comparison among
                  existing shadow detection algorithms, pointing out
                  their performance under different criterions},
}

@article{Price86,
  author =	 "K. Price",
  title =	 "Hierarchical matching using relaxation",
  journal =	 "Computer Vision Graphics Image Proc.",
  volume =	 34,
  pages =	 "66-75",
  year =	 1986
}

@Article{Prim57bell,
  author =	 {R.C. Prim},
  title =	 {Shortest connection networks and some
                  generalizations},
  journal =	 {Bell System Technical Journal},
  year =	 1957,
  pages =	 {1389--1401},
  r-Blair93chapter ={Prim's algorithm \cite{Prim57bell} is an
                  efficient method for computing a maximum-weight
                  (minimum- weight) spanning tree of a weighted
                  graph.},
}

@inproceedings{Pritchett98b,
  AUTHOR =	 "Pritchett, P. and Zisserman, A.",
  TITLE =	 "Matching and Reconstruction from Widely Separated
                  Views",
  BOOKTITLE =	 "SMILE 98 European Workshop on {3D} Structure from
                  Multiple Images of Large-Scale Environments,
                  Freiburg, Germany",
  YEAR =	 1998,
}

@inproceedings{Pritchett98iccv,
  Author =	 {Pritchett, P. and Zisserman, A.},
  Year =	 1998,
  booktitle =	 ICCV,
  Pages =	 {754--760},
  Title =	 {Wide baseline stereo matching},
  Abstract =	 {The objective of this work is to enlarge the class
                  of camera motions for which epipolar geometry and
                  image correspondences can be computed
                  automatically. This facilitates matching between
                  quite disparate views-wide baseline stereo. Two
                  extensions are made to the current small baseline
                  algorithms: first, and most importantly, a viewpoint
                  invariant measure is developed for assessing the
                  affinity of corner neighbourhoods over image pairs;
                  second, algorithms are given for generating putative
                  corner matches between image pairs using local
                  homographies. Two novel infrastructure developments
                  are also described: the automatic generation of
                  local homographies, and the combination of possibly
                  conflicting sets of matches prior to RANSAC
                  estimation. The wide baseline matching algorithm is
                  demonstrated on a number of image pairs with varying
                  relative motion, and for different scene types. All
                  processing is automatic},
  r-Kosecka05cviu ={The detection and matching of rectangular regions
                  has been previously proposed by [this], in the
                  context of the same problem.}
}

@inproceedings{Proesmans96icpr,
  author =	 {M. Proesmans and L. Van Gool and A. Oosterlinck},
  title =	 {One-Shot Active 3D Shape Acquisition},
  booktitle =	 ICPR,
  year =	 1996,
  pages =	 336,
}

@Book{Prusinkiewicz90,
  author =	 {P. Prusinkiewicz and A. Lindenmayer},
  title =	 {The Algorithmic Beauty of Plants},
  publisher =	 {Springer-Verlag},
  year =	 1990,
}

@Article{Psiaki99automatica,
  author =	 {M.L. Psiaki},
  title =	 {Square-Root Information Filtering and Fixed-Interval
                  Smoothing with Singularities},
  journal =	 {Automatica},
  year =	 1999,
  volume =	 35,
  number =	 7,
  pages =	 {1323-1331},
  month =	 {July},
}

@PHDTHESIS{Puglisi93thesis,
  AUTHOR =	 {C.~Puglisi},
  TITLE =	 {{QR} factorization of large sparse overdetermined
                  and square matrices using the multifrontal method in
                  a multiprocessor environment},
  YEAR =	 1993,
  SCHOOL =	 {CERFACS, Toulouse, France},
  JURY =	 {M.~Arioli and \AA.~Bj{\"o}rck(rapporteur) and
                  M.J.~Dayd\'e and I.S.~Duff and J.~Noailles and
                  B.~Philippe(rapporteur)},
  NOTE =	 {TH/PA/93/33}
}

@Article{Pulford96,
  author =	 {G. W. Pulford and R. J. Evans},
  title =	 {Probabilistic Data Association for Systems With
                  Multiple Simultaneous Measurements},
  journal =	 {Automatica},
  year =	 1996,
  volume =	 32,
  number =	 9,
  pages =	 {1311-1316},
  month =	 {September},
}

@InProceedings{Pulford96b,
  author =	 {G. W. Pulford and B. F. La Scala},
  title =	 {Manoeuvring Target Tracking using the
                  Expectation-Maximisation Algorithm},
  booktitle =	 {Proc. 4th Int Conf. on Control, Automation, Robotics
                  and Vision, Singapore},
  pages =	 {2340-2344},
  year =	 1996,
}

@InProceedings{Pulford96cdc,
  author =	 {G. W. Pulford and A. Logothetis},
  title =	 {An Expectation-Maximisation Tracker for Multiple
                  Observations of a Single Target in Clutter},
  booktitle =	 CDC,
  address =	 {Kobe,Japan},
  month =	 {Dec.},
  pages =	 {4997-5003},
  year =	 1996,
}

@Unpublished{Pulford97b,
  author =	 {G. W. Pulford and B. F. La Scala},
  title =	 {MAP Estimation of Target Manoeuvre Sequence with the
                  Expectation-Maximisation Algorithm},
  note =	 {Submitted to IEEE Trans. Aerospace E. S., July 1997},
  year =	 1997,
}

@Article{Pulford98,
  author =	 {Pulford, G.W. and Evans, R.J.},
  title =	 {A multipath data association tracker for
                  over-the-horizon radar},
  journal =	 AES,
  year =	 1998,
  volume =	 34,
  number =	 4,
  pages =	 {1165-1183},
  month =	 {October},
}

@InProceedings{Pulli99_3dim,
  author =	 {Kari Pulli},
  title =	 {Multiview Registriation for Large Data Sets},
  booktitle =	 _3DIM,
  year =	 1999,
}

@article{Punskaya02,
  author =	 "E. Punskaya and C. Andrieu and A. Doucet and
                  W.J. Fitzgerald",
  title =	 "Bayesian Curve Fitting Using {MCMC} With
                  Applications to Signal Segmentation",
  journal =	 SP,
  pages =	 "747-758",
  volume =	 50,
  issue =	 3,
  year =	 2002,
  month =	 "March"
}

@InProceedings{Pupilli05bmvc,
  author =	 {M. Pupilli and A. Calway},
  title =	 {Real-time Camera Tracking using a Particle Filter},
  booktitle =	 BMVC,
  month =	 {Sep},
  year =	 2005,
  r-Eade06cvpr = {Pupilli and Calway [this] use a particle cloud to
                  represent camera pose hypotheses, while landmarks
                  are represented communally. The focus of the work is
                  on robust camera localization, so results with many
                  landmarks are not shown. Using 500 pose particles,
                  the system operates at real time when observing four
                  known landmarks, but drops to below frame rate when
                  observing eight landmarks.},
  r-Smith06bmvc ={...Pupilli and Calway [this] have demonstrated
                  real-time camera tracking using a particle filter,
                  which provides a good robustness, but theirs is
                  predominantly a tracking system; its mapping ability
                  is currently rudimentary, which restricts its range
                  of applications.},
}

@inproceedings{Quan97cvpr,
  AUTHOR =	 "Quan, L.",
  TITLE =	 "Uncalibrated {1D} Camera and {3D} Affine
                  Reconstruction of Lines",
  BOOKTITLE =	 "CVPR97",
  YEAR =	 1997,
  PAGES =	 "60-65"
}

@article{Quan97pami,
  AUTHOR =	 "Quan, L. and Kanade, T.",
  TITLE =	 "Affine Structure from Line Correspondences with
                  Uncalibrated Affine Cameras",
  JOURNAL =	 "PAMI",
  VOLUME =	 19,
  YEAR =	 1997,
  NUMBER =	 8,
  MONTH =	 "August",
  PAGES =	 "834-845"
}

@article{Quan99pami,
  fullauthor =	 "Long Quan and Zhong-Dan Lan",
  author =	 "L. Quan and Z.-D. Lan",
  title =	 "Linear N-Point Camera Pose Determination",
  journal =	 PAMI,
  volume =	 21,
  number =	 8,
  pages =	 "774-780",
  year =	 1999,
}

@inproceedings{Quattoni05nips,
  author =	 {Ariadna Quattoni and Michael Collins and Trevor
                  Darrel},
  title =	 {Conditional Random Fields for Object Recognition},
  booktitle =	 NIPS,
  year =	 2005,
}

@article{Quattoni07pami,
  Author =	 {Ariadna Quattoni, Sybor Wang, Louis-Philippe
                  Morency, Morency Collins, Trevor Darrell},
  Title =	 {Hidden-state Conditional Random Fields },
  Journal =	 {PAMI},
  Year =	 {2007},
  Booktitle =	 PAMI,
  Number =	 {10},
  Pages =	 {1848-1852},
  Volume =	 {29},
  Keywords =	 {crf, hidden, object recognition, gesture
                  recognition},
}

@article{Quintana03jrs,
  author =	 {Quintana,Fernando A. and Iglesias,Pilar L.},
  title =	 {Bayesian clustering and product partition models},
  journal =	 "{J Royal Statistical Soc B}",
  volume =	 65,
  number =	 2,
  pages =	 {557--557},
  year =	 2003
}

@InProceedings{Qureshi05pets,
  author =	 {F. Z. Qureshi and D. Terzopoulos},
  fullauthor =	 {Faisal Z. Qureshi and Demetri Terzopoulos},
  title =	 {Towards Intelligent Camera Networks: A Virtual
                  Vision Approach},
  booktitle =	 PETS,
  year =	 2005,
}

@InProceedings{Rabani01siam,
  author =	 {E. Rabani and S. Toledo},
  fullauthor =	 {Eran Rabani and Sivan Toledo},
  title =	 {Out-of-core {SVD} and {QR} decompositions},
  booktitle =	 {Proc. 10th SIAM Conf. on Parallel Processing for
                  Scientific Computing},
  year =	 2001,
  address =	 {Norfolk, Virginia},
  month =	 {March},
}

@INPROCEEDINGS{Rabiner86a,
  AUTHOR =	 {Rabiner, L.R. and Juang, B.H.},
  TITLE =	 {An Introduction to Hidden {Markov} Models},
  BOOKTITLE =	 {IEEE ASSP Magazine},
  YEAR =	 1986
}

@inproceedings{Rabinovich07iccv,
  author =	 {A. Rabinovich and A. Vedaldi and C. Galleguillos and
                  E. Wiewiora and S. Belongie},
  title =	 {Objects in Context},
  booktitle =	 ICCV,
  year =	 2007,
}

@misc{Radish,
  fullauthor =	 "Andrew Howard and Nicholas Roy",
  author =	 "A. Howard and N. Roy",
  year =	 2003,
  title =	 "The Robotics Data Set Repository ({R}adish)",
  url =		 "http://radish.sourceforge.net/",
}

@InProceedings{Rago95,
  author =	 {Rago, C. and Willett, P. and Streit, R.},
  title =	 {A comparison of the JPDAF and PMHT tracking
                  algorithms},
  booktitle =	 {International Conference on Acoustics, Speech, and
                  Signal Processing},
  pages =	 {3571 -3574},
  year =	 1995,
  volume =	 5,
}

@InProceedings{Rahimi04cvpr,
  author =	 {A. Rahimi and B. Dunagan and T. Darrell},
  fullauthor =	 {Ali Rahimi and Brian Dunagan and Trevor Darrell},
  title =	 {Simultaneous Calibration and Tracking with a Network
                  of Non-Overlapping Sensors},
  booktitle =	 CVPR,
  year =	 2004,
}

@InProceedings{Ramanan03,
  author =	 {D. Ramanan and D. A. Forsyth},
  title =	 {Finding and Tracking People From the Bottom Up},
  booktitle =	 CVPR,
  year =	 2003,
}

@InProceedings{Ramos05,
  author =	 {Ramos, F.T. and Upcroft, B. and Kumar, S. and
                  Durrant-Whyte, H.F.},
  title =	 {A Bayesian Approach for Place Recognition},
  booktitle =	 {{IJCAI} Workshop on Reasoning with Uncertainty in
                  Robotics (RUR-05)},
  year =	 2005,
}

@Article{Ran07ijcv,
  author =	 {Y. Ran, I. Weiss, Q. Zheng and L. S. Davis},
  fullauthor =	 {Yang Ran, Isaac Weiss, Qinfen Zheng and Larry
                  S. Davis},
  title =	 {{Pedestrian Detection via Periodic Motion Analysis}},
  journal =	 IJCV,
  year =	 2007,
  volume =	 71,
  number =	 2,
  pages =	 {143-160},
}

@Article{Ranade80,
  author =	 {S. Ranade and A. Rosenfeld},
  title =	 {Point pattern matching by relaxation},
  journal =	 PR,
  year =	 1980,
  volume =	 12,
  pages =	 {269-275},
}

@PhdThesis{Rander98thesis,
  author =	 {P. Rander},
  title =	 {A Multi-Camera Method for 3D Digitization of
                  Dynamic, Real-World Event},
  school =	 {Carnegie Mellon University},
  year =	 1998,
}

@inproceedings{Ranganathan04iros,
  author =	 {A. Ranganathan and F. Dellaert},
  title =	 {Inference in the Space of Topological Maps: An
                  {MCMC}-Based Approach},
  booktitle =	 IROS,
  year =	 2004,
  Abstract =	 {While probabilistic techniques have been considered
                  extensively in the context of metric maps, no
                  general purpose probabilistic methods exist for
                  topological maps. We present the concept of
                  Probabilistic Topological Maps (PTMs), a
                  sample-based representation that approximates the
                  posterior distribution over topologies given the
                  available sensor measurements. The PTM is obtained
                  through the use of MCMC-based Bayesian inference
                  over the space of all possible topologies. It is
                  shown that the space of all topologies is equivalent
                  to the space of set partitions of all available
                  measurements. While the space of possible topologies
                  is intractably large, our use of Markov chain Monte
                  Carlo sampling to infer the approximate histograms
                  overcomes the combinatorial nature of this space and
                  provides a general solution to the correspondence
                  problem in the context of topological mapping. We
                  present experimental results that validate our
                  technique and generate good maps even when using
                  only odometry as the sensor measurements.},
  c-dellaert =	 {Our own work}
}

@Unpublished{Ranganathan04nips-submission,
  author =	 {A. Ranganathan and F. Dellaert},
  title =	 {Dirichlet Process based {Bayesian} Partition Models
                  for Robot Topological Mapping},
  note =	 {Submitted to NIPS '04},
  month =	 {June},
  year =	 2004,
}

@TechReport{Ranganathan04tr,
  author =	 {A. Ranganathan and F. Dellaert},
  title =	 "{Dirichlet Process based Bayesian Partition Models
                  for Robot Topological Mapping}",
  number =	 {GIT-GVU-04-21},
  institution =	 {GVU, College of Computing},
  year =	 2004,
}

@inproceedings{Ranganathan05rss,
  author =	 {A. Ranganathan and F. Dellaert},
  title =	 {Data driven {MCMC} for Appearance-based Topological
                  mapping},
  booktitle =	 {Robotics: {S}cience and {S}ystems {I}},
  year =	 2005,
  pages =	 "209-216",
}

@inproceedings{Ranganathan06icra,
  title =	 {A {R}ao-{B}lackwellized Particle Filter for
                  Topological Mapping},
  author =	 {A. Ranganathan and F. Dellaert},
  booktitle =	 ICRA,
  pages =	 {810-817},
  year =	 2006,
}

@Article{Ranganathan06tro,
  author =	 {A. Ranganathan and E. Menegatti and F. Dellaert},
  title =	 {{Bayesian} Inference in the Space of Topological
                  Maps},
  journal =	 TRO,
  volume =	 22,
  number =	 1,
  pages =	 {92--107},
  year =	 2006,
  Abstract =	 {While probabilistic techniques have previously been
                  investigated extensively for performing inference
                  over the space of metric maps, no corresponding
                  general purpose methods exist for topological
                  maps. We present the concept of Probabilistic
                  Topological Maps (PTMs), a sample-based
                  representation that approximates the posterior
                  distribution over topologies given available sensor
                  measurements. We show that the space of topologies
                  is equivalent to the intractably large space of set
                  partitions on the set of available measurements. The
                  combinatorial nature of the problem is overcome by
                  computing an approximate, sample-based
                  representation of the posterior. The PTM is obtained
                  by performing Bayesian inference over the space of
                  all possible topologies and provides a systematic
                  solution to the problem of perceptual aliasing in
                  the domain of topological mapping. In this paper, we
                  describe a general framework for modeling
                  measurements, and the use of a Markov chain Monte
                  Carlo (MCMC) algorithm that uses specific instances
                  of these models for odometry and appearance
                  measurements to estimate the posterior
                  distribution. We present experimental results that
                  validate our technique and generate good maps when
                  using odometry and appearance, derived from
                  panoramic images, as sensor measurements.},
  c-dellaert =	 {Our own work}
}

@InProceedings{Ranganathan07ijcai,
  author =	 {A. Ranganathan and M. Kaess and F. Dellaert},
  fullauthor =	 {Ananth Ranganathan and Michael Kaess and Frank
                  Dellaert},
  title =	 {Loopy {SAM}},
  booktitle =	 IJCAI,
  address =	 {Hyderabad, India},
  pages =	 {2191-2196},
  year =	 2007,
  abstract =	 {Smoothing approaches to the Simultaneous
                  Localization and Mapping (SLAM) problem in robotics
                  are superior to the more common filtering approaches
                  in being exact, better equipped to deal with
                  non-linearities, and computing the entire robot
                  trajectory. However, while filtering algorithms that
                  perform map updates in constant time exist, no
                  analogous smoothing method is available. We aim to
                  rectify this situation by presenting a
                  smoothingbased solution to SLAM using Loopy Belief
                  Propagation (LBP) that can perform the trajectory
                  and map updates in constant time except when a loop
                  is closed in the environment. The SLAM problem is
                  represented as a Gaussian Markov Random Field (GMRF)
                  over which LBP is performed. We prove that LBP, in
                  this case, is equivalent to Gauss-Seidel relaxation
                  of a linear system. The inability to compute
                  marginal covariances efficiently in a smoothing
                  algorithm has previously been a stumbling block to
                  their widespread use. LBP enables the efficient
                  recovery of the marginal covariances, albeit
                  approximately, of landmarks and poses. While the
                  final covariances are overconfident, the ones
                  obtained from a spanning tree of the GMRF are
                  conservative, making them useful for data
                  association. Experiments in simulation and using
                  real data are presented.},
}

@InProceedings{Ranganathan07iros,
  author =	 {A. Ranganathan and M. Kaess and F. Dellaert},
  fullauthor =	 {Ananth Ranganathan and Michael Kaess and Frank
                  Dellaert},
  title =	 {Fast 3{D} Pose Estimation With Out-of-Sequence
                  Measurements},
  booktitle =	 IROS,
  address =	 {San Diego, CA},
  month =	 {Oct},
  year =	 {2007},
  note =	 {To appear},
  abstract =	 {We present an algorithm for pose estimation using
                  fixed-lag smoothing. We show that fixed-lag
                  smoothing enables inclusion of measurements from
                  multiple asynchronous measurement sources in an
                  optimal manner. Since robots usually have a
                  plurality of uncoordinated sensors, our algorithm
                  has an advantage over filtering-based estimation
                  algorithms, which cannot incorporate delayed
                  measurements optimally. We provide an implementation
                  of the general fixed-lag smoothing algorithm using
                  square root smoothing, a technique that has recently
                  become prominent. Square root smoothing uses fast
                  sparse matrix factorization and enables our
                  fixed-lag pose estimation algorithm to run at
                  upwards of 20 Hz. Our algorithm has been extensively
                  tested over hundreds of hours of operation on a
                  robot operating in outdoor environments. We present
                  results based on these tests that verify our claims
                  using wheel encoders, visual odometry, and GPS as
                  sensors.},
}

@Inproceedings{Ranganathan07rss,
  author =	 {A. Ranganathan and F. Dellaert},
  fullauthor =	 {Ananth Ranganathan and Frank Dellaert},
  title =	 "{Semantic Modeling of Places using Objects}",
  year =	 {2007},
  booktitle =	 RSS,
  address =	 {Atlanta; USA},
}

@TechReport{Ranganathan07tr,
  author =	 {A. Ranganathan and F. Dellaert},
  title =	 "{Probabilistic Topological Mapping for Mobile Robots
                  using Urn Models}",
  number =	 {GIT-GVU-07-03},
  institution =	 {GVU, College of Computing},
  year =	 2007,
}

@InProceedings{Ranganathan08eccv,
  author =	 {A. Ranganathan and M-H. Yang},
  fullauthor =	 {Ananth Ranganathan and Ming-Hsuan Yang},
  title =	 {Online Sparse Matrix {G}aussian Process Regression and
                  Vision Applications},
  pages =	 {468-482},
  booktitle =	 ECCV,
  year =	 2008,
}

@inproceedings{Rangarajan94,
  author =	 "A. Rangarajan and E. Mjolsness",
  title =	 "A Lagrangian relaxation network for graph matching",
  booktitle =	 "Proc. Int. Conf. Neural Networks",
  volume =	 7,
  publisher =	 "Inst. Electrical {\&} Electronics Engineers",
  pages =	 "4629--4634",
  year =	 1994,
}

@article{Rangarajan97,
  author =	 "A. Rangarajan and E. Mjolsness and S. Pappu and
                  L. Davachi",
  title =	 "A Robust Point Matching Algorithm for Autoradiograph
                  Alignment",
  journal =	 "Medical Image Analysis",
  volume =	 4,
  number =	 1,
  pages =	 "379-398",
  year =	 1997,
}

@InProceedings{Ransford08hotpower,
  author =	 {B. Ransford, S. S. Clark, M. Salajegheh, and K. Fu},
  title =	 {Getting things done on computational {RFID}s with
                  energy-aware checkpointing and voltage-aware
                  scheduling},
  OPTbooktitle = {USENIX Workshop on Power Aware Computing and Systems
                  (HotPower)},
  OPTyear =	 {2008},
  OPTmonth =	 {December},
  c-dellaert =	 {cited in MassiveSLAM paper}
}

@InProceedings{Rao01cvpr,
  author =	 {Rao, C. and Shah, M},
  title =	 {View-invariance in action recognition},
  booktitle =	 CVPR,
  year =	 2001,
  volume =	 2,
  pages =	 {316-322},
}

@article{Rao91cta,
  Author =	 {Rao, B. S. and Durrant-Whyte, H. F.},
  journal =	 {Control Theory and Applications, IEE Proceedings D},
  Number =	 5,
  Pages =	 {413--420},
  Title =	 {Fully decentralised algorithm for multisensor Kalman
                  filtering},
  Volume =	 138,
  Year =	 1991,
  Abstract =	 {An algorithm that achieves complete decentralisation
                  of the Kalman filter algorithm amongst the sensing
                  nodes of a multisensor system is preserved. This
                  algorithm does not require any form of central
                  processing facility or centralised communications
                  medium. Each sensing node implements its own local
                  Kalman filter to arrive at a partial decision which
                  it then broadcasts to every other node. Each node
                  then assimilates this received information to arrive
                  at its own local estimate of the system state. The
                  algorithm guarantees that each local estimate thus
                  obtained is identical to the estimate that would be
                  obtained if a conventional, completely centralised,
                  Kalman filter were used. Because there is no single
                  central processing node the algorithm is highly
                  resilient to loss of one or more sensing nodes. The
                  fully decentralised nature ensures that it is ideal
                  for implementation on a parallel processing array,
                  such as a transputer network. The algorithm has been
                  tested using a simulated multiperson pursuit-evasion
                  game to check the viability. The algorithm has also
                  been implemented on a transputer based array of
                  cameras to perform tracking of an object moving
                  around a room},
  c-dellaert =	 {Journal version of \citet{DurrantWhyte90icra},
                  related work more mature, math identical. New:
                  simulation results for },
}

@Article{Rao91ijrr,
  Author =	 {S.Y. Rao and H. Durrant-Whyte and A. Sheen},
  title =	 {A fully decentralized multi-sensor system for
                  tracking and surveillance},
  journal =	 IJRR,
  year =	 {1991},
  volume =	 {12},
  number =	 {1},
  c-DurrantWhyte01fusion ={Work on decentralised systems began in 1989
                  as part of the ESPRIT project SKIDS. In the SKIDS
                  project, a fully decentralised surveillance system
                  was implemented using four cameras and a Transputer
                  based architecture. The network was a
                  fully-connected point-to-point topology. The system
                  was capable of tracking multiple targets (humans and
                  robots) and addressed such issues as decentralised
                  data association and decentralised
                  identification. The SKIDS demonstrator, which
                  continued to be refined and operated for almost 10
                  years, laid the basis for all subsequent work on
                  decentralised data fusion.}
}

@inproceedings{Rao91iros,
  Author =	 {Rao, B. S. Y. and Manyika, J. M. and Durrant-Whyte,
                  H. F.},
  booktitle =	 IROS,
  Pages =	 {1095--1100},
  volume =	 2,
  Title =	 {Decentralized algorithms and architecture for
                  tracking and identification},
  Year =	 1991,
  Abstract =	 {We present two algorithms for tracking and
                  identification in decentralized multi-sensor
                  systems. Decentralized architectures have many
                  benefits in terms of modularity, speed and
                  robustness. The state estimation (tracking)
                  algorithm is a decentralized Kalman filter (DKF)
                  based on the extended Kalman filter. Identification
                  is achieved by the decentralized Bayesian
                  identification (DBI) algorithm, which identifies
                  targets being tracked. For each of the algorithms
                  The authors discuss optimality and the effect of
                  reducing connectivity. The structure of the
                  algorithms leads to the development of an
                  architecture for a modular sensing node based on
                  communication considerations. The authors present
                  example implementations of both algorithms on actual
                  transputer-based sensing nodes. They describe RCD
                  (region of constant depth) tracking and for this
                  develop a monopulse sonar arrangement with which
                  they implement real-time autonomous tracking by a
                  single sensor node. The second example
                  implementation describes identification of targets
                  being tracked by the DKF using the DBI on actual CCD
                  camera-based nodes},
  c-dellaert =	 {DBI is a second phase to do a classification of
                  targets, and has the same structure as the DKF, but
                  is for discrete variables. Not clear how well it is
                  understood by the authors that DKF is just an
                  instance of DBI (although, I did not fully check
                  that: I'm assuming they did it right).},
}

@Article{Raol02rrn,
  author =	 {J.R. Raol and G. Girija},
  title =	 {Sensor data fusion algorithms using square-root
                  information filtering},
  journal =	 {{IEE} Proceedings on Radar, Sonar and Navigation},
  year =	 {2002},
  volume =	 {149},
  number =	 {2},
  pages =	 {89-96},
}

@Article{Rasheed05tm,
  author =	 {Z. Rasheed and M. Shah},
  fullauthor =	 {Zeeshan Rasheed and Mubarak Shah},
  title =	 {{Detection and Representation of Scenes in Videos}},
  journal =	 "IEEE Transactions on Multimedia",
  volume =	 7,
  number =	 6,
  month =	 {December},
  year =	 2005,
  keywords =	 {shot transition detection, frame similarity, video
                  summary},
  c-sangmin =	 {use a hand-crafted function to compute the
                  similarity between frames represented by the
                  features, then build pairwise similarity matrix and
                  do spectral clustering (normalized cut) to build
                  clusters.},
}

@Article{Rasmussen01,
  author =	 {C. Rasmussen and G.D. Hager},
  title =	 {Probabilistic Data Association Methods for Tracking
                  Complex Visual Objects},
  journal =	 PAMI,
  year =	 2001,
  volume =	 23,
  number =	 6,
  pages =	 {560--576},
  month =	 {June},
}

@inproceedings{Rasmussen02,
  author =	 {Rasmussen, C. E.},
  title =	 {The Infinite Gaussian Mixture Model},
  year =	 2000,
  publisher =	 MIT,
  pages =	 {554-560},
  booktitle =	 {Advances in Neural Information Processing Systems
                  12},
  editor =	 {Sara A. Solla, Todd K. Leen and Klaus-Robert Muller},
  location =	 {NIPS*12}
}

@InProceedings{Rasmussen96,
  author =	 {C. Rasmussen and G.D. Hager},
  title =	 {Robot navigation using image sequences},
  crossref =	 {_AAAI96},
}


@InProceedings{Rasmussen98,
  author =	 "C. Rasmussen and G.D. Hager",
  title =	 "Joint probabilistic techniques for tracking objects
                  using multiple vision clues",
  pages =	 "191-196",
  booktitle =	 IROS,
  year =	 1998,
}

@article{Rauch63,
  author =	 {H. Rauch},
  title =	 {Solutions to the linear smoothing problem},
  journal =	 {IEEE Transactions on Automatic Control},
  year =	 1963,
  volume =	 8,
  number =	 4,
  pages =	 {371--372},
}

@InProceedings{Reeves95,
  author =	 {S. J. Reeves},
  title =	 {Selection of Observations in Magnetic Resonance
                  Spectroscopic Imaging},
  booktitle =	 ICIP,
  year =	 1995,
}

@InProceedings{Rehg91,
  author =	 "J.M. Rehg and A.P. Witkin",
  title =	 "Visual tracking with deformation models",
  pages =	 "844-850",
  booktitle =	 ICRA,
  year =	 1991,
}

@InProceedings{Rehg95,
  author =	 "James M. Rehg and Takeo Kanade",
  title =	 "Model-Based Tracking of Self-Occluding Articulated
                  Objects",
  pages =	 "612-617",
  booktitle =	 ICCV,
  year =	 1995,
}

@Article{Reid79itac,
  author =	 "D.B. Reid",
  title =	 "An algorithm for tracking multiple targets",
  journal =	 ITAC,
  year =	 1979,
  volume =	 "AC-24",
  number =	 6,
  pages =	 "84--90",
  month =	 "December",
}

@Article{Reinhard01,
  author =	 {E. Reinhard and M. Ashikhmin and B. Gooch and
                  P. Shirley},
  title =	 {Color transfer between images},
  journal =	 {IEEE Computer Graphics and Applications},
  year =	 2001,
  pages =	 {34-41},
  month =	 {September/October},
}

@inproceedings{Reinhold98improving,
  author =	 "B. Reinhold",
  title =	 "Improving the {R}egistration {P}recision by {V}isual
                  {H}orizon {S}ilhouette {M}atching",
  booktitle =	 "Proceedings of the First IEEE Workshop on Augmented
                  Reality",
  year =	 1998,
  month =	 "November 1",
  address =	 "San Francisco, CA",
  url =		 "http://citeseer.nj.nec.com/reinhold98improving.html",
  pdf =		 "pdf/reinhold98improving.pdf",
  ps =		 "ps/RBiwar98.ps"
}

@Article{Rekleitis01,
  author =	 {Ioannis M. Rekleitis and Gregory Dudek and Evangelos
                  Milios},
  title =	 {Multi-Robot Collaboration for Robust Exploration},
  journal =	 {Annals of Mathematics and Artificial Intelligence},
  year =	 2001,
  volume =	 31,
  number =	 {1-4},
  pages =	 {7-40},
  r-Burgard05tro ={focus on the problem of reducing the odometry error
                  during exploration. They separate the environment
                  into stripes that are explored successively by the
                  robot team. Whenever one robot moves, the other
                  robots are kept stationary and observe the moving
                  robot, a strategy similar to the presented by
                  Kurazume and Shigemi [Kurazume94icra]. Whereas this
                  approach can signicantly reduce the odometry error
                  during the exploration process, it is not designed
                  to distribute the robots over the
                  environment. Rather, the robots are forced to stay
                  close to each other in order to remain in the
                  visibility range.e},
}

@InProceedings{Rekleitis2003d,
  author =	 {B. Lisien and D. Morales and D. Silver and G. Kantor
                  and I. Rekleitis and H. Choset},
  title =	 {Hierarchical Simultaneous Localization and Mapping},
  booktitle =	 IROS,
  pages =	 {448--453},
  year =	 2003,
  c-ananth =	 {Finally, Lisien et al. [Rekleitis2003d] describe a
                  method that combines locally estimated feature-based
                  maps with a global topological map. Data association
                  for the local maps is performed using a simple
                  heuristic wherein each measurement is associated
                  with the existing landmark having the minimum
                  distance to the measured location.},
}

@article{Remolina04,
  author =	 {E. Remolina and B. Kuipers},
  title =	 {Towards a general theory of topological maps},
  journal =	 AI,
  volume =	 152,
  number =	 1,
  pages =	 {47-104},
  year =	 2004,
  c-ananth =	 {Another recent approach gives an algorithm to build
                  a tree of all possible topological maps that conform
                  to the measurements, but in a non-probabilistic
                  manner [Savelli04iros][Remolina04].},
}

@InProceedings{Ren03iccv,
  author =	 {Xiaofeng Ren and Jitendra Malik},
  title =	 { Learning Discriminative Models for Image
                  Segmentation},
  booktitle =	 {ICCV},
  year =	 2003,
  volume =	 1,
  pages =	 {10-17},
}

@Article{Ren05siggraph,
  author =	 {Ren, L. and Patrick, A. and Efros, A. and Hodgins,
                  J. and Rehg, J. M.},
  title =	 {A {D}ata-{D}riven {A}pproach to {Q}uantifying
                  {N}atural {H}uman {M}otion},
  journal =	 {ACM Trans. on Graphics, Special Issue: Proc. of 2005
                  SIGGRAPH Conf.},
  volume =	 24,
  number =	 3,
  pages =	 {1090-1097},
  month =	 {August},
  year =	 2005,
}

@InProceedings{Rencken93,
  author =	 {W.D. Rencken},
  title =	 {Concurrent localisation and map building using
                  ultrasonic sensors},
  booktitle =	 {IEEE Int. Workshop on Intelligent Robots and
                  Systems},
  year =	 1993,
  pages =	 {2192-2197},
}

@ARTICLE{Renninger04vision,
  author =	 {Laura Walker Renninger and Jitendra Malik},
  title =	 {When is scene recognition just texture recognition?},
  journal =	 {Vision Research},
  year =	 {2004},
  volume =	 {44},
  pages =	 {2301--2311}
}

@InProceedings{Reuter00,
  author =	 {J. Reuter},
  title =	 {Mobile robot localization using PDAB},
  booktitle =	 ICRA,
  year =	 2000,
}

@article{Richardson06ml,
  author =	 {M. Richardson and P. Domingos},
  fullauthor =	 {Matthew Richardson and Pedro Domingos},
  year =	 2006,
  title =	 {Markov logic networks},
  journal =	 ML,
  volume =	 62,
  number =	 {1-2},
  pages =	 {107-136},
  year =	 2006,
}

@article{Richardson97,
  author =	 {S. Richardson and P. J. Green},
  year =	 1997,
  title =	 {On {Bayesian} analysis of mixtures with an unknown
                  number of components (with discussion)},
  journal =	 {Journal of the Royal Statistical Society. Series B
                  (Methodological)},
  volume =	 59,
  pages =	 {731--792}
}

@inproceedings{Ridley02,
  Author =	 {Ridley, M. and Nettleton, E. and Sukkarieh, S. and
                  Durrant-Whyte, H.},
  booktitle =	 {Intl. Conf. Information Fusion},
  Pages =	 {616--623},
  volume =	 1,
  Title =	 {Tracking in decentralised air-ground sensing
                  networks},
  Year =	 2002,
  Abstract =	 {This paper describes the theoretical and practical
                  development of a decentralised air and ground
                  sensing network for target tracking and
                  identification. The theoretical methods employed for
                  studying decentralised data fusion problems are
                  based on the information-filter formulation of the
                  Kalman filter algorithm and on information-theoretic
                  methods derived from the Bayes theorem. The paper
                  particularly focuses on how these methods are
                  applied in very large heterogeneous sensor networks,
                  where there may be a significant amount of data
                  delay or corruption in communication. This paper
                  then describes the development of a practical system
                  aimed at demonstrating some of these principles. The
                  system consists of a number of unmanned air vehicles
                  (UAVs), with radar and vision payloads, able to
                  observe a number of ground targets. The UAV sensor
                  payloads are constructed in a modular fashion, with
                  the ability to communicate in a network with both
                  other air-borne and other ground sensors. The ground
                  sensor system comprises of multiple modular sensing
                  nodes which include vision scanned laser, steerable
                  radar, multiple fixed radar arrays, and combined
                  night vision (IR)-radar.},
}

@Article{Ripley77,
  author =	 {B.D. Ripley},
  title =	 {Modelling Spatial Patterns},
  journal =	 {Journal of the Royal Statistical Society. Series B
                  (Methodological)},
  year =	 {1977},
  volume =	 {39},
  number =	 {2},
  pages =	 {172-212},
}

@Article{Rish00jar,
  author =	 {Rish, I., and Dechter, R.},
  title =	 {Resolution versus Search: Two Strategies for {SAT}},
  journal =	 {Journal of Automated Reasoning},
  year =	 2000,
  volume =	 24,
  number =	 {1/2},
  pages =	 {225--275},
  month =	 {January},
  r-Mateescu07ijcai ={Variable Elimination and Conditioning (VEC) is
                  an algorithm that combines the virtues of both
                  inference and search. One of its remarkably
                  successful applications is the genetic linkage
                  analysis software Superlink \cite{Fishelson and
                  Geiger, 2002}. VEC works by interleaving elimination
                  and conditioning of variables. Typically, given an
                  ordering, it prefers the elimina- tion of a variable
                  whenever possible, and switches to conditioning
                  whenever space limitations require it, and continues
                  in the same manner until all variables have been
                  processed.},
}

@InProceedings{Rittscher99,
  author =	 "J. Rittscher and A. Blake",
  title =	 "Classification of human body motion",
  booktitle =	 ICCV,
  year =	 1999,
}

@Article{Roach80pami,
  author =	 {J.W. Roach and J.K. Aggarwal},
  title =	 {Determining the movement of objects from a sequence
                  of images},
  journal =	 PAMI,
  year =	 1980,
  volume =	 2,
  number =	 6,
  pages =	 {554-562},
}

@Book{Robert99,
  author =	 {C.P. Robert and G. Casella},
  title =	 {Monte {C}arlo Statistical Methods},
  publisher =	 {Springer},
  year =	 1999,
}

@InProceedings{Roberts09cvpr,
  author =	 {Richard Roberts and Christian Potthast and Frank Dellaert},
  title =	 {Learning General Optical Flow Subspaces for Egomotion Estimation and Detection of Motion Anomalies},
  booktitle =	 CVPR,
  year =	 2009,
}

@Article{Roberts09jfr,
  author =	 {Richard Roberts and Charles Pippin and Tucker Balch},
  title =	 {Learning Outdoor Mobile Robot Behaviors by Example},
  journal =	 {Journal of Field Robotics},
  volume =	 26,
  number =	 2,
  year =	 2009,
  pages =	 {176-195},
  added-by =	 {richard},
}

@InCollection{Roberts96,
  author =	 "G.O. Roberts",
  title =	 "Markov chain concepts related to sampling
                  algorithms",
  crossref =	 "Gilks96",
}

@InProceedings{Robertson02eccv,
  author =	 "D. P. Robertson and R. Cipolla",
  title =	 {Building Architectural Models from Many Views Using
                  Map Constraints},
  booktitle =	 ECCV,
  year =	 2002,
  volume =	 2,
  pages =	 "155-169",
}

@InProceedings{Robertson04bmvc,
  author =	 {D. Robertson and R. Cipolla},
  fullauthor =	 {Duncan Robertson and Roberto Cippola},
  title =	 {An Image-Based System for Urban Navigation},
  booktitle =	 {BMVC},
  year =	 2004,
  Abstract =	 {We describe the prototype of a system intended to
                  allow a user to navigate in an urban environment
                  using a mobile telephone equipped with a camera. The
                  system uses a database of views of building facades
                  to determine the pose of a query view provided by
                  the user. Our method is based on a novel
                  wide-baseline matching algorithm that can identify
                  corresponding building facades in two views despite
                  significant changes of viewpoint and lighting. We
                  show that our system is capable of localising query
                  views reliably in a large part of Cambridge city
                  centre.},
  Wang06_3dpvt = {In the context of similar applications, the problem
                  of location and building recognition has been
                  addressed by several authors in the past, mostly
                  considering outdoors scenes. In
                  \cite{Robertson04bmvc} the authors used vertical
                  vanishing direction for alignment of a building view
                  in the query image to the canonical view in the
                  database and proposed matching using point features
                  followed by the relative pose recovery between the
                  views. The alignment step relied on the presence of
                  dominant plane and hence was applicable to scenarios
                  with dominant building facades. The actual
                  triangulation using known GPS locations was not
                  carried out.},
}

@Article{Rockmore00fft,
  author =	 {D. Rockmore},
  title =	 {The {FFT} - an algorithm the whole family can use},
  pages =	 {60--64},
  crossref =	 {_CSE00Jan},
}

@InCollection{Rockmore97applications,
  year =	 1997,
  author =	 {D.N. Rockmore},
  fullauthor =	 {Daniel N. Rockmore},
  title =	 {Some Applications of Generalized {FFTs}},
  booktitle =	 {Groups and Computation II},
  pages =	 {329--369},
  editor =	 {L. Finkelstein and W. Kantor},
  volume =	 28,
  series =	 {DIMACS Series in Discrete Math and Computer Science},
}

@InProceedings{Rodriguez04icra,
  author =	 {D. Rodriguez-Losada and F. Matia and A. Jimenez},
  title =	 {Local Maps Fusion for Real Time Multirobot Indoor
                  Simultaneous Localization and Mapping},
  booktitle =	 ICRA,
  pages =	 {1308-1313},
  year =	 2004,
  volume =	 2,
  Abstract =	 {This paper presents an implementation of the Local
                  Maps Fusion concept for the Simultaneous
                  Localization and Mapping (SLAM) problem within the
                  Extended Kalman Filter (EKF) framework. Several
                  problems never addressed before, arise while
                  implementing the solution for indoor environments,
                  and are successfully solved to obtain maps of quite
                  large real indoor environments with more than one
                  robot in real time.}
}

@inproceedings{Rofer03icra,
  Author =	 {Rofer, T. and Jungel, M.},
  booktitle =	 ICRA,
  Pages =	 {856--861},
  Title =	 {Vision-based fast and reactive Monte-Carlo
                  localization},
  Ty =		 {CONF},
  Volume =	 1,
  Year =	 2003,
  Abstract =	 {This paper presents a fast approach for vision-based
                  self-localization in RoboCup. The vision system
                  extracts the features required for localization
                  without processing the whole image and is a fist
                  step towards independence of lighting conditions. In
                  the field of self-localization, some new ideas are
                  added to the well-known Monte Carlo localization
                  approach that increase both stability and
                  reactivity, while keeping the processing time low.},
}

@Book{Rogers98,
  author =	 "David F. Rogers",
  title =	 "Procedural Elements for Computer Graphics",
  publisher =	 "McGraw Hill",
  address =	 "Boston, MA",
  edition =	 "Second",
  year =	 1998
}

@InProceedings{Roman04ivis,
  author =	 {A.Roman and G.Garg and M.Levoy},
  title =	 {Interactive design of multi-perspective images for
                  visualizing urban landscapes},
  booktitle =	 IVIS,
  pages =	 {537-544},
  year =	 2004,
}

@InProceedings{Romdhani2001,
  author =	 {S. Romdhani and P. Torr and B. Schoelkopf and
                  A. Blake},
  year =	 2001,
  title =	 {Computationally efficient face detection},
  booktitle =	 ICCV,
  pages =	 {695-700}
}

@inproceedings{Rosario99agents,
  author =	 "Barbara Rosario and Nuria Oliver and Alex Pentland",
  title =	 "A synthetic agent system for {Bayesian} modeling
                  human interactions",
  booktitle =	 "Proceedings of the Third International Conference on
                  Autonomous Agents (Agents'99)",
  publisher =	 "ACM Press",
  address =	 "Seattle, WA, USA",
  editor =	 "Oren Etzioni and J{\"o}rg P. M{\"u}ller and Jeffrey
                  M. Bradshaw",
  pages =	 "342--343",
  year =	 1999,
  url =		 "citeseer.nj.nec.com/rosario99synthetic.html"
}

@TechReport{Rosch99,
  author =	 {Hartmut Rosch},
  title =	 {A Survey of Rendering and Tracking Systems for Mixed
                  Reality},
  institution =	 {Technical University of Ilmenau},
  year =	 1999,
  note =	 {Technical Paper from 22. Dec. 1999},
}

@Article{Rose70,
  author =	 {D.J. Rose},
  title =	 {Triangulated graphs and the elimination process},
  Journal =	 {J. Math. Anal. Appl.},
  year =	 1970,
  volume =	 32,
  pages =	 {597--609},
  abstract =	 {A triangulated graph is a graph in which for every
                  cycle of length l > 3, there is an edge joining two
                  nonconsecutive vertices. In this paper we study
                  triangulated graphs and show that they play an
                  important role in the elimination process. The
                  results have application in the study of the
                  numerical solution of sparse positive definite
                  systems of linear equations by Gaussian
                  elimination.},
  r-MathSciNet = {From the author's introduction: "The graph-theoretic
                  results in this paper are related to the study of
                  the following question. Given an $n\times n$
                  positive definite matrix $M$ that is sparse (many
                  zero entries), which of the matrices $PMP^T$ ($P$ an
                  $n\times n$ permutation matrix) should we use to
                  solve a system equivalent to $Mx=b$ by Gaussian
                  elimination? S. V. Parter \cite{Parter61siam}
                  discussed this question when $M$ was represented by
                  a tree, and he showed that an ordering $P$ could be
                  found which resulted in a `perfect' elimination
                  scheme. Our results show this is true more generally
                  when $M$ can be represented by a triangulated
                  graph. We present here only the theoretical aspects
                  of elimination and will present elsewhere the
                  applications of this analysis to the study of
                  efficient numerical solution of sparse positive
                  definite systems of equations."},
  r-Bartels06uai ={Vertex elimination is an algorithm that can be used
                  to triangulate graphs.}
}

@InCollection{Rose72chapter,
  author =	 {D.J. Rose},
  title =	 {A graph-theoretic study of the numerical solution of
                  sparse positive definite systems of linear
                  equations},
  booktitle =	 {Graph Theory and Computing},
  pages =	 {183-217},
  publisher =	 {Academic Press},
  year =	 {1972},
  editor =	 {R.C. Read},
  r-MathSciNet = {The effect of the order of elimination upon a sparse
                  positive definite linear system is discussed. The
                  elimination process is formulated as vertex
                  elimination of the undirected graph associated with
                  the coefficient matrix of the system. It is shown
                  that considerable insight into the elimination
                  process can be gained by studying the evolution of
                  the cycle structure and the vertex-separator
                  structure of a graph under elimination. It is shown
                  that monotone transitive graphs are triangulated
                  graphs and conversely. The monotone transitive
                  graphs can be characterized by a property of their
                  separators. Best and good orderings are discussed
                  and by counting the arithmetic operations required
                  for the decompositions, the criteria for
                  optimization are related to the computational
                  complexity of calculations in the elimination
                  process.},
  r-Blair93chapter ={It is well known that chordal graphs model the
                  sparsity structure of the Cholesky factor of a
                  sparse positive definite matrix
                  \cite{Rose72chapter}.},
  r-Heggernes06dm ={Although we know today that minimal triangulations
                  are closely related to minimal separators, sparse
                  matrix computations was the first field to study
                  different triangulations of a given graph
                  \cite{George81book, Parter61siam, Rose72chapter}.}
}

@inproceedings{Rose75stoc,
  author =	 {D.J. Rose and R.E. Tarjan},
  fullauthor =	 {Donald J. Rose and R. Endre Tarjan},
  title =	 {Algorithmic aspects of vertex elimination},
  booktitle =	 STOC,
  year =	 1975,
  pages =	 {245--254},
  location =	 {Albuquerque, New Mexico, United States},
  doi =		 {http://doi.acm.org/10.1145/800116.803775},
  publisher =	 {ACM Press},
  address =	 {New York, NY, USA},
  abstract =	 {We consider a graph-theoretic elimination process
                  which is related to performing Gaussian elimination
                  on sparse symmetric and unsymmetrlc systems of
                  linear equations. We discuss good algorithms for
                  finding elimination orderings, showing that a
                  generalization of breadth-first search, called
                  lexicographlc search, can be used to find perfect
                  orderlngs in O(n+e) time and minimal orderlngs in
                  O(ne) time, if the problem graph is undirected and
                  has n vertices and e edges. We also give efficient
                  (though slower) algorithms for generating such
                  orderings on directed graphs. We claim that the
                  minimum ordering problem for directed graphs is
                  NP-complete, and conjecture that it is also
                  NP-complete for undirected graphs. We include a
                  brief discussion of the relation of elimination to
                  transitive closure and discuss some unresolved, more
                  general, issues.},
  quotes =	 {The unordered graph G = (V,E) then corresponds to
                  the equivalence class of matrices PMP T , where P is
                  any permutation matrix. Solving the system (1) using
                  Gaussian elimination, in general, creates new
                  nonzero elements; the edges corresponding to these
                  new elements, say F(O ) , are called the "fill
                  in". In order to make the elimination process
                  efficient, we might, for example, like to minimize
                  the fill in.},
  c-dellaert =	 {Linear algebra thread, completely missed by CSP
                  people ?}
}

@Article{Rose76siam,
  author =	 {D.J. Rose and R.E. Tarjan and G.S. Lueker},
  title =	 {Algorithmic aspects of vertex elimination on graphs},
  journal =	 {SIAM J. Comput.},
  year =	 {1976},
  volume =	 {5},
  pages =	 {266--283},
  r-Blair93chapter ={introduced the first linear-time algorithm for
                  producing a PEO, known as the lexicographic breadth
                  first search algorithm},
  r-Heggernes06dm ={Since the problem of computing minimum
                  triangulations is NP-hard, the related polynomially
                  solvable problem of computing minimal triangulations
                  became interesting, and the first algorithms for it
                  appeared in 1976 \cite{Ohtsuki76siam,
                  Rose76siam}. The number of edges in a minimal
                  triangulation can be far from minimum.},
}

@inproceedings{Rosen68acmnc,
  author =	 {R. Rosen},
  title =	 {Matrix bandwidth minimization},
  booktitle =	 {Proceedings of the 1968 23rd ACM national
                  conference},
  year =	 1968,
  pages =	 {585--595},
  doi =		 {http://doi.acm.org/10.1145/800186.810622},
  publisher =	 {ACM Press},
  address =	 {New York, NY, USA},
  abstract =	 {In the analysis of a structural problem by the
                  finite element method, a large order stiffness
                  matrix is created which describes mathematically the
                  inter-connectivity of the system. The structure is
                  defined in three dimensional space by discrete
                  points called nodes. Each node is represented by its
                  coordinates in the space. The nodes are then
                  connected by the various finite elements that the
                  particular computer program may utilize. (i.e., bar
                  members, rectangular or triangular panels, three
                  dimensional tetrahedrons, etc.)},
  c-dellaert =	 {no references}
}

@InProceedings{Rosencrantz03uai,
  author =	 "M. Rosencrantz and G. Gordon and S. Thrun",
  title =	 "Decentralized sensor fusion with distributed
                  particle filters",
  booktitle =	 UAI,
  year =	 2003,
  abstract =	 "This paper presents a scalable Bayesian technique
                  for decentralized state estimation from multiple
                  platforms in dynamic environments. As has long been
                  recognized, centralized architectures impose severe
                  scaling limitations for distributed systems due to
                  the enormous communication overheads. We propose a
                  strictly decentralized approach in which only nearby
                  platforms exchange information. They do so through
                  an interactive communication protocol aimed at
                  maximizing information flow. Our approach is
                  evaluated in the context of a distributed
                  surveillance scenario that arises in a robotic
                  system for playing the game of laser tag. Our
                  results, both from simulation and using physical
                  robots, illustrate an unprecedented scaling
                  capability to large teams of vehicles.",
  quotes =	 {This paper extends previous research in two critical
                  directions: our decentralized filter can cope with
                  dynamic environments and it can handle non-Gaussian
                  posteriors.},
  c-Upcroft06iser ="Rosencrantz et al. demonstrated non-Gaussian
                  distributed state estimation in the context of
                  robotic laser tag. Correlated estimation errors due
                  to common information communicated between nodes in
                  the past (also known as data incest) [Bar-Shalom]
                  were not considered. Accounting for data incest in
                  decentralised architectures is the key problem in
                  ensuring mathematically consistent and convergent
                  solutions"
}

@article{Rosenfeld66,
  author =	 "A. Rosenfeld and J. L. Pfalz",
  title =	 "Sequential operations in digital picture processing",
  journal =	 "Journal of the Association for Computing Machinery",
  volume =	 "13",
  pages =	 "471--494",
  year =	 "1966"
}

@inproceedings{Rosenthal77stoc,
  author =	 {A. Rosenthal},
  fullauthor =	 {Arnie Rosenthal},
  title =	 {Nonserial dynamic programming is optimal},
  booktitle =	 STOC,
  year =	 1977,
  pages =	 {98--105},
  location =	 {Boulder, Colorado, United States},
  doi =		 {http://doi.acm.org/10.1145/800105.803399},
  publisher =	 {ACM Press},
  address =	 {New York, NY, USA},
  abstract =	 {We show that nonserial dynamic programming is
                  optimal among one class of algorithms for an
                  important class of discrete optimization
                  problems. We consider discrete, multivariate,
                  optimization problems in which the objective
                  function is given as a sum of terms. Each term is a
                  function of only a subset of the variables. We first
                  consider a class of optimization algorithms which
                  eliminate suboptimal solutions by comparing the
                  objective function on "comparable" partial
                  solutions. A large, natural subclass of comparison
                  algorithms in which the subproblems considered are
                  either nested or nonadjacent (i.e., noninteracting)
                  is then defined. It is shown that a
                  variable-elimination procedure, nonserial dynamic
                  programming, is optimal in an extremely strong sense
                  among all algorithms in the subclass. The results'
                  strong implications for choosing deterministic,
                  adaptive, and nondeterministic algorithms for the
                  optimization problem, for defining a complexity
                  measure for a pattern of interactions, and for
                  describing general classes of decomposition
                  procedures are discussed. Several possible
                  extensions and unsolved problems are mentioned.},
  c-dellaert =	 {refers to Bertele72book, defines an "interaction
                  graph" == MRF, shows NSDP is an instance of
                  "non-overlapping" comparison algorithms and proves
                  it is optimal.}
}

@Article{Rosenthal95,
  author =	 {J. S. Rosenthal},
  title =	 {Convergence Rates for Markov Chains},
  journal =	 {SIAM Review},
  year =	 {1995},
  volume =	 {1995},
  number =	 {3},
  pages =	 {387-405},
  month =	 {September},
}

@InProceedings{Rosin95,
  author =	 {P. Rosin and T. Ellis},
  title =	 {Image Difference Threshold Strategies and Shadow
                  Detection},
  booktitle =	 BMVC,
  pages =	 {347-356},
  year =	 1995,
}

@TechReport{Rossi83tr,
  author =	 {D.J. Rossi and A.S. Willsky},
  title =	 {Maximum likelihood estimation of object size and
                  orientation from projection data},
  institution =	 {Laboratory for Information and Decision Systems,
                  Massachusetts Institute of Technology},
  year =	 1983,
  number =	 {LIDS-P; 1348},
}

@InProceedings{Rosten05iccv,
    title       =    "Fusing points and lines for high performance tracking.",
    author      =    "E. Rosten and T. Drummond",
    year        =    "2005",
    month       =    "October",
    pages       =    "1508--1511",
    volume      =    "2",
    booktitle   =    ICCV,
}

@InProceedings{Rosten06eccv,
    title       =    "Machine learning for high-speed corner detection",
    author      =    "E. Rosten and T. Drummond",
    year        =    "2006",
    month       =    "May",
    booktitle   =    ECCV,
}

@InProceedings{Rosti02icassp,
	Author = {A-V.I. Rosti and M.J.F. Gales},
	Title = {Factor analyzed hidden Markov models},
	Year = {2002},
	Booktitle = ICASSP,
	Keywords = {dimension reduction, factor analysis},
}

@InProceedings{Rosti04,
  author =	 {A-V.I. Rosti and M.J.F. Gales},
  title =	 {Rao-Blackwellised {G}ibbs sampling for switching
                  linear dynamical systems},
  booktitle =	 ICASSP,
  year =	 2004,
  volume =	 1,
  pages =	 {809-812},
}

@InProceedings{Roth92,
  author =	 {Y. Roth and A. Wu and R. Arpaci and T. Weymouth and
                  R. Jain},
  title =	 {Model-driven pose correction},
  booktitle =	 ICRA,
  year =	 1992,
  pages =	 {2625-2630},
}

@InProceedings{Rother03iccv,
  author =	 {C. Rother},
  title =	 {Linear Multi-View Reconstruction of Points, Lines,
                  Planes and Cameras, using a Reference Plane},
  booktitle =	 ICCV,
  pages =	 {1210-1217},
  year =	 2003,
}

@PhdThesis{Rother03thesis,
  author =	 {C. Rother},
  title =	 {Multi-View Reconstruction and Camera Recovery using
                  a Real or Virtual Reference Plane},
  school =	 {Royal Institute of Technology, Sweden (KTH)},
  year =	 2003,
}

@article{Rothganger06ijcv,
  author =	 {F. Rothganger and S. Lazebnik and C. Schmid and
                  J. Ponce},
  title =	 {Object modeling and recognition using local
                  affine-invariant image descriptors and multi-view
                  spatial contraints},
  journal =	 IJCV,
  year =	 2006,
  note =	 "Accepted for publication",
}

@article{Rothkopf07jov,
  author =	 {Rothkopf, C. A. and Ballard D. H. and Hayhoe, M. M.},
  year =	 2007,
  title =	 {Task and context determine where you look},
  journal =	 {J. Vision},
  volume =	 7,
  number =	 14,
  pages =	 {1-20},
  abstract =	 {The deployment of human gaze has been almost
                  exclusively studied independent of any specific
                  ongoing task and limited to two-dimensional picture
                  viewing. This contrasts with its use in everyday
                  life, which mostly consists of purposeful tasks
                  where gaze is crucially involved. To better
                  understand deployment of gaze under such
                  circumstances, we devised a series of experiments,
                  in which subjects navigated along a walkway in a
                  virtual environment and executed combinations of
                  approach and avoidance tasks. The position of the
                  body and the gaze were monitored during the
                  execution of the task combinations and dependence of
                  gaze on the ongoing tasks as well as the visual
                  features of the scene was analyzed. Gaze
                  distributions were compared to a random gaze
                  allocation strategy as well as a specific ?aliency
                  model.?Gaze distributions showed high similarity
                  across subjects. Moreover, the precise fixation
                  locations on the objects depended on the ongoing
                  task to the point that the specific tasks could be
                  predicted from the subject? fixation data. By
                  contrast, gaze allocation according to a random or a
                  saliency model did not predict the executed
                  fixations or the observed dependence of fixation
                  locations on the specific task.},
  c-dellaert =	 {Highly predictable task-related gaze, not bottom-up
                  saliency.}
}

@inproceedings{Rottman05aaai,
  author =	 {A. Rottmann and O. Martinez Mozos and C. Stachniss
                  and W. Burgard},
  title =	 {Semantic Place Classification of Indoor Environments
                  with Mobile Robots using Boosting},
  booktitle =	 AAAI,
  year =	 2005,
}

@InProceedings{Roumeliotis00,
  author =	 {S.I. Roumeliotis and G.A. Bekey},
  title =	 {Bayesian estimation and {K}alman filtering: a
                  unified framework for mobile robot localization},
  booktitle =	 ICRA,
  pages =	 {2985-2992},
  year =	 2000,
}

@inproceedings{Roumeliotis00cdc,
  Author =	 {Roumeliotis, S. I. and Bekey, G. A.},
  booktitle =	 CDC,
  Pages =	 {3477--3482},
  volume =	 4,
  Title =	 {Synergetic localization for groups of mobile robots},
  Volume =	 4,
  Year =	 2000,
  Abstract =	 {We present a new approach to the problem of
                  simultaneously localizing a group of mobile robots
                  capable of sensing each other. Each of the robots
                  collects sensor data regarding its own motion and
                  shares this information with the rest of the team
                  during the update cycles. A single estimator, in the
                  form of a Kalman filter, processes the available
                  positioning information from all the members of the
                  team and produces a pose estimate for each of
                  them. The equations for this centralized estimator
                  can be written in a decentralized form thus allowing
                  this single Kalman filter to be decomposed into a
                  number of smaller communicating filters, each of
                  them processing local data for most of the time. The
                  resulting decentralized estimation scheme
                  constitutes a unique mean for fusing measurements
                  collected from a variety of sensors with minimal
                  communication and processing requirements. The
                  distributed localization algorithm is applied to a
                  group of 3 robots and the improvement in
                  localization accuracy is presented. Finally, a
                  comparison to the equivalent distributed information
                  filter is provided},
}

@conference{Saria07uai,
	Author = {S. Saria, U. Nodelman, and D. Koller},
	Booktitle = {UAI},
	Keywords = {expectation propagation, continous markov model},
	Title = {Reasoning at the Right Time Granularity},
	Year = {2007},
}

@Article{Roumeliotis02tra,
  author =	 {S.I. Roumeliotis and G.A. Bekey},
  title =	 {Distributed Multi-Robot Localization},
  journal =	 TRA,
  year =	 {2002},
  month =	 {August},
  note =	 {To Appear},
}

@Book{Rousseeuw81,
  author =	 {P. J. Rousseeuw and A. M. Leroy},
  title =	 {Robust Regression and Outlier Detection},
  publisher =	 Wiley,
  year =	 1981,
}

@Article{Rousseeuw84,
  author =	 {P. J. Rousseeuw},
  title =	 {Least Median of squares regression},
  journal =	 {Journal of the American Statistical Association},
  year =	 1984,
  pages =	 {871--880},
  volume =	 79,
}

@InProceedings{Rousso98,
  author =	 {B. Rousso and S. Peleg and I. Finci and A. Rav-Acha},
  title =	 {Universal Mosaicing using Pipe Projection},
  booktitle =	 ICCV,
  pages =	 {945-952},
  year =	 1998,
}


@Article{Roweis00science,
  author =	 {S. Roweis and L.K. Saul},
  fullauthor =	 {Sam Roweis and Lawrence K. Saul},
  title =	 {Nonlinear dimensionality reduction by locally linear
                  embedding},
  journal =	 {Science},
  month =	 {December},
  year =	 2000,
  volume =	 290,
  number =	 5500,
  pages =	 {2223-2326},
}

@inproceedings{Roweis98nips,
  author =	 "S. Roweis",
  title =	 "{EM} Algorithms for {PCA} and {SPCA}",
  booktitle =	 "Advances in Neural Information Processing Systems",
  volume =	 10,
  publisher =	 "The {MIT} Press",
  editor =	 "Michael I. Jordan and Michael J. Kearns and Sara
                  A. Solla",
  year =	 1998,
}

@Article{Roweis99a,
  author =	 {S. Roweis and Z. Ghahramani},
  title =	 {A {U}nifying {R}eview of {L}inear {G}aussian
                  {M}odels},
  journal =	 {Neural Computation},
  year =	 1999,
  volume =	 11,
  number =	 2,
  pages =	 {305-345},
}

@Article{Roweis99nc,
  author =	 {S. Roweis, and Z. Ghahramani},
  title =	 {A Unifying Review of Linear Gaussian Models},
  journal =	 {Neural Computation},
  year =	 1999,
  volume =	 11,
  number =	 2,
  pages =	 {305-345}
}

@inproceedings{Rowley97,
  AUTHOR =	 "Rowley, H.A. and Rehg, J.M.",
  TITLE =	 "Analyzing Articulated Motion Using
                  Expectation-Maximization",
  BOOKTITLE =	 "CVPR97",
  YEAR =	 1997,
  PAGES =	 "935-941"
}

@article{Rowley98pami,
  author =	 "Henry A. Rowley and Shumeet Baluja and Takeo Kanade",
  title =	 "Neural Network-Based Face Detection",
  journal =	 PAMI,
  volume =	 20,
  number =	 1,
  pages =	 "23-38",
  year =	 1998,
  url =		 "citeseer.nj.nec.com/rowley96neural.html"
}

@InProceedings{Roy98,
  author =	 "S. Roy and I. Cox",
  title =	 "A Maximum-Flow Formulation of the N-camera Stereo
                  Correspondence Problem",
  booktitle =	 ICCV,
  pages =	 "492--499",
  year =	 1998
}

@inproceedings{Rozier00,
  author =	 {J. Rozier and K. Karahalios and J. Donath},
  title =	 {Hear\&{T}here: An {A}ugmented {R}eality {S}ystem of
                  {L}inked {A}udio},
  booktitle =	 {Proceedings of the International Conference on
                  Auditory Display ICAD 2000, April 2-5},
  year =	 2000,
  url =		 {http://smg.media.mit.edu/projects/HearAndThere/},
  pages =	 {63-67},
}

@InProceedings{Ruan98acc,
  author =	 {Ruan, Y. and Willett, P. and Streit, R.},
  title =	 {The PMHT for maneuvering targets},
  booktitle =	 ACC,
  pages =	 {2432 -2433},
  year =	 1998,
  volume =	 4,
}

@INPROCEEDINGS{Ruan99,
  author =	 {Y. Ruan and P. Willet and R. Streit},
  title =	 {Assignment versus PMHT in Multi-Sensor/Multi-Target
                  Tracking},
  booktitle =	 {Proceedings of the IEEE Conference on Target
                  Tracking: Algorithms and Applications},
  year =	 1999,
  address =	 {London}
}

@InProceedings{Rubin88,
  author =	 "Rubin, D.B.",
  title =	 "Using the {SIR} algorithm to simulate posterior
                  distributions",
  volume =	 3,
  pages =	 "395--402",
  booktitle =	 "Bayesian Statistics",
  year =	 1988,
  publisher =	 "Oxford University Press"
}

@INCOLLECTION{Rumelhart86b,
  AUTHOR =	 {Rumelhart, D. E. and Zipser, D.},
  TITLE =	 {Feature Discovery by Competitive Learning},
  BOOKTITLE =	 {Parallel Distributed Processing. Vol. I + II},
  PUBLISHER =	 MIT,
  YEAR =	 1986,
  EDITOR =	 {Rumelhart, D. E. and McClelland, J. L.}
}

@InProceedings{Rusinkiewicz01,
  author =	 {Rusinkiewicz, S. and Levoy, M.},
  title =	 {Efficient Variants of the ICP Algorithm},
  year =	 2001,
  booktitle =	 _3DIM,
}

@InProceedings{Russel93,
  author =	 "M. Russel",
  fullauthor =	 "Martin Russel",
  title =	 "A segmental {HMM} for speech pattern matching",
  booktitle =	 ICASSP,
  year =	 1993,
  pages =	 "499-502",
}

@Book{Russell02book,
  author =	 "S. Russel and P. Norvig",
  title =	 "Artificial Intelligence, A Modern Approach",
  publisher =	 "Prentice-Hall",
  year =	 2002,
}

@InProceedings{Rusu08iros,
  author =	 {Radu Bogdan Rusu and Zoltan Csaba Marton and Nico
                  Blodow and Mihai Emanuel Dolha and Michael Beetz},
  title =	 {Functional Object Mapping of Kitchen Environments},
  booktitle =	 IROS,
  year =	 {2008}
}

@InProceedings{Rusu08iros,
  author = {Radu Bogdan Rusu and Zoltan Csaba Marton and Nico Blodow and Mihai Emanuel Dolha and Michael Beetz},
  title = {Functional Object Mapping of Kitchen Environments},
  booktitle = IROS,
  year = {2008}
}

@InProceedings{Rybski03,
  title =	 {Using Visual Features to Build Topological Maps of
                  Indoor Environments},
  author =	 {P. E. Rybski and F. Zacharias and J-F. Lett and
                  O. Masoud and M. Gini and N. Papanikolopoulos},
  booktitle =	 ICRA,
  year =	 2003,
}

@Misc{S2Kit,
  author =	 {P. Kostelec and D. Rockmore},
  title =	 {S2Kit: A Lite Version of {SpharmonicKit}},
  howpublished = {Project web page},
  month =	 {February},
  year =	 2004,
  note =	 {http://www.cs.dartmouth.edu/~geelong/sphere},
}

@Book{Sadun01book,
  author =	 {Lorenzo Sadun},
  title =	 {Applied Linear Algebra: The Decoupling Principle},
  publisher =	 {Prentice Hall},
  year =	 2001,
}

@InProceedings{Saez05icra,
  author =	 {J.M. S\'{a}ez and F. Escolano},
  fullauthor =	 {Juan Manuel S\'{a}ez and Francisco Escolano},
  title =	 {Entropy Minimization {SLAM} using Stereo Vision},
  booktitle =	 ICRA,
  location =	 {Barcelona, Spain},
  month =	 {Apr},
  year =	 2005,
  abstract =	 {In this paper we present an information-based
                  approach to solve the SLAM problem using stereo
                  vision. This approach results for an improvement, in
                  terms of both efficiency and robustness, of our
                  early multi-view ICP randomized algorithm. Instead
                  of minimizing an ICP-based cost, we propose the
                  minimization of the entropy of the 2D distribution
                  induced by the projection of the 3D point cloud. In
                  addition we embed both the egomotion/action
                  estimation algorithm which precedes global
                  rectification and the new global rectification
                  algorithm in an autonomous exploration schema. We
                  assume plane-parallel environments and, for the sake
                  of efficiency, we also assume a flat floor and a
                  fixed stereo camera mounted on the robot. We show
                  successful experiments both under tele-operating the
                  robot and under autonomous navigation.},
  c-kaess =	 {Uses trinocular stereo, extension of Saez04icra,
                  entropy instead of ICP. Applies a "global
                  rectification algorithm" based on quasi-random
                  updates of multiple actions simultaneously. Shows
                  interesting results for rooms and corridors, also
                  for autonomous exploration.},
}

@InProceedings{Sainz96,
  author =	 {M. Sainz and A. Sanfeliu},
  title =	 {Learning bidimensional context dependent models
                  using a context-sensitive language},
  booktitle =	 {13th International Conference on Pattern
                  Recognition},
  address =	 {Viena, Austria},
  month =	 "August",
  year =	 1996,
}

@InProceedings{Saitoh99,
  AUTHOR =	 {F. Saitoh},
  TITLE =	 {Image contrast enhancement using genetic algorithm},
  BOOKTITLE =	 {IEEE International Conference on SMC},
  YEAR =	 1999,
  PAGES =	 {899-904 },
}

@InProceedings{Saitoh99,
  AUTHOR =	 {F. Saitoh},
  TITLE =	 {Image contrast enhancement using genetic algorithm},
  BOOKTITLE =	 {IEEE International Conference on SMC},
  YEAR =	 1999,
  PAGES =	 {899-904 },
}

@InProceedings{Sakakibara94,
  author =	 "Yasubumi Sakakibara and Michael Brown and Rebecca
                  Underwood and I. Saira Mian and David Haussler",
  title =	 "Stochastic Context-Free Grammars for Modeling {RNA}",
  booktitle =	 "Proceedings of the 27th Hawaii International
                  Conference on System Sciences",
  publisher =	 "IEEE Computer Society Press",
  address =	 "Honolulu",
  pages =	 "284--283",
  year =	 1994,
}

@article{Sala06tro,
  title =	 {Landmark Selection for Vision-Based Navigation},
  author =	 {Pablo Sala and Robert Sim and Ali Shokoufandeh and
                  Sven Dickinson},
  journal =	 TRO,
  volume =	 22,
  number =	 2,
  pages =	 {334--349},
  month =	 {April},
  year =	 2006,
  Abstract =	 {Recent work in the object recognition community has
                  yielded a class of interest-point-based features
                  that are stable under significant changes in scale,
                  viewpoint, and illumination, making them ideally
                  suited to landmark-based navigation. Although many
                  such features may be visible in a given view of the
                  robot? environment, only a few such features are
                  necessary to estimate the robot? position and
                  orientation. In this paper, we address the problem
                  of automatically selecting, from the entire set of
                  features visible in the robot? environment, the
                  minimum (optimal) set by which the robot can
                  navigate its environment. Specifically, we decompose
                  the world into a small number of maximally sized
                  regions, such that at each position in a given
                  region, the same small set of features is
                  visible. We introduce a novel graph theoretic
                  formulation of the problem, and prove that it is
                  NP-complete. Next, we introduce a number of
                  approximation algorithms and evaluate them on both
                  synthetic and real data. Finally, we use the
                  decompositions from the real image data to measure
                  the localization performance versus the undecomposed
                  map.},
  c-dellaert =	 {Focused on feature selection for optimal
                  localization}
}

@Article{Salvador04cviu,
  author =	 {E. Salvador and A. Cavallaro and T. Ebrahimia},
  title =	 {Cast shadow segmentation using invariant color
                  features},
  journal =	 {Computer Vision and Image Understanding},
  year =	 {2004},
  volume =	 {95},
  pages =	 {238-259},
  abstract =	 {Shadows are integral parts of natural scenes and one
                  of the elements contributing to nat- uralness of
                  synthetic scenes. In many image analysis and
                  interpretation applications, shadows interfere with
                  fundamental tasks such as object extraction and
                  description. For this reason, shadow segmentation is
                  an important step in image analysis. In this paper,
                  we propose a new cast shadow segmentation algorithm
                  for both still and moving images. The proposed
                  technique exploits spectral and geometrical
                  properties of shadows in a scene to perform this
                  task. The presence of a shadow is first hypothesized
                  with an initial and simple evidence based on the
                  fact that shadows darken the surface which they are
                  cast upon. The validity of detected regions as
                  shadows is further verified by making use of more
                  complex hypotheses on color invariance and geometric
                  properties of shadows. Finally, an information
                  integration stage confirms or rejects the initial
                  hypothesis for every detected region. Simulation
                  results show that the proposed algorithm is robust
                  and efficient in detecting shadows for a large class
                  of scenes.},
  c-houdan =	 {Color invariance here is similar to chromaticity,
                  includes normalized rgb, hue, saturation,
                  etc. Geometrical properties of shadows are
                  used. Nice results},
}

@Article{Sanchez04,
  author =	 "O. Sanchez and F. Dibos",
  title =	 "Displacement Following of Hidden Objects in a Video
                  Sequence",
  journal =	 IJCV,
  year =	 2004,
  volume =	 57,
  number =	 2,
  pages =	 "91-105",
}

@INPROCEEDINGS{Sarafraz09wacv,
  title =	 {Polarization-based stereovision in scattering media},
  author =	 {Sarafraz, A. and Negahdaripour, S. and Schechner,
                  Y.Y.},
  booktitle =	 {IEEE Workshop on Applications in Computer Vision},
  year =	 2009,
}

@InProceedings{Satoh03,
  author =	 {K.Satoh and S.Uchiyama and H.Yamamoto and H.Tamura},
  title =	 {Robust Vision-Based Registration Utilizing
                  Bird's-Eye View with User's View},
  booktitle =	 {ISMAR},
  year =	 2003,
}

@Article{Saul96,
  author =	 {L.K. Saul and T. Jaakkola and M.I. Jordan},
  title =	 {Mean Field Theory for Sigmoid Belief Networks},
  journal =	 JAIR,
  year =	 1996,
  volume =	 4,
  pages =	 {61-67},
  month =	 {March},
}

@InProceedings{Savarese07iccv,
  author = {S. Savarese and L. Fei-Fei},
  title = {3D generic object categorization, localization and pose estimation},
  booktitle = ICCV,
  year = {2007}
}

@InProceedings{Savelli04iros,
  author =	 {F. Savelli and B. Kuipers},
  year =	 2004,
  title =	 {Loop-closing and planarity in topological
                  map-building},
  booktitle =	 IROS,
  c-ananth =	 {Another recent approach gives an algorithm to build
                  a tree of all possible topological maps that conform
                  to the measurements, but in a non-probabilistic
                  manner [Savelli04iros][Remolina04].},
}

@PhdThesis{Savelli05thesis,
  author =	 {F. Savelli},
  title =	 "Topological Mapping of Ambiguous Space: Combining
                  Qualitative Biases and Metrical Information",
  school =	 {Department of {C}omputer and {S}ystems {S}cience,
                  {U}niversity of {R}ome "{L}a {S}apienza"},
  year =	 2005,
}

@Inproceedings  {Sawhney94a,
  key =		 "Sawhney",
  author =	 "Sawhney, H. S.",
  fullauthor =	 "Harpreet S. Sawhney",
  title =	 "{3D} Geometry from Planar Parallax",
  booktitle =	 CVPR,
  publisher =	 "IEEE Computer Society",
  address =	 "Seattle, Washington",
  month =	 "June",
  year =	 1994,
  pages =	 "929-934",
  keywords =	 "projective structure from motion, planar parallax",
  bibdate =	 "Wed Jul 13 13:07:47 EDT 1994"
}

@Inproceedings  {Sawhney94b,
  key =		 "Sawhney",
  author =	 "Sawhney, H. S.",
  fullauthor =	 "Harpreet S. Sawhney",
  title =	 "Simplifying motion and structure analysis using
                  planar parallax and image warping",
  booktitle =	 ICPR,
  publisher =	 "IEEE Computer Society Press",
  address =	 "Jerusalem, Israel",
  month =	 "October",
  year =	 1994,
  volume =	 "A",
  pages =	 "403-408",
  keywords =	 "structure from motion, image warping, planar
                  parallax",
  bibdate =	 "Fri Aug 12 11:35:17 EDT 1994"
}

@InProceedings{Sawhney95,
  author =	 {Sawhney, H. S. and S. Ayer and M. Gorkani},
  title =	 {Model-based {2D} \& {3D} Dominant Motion Estimation
                  for Mosaicking and Video Representation},
  booktitle =	 ICCV,
  pages =	 {583-590},
  year =	 1995,
}

@inproceedings  {Sawhney97,
  key =		 "Sawhney",
  author =	 "Sawhney, H. S. and Kumar, R.",
  fullauthor =	 "Harpreet S. Sawhney and Rakesh Kumar",
  title =	 "True Multi-Image Alignment and its Application to
                  Mosaicing and Lens Distortion Correction",
  booktitle =	 CVPR,
  address =	 "San Juan, Puerto Rico",
  month =	 "June",
  year =	 1997,
  pages =	 "450-456",
  keywords =	 "panoramic image construction, calibration",
  bibdate =	 "Mon 06/23/1997 11:12a"
}

@InProceedings{Sawhney98,
  author =	 {Sawhney, H. S. and Kumar, R. and G. Gendel and
                  J. Bergen and D. Dixon and V. Paragano},
  title =	 {Video{B}rush: Experiences with Consumer Video
                  Mosaicing},
  booktitle =	 WACV,
  year =	 1998,
  pages =	 {56-62},
}

@InProceedings{Sawhney98b,
  author =	 {H.S. Sawhney and Steve Hsu and R. Kumar},
  title =	 {Robust Video Mosaicing through Topology Inference
                  and Local to Global Alignment},
  booktitle =	 ECCV,
  year =	 1998,
}

@Article{Schaffalitzky00ivc,
  author =	 "Schaffalitzky, F. and Zisserman, A.",
  title =	 "Planar Grouping for Automatic Detection of Vanishing
                  Lines and Points",
  URL =		 "http://www.robots.ox.ac.uk/~vgg",
  journal =	 IVC,
  pages =	 "647--658",
  volume =	 18,
  year =	 2000,
}

@InProceedings{Schaffalitzky02civr,
  author =	 "Schaffalitzky, F. and Zisserman, A.",
  title =	 "Automated Scene Matching in Movies",
  booktitle =	 "Proc. of the Challenge of Image and Video Retrieval,
                  London",
  year =	 2002,
  note =	 "To appear."
}

@InProceedings{Schaffalitzky02eccv,
  author =	 "Schaffalitzky, F. and Zisserman, A.",
  title =	 "Multi-view matching for unordered image sets, or
                  {``How do I organize my holiday snaps?''}",
  booktitle =	 ECCV,
  pages =	 "414--431",
  year =	 2002,
  publisher =	 "Springer-Verlag",
  r-Wang06_3dpvt ={Wide-baseline matching techniques were used for
                  ordering of a set of widely separated views in
                  [6]. The focus of this approach was on deciding how
                  to ?stitch??the unordered set of views assuming
                  that they came from approximately same location. The
                  approach was demonstrated on two different data with
                  substantial overlap between the views. The GPS
                  coordinates were not available, hence the location
                  triangulation stage was not considered.},
}

@InProceedings{Schaffalitzky98bmvc,
  author =	 "Schaffalitzky, F. and Zisserman, A.",
  title =	 "Geometric Grouping of Repeated Elements within
                  Images",
  booktitle =	 BMVC,
  pages =	 "13--22",
  year =	 1998,
  URL =		 "http://www.robots.ox.ac.uk/~vgg",
}

@InProceedings{Schapire99ijcai,
  author =	 {Robert E. Schapire},
  title =	 {A brief introduction to boosting},
  booktitle =	 IJCAI,
  year =	 1999,
}

@Article{Scharstein02ijcv,
  author =	 "D. Scharstein and R. Szeliski",
  title =	 "A taxonomy and evaluation of dense two-frame stereo
                  correspondence algorithms",
  journal =	 IJCV,
  year =	 2002,
  month =	 "May",
  pages =	 "7-42",
  volume =	 47,
  number =	 1,
}

@InProceedings{Scharstein96,
  author =	 {D. Scharstein and R. Szeliski},
  title =	 {Stereo matching with non-linear diffusion},
  booktitle =	 CVPR,
  pages =	 {343-350},
  year =	 1996,
}

@article{Schattschneider78,
  author =	 "Schattschneider, D.",
  title =	 "The Plane Symmetry Groups: Their Recognition and
                  Notation",
  journal =	 "The American Mathematical Monthly",
  year =	 1978,
  month =	 "June",
  volume =	 85,
  number =	 6,
  pages =	 "439-450",
}

@ARTICLE{Schechner05joe,
  title =	 {Recovery of underwater visibility and structure by
                  polarization analysis},
  author =	 {Schechner, Y.Y. and Karpel N.},
  journal =	 {Oceanic Engineering, IEEE Journal of},
  year =	 2005,
  month =	 {July },
  volume =	 30,
  number =	 3,
  pages =	 {570-587},
}

@InProceedings{Schellewald03,
  author =	 {C. Schellewald, C. Schnorr},
  title =	 {Subgraph Matching with Semidefinite Programming},
  booktitle =	 IWCIA,
  year =	 2003,
}

@InProceedings{Schiele94,
  author =	 "Schiele, B. and Crowley, J. L.",
  title =	 "A Comparison of Position Estimation Techniques Using
                  Occupancy Grids",
  booktitle =	 ICRA,
  volume =	 2,
  year =	 1994,
  pages =	 "1628-1634"
}

@InProceedings{Schindler04cvpr,
  author =	 {G. Schindler and F. Dellaert},
  fullauthor =	 {Grant Schindler and Frank Dellaert},
  title =	 {{Atlanta World}: An Expectation-Maximization
                  Framework for Simultaneous Low-level Edge Grouping
                  and Camera Calibration in Complex Man-Made
                  Environments},
  crossref =	 {_CVPR04},
  url =
                  {http://www.cc.gatech.edu/~dellaert/pub/Schindler04cvpr.pdf}
}

@InProceedings{Schindler05iccv_dv,
  author =	 {G. Schindler and F. Dellaert},
  fullauthor =	 {Grant Schindler and Frank Dellaert},
  title =	 {A {Rao-Blackwellized} Parts-Constellation Tracker},
  booktitle =	 {ICCV Workshop on Dynamical Vision; International
                  Conference on Computer Vision},
  year =	 2005,
  url =
                  {http://www.cc.gatech.edu/~dellaert/pub/Schindler05iccv_dv.pdf}
}

@InProceedings{Schindler06_3dpvt,
  author =	 {G. Schindler and F. Dellaert},
  title =	 {Line-Based Structure From Motion for Urban
                  Environments},
  booktitle =	 PVT,
  year =	 2006,
}

@InProceedings{Schindler07cvpr,
  author =	 {G. Schindler and F. Dellaert and S.B. Kang},
  fullauthor =	 {Grant Schindler and Frank Dellaert and Sing Bing
                  Kang},
  title =	 {Inferring Temporal Order of Images From {3D}
                  Structure},
  booktitle =	 CVPR,
  year =	 2007,
}

@InProceedings{Schindler07cvpr2,
  author =	 {G. Schindler and M. Brown and R. Szeliski},
  fullauthor =	 {Grant Schindler and Matthew Brown and Rick Szeliski},
  title =	 {City-Scale Location Recognition},
  booktitle =	 CVPR,
  year =	 2007,
}

@InProceedings{Schindler08cvpr,
  author =	 {G. Schindler and P. Krishnamurthy and R. Lublinerman
                  and Y. Liu and F. Dellaert},
  title =	 {Detecting and Matching Repeated Patterns for
                  Automatic Geo-tagging in Urban Environments},
  booktitle =	 CVPR,
  year =	 2008,
}

@InProceedings{Schlenzig94,
  author =	 "J. Schlenzig and E. Hunter and and R. Jain",
  title =	 "Recursive Identification of Gesture Inputs Using
                  Hidden {M}arkov Models",
  booktitle =	 WACV,
  year =	 1994,
}

@article{Schmid00ijcv,
  author =	 "C. Schmid and R. Mohr and C. Bauckhage",
  fullauthor =	 "Cordelia Schmid and Roger Mohr and Christian
                  Bauckhage",
  title =	 "Evaluation of Interest Point Detectors",
  journal =	 IJCV,
  volume =	 37,
  number =	 2,
  pages =	 "151-172",
  year =	 2000,
}

@InProceedings{Schmid94,
  author =	 "Schmid, M.",
  title =	 "An approach to model-based 3-D recognition of
                  vehicles in real time by machine vision",
  volume =	 3,
  booktitle =	 IROS,
  year =	 1994,
  address =	 "Munich, Germany",
  month =	 "September",
}

@article{Schmid97,
  author =	 "C. Schmid and R. Mohr",
  title =	 "Local Grayvalue Invariants for Image Retrieval",
  journal =	 PAMI,
  volume =	 19,
  number =	 5,
  pages =	 "530-535",
  year =	 1997,
}

@Article{Schmidt98ai,
  author =	 {T. Schmidt and P.P. Shenoy},
  fullauthor =	 {Tuija Schmidt and Prakash P. Shenoy},
  title =	 {Some improvements to the {Shenoy-Shafer} and {Hugin}
                  architectures for computing marginals},
  journal =	 AI,
  year =	 1998,
  volume =	 102,
  number =	 2,
  pages =	 {323--333},
  month =	 {July},
  abstract =	 {The main aim of this paper is to describe two
                  modifications to the Shenoy-Shafer architecture with
                  the goal of making it computationally more efficient
                  in computing marginals of the joint valuation. We
                  also describe a modification to the Hugin
                  architecture. Finally, we briefly compare the
                  traditional and modified architectures by solving a
                  couple of small Bayesian networks, and conclude with
                  a statement of further research.},
  r-Kask05ai =	 {In the area of belief networks, junction-tree
                  clustering emerged as the leading strategy for
                  performing probabilistic inference
                  \cite{Lauritzen88jrssb}. Variants of this approach
                  were subsequently offered as a means to better
                  address time-space considerations
                  \cite{Jensen90csq,Schmidt98ai,Shafer90amai}.}
}

@InProceedings{Schmitt99,
  author =	 {M. Schmitt and M. Rous and A. Matsikis and
                  K.-F. Kraiss},
  title =	 {Vision-based self-localization of a mobile robot
                  using a virtual environment},
  booktitle =	 ICRA,
  pages =	 {2911-2916},
  year =	 1999,
  month =	 {May},
  organization = {IEEE},
}

@InProceedings{Schneegans07ecmr,
  author =	 {S. Schneegans and P. Vorst and A. Zell},
  title =	 {Using RFID Snapshots for Mobile Robot
                  Self-Localization},
  booktitle =	 {Proc. of the 3rd European Conference on Mobile
                  Robots},
  year =	 {2007}
}

@InProceedings{Schneegans07ecmr,
  author = {S. Schneegans and P. Vorst and A. Zell},
  title = {Using RFID Snapshots for Mobile Robot Self-Localization},
  booktitle = {Proc. of the 3rd European Conference on Mobile Robots},
  year = {2007}
}

@inproceedings{Schneiderman04cvpr,
  author =	 "Henry Schneiderman",
  title =	 "Feature-Centric Evaluation for Efficient Cascaded
                  Object Detection",
  booktitle =	 CVPR,
  month =	 "June",
  year =	 2004,
  publisher =	 "IEEE"
}

@InProceedings{Schodl00,
  author =	 "A. Sch{\"{o}}dl and R. Szeliski and D.H. Salesin and
                  I. Essa",
  fullauthor =	 "Arno Sch{\"{o}}dl and Richard Szeliski and David
                  H. Salesin and Irfan Essa",
  title =	 "Video Textures",
  booktitle =	 SIGGRAPH,
  year =	 2000,
}

@InProceedings{Schodl98,
  author =	 "A. Sch{\"{o}}dl and A. Haro and I. Essa",
  title =	 "Head Tracking using a textured polygonal model",
  booktitle =	 "Proc. Workshop on Perc. User Interfaces",
  year =	 1998,
}

@article{Scholkopf95ab,
  author =	 {Sch\"{o}lkopf, B. and H.A. Mallot},
  year =	 1995,
  title =	 {View-based cognitive mapping and path planning},
  journal =	 {Adaptive Behavior},
  volume =	 3,
  pages =	 {311--348},
  r-Franz98ar =	 {Humans, for instance, are able to navigate in
                  unknown environments after presentation of sequences
                  of connected views (e.g., \cite{ONeill91eb}). This
                  has led to the concept of a view graph as a minimum
                  representation required to explain experimentally
                  observed navigation competences
                  \cite{Scholkopf95ab}. A view graph is defined as a
                  topological representation consisting of local views
                  and their spatial relations. Depending on the task,
                  these relations can be, e.g., movement decisions
                  connecting the views, or mere adjacencies. .. For
                  maze-like environments, \cite{Sch\"{o}lkopf95ab}
                  have shown that learning a graph of views and
                  movement decisions is sufficient to generate various
                  forms of navigation behaviour known from rodents.},
  c-dellaert =	 {Introduces view graph. Directed place graph has
                  places and corridors traversals, view graph has
                  views at ends of corridors, directed edge if one
                  view can be followed by another. Then some nueral
                  net stuff...},
}

@InProceedings{Schreer02vpmc,
  author =	 {O. Schreer and I. Feldmann and U. Golz and P. Kauff},
  title =	 {Fast and Robust Shadow Detection in VideoConference
                  Applications},
  booktitle =	 {International Symposium on Video/Image Processing
                  and Multimedia Communications},
  pages =	 {371-375},
  year =	 2002,
  month =	 {June},
  abstract =	 {A new approach for real-time shadow detection and
                  elimination is presented. In difference to extisting
                  methods, hue and saturation is approximated in the
                  YUV-color space straight away. We show the linear
                  influence of shadow to the YUV-values and exploit
                  this behaviour in a fast decision scheme. The
                  proposed method is robust and capable for real-time
                  video processing without any need of color space
                  transformation},
  c-houdan =	 {YUV color space corresponds closely to the human
                  perception more thant RGB space, but less than HSV
                  space. Pfinder (Wren97pami) also use YUV space to
                  model the scene and compensate for shadow},
}

@inproceedings{Schroter03ogrw,
  title =	 {{RG} {M}apping: {B}uilding Object-Oriented
                  Representations of Structured Human Environments},
  author =	 {D. Schroter and M. Beetz and B. Radig},
  booktitle =	 {6-th Open Russian-German Workshop on Pattern
                  Recognition and Image Understanding ({OGRW})},
  year =	 2003,
}

@InProceedings{Schroter04dagm,
  author =	 {D. Schroter and T. Weber and M. Beetz and B. Radig},
  title =	 {Detection and Classification of Gateways for the
                  Acquisition of Structured Robot Maps},
  booktitle =	 {Proceedings of 26th Pattern Recognition Symposium
                  ({DAGM})},
  year =	 2004,
  abstract =	 {The automatic acquisition of structured object maps
                  requires sophisticated perceptual mechanisms that
                  enable the robot to recognize the objects that are
                  to be stored in the robot map. This paper
                  investigates a particular object recognition
                  problem: the automatic detection and classification
                  of gateways in office environments based on laser
                  range data. We will propose, discuss, and
                  empirically evaluate a sensor model for crossing
                  gateways and different approaches to gateway
                  classification including simple maximum classifiers
                  and HMM-based classification of observation
                  sequences.},
}

@inproceedings{Schroter04icra,
  title =	 {Acquiring Models of Rectangular Objects for Robot
                  Maps},
  author =	 {D. Schroter and M. Beetz},
  booktitle =	 ICRA,
  year =	 {2004},
  abstract =	 {State-of-the-art robot mapping approaches are
                  capable of acquiring impressively accurate 2D and 3D
                  models of their environments. To the best of our
                  knowledge few of them can acquire models of
                  task-relevant objects. In this paper, we introduce a
                  novel method for acquiring models of taskrelevant
                  objects from stereo images. The proposed algorithm
                  applies methods from projective geometry and works
                  for rectangular objects, which are, in office- and
                  museum-like environments, the most commonly found
                  subclass of geometric objects. The method is shown
                  to work accurately and for a wide range of viewing
                  angles and distances.},
}

@article{Schultz03,
  author =	 {D. Schulz and W. Burgard and D. Fox and
                  A. B. Cremers.},
  title =	 {People Tracking with a Mobile Robot Using
                  Sample-based Joint Probabilistic Data Association
                  Filters},
  journal =	 IJRR,
  volume =	 22,
  number =	 2,
  year =	 2003
}

@inproceedings {Schultz03b,
  title =	 {People Tracking with Anonymous and {ID}-sensors
                  Using {Rao-Blackwellised} Particle Filters},
  author =	 {D. Schulz and D. Fox and J. Hightower},
  booktitle =	 IJCAI,
  year =	 2003
}

@Article{Schultz94,
  AUTHOR =	 "R. R. Schultz and R. L. Stevenson",
  title =	 {A {B}ayesian Approach to Image Expansion for
                  Improved Definition},
  journal =	 IP,
  year =	 1994,
  volume =	 3,
  number =	 3,
  pages =	 {233--242}
}

@InProceedings{Schultz95,
  author =	 {R. R. Schultz and R. L. Stevenson},
  title =	 {Improved definition video frame enhancement},
  booktitle =	 ICASSP,
  pages =	 {2169-2172},
  year =	 1995,
  volume =	 {IV},
  month =	 {May},
}

@article{Schultz96,
  AUTHOR =	 "R. R. Schultz and R. L. Stevenson",
  TITLE =	 "Extraction of High-Resolution Frames from Video
                  Sequences",
  JOURNAL =	 IP,
  VOLUME =	 5,
  YEAR =	 1996,
  NUMBER =	 6,
  MONTH =	 "June",
  PAGES =	 "996-1011"
}

@InProceedings{Schulz01,
  author =	 {D. Schulz and W. Burgard and D. Fox and
                  A. B. Cremers.},
  title =	 {Tracking Multiple Moving Targets with a Mobile Robot
                  using Particle Filters and Statistical Data
                  Association},
  booktitle =	 ICRA,
  year =	 2001,
}

@TechReport{Schumacker69,
  author =	 "R. Schumacker and B. Brand and M. Gillilan and
                  W. Sharp",
  title =	 "Study for applying computer-generated images to
                  visual simulation Navigation",
  institution =	 "U.S. Air Force Human Resources Lab., Air Force
                  Systems Command, Brooks AFB, TX",
  year =	 1969,
  type =	 "Tech. Rep.",
  number =	 "AFHRL-TR-69-14, NTIS AD700375",
  month =	 "September",
}

@article{Sclaroff95,
  AUTHOR =	 "Sclaroff, S. and Pentland, A.P.",
  TITLE =	 "Modal Matching for Correspondence and Recognition",
  JOURNAL =	 PAMI,
  VOLUME =	 17,
  YEAR =	 1995,
  NUMBER =	 6,
  MONTH =	 "June",
  PAGES =	 "545-561"
}

@InProceedings{Sclaroff98,
  author =	 "S. Sclaroff and J. Isodoro",
  title =	 "Active blobs",
  booktitle =	 ICCV,
  year =	 1998,
}

@article{Scott91,
  AUTHOR =	 "Scott, G.L. and Longuet-Higgins, H.C.",
  TITLE =	 "An Algorithm for Associating the Features of Two
                  Images",
  JOURNAL =	 RoyalP,
  VOLUME =	 "B-244",
  YEAR =	 1991,
  PAGES =	 "21-26"
}

@InProceedings{Se01icra,
  author =	 {S. Se and D. Lowe and J. Little},
  fullauthor =	 {Stephen Se and David Lowe and Jim Little},
  title =	 {Vision-based Mobile Robot Localization and Mapping
                  using Scale-Invariant Features},
  booktitle =	 ICRA,
  pages =	 {2051-2058},
  location =	 {Seoul, Korea},
  month =	 {May},
  year =	 2001,
  abstract =	 {A key component of a mobile robot system is the
                  ability to localize itself accurately and build a
                  map of the environment simultaneously. In this
                  paper, a vision-based mobile robot localization and
                  mapping algorithm is described which uses
                  scale-invariant image features as landmarks in
                  unmodified dynamic environments. These 3D landmarks
                  are localized and robot ego-motion is estimated by
                  matching them, taking into account the feature
                  viewpoint variation. With our Triclops stereo vision
                  system, experiments show that these features are
                  robustly matched between views, 3D landmarks are
                  tracked, robot pose is estimated and a 3D map is
                  built.},
  r-Meltzer04iros ={Se at. al. [this] employed the SIFT scale and
                  orientation constraints for matching stereo
                  images. After matching they used a least-squares
                  procedure to compute the camera egomotion for better
                  localization. Their features had a viewpoint
                  variation limit of 20 degrees. --- Se et. al. [this]
                  store the original view direction of the feature and
                  make a new feature in the database if the view
                  direction varies more than the threshold of 20
                  degrees.},
  c-kaess =	 {Uses scale-invariant SIFT features for 3D mapping
                  and localization. Depth is calculated by epipolar,
                  disparity, SIFT scale and orientation constraints on
                  data from a Triclops stereo vision system. Using
                  odometry information to predict feature coordinates
                  and their scale and orientation, features can be
                  tracked and used in least-squares minimization to
                  obtain better localization of both robot and
                  landmarks. Outliers are eliminated by discarding
                  features with significant residual errors. Landmarks
                  are kept in a database, and updated by averaging
                  (Kalman filter suggested, see later work). By
                  counting matches for each landmark, dynamic objects
                  can be removed from the map. Some experimental
                  results are shown.},
}

@InProceedings{Se01iros,
  author =	 {S. Se and D. Lowe and J. Little},
  fullauthor =	 {Stephen Se and David Lowe and Jim Little},
  title =	 {Local and Global Localization for Mobile Robots
                  using Visual Landmarks},
  booktitle =	 IROS,
  location =	 {Hawaii, USA},
  month =	 {Nov},
  year =	 2001,
  abstract =	 {Our mobile robot system uses scale-invariant visual
                  landmarks to localize itself and build a 3D map of
                  the environment simultaneously. As image features
                  are not noise-free, we carry out error analysis and
                  use Kalman Filters to track the 3D landmarks,
                  resulting in a database map with landmark positional
                  uncertainty. By matching a set of landmarks as a
                  whole, our robot can localize itself globally based
                  on the database containing landmarks of sucient
                  distinctiveness. Experiments show that recognition
                  of position within a map without any prior estimate
                  can be achieved using the scale-invariant
                  landmarks.},
  c-kaess =	 {Performs error analysis and adds Kalman filters to
                  [Se01icra] to keep track of uncertainty of 3D
                  landmarks. The uncertainty of the robot position is
                  obtained from the least-squares minimization and
                  propagated to the landmark uncertainty. Global
                  localization is performed using a Hough transform.},
}

@Article{Se02ijrr,
  author =	 {S. Se and D. Lowe and J. Little},
  fullauthor =	 {Stephen Se and David Lowe and Jim Little},
  title =	 {Mobile Robot Localization and Mapping with
                  Uncertainty using Scale-Invariant Visual Landmarks},
  journal =	 IJRR,
  volume =	 21,
  number =	 8,
  pages =	 {735-758},
  month =	 {Aug},
  year =	 2002,
  abstract =	 {A key component of a mobile robot system is the
                  ability to localize itself accurately and,
                  simultaneously, to build a map of the
                  environment. Most of the existing algorithms are
                  based on laser range finders, sonar sensors or
                  artificial landmarks. In this paper, we describe a
                  vision-based mobile robot localization and mapping
                  algorithm, which uses scale-invariant image features
                  as natural landmarks in unmodified environments. The
                  invariance of these features to image translation,
                  scaling and rotation makes them suitable landmarks
                  for mobile robot localization and map building.With
                  our Triclops stereo vision system, these landmarks
                  are localized and robot ego-motion is estimated by
                  least-squares minimization of the matched
                  landmarks. Feature viewpoint variation and occlusion
                  are taken into account by maintaining a view
                  direction for each landmark. Experiments show that
                  these visual landmarks are robustly matched, robot
                  pose is estimated and a consistent three-dimensional
                  map is built. As image features are not noise-free,
                  we carry out error analysis for the landmark
                  positions and the robot pose. We use Kalman filters
                  to track these landmarks in a dynamic environment,
                  resulting in a database map with landmark positional
                  uncertainty.},
  r-Sim06crv =	 {[this]... a laboratory environment was successfully
                  mapped by using a Kalman Filter and assuming
                  independence between landmark and pose
                  estimates. For larger environments, this approach is
                  likely to be overconfident and lead to filter
                  divergence.},
  c-kaess =	 {Summarizes Se01icra and Se01iros},
}

@InProceedings{Se02iros,
  author =	 {S. Se and D. Lowe and J. Little},
  fullauthor =	 {Stephen Se and David Lowe and Jim Little},
  title =	 {Global Localization using Distinctive Visual
                  Features},
  booktitle =	 IROS,
  pages =	 {226-231},
  year =	 2002,
}

@InProceedings{Se02iros2,
  author =	 {S. Se and D. Lowe and J. Little},
  fullauthor =	 {Stephen Se and David Lowe and Jim Little},
  title =	 {Vision-based Mapping with Backward Correction},
  booktitle =	 IROS,
  pages =	 {153-158},
  location =	 {Lausanne, Switzerland},
  month =	 {Sep},
  year =	 2002,
  abstract =	 {We consider the problem of creating a consistent
                  alignment of multiple 3D submaps containing
                  distinctive visual landmarks in an unmodified
                  environment. An efficient map alignment algorithm
                  based on landmark specificity is proposed to align
                  submaps. This is followed by a global minimization
                  using the close-theloop constraint. Landmark
                  uncertainty is taken into account in the pair-wise
                  alignment and the global minimization
                  process. Experiments show that pair-wise alignment
                  of submaps with backward correction produces a
                  consistent global 3D map. Our vision-based mapping
                  approach using sparse 3D data is different from
                  other existing approaches which use dense 2D range
                  data from laser or sonar rangefinders.},
  c-kaess =	 {Closes the loop by error propagation over alignment
                  of sub-maps. Drifts are detected by a decreased
                  number of matches and consequently a new sub-map is
                  started. Submaps are aligned pair-wise or
                  incrementally, where the latter one allows detection
                  of loop-closures. If a loop-closure is detected, the
                  alignment error is "distributed" over the loop by
                  minimizing the overall error over previously
                  calculated alignments. The problem is reduced to
                  solving a linear equation system. An extension
                  includes probabilistic knowledge about the 3D
                  landmark locations. The algorithm runs in real-time,
                  but assumes loop-closure with the first sub-map.},
}

@Article{Se05tro,
  author =	 {S. Se and D.G. Lowe and J.J. Little},
  fullauthor =	 {Stephen Se and David G. Lowe and Jim J. Little},
  title =	 {Vision-Based Global Localization and Mapping for
                  Mobile Robots},
  journal =	 TRO,
  volume =	 21,
  number =	 3,
  pages =	 {364-375},
  month =	 {Jun},
  year =	 2005,
  abstract =	 {We have previously developed a mobile robot system
                  which uses scale-invariant visual landmarks to
                  localize and simultaneously build three-dimensional
                  (3-D) maps of unmodified environments. In this
                  paper, we examine global localization, where the
                  robot localizes itself globally, without any prior
                  location estimate. This is achieved by matching
                  distinctive visual landmarks in the current frame to
                  a database map. A Hough transform approach and a
                  RANSAC approach for global localization are
                  compared, showing that RANSAC is much more efficient
                  for matching specific features, but much worse for
                  matching nonspecific features. Moreover, robust
                  global localization can be achieved by matching a
                  small submap of the local region built from multiple
                  frames. This submap alignment algorithm for global
                  localization can be applied to map building, which
                  can be regarded as alignment of multiple 3-D
                  submaps. A global minimization procedure is carried
                  out using the loop closure constraint to avoid the
                  effects of slippage and drift accumulation. Landmark
                  uncertainty is taken into account in the submap
                  alignment and the global minimization
                  process. Experiments show that global localization
                  can be achieved accurately using the scale-invariant
                  landmarks. Our approach of pairwise submap alignment
                  with backward correction in a consistent manner
                  produces a better global 3-D map.},
  c-kaess =	 {Similar to Se02iros (not referenced), but focuses on
                  global localization, based on matching local
                  submaps. Compares a Hough Transform and a RANSAC
                  based approach. Uses SIFT features and trinocular
                  stereo. Proposes mapping by aligning submaps with
                  backward correction via Lu&Milios, as in
                  Se02iros. Results shown for 10x10m with 4 submaps.},
}

@InProceedings{Sedlazeck09oceans,
  author =	 {A. Sedlazeck and C. Albrechts and K.  Koser and
                  R. Koch},
  fullauthor =	 {Anne Sedlazeck and Christian Albrechts and Kevin
                  Koser and Reinhard Koch},
  title =	 {{3D} Reconstruction based on Underwater Video from
                  {ROV} {KIEL} 6000 Considering Underwater Imaging
                  Conditions},
  crossref =	 {_Oceans09Bremen},
  c-dellaert =	 {Feature tracking, epipolar geometry, bundle
                  adjustment, dense depth map using dense stereo on a
                  pairwise basis, fused through unknown means (i.e.,
                  better than Delaunay). Focuses on image correction
                  and removal of artifacts due to water attenuation
                  etc.}
}

@Book{Seeley95book,
  author =	 {T.D. Seeley},
  title =	 {The Wisdom of the Hive},
  publisher =	 {Harvard University Press},
  year =	 1995,
}

@InProceedings{Seidel81ijcai,
  author =	 {R. Seidel},
  title =	 {A new method for solving constraint satisfaction
                  problems},
  booktitle =	 IJCAI,
  pages =	 {338--342},
  year =	 1981,
  r-Dechter92chapter ={Seminal reference for Adaptive-Consistency, the
                  variant of elimination for CSP},
  c-dellaert =	 {Calls this the "invasion procedure". An invasion is
                  a series of induced graphs, this time numbered from
                  leaves to roots, where $G_i$ is a subgraph of
                  $G_{i+1}$. Noteworthy as references
                  \cite{Lipton79sep} and uses it to prove bounds on
                  CSP in planar graphs.},
}

@Article{Seitz02ijcv,
  author =	 "S.M. Seitz and J. Kim",
  title =	 "The Space of All Stereo Images",
  journal =	 IJCV,
  year =	 2002,
  pages =	 "307-314",
}

@inproceedings{Seitz95iccv,
  author =	 "S.M. Seitz and C.R. Dyer",
  title =	 "Complete Structure from Four Point Correspondences",
  booktitle =	 ICCV,
  pages =	 {330-337},
  year =	 1995
}

@InProceedings{Seki03cvpr,
  author =	 {M. Seki and T. Wada and H. Fujiwara and K. Sumi},
  title =	 {Background Subtraction based on Cooccurrence of
                  Image Variations},
  booktitle =	 CVPR,
  volume =	 2,
  pages =	 {65-72},
  year =	 2003,
  abstract =	 {This paper presents a novel background subtraction
                  method for detecting foreground objects in dynamic
                  scenes involving swaying trees and fluttering
                  flags. Most methods proposed so far adjust the
                  permissible range of the background image variations
                  according to the training samples of background
                  images. Thus, the detection sensitivity decreases at
                  those pixels having wide permissible ranges. If we
                  can narrow the ranges by analyzing input images, the
                  detection sensitivity can be improved. For this
                  narrowing, we employ the property that image
                  variations at neighboring image blocks have strong
                  correlation, also known as cooccurrence. This
                  approach is essentially different from chronological
                  background image updating or morphological
                  postprocessing. Experimental results for real images
                  demonstrate the effectiveness of our method. },
  c-houdan =	 {It explores the correlation of image neighboring
                  pixels/blocks. The vatiation of one background
                  blocks is narrowed by its 8 neighboring blocks. But
                  the experimental results are not good enough yet},
}

@InProceedings{Sengupta88,
  author =	 {Sengupta, D. and Iltis, R.A.},
  title =	 {Computationally efficient tracking of multiple
                  targets by probabilistic data association using
                  neural networks},
  booktitle =	 ICASSP,
  pages =	 {2152--2155},
  year =	 1988,
  volume =	 4,
}

@Article{Sengupta89,
  author =	 {Sengupta, D. and Iltis, R.A.},
  title =	 {Neural solution to the multitarget tracking data
                  association problem},
  journal =	 AES,
  year =	 1989,
  volume =	 25,
  number =	 1,
  pages =	 {96--108},
  month =	 {January},
}

@inproceedings{Sha07nips,
  Author =	 {Fei Sha and Lawrence K. Saul},
  Title =	 {Large Margin Hidden Markov Models for Automatic
                  Speech Recognition},
  Booktitle =	 NIPS,
  Year =	 {2007},
  Pages =	 {1249-1256},
  Keywords =	 {hmm},
  c-sangmin =	 {Nice work on large margin HMMs (?). In fact, the
                  work has some flavor of Markov chain since in the
                  training process there are known ground truth hidden
                  state labels which are phoneme labels. Nontheless,
                  the idea of learning even the transition model
                  jointly with the emission models to minimize the
                  Haming distance between the inferred labels is quite
                  interesting. They note that the insight of using
                  Hamming distance was first observed by Taskar et
                  al's work on Max-Margin Markov networks.},
}

@Book{Shafer76book,
  author =	 {G. Shafer},
  title =	 {A Mathematical Theory of Evidence},
  publisher =	 {Princeton University Press},
  year =	 1976,
  preface =	 {In the spring of 1971, I attended a course on
                  statistical inference taught by Arthur Dempster at
                  Harvard. In the fall of that same year Geoffrey
                  Watson suggested I give a talk expositing Dempster's
                  work on upper and lower probabilities to the
                  Department of Statistics at Princeton. This essay is
                  one of the results of the ensuing effort. It offers
                  a reinterpretation of Dempster's work, a
                  reinterpretation that identifies his "lower
                  probabilities" as epistemic probabilities or degrees
                  of belief, takes the rule for combining such degrees
                  of belief as fundamental, and abandons the idea that
                  they arise as lower bounds over classes of Bayesian
                  probabilities.},
  r-Shenoy90uai ={We represent each item of evidence by a belief
                  function and combine these belief functions by
                  Dempster's rule \cite{Shafer76book}.},
}

@Article{Shafer90amai,
  author =	 {G. Shafer and Prakash P. Shenoy},
  title =	 {Probability Propagation},
  journal =	 {Annals of Mathematics and Artificial Intelligence},
  year =	 1990,
  volume =	 2,
  pages =	 {327--352},
  abstract =	 {In this paper we give a simple account of local
                  computation of marginal probabilities for when the
                  joint probability distribution is given in factored
                  form and the sets of variables involved in the
                  factors form a hypertree. Previous expositions of
                  such local computation have emphasized conditional
                  probability. We believe this emphasis is
                  misplaced. What is essential to local computation is
                  a factorization. It is not essential that this
                  factorization be interpreted in terms of conditional
                  probabilities. The account given here avoids the
                  divisions required by conditional probabilities and
                  generalizes readily to alternative measures of
                  subjective probability, such Dempster-Shafer or
                  Spohnian belief functions.},
  quotes =	 {The purpose of this paper is to simplify and unify
                  previous work.... In Shafer and Shenoy \cite{24}, we
                  explain how to abstract the approach given here to a
                  set of axioms that apply not only to probability and
                  belief-function propagation but also to constraint
                  propagation (Seidel \cite{22}, Dechter and Pearl
                  \cite{7}, Shenoy and Shafer \cite{29}), discrete
                  optimization (Bertele and Brioschi \cite{4}, Shenoy
                  and Shafer \cite{30}), solving systems of linear
                  equations (Rose \cite{21}), propagation of Spohnian
                  belief functions (Spohn \cite{32}, Hunter
                  \cite{10}), retrieval from acyclic databases
                  (Malvestuto \cite{16}, Beeri et al. \cite{2}), rule
                  propagation in rule-based systems (Shenoy
                  \cite{26}), and implementation of the Kalman filter
                  (Dempster \cite{8}, Meinhold and Singpurwalla
                  \cite{17}). },
  r-Kask05ai =	 {In the area of belief networks, junction-tree
                  clustering emerged as the leading strategy for
                  performing probabilistic inference
                  \cite{Lauritzen88jrssb}. Variants of this approach
                  were subsequently offered as a means to better
                  address time-space considerations
                  \cite{Jensen90csq,Schmidt98ai,Shafer90amai}.},
  r-Kask05ai =	 {Tree clustering schemes have been widely used for
                  constraint processing, probabilistic reasoning and
                  for graphical models in general. The most popular
                  variants are join-tree clustering algorithms, also
                  called junction-trees. The schemes vary somewhat in
                  their graph definitions as well as in the way
                  tree-decompositions are processed \cite{Maier83book,
                  Dechter89ai, Jensen90csq, Lauritzen97amai,
                  Shenoy96uai, Gottlob00ai}. However, they all involve
                  a decomposition of a hyper-graph into a hyper-tree.},
  c-dellaert =	 {Linear algebra connection via Rose70. Use the term
                  Markov Tree.},
}

@InProceedings{Shah95,
  author =	 {S. Shah and J.K. Aggarwal},
  title =	 {Modeling structured environments using robot vision},
  booktitle =	 ACCV,
  year =	 1995,
}

@InProceedings{Shah95b,
  author =	 {S. Shah and J.K. Aggarwal},
  title =	 {Autonomous Mobile Robot navigation using Fish-eye
                  lenses},
  booktitle =	 {International Computer Science Conference},
  year =	 1995,
}

@Article{Shakanuga92,
  author =	 {T. Shakanuga},
  title =	 {{3-D} Corridor scene modeling from a single view
                  under natural lighting conditions},
  journal =	 PAMI,
  year =	 1992,
  volume =	 14,
  month =	 {February},
  pages =	 {293-298},
}

@Article{Shamma89,
  author =	 {S.A. Shamma and N. Shen and P. Gopalaswamy},
  title =	 {Stereausis: Binaural Processing without Neural
                  Delays},
  journal =	 {Journal of The Acoustical Society of America},
  volume =	 86,
  pages =	 {999-1006},
  year =	 1989,
}

@InProceedings{Shao05sca,
  author =	 {W. Shao and D. Terzopoulos},
  fullauthor =	 {Wei Shao and Demetri Terzopoulos},
  title =	 {{Autonomous Pedestrians}},
  booktitle =	 {SIGGRAPH/EG Symposium on Computer Animation (SCA)},
  year =	 2005,
  keywords =	 {animation, crowd simulation, ALife},
}

@Article{Shapiro81,
  author =	 {L.G. Shapiro and R.M. Haralick},
  title =	 {Structural descriptions and inexact matching},
  journal =	 PAMI,
  year =	 1981,
  volume =	 3,
  number =	 5,
  pages =	 {504-519},
}

@article{Shapiro92,
  AUTHOR =	 "Shapiro, L.S. and Brady, J.M.",
  TITLE =	 "Feature-Based Correspondence: An Eigenvector
                  Approach",
  JOURNAL =	 IVC,
  VOLUME =	 10,
  YEAR =	 1992,
  NUMBER =	 5,
  MONTH =	 "June",
  PAGES =	 "283-288"
}

@article{Shashua2001,
  author =	 {A.Shashua and T.Riklin-Raviv},
  title =	 {The quotient image: class-based re-rendering and
                  recognition withvarying illuminations},
  journal =	 PAMI,
  volume =	 23,
  number =	 2,
  pages =	 {129-139},
  year =	 2001,
}

@article{Shashua2001,
  author =	 {A.Shashua and T.Riklin-Raviv},
  title =	 {The quotient image: class-based re-rendering and
                  recognition withvarying illuminations},
  journal =	 PAMI,
  volume =	 23,
  number =	 2,
  pages =	 {129-139},
  year =	 2001,
}

@PhdThesis{Shashua92,
  author =	 "A Shashua",
  title =	 "Geometry and Photometry in {3D} Visual Recognition",
  school =	 "MIT",
  year =	 1992,
}

@inproceedings{Shashua94,
  AUTHOR =	 "Shashua, A. and Toelg, S.",
  TITLE =	 "The Quadric Reference Surface: Applications in
                  Registering Views of Complex {3D} Objects",
  BOOKTITLE =	 ECCV,
  YEAR =	 1994,
  PAGES =	 "B:407-416"
}

@InProceedings{Shashua94b,
  AUTHOR =	 "Shashua, A. and Toelg, S.",
  TITLE =	 "The Quadric Reference Surface: Theory and
                  Applications",
  BOOKTITLE =	 "ARPA94",
  YEAR =	 1994,
  PAGES =	 "II:1451-1459"
}

@inproceedings{Shashua95,
  author =	 "Shashua, A. and Werman, M.",
  title =	 "Trilinearity of Three Perspective Views and its
                  Associated Tensor",
  booktitle =	 ICCV,
  pages =	 "920--925",
  year =	 1995,
}

@Article{Shashua96,
  AUTHOR =	 "Shashua, A. and Navab, N.",
  TITLE =	 "Relative Affine Structure: Canonical Model for {3D}
                  from {2D} Geometry and Applications",
  JOURNAL =	 PAMI,
  VOLUME =	 18,
  YEAR =	 1996,
  NUMBER =	 9,
  MONTH =	 "September",
  PAGES =	 "873-883"
}

@InProceedings{Shashua97,
  author =	 "A. Shashua",
  title =	 "Trilinear Tensor: The Fundamental Construct of
                  Multiple-view Geometry and its Applications",
  booktitle =	 "Intl. Workshop on Algebraic Frames For The
                  Perception Action Cycle (AFPAC), Kiel Germany",
  year =	 1997,
  month =	 "September",
}

@article{Shatkay02jair,
  journal =	 {Journal of Artificial Intelligence Research},
  volume =	 16,
  year =	 2002,
  pages =	 {167-207},
  month =	 {March},
  title =	 {Learning Geometrically-Constrained Hidden Markov
                  Models for Robot Navigation: Bridging the
                  Topological-Geometrical Gap},
  author =	 {H. Shatkay and L.P. Kaelbling},
  fullauthor =	 {Hagit Shatkay and Leslie Pack Kaelbling},
  abstract =	 {Hidden Markov models (HMMs) and partially observable
                  Markov decision processes (POMDPs) provide useful
                  tools for modeling dynamical systems. They are
                  particularly useful for representing the topology of
                  environments such as road networks and office
                  buildings, which are typical for robot navigation
                  and planning. The work presented here describes a
                  formal framework for incorporating readily available
                  odometric information and geometrical constraints
                  into both the models and the algorithm that learns
                  them. By taking advantage of such information,
                  learning HMMs/POMDPs can be made to generate better
                  solutions and require fewer iterations, while being
                  robust in the face of data reduction. Experimental
                  results, obtained from both simulated and real robot
                  data, demonstrate the effectiveness of the
                  approach.},
  c-dellaert =	 {learn an HMM using odometry to impose metric
                  structure. Journal version of
                  \citet{Shatkay97ijcai}}
}

@INPROCEEDINGS{Shatkay97ijcai,
  AUTHOR =	 {Shatkay, H. and Kaelbling, L.},
  TITLE =	 {Learning Topological Maps with Weak Local Odometric
                  Information},
  YEAR =	 1997,
  pages =	 {920-929},
  BOOKTITLE =	 IJCAI,
  abstract =	 {Topological maps provide a useful abstraction for
                  robotic navigation and planning. Although stochastic
                  maps can theoretically be learned using the
                  Baum-Welch algorithm, without strong prior
                  constraint on the structure of the model it is slow
                  to converge, requires a great deal of data, and is
                  often stuck in local minima. In this paper, we
                  consider a special case of hidden Markov models for
                  robot-navigation environments, in which states are
                  associated with points in a metric configuration
                  space. We assume that the robot has some odometric
                  ability to measure relative transformations between
                  its configurations. Such odometry is typically not
                  precise enough to suffice for building a global map,
                  but it does give valuable local information about
                  relations between adjacent states. We present an
                  extension of the Baum-Welch algorithm that takes
                  advantage of this local odometric information,
                  yielding faster convergence to better solutions with
                  less data.},
  c-dellaert =	 {learn an HMM using odometry to impose metric
                  structure},
  c-ananth =	 {The pioneering work in this regard is by Shatkay and
                  Kaelbling [Shatkay97a] that uses the Baum-Welch
                  algorithm, a variant of the EM algorithm used in the
                  context of HMMs, to solve the aliasing problem for
                  topological mapping.}
}

@PHDTHESIS{Shatkay98a,
  AUTHOR =	 {Shatkay, H.},
  TITLE =	 {Learning Models for Robot Navigation},
  YEAR =	 {1998},
  SCHOOL =	 {Computer Science Department, Brown University},
  ADDRESS =	 {Providence, RI}
}

@Article{Shaw69,
  author =	 {A.C. Shaw},
  title =	 {Parsing of graph-representable pictures},
  journal =	 {J. ACM},
  year =	 1969,
  volume =	 17,
  pages =	 {453-487 },
}

@TechReport{Shekarforoush95,
  author =	 {H.~Shekarforoush and M.~Berthod and J.~Zerubia},
  title =	 {{3D} Super-Resolution Using Generalized Sampling
                  Expansion},
  institution =	 {{INRIA}},
  year =	 1995,
  number =	 2706,
  month =	 {November}
}

@Article{Shekarforoush96,
  author =	 {H.~Shekarforoush and M.~Berthod and J.~Zerubia and
                  M.~Werman},
  title =	 {Sub-Pixel {B}ayesian Estimation of Albedo and
                  Height},
  journal =	 ijcv,
  year =	 1996,
  volume =	 19,
  number =	 3,
  pages =	 {289--300}
}

@Article{Shenoy86expert,
  author =	 {Shenoy, P. P. and Shafer, G. },
  title =	 {Propagating belief functions using local
                  computations,},
  journal =	 {IEEE Expert},
  year =	 1986,
  month =	 {Fall},
  volume =	 1,
  number =	 3,
  pages =	 {43--52},
  quotes =	 {We believe that the scheme we describe here will
                  prove useful in expert systems.... We would like to
                  emphasize that the basic idea of local computation
                  for propagating probabilities is Judea Pearl's... We
                  see our contribution as extending Pearl's idea from
                  Bayesian probabilities to belief functions.},
  r-Shenoy90uai ={The axioms are abstracted from the belief-function
                  work of the authors e.g. \cite{Shenoy86expert}},
}

@InProceedings{Shenoy90uai,
  author =	 {P. Shenoy and G. Shafer},
  title =	 {Axioms for probability and belief-function
                  propagation},
  crossref =	 {_UAI90},
  pages =	 {169--198},
  quotes =	 {We represent each item of evidence by a belief
                  function and combine these belief functions by
                  Dempster's rule \cite{Shafer76book}.... As we shall
                  see, hypertrees are closely related to Markov
                  trees. The vertices of a Markov tree are always
                  hyperedges of a hypertree, and the hyper- edges of a
                  hypertree can always be arranged in a Markov tree.},
  r-Kask05ai =	 {Our work is related in aim and content to the
                  earlier work of Shenoy and Shafer
                  \cite{Shenoy90uai}, who presented a unifying,
                  axiomatic, approach for reasoning tasks.},
  c-dellaert =	 {Linear algebra connection via Rose70. Talks about
                  hypergraphs (=factor graphs) and hypertrees (=
                  junction tree ??).},
}

@INPROCEEDINGS{Shenoy96uai,
  AUTHOR =	 "P. Shenoy ",
  FULLAUTHOR =	 "Prakash Shenoy ",
  TITLE =	 "Binary Join Trees",
  crossref =	 {_UAI96},
  PAGES =	 "492--499",
  abstract =	 {The main goal of this paper is to describe a data
                  structure called binary join trees that are useful
                  in computing multiple marginals efficiently using
                  the Shenoy-Shafer architecture. We define binary
                  join trees, describe their utility, and sketch a
                  procedure for constructing them.},
  r-Kask05ai =	 "Tree clustering schemes have been widely used for
                  constraint processing, probabilistic reasoning and
                  for graphical models in general. The most popular
                  variants are join-tree clustering algorithms, also
                  called junction-trees. The schemes vary somewhat in
                  their graph definitions as well as in the way
                  tree-decompositions are processed \cite{Maier83book,
                  Dechter89ai, Jensen90csq, Shenoy96uai,
                  Lauritzen97amai, Gottlob00ai}. However, they all
                  involve a decomposition of a hyper-graph into a
                  hyper-tree.",
}

@Article{Shi00pami,
  author =	 {J.Shi and J.Malik},
  title =	 {Normalized cuts and image segmentation},
  journal =	 PAMI,
  year =	 2000,
  volume =	 24,
  number =	 5,
}

@INPROCEEDINGS{Shi04cvpr,
  author =	 {Y. Shi and Y. Huang and D. Minnen and A. Bobick and
                  I. Essa},
  title =	 {{Propagation Networks for Recognition of Partially
                  Ordered Sequential Action}},
  booktitle =	 CVPR,
  year =	 2004,
  volume =	 2,
  pages =	 {862--870},
}

@InProceedings{Shi04icasp,
  author =	 "C.Shi and K.Yu and S.Li",
  title =	 "Automatic image quality improvement for
                  videoconferencing",
  booktitle =	 "Proceedings of the IEEE International Conference on
                  Acoustics, Speech and Signal Processing",
  year =	 2004,
}

@InProceedings{Shi94,
  author =	 "J. Shi and C. Tomasi",
  title =	 "Good Features to track",
  pages =	 "593-600",
  booktitle =	 CVPR,
  year =	 1994,
}

@Book{Shilov77,
  author =	 {Georgi E. Shilov},
  title =	 {Linear Algebra},
  publisher =	 {Dover Publications},
  year =	 1977,
  address =	 {Mineola, NY},
}

@article{Shinoda01vr,
  author =	 {Shinoda, H. and Hayhoe, M. and Shrivastava, A.},
  year =	 2001,
  title =	 {What controls attention in natural environments?},
  journal =	 {Vision Research},
  note =	 {Special issue on Eye Movements and Vision in the
                  Natural World},
  volume =	 41,
  pages =	 {3535--3546},
  abstract =	 {The highly task-specific fixation patterns revealed
                  in performance of natural tasks demonstrate the
                  fundamentally active nature of vision, and suggest
                  that in many situations, top-down processes may be a
                  major factor in the acquisition of visual
                  information. Understanding how a top-down visual
                  system could function requires understanding the
                  mechanisms that control the initiation of the
                  different task-specific computations at the
                  appropriate time. This is particularly difficult in
                  dynamic environments, like driving, where many
                  aspects of the visual input may be unpredictable. We
                  therefore examined drivers?ability to detect Stop
                  signs in a virtual environment when the signs were
                  visible for restricted periods of time. Detection
                  performance is heavily modulated both by the
                  instructions and the local visual context. This
                  suggests that visibility of the signs requires
                  active search, and that the frequency of this search
                  is influenced by learnt knowledge of the
                  probabilistic structure of the environment.},
  r-Hayhoe05tics ={In driving, \citet{Shinoda01vr} showed that
                  approximately 45\% of fixations fell close to
                  intersections. As a consequence of this, subjects
                  were more likely to notice ?top?signs located at
                  intersections as opposed to signs in the middle of a
                  block, suggesting in turn that subjects have learnt
                  that traffic signs are more likely around
                  intersections.},
  c-dellaert =	 {Driving = simple routines, gaze is directed
                  top-down},
}

@InProceedings{Shokoufandeh99,
  author =	 "A. Shokoufandeh and S. Dickinson",
  title =	 "Applications of bipartite matching to problems in
                  object recognition",
  booktitle =	 "IEEE Workshop on Graph Algorithms and Computer
                  Vision at ICCV'99",
  year =	 1999
}

@article{Sholl97jeplmc,
  author =	 {Sholl, M.J. and Nolin, T.L.},
  year =	 1997,
  title =	 {Orientation specificity in representations of place},
  journal =	 JEPLMC,
  colume =	 23,
  pages =	 {1496--1507},
  abstract =	 {Although some studies have shown that a single view
                  produces an orientation-free representation of place
                  (C. C. Presson, N. DeLange, & M. D. Hazelrigg, 1989;
                  C. C. Presson & M. D. Hazelrigg, 1984), others
                  suggest that an orientation-specific representation
                  is formed (J. J. Rieser, 1989). Five experiments are
                  reported that together with existing studies,
                  suggest that orientation-free performance requires a
                  conjunction of study-test conditions, including a
                  "horizontal" viewing angle during encoding, a
                  room-sized test space, and "on-path" testing. If any
                  one of these conditions was not satisfied,
                  orientation-specific performance was observed at
                  test. The findings support a multiple-view model of
                  orientation invariance and suggest that there is
                  something special about on-path testing that permits
                  orientation-free performance under some conditions.},
  c-dellaert =	 {Experimental psych paper, seems to support multiple
                  views (orientation-specific representations) to deal
                  with orientation invariance, except under specific
                  well-defined conditions.}
}

@article{Sholl99jscc,
  author =	 {Sholl, M. J.},
  year =	 1999,
  title =	 {Egocentric frames of reference used for the
                  retrieval of survey knowledge learned by map and
                  navigation},
  journal =	 {J. Spatial Cognition and Computation},
  volume =	 1,
  pages =	 {475--494},
  Abstract =	 {Two experiments are reported that use a
                  ?oint-to-unseen-targets?task to study the role of
                  egocentric reference frames in the retrieval of
                  survey knowledge learned from either studying a map
                  or navigating an environment. In Experiment 1,
                  performance was generally consistent with the
                  hypothesis that map knowledge is retrieved using a
                  frame of reference centered on the eye,
                  characterized by (a) a fixed orientation in a
                  ?rontal representational plane?and (b) equal access
                  to spatial relations both in front of, or above, and
                  behind, or below, a right-left retrieval axis. The
                  results of Experiment 2 were consistent with the
                  hypothesis that environment knowledge is retrieved
                  within a frame of reference centered on the body,
                  characterized by (a) flexible orientation within a
                  ?ransverse representational plane?and (b) privileged
                  access to spatial relations located in front of the
                  right-left retrieval axis in representational
                  space. Both types of knowledge function as if they
                  preserve information about the Euclidean angles
                  connecting elements in physical space.}
}

@inproceedings{Shotton06eccv,
  author =	 {J. Shotton and J. Winn and C. Rother and
                  A. Criminisi},
  title =	 {TextonBoost: Joint Appearance, Shape and Context
                  Modeling for Multi-Class Object Recognition and
                  Segmentation},
  booktitle =	 ECCV,
  year =	 {2006},
}

@Article{Shum00,
  author =	 {H.-Y. Shum and R. Szeliski},
  title =	 {Construction of panoramic mosaics with global and
                  local alignment},
  journal =	 IJCV,
  year =	 2000,
  volume =	 36,
  number =	 2,
  pages =	 {101--130},
  month =	 {February},
}

@techreport     {Shum97,
  key =		 "Shum",
  author =	 "Shum, H.-Y. and Szeliski, R.",
  fullauthor =	 "Heung-Yeung Shum and R. Szeliski",
  title =	 "Panoramic Image Mosaics",
  institution =	 "Microsoft Research",
  number =	 "MSR-TR-97-23",
  month =	 "September",
  year =	 1997,
  keywords =	 "panoramic image mosaics, texture map extraction",
  bibdate =	 "Fri 08/29/1997 10:13p"
}

@inproceedings  {Shum98,
  key =		 "Shum",
  author =	 "Shum, H.-Y. and Szeliski, R.",
  fullauthor =	 "Heung-Yeung Shum and R. Szeliski",
  title =	 "Construction and refinement of panoramic mosaics
                  with global and local alignment",
  booktitle =	 ICCV,
  address =	 "Bombay",
  month =	 "January",
  year =	 1998,
  pages =	 "953-958",
  keywords =	 "panoramic image mosaics, texture map extraction",
  bibdate =	 "Mon 04/07/1997 11:33a"
}

@InProceedings{Shum98cvpr,
  author =	 {H.Y.Shum and M.Han and R. Szeliski},
  title =	 {Interactive construction of 3d models from panoramic
                  mosaics},
  booktitle =	 CVPR,
  pages =	 {427-433},
  year =	 1998,
  abstract =	 {"This paper presents an interactive modeling system
                  that constructs 3D models from a collection of
                  panoramic image mosaics. A panoramic mosaic consists
                  of a set of images taken around the same viewpoint,
                  and a transformation matrix associated with each
                  input image. Our system first recovers the camera
                  pose for each mosaic from known line directions and
                  points, and then constructs the 3D model using all
                  available geometrical constraints. We partition
                  constraints into soft and hard linear constraints so
                  that the modeling process can be formulated as a
                  linearlyconstrained least-squares problem, which can
                  be solved efficiently using QR factorization. The
                  results of extracting wire frame and texture-mapped
                  3D models from single and multiple panoramas are
                  presented.},
  r-Dick99bmvc = { More recent interactive modelling systems such as
                  PhotoBuilder[Cipolla99icmcs] and [Shum98cvpr]
                  require only that the user specify key image
                  features such as parallel or orthogonal lines, but
                  the effort required of the user quickly becomes
                  prohibitive as the desired model complexity and
                  number of images increases.},
}

@article{Shum98interactive,
  author =	 "H. Shum and R. Szeliski and S. Baker and M. Han and
                  P. Anandan",
  fullauthor =	 "Heung-Yeung Shum and Richard Szeliski and Simon
                  Baker and Mei Han and P. Anandan",
  title =	 "Interactive {$3$D} Modeling from Multiple Images
                  Using Scene Regularities",
  journal =	 "Lecture Notes in Computer Science",
  volume =	 1506,
  pages =	 236,
  year =	 1998,
  url =		 "citeseer.nj.nec.com/shum98interactive.html"
}

@InProceedings{Shum99cvpr,
  author =	 {H. Shum and Q. Ke and Z. Zhang},
  fullauthor =	 {Heung-Yeung Shum and Qifa Ke and Zhengyou Zhang},
  title =	 {Efficient bundle adjustment with virtual key frames:
                  a hierarchical approach to multi-frame structure
                  from motion},
  booktitle =	 CVPR,
  volume =	 2,
  month =	 {June},
  year =	 1999,
}

@Article{Shumway92asa,
  author =	 {Shumway, R.H. and Stoffer, D.S.},
  title =	 {Dynamic linear models with switching},
  journal =	 {Journal of the American Statistical Association},
  year =	 1992,
  volume =	 86,
  pages =	 {763-769},
}

@INPROCEEDINGS{Shwartz06cvpr,
  title =	 {Blind Haze Separation},
  author =	 {Shwartz, S. and Namer, E. and Schechner, Y.Y.},
  booktitle =	 {Computer Vision and Pattern Recognition, 2006 IEEE
                  Computer Society Conference on},
  year =	 2006,
  volume =	 2,
  pages =	 { 1984-1991},
}

@InProceedings{Sidenbladh03,
  author =	 "H. Sidenbladh and S.L. Wirkander",
  title =	 "Tracking random sets of vehicles in terrain",
  booktitle =	 "2nd {IEEE} Workshop on Multi-Object Tracking",
  address =	 "Madison, WI, USA",
  year =	 2003,
}

@Unpublished{Sidenbladh04,
  author =	 {H. Sidenbladh and S.L. Wirkander},
  title =	 {Particle filtering for random sets},
  year =	 2004,
  note =	 {Unpublished}
}

@Misc{Siek98,
  author =	 {J.G. Siek, A. Lumsdaine},
  title =	 {The {M}atrix {T}emplate {L}ibrary: a generic
                  programming approach to high performance numerical
                  linear algebra},
  year =	 1998,
}

@inproceedings{Sigal06cvpr,
  author =	 {L. Sigal and M. J. Black},
  fullauthor =	 {Leonid Sigal and Michael J. Black},
  title =	 {Measure Locally, Reason Globally:
                  Occlusion-sensitive Articulated Pose Estimation},
  booktitle =	 CVPR,
  year =	 2006,
  isbn =	 {0-7695-2597-0},
  pages =	 {2041--2048},
  doi =		 {http://dx.doi.org/10.1109/CVPR.2006.180},
}

@inproceedings{SigalCVPR04,
  author =	 {L. Sigal and S. Bhatia and S. Roth and M.J. Black
                  and M. Isard},
  fullauthor =	 {Leonid Sigal and Sidharth Bhatia and Stefan Roth and
                  Michael J. Black and Michael Isard},
  title =	 {Tracking Loose-Limbed People.},
  booktitle =	 CVPR,
  year =	 2004,
  pages =	 {421-428},
  ee =
                  {http://csdl.computer.org/comp/proceedings/cvpr/2004/2158/01/215810421abs.htm},
  bibsource =	 {DBLP, http://dblp.uni-trier.de}
}

@Unpublished{Sim03waml,
  author =	 {R. Sim and G. Dudek},
  fullauthor =	 {Robert Sim and Gregory Dudek},
  title =	 {Self-Organizing Visual Maps},
  booktitle =	 {Workshop on Advances in Machine Learning},
  note =	 {Presentation, no published proceedings, see
                  Sim04aaai for conference version},
  month =	 {Aug},
  year =	 2003,
}

@InProceedings{Sim04aaai,
  author =	 {R. Sim and G. Dudek},
  fullauthor =	 {Robert Sim and Gregory Dudek},
  title =	 {Self-Organizing Visual Maps},
  booktitle =	 AAAI,
  location =	 {San Jose, CA},
  month =	 {Jul},
  year =	 2004,
  abstract =	 {This paper deals with automatically learning the
                  spatial distribution of a set of images. That is,
                  given a sequence of images acquired from
                  well-separated locations, how can they be arranged
                  to best explain their genesis? The solution to this
                  problem can be viewed as an instance of robot
                  mapping although it can also be used in other
                  contexts. We examine the problem where only limited
                  prior odometric information is available, employing
                  a feature-based method derived from a probabilistic
                  pose estimation framework. Initially, a set of
                  visual features is selected from the images and
                  correspondences are found across the ensemble. The
                  images are then localized by first assembling the
                  small subset of images for which odometric
                  confidence is high, and sequentially inserting the
                  remaining images, localizing each against the
                  previous estimates, and taking advantage of any
                  priors that are available. We present experimental
                  results validating the approach, and demonstrating
                  metrically and topologically accurate results over
                  two large image ensembles. Finally, we discuss the
                  results, their relationship to the autonomous
                  exploration of an unknown environment, and their
                  utility for robot localization and navigation.},
  c-kaess =	 {Conference version of Sim03waml},
}

@InProceedings{Sim05rur,
  author =	 {R. Sim and P. Elinas and M. Griffin and J.J. Little},
  fullauthor =	 {Robert Sim and Pantelis Elinas and Matt Griffin and
                  James J. Little},
  title =	 {Vision-based {SLAM} using the {R}ao-{B}lackwellised
                  Particle Filter},
  booktitle =	 {Proc. of the IJCAI Workshop on Reasoning with
                  Uncertainty in Robotics (RUR)},
  location =	 {Edinburgh, Scotland},
  month =	 {Jul},
  year =	 2005,
  abstract =	 {We consider the problem of Simultaneous Localization
                  and Mapping (SLAM) from a Bayesian point of view
                  using the Rao-Blackwellised Particle Filter
                  (RBPF). We focus on the class of indoor mobile
                  robots equipped with only a stereo vision
                  sensor. Our goal is to construct dense metric maps
                  of natural 3D point landmarks for large cyclic
                  environments in the absence of accurate landmark
                  position measurements and reliable motion
                  estimates. Landmark estimates are derived from
                  stereo vision and motion estimates are based on
                  visual odometry. We distinguish between landmarks
                  using the Scale Invariant Feature Transform
                  (SIFT). Our work defers from current popular
                  approaches that rely on reliable motion models
                  derived from odometric hardware and accurate
                  landmark measurements obtained with laser
                  sensors. We present results that show that our model
                  is a successful approach for vision-based SLAM, even
                  in large environments. We validate our approach
                  experimentally, producing the largest and most
                  accurate vision-based map to date, while we identify
                  the areas where future research should focus in
                  order to further increase its accuracy and
                  scalability to significantly larger environments.},
  r-Davison07pami ={Recently published work by Sim et al. [this] uses
                  an algorithm combining SIFT features and FastSLAM
                  filtering to achieve particularly large-scale
                  vision-only SLAM mapping. Their method is
                  processor-intensive, and at an average of 10 seconds
                  processing time per frame is currently a large
                  factor away from real-time operation.},
  r-Eade06cvpr = {FastSLAM has been previously applied to vision-based
                  SLAM by Sim [this]. However, Sim? system uses a
                  bottomup approach to SLAM, building a large database
                  of feature descriptors into which features from
                  novel views are matched to localize the robot. This
                  approach precludes realtime operation of his system,
                  which has a mean processing time per frame of
                  11.9s. Furthermore, Sim? system uses a stereo camera
                  rig,},
  c-kaess =	 {Combines FastSLAM and Se02ijrr, achieving slow
                  mapping (10s/frame) in large-scale environments
                  based on a stereo camera.}
}

@InProceedings{Sim06crv,
  author =	 {R. Sim and P. Elinas and M. Griffin and A. Shyr and
                  J.J. Little},
  fullauthor =	 {Robert Sim and Pantelis Elinas and Matt Griffin and
                  Alex Shyr and James J. Little},
  title =	 {Design and Analysis of a Framework for Real-time
                  Vision-based {SLAM} using {R}ao-{B}lackwellised
                  Particle Filters},
  booktitle =	 {Proc. of the 3rd Canadian Conf. on Computer and
                  Robotic Vision (CRV)},
  location =	 {Quebec City, Canada},
  month =	 {Jun},
  year =	 2006,
  abstract =	 {This paper addresses the problem of simultaneous
                  localization and mapping (SLAM) using vision-based
                  sensing. We present and analyse an implementation of
                  a Rao-Blackwellised particle filter (RBPF) that uses
                  stereo vision to localize a camera and 3D landmarks
                  as the camera moves through an unknown
                  environment. Our implementation is robust, can
                  operate in real-time, and can operate without
                  odometric or inertial measurements. Furthermore, our
                  approach supports a 6-degree-of-freedom pose
                  representation, vision-based ego-motion estimation,
                  adaptive resampling, monocular operation, and a
                  selection of odometry-based, observation-based, and
                  mixture (combining local and global pose estimation)
                  proposal distributions. This paper also examines the
                  run-time behavior of efficiently designed RBPFs,
                  providing an extensive empirical analysis of the
                  memory and processing characteristics of RBPFs for
                  vision-based SLAM. Finally, we present experimental
                  results demonstrating the accuracy and efficiency of
                  our approach.},
  c-kaess =	 {Provides a general framework for vision-based SLAM
                  based on RBPFs, with a focus on the necessary data
                  structure. Experimental results compare the
                  algorithms behavior based on Elinas06icra (without
                  mixture proposal, more like Sim05rur), for the cases
                  of visual odometry only, monocular as well as
                  stereo.},
}

@InProceedings{Sim06iros,
  author =	 {R. Sim and J.J. Little},
  fullauthor =	 {Robert Sim and James J. Little},
  title =	 {Autonomous Vision-based Exploration and Mapping
                  using Hybrid Maps and {R}ao-{B}lackwellised Particle
                  Filters},
  booktitle =	 IROS,
  location =	 {Beijing, China},
  month =	 {Oct},
  year =	 2006,
  abstract =	 {This paper addresses the problem of exploring and
                  mapping an unknown environment using a robot
                  equipped with a stereo vision sensor. The main
                  contribution of our work is a fully automatic
                  mapping system that operates without the use of
                  active ranger sensors (such as laser or sonic
                  transducers), can operate in real-time and can
                  consistently produce accurate maps of large-scale
                  environments. Our approach implements a Rao-
                  Blackwellised particle filter (RBPF) to solve the
                  simultaneous localization and mapping problem and
                  uses efficient data structures for real-time data
                  association, mapping, and spatial reasoning. We
                  employ a hybrid map representation that infers 3D
                  point landmarks from image features to achieve
                  precise localization, coupled with occupancy grids
                  for safe navigation. This paper describes our
                  framework and implementation, and presents our
                  exploration method, and experimental results
                  illustrating the functionality of the system.},
  c-kaess =	 {Extension of Sim06crv and Elinas06icra to autonomous
                  (real-time) exploration and mapping (without mixture
                  proposal, more like Sim05rur). Mainly adds a
                  just-in-time occupancy updating, in which only the
                  occupancy grid of the ML particle is updated, based
                  on trinocular stereo. When the ML state changes, an
                  old map is retrieved and all newer measurements
                  included. Exploration by selecting optimal
                  destinations to expand map coverage, then using A*
                  search over the occupancy grid, and finally panning
                  the camera at the goal for maximum coverage.},
}

@Article{Sim07ijcv,
  author =	 {R. Sim and P. Elinas and J.J. Little},
  fullauthor =	 {Robert Sim and Pantelis Elinas and James J. Little},
  title =	 {A Study of the {R}ao-{B}lackwellised Particle Filter
                  for Efficient and Accurate Vision-Based {SLAM}},
  journal =	 IJCV,
  volume =	 74,
  number =	 3,
  pages =	 {303-318},
  month =	 {Sep},
  year =	 2007,
  abstract =	 {With recent advances in real-time implementations of
                  filters for solving the simultaneous localization
                  and mapping (SLAM) problem in the range-sensing
                  domain, attention has shifted to implementing SLAM
                  solutions using vision-based sensing. This paper
                  presents and analyses different models of the
                  Rao-Blackwellised particle filter (RBPF) for
                  vision-based SLAM within a comprehensive application
                  architecture. The main contributions of our work are
                  the introduction of a new robot motion model
                  utilizing structure from motion (SFM) methods and a
                  novel mixture proposal distribution that combines
                  local and global pose estimation. In addition, we
                  compare these under a wide variety of operating
                  modalities, including monocular sensing and the
                  standard odometry-based methods. We also present a
                  detailed study of the RBPF for SLAM, addressing
                  issues in achieving real-time, robust and
                  numerically reliable filter behavior. Finally, we
                  present experimental results illustrating the
                  improved accuracy of our proposed models and the
                  efficiency and scalability of our implementation.},
}

@InProceedings{Simmons95,
  author =	 "Simmons, R. and Koenig, S.",
  title =	 "Probabilistic Robot Navigation in Partially
                  Observable Environments",
  booktitle =	 "Proc.~International Joint Conference on Artificial
                  Intelligence",
  pages =	 {1080 - 1087},
  year =	 1995,
  c-ananth =	 {A similar but slightly more sophisticated approach
                  was given by Simmons and Koenig [Simmons95], in
                  which the environment is modeled using a POMDP that
                  updates belief states based on observations received
                  by the robot.},
}

@InProceedings{Simmons95iros,
  author =	 {R. Simmons and E. Krotkov and L. Chrisman and
                  F. Cozman and R. Goodwin and M. Herbert},
  title =	 {Experience with Rover Navigation for Lunar-Like
                  Terrains},
  booktitle =	 ICRA,
  pages =	 {441-446},
  year =	 1995
}

@InProceedings{Simon00,
  author =	 {G.Simon and A.Fitzgibbon and A.Zisserman},
  title =	 {Markerless Tracking Using Planar Structures in the
                  Scene},
  booktitle =	 {ISAR},
  year =	 2000,
}

@InProceedings{Simon02,
  author =	 {G.Simon and M.Berger},
  title =	 {Reconstructing while Registering: a Novel Approach
                  for Markerless Augmented Reality},
  booktitle =	 {ISMAR},
  year =	 2002,
}

@InProceedings{Simon02bmvc,
  author =	 {G.Simon and M.Berger},
  title =	 {Real Time Registration of Known or Recovered
                  Multi-Planar Structures: Application to AR},
  booktitle =	 {BMVC},
  year =	 2002,
}

@Article{Sin95,
  author =	 {B. Sin and J.H. Kim},
  title =	 {Nonstationary hidden {M}arkov model},
  journal =	 {Segnal Process},
  year =	 1995,
  volume =	 46,
  pages =	 {31-46},
}

@Article{Singer74,
  author =	 {R.A. Singer and R.G. Sea and K. Housewright},
  title =	 {Derivation and evaluation of improved tracking
                  filters for use in dense multitarget environments},
  journal =	 {IEEE Trans. Information Theory},
  year =	 1974,
  volume =	 20,
  pages =	 {423-432},
  month =	 {July},
}

@InProceedings{Singh00icra,
  author =	 {S. Singh and R. Simmons and T. Smith and A Stentz
                  and V Verma and A Yahja and K Schwehr},
  title =	 {Recent Progress in Local and Global Traversability
                  for Planetary Rovers},
  booktitle =	 ICRA,
  year =	 2000,
  pages =	 {1194-1200},
}

@InProceedings{Sinha04cvpr,
  author =	 {S. N. Sinha and M. Pollefeys and L. McMillan},
  fullauthor =	 {Sudipta N. Sinha and Marc Pollefeys and Leonard
                  McMillan},
  title =	 {Camera Network Calibration from Dynamic Silhouettes},
  booktitle =	 CVPR,
  year =	 2004,
}

@InProceedings{Sinha04omnivis,
  author =	 {S.N. Sinha and M. Pollefeys},
  title =	 {Towards Calibrating a Pan-Tilt-Zoom Camera Network},
  booktitle =	 {OMNIVIS: Omnidirectional Vision and Camera Networks},
  year =	 2004,
}

@Article{Sinkhorn64,
  author =	 {R. Sinkhorn},
  fullauthor =	 {Richard Sinkhorn},
  title =	 {A relationship between arbitrary positive matrices
                  and doubly stochastic matrices},
  journal =	 {Annals of Mathematica Statistics},
  year =	 1964,
  volume =	 35,
  number =	 2,
  pages =	 {876-879},
  month =	 {June},
}

@Article{Sirovich87,
  AUTHOR =	 "Sirovich, L. and Kirby, M.",
  TITLE =	 "Low Dimensional Procedure for the Characterization
                  of Human Faces",
  JOURNAL =	 "JOSA-A",
  VOLUME =	 4,
  YEAR =	 1987,
  NUMBER =	 3,
  PAGES =	 "519-524"
}

@Article{Sittler64,
  author =	 {R.W. Sittler},
  title =	 {An optimal data association problem in surveillance
                  theory},
  journal =	 {IEEE Transactions on Military Electronics},
  year =	 1964,
  volume =	 {MIL-8},
  pages =	 {125-139},
  month =	 {April},
}

@inproceedings{Sivic05,
  author =	 "Josef Sivic and Bryan Russell and Alexei A. Efros
                  and Andrew Zisserman and Bill Freeman",
  title =	 "Discovering Objects and Their Location in Images",
  booktitle =	 ICCV,
  year =	 2005
}

@article{Slabaugh01vg,
  title =	 {{A Survey of Methods for Volumetric Scene
                  Reconstruction from Photographs}},
  author =	 {Slabaugh, G. and Culbertson, B. and Malzbender,
                  T. and Schafer, R.},
  journal =	 {Volume Graphics 2001: Proceedings of the Joint IEEE
                  Tcvg and Eurographics Workshop in Stony Brook, New
                  York, Usa, June 21-22, 2001},
  year =	 2001,
  publisher =	 {Springer}
}

@Book{Slama80book,
  editor =	 {C.C. Slama},
  title =	 {Manual of Photogrammetry},
  publisher =	 {American Society of Photogrammetry and Remote
                  Sensing},
  year =	 1980,
  address =	 {Falls Church, VA},
}

@inproceedings{Sminchisescu03,
  author =	 {C. Sminchisescu and B. Triggs},
  title =	 {Kinematic Jump Processes For Monocular {3D} Human
                  Tracking},
  booktitle =	 CVPR,
  year =	 2003,
  pages =	 {69-76},
}

@InProceedings{Smith05,
  author =	 {K. Smith and D. Gatica-Perez and J. M. Odobez},
  title =	 {Using Particles to Track Varying Numbers of
                  Interacting People},
  booktitle =	 CVPR,
  year =	 2005,
}

@InProceedings{Smith06bmvc,
  author =	 {P. Smith and I. Reid and A. Davison},
  fullauthor =	 {Paul Smith and Ian Reid and Andrew Davison},
  title =	 {Real-Time Monocular {SLAM} with Straight Lines},
  booktitle =	 BMVC,
  month =	 {Sep},
  year =	 2006,
  abstract =	 {The use of line features in real-time visual
                  tracking applications is commonplace when a prior
                  map is available, but building the map while
                  tracking in real-time is much more difficult. We
                  describe how straight lines can be added to a
                  monocular Extended Kalman Filter Simultaneous
                  Mapping and Localisation (EKF SLAM) system in a
                  manner that is both fast and which integrates easily
                  with point features. To achieve real-time operation,
                  we present a fast straight-line detector that
                  hypothesises and tests straight lines connecting
                  detected seed points. We demonstrate that the
                  resulting system provides good camera localisation
                  and mapping in real-time on a standard workstation,
                  using either line features alone, or lines and
                  points combined.},
  c-kaess =	 {Claims to be first monocular real-time SLAM using
                  lines. Describes a fast straight line detection
                  algorithm, that does not aim at extracting all
                  lines. Lines are initialized as semi-infinite
                  planes. Preliminary SLAM results combining points
                  and lines are shown.},
}

@Article{Smith75itac,
  author =	 {P.L. Smith and G. Buechler},
  title =	 {A branching algorithm for discriminating and
                  tracking multiple objects},
  journal =	 ITAC,
  year =	 1975,
  volume =	 20,
  pages =	 {101-104},
}

@Article{Smith87,
  author =	 {R. Smith and P. Cheeseman},
  title =	 {On the representation and estimation of spatial
                  uncertainty},
  journal =	 IJRR,
  Volume =	 5,
  number =	 4,
  pages =	 {56-68},
  year =	 1987,
  r-DurrantWhyte06ram ={Work by Smith and Cheesman [this] and
                  Durrant-Whyte [DurrantWhyte88tra] established a
                  statistical basis for describing relationships
                  between landmarks and manipulating geometric
                  uncertainty. A key element of this work was to show
                  that there must be a high degree of correlation
                  between estimates of the location of different
                  landmarks in a map and that indeed these
                  correlations would grow with successive
                  observations.},
}

@InProceedings{Smith87b,
  author =	 {R. Smith and M. Self and P. Cheeseman},
  title =	 {A stochastic map for uncertain spatial
                  relationships},
  booktitle =	 {Int. Symp on Robotics Research},
  year =	 1987,
}

@InCollection{Smith90,
  author =	 {R. Smith and M. Self and P. Cheeseman},
  title =	 {Estimating uncertain spatial relationships in
                  {R}obotics},
  booktitle =	 {Autonomous Robot Vehicles},
  publisher =	 {Springer-Verlag},
  editor =	 {I. Cox and G. Wilfong},
  PAGES =	 {167--193},
  year =	 1990,
  abstract =	 {In this paper, we describe a representation for
                  spatial information, called the stochastic map, and
                  associated procedures for building it, reading
                  information from it, and revising it incrementally
                  as new information is obtained. The map contains the
                  estimates of relationships among objects in the map,
                  and their uncertainties, given all the available
                  information. The procedures provide a general
                  solution to the problem of estimating uncertain
                  relative spatial relationships. The estimates are
                  probabilistic in nature, an advance over the
                  previous, very conservative, worst-case approaches
                  to the problem. Finally, the procedures are
                  developed in the context of state-estimation and
                  filtering theory, which provides a solid basis for
                  numerous extensions.},
  r-DurrantWhyte06ram ={This paper showed that as a mobile robot moves
                  through an unknown environment taking relative
                  observations of landmarks, the estimates of these
                  landmarks are all necessarily correlated with each
                  other because of the common error in estimated
                  vehicle location [27]. The implication of this was
                  profound: A consistent full solution to the combined
                  localisation and mapping problem would require a
                  joint state composed of the vehicle pose and every
                  landmark position, to be updated following each
                  landmark observation. In turn, this would require
                  the estimator to employ a huge state vector (of
                  order the number of landmarks maintained in the map)
                  with computation scaling as the square of the number
                  of landmarks.},
}

@incollection{Smith91,
  AUTHOR =	 {R. Smith and M. Self and P. Cheeseman},
  TITLE =	 {A Stochastic Map for Uncertain Spatial
                  Relationships},
  YEAR =	 1991,
  BOOKTITLE =	 {Autonomous Mobile Robots: Perception, Mapping, and
                  Navigation (Vol. 1)},
  EDITOR =	 {S. S. Iyengar and A. Elfes},
  PUBLISHER =	 {IEEE Computer Society Press},
  ADDRESS =	 {Los Alamitos, CA},
  PAGES =	 {323-330}
}

@Article{Smith92,
  author =	 "A.F.M. Smith and A.E. Gelfand",
  title =	 "Bayesian Statistics Without Tears: A
                  Sampling-Resampling Perspective",
  journal =	 "American Statistician",
  year =	 1992,
  volume =	 46,
  number =	 2,
  pages =	 "84-88"
}

@PhdThesis{Smith98,
  author =	 {C.M. Smith},
  title =	 {Integrating Mapping and Navigation},
  school =	 {Massachusetts Institute of Technology},
  year =	 1998,
}

@Article{Smyth98prl,
  author =	 "P. Smyth",
  title =	 "Belief Networks, Hidden {M}arkov Models, and
                  {M}arkov Random Fields: a Unifying View",
  journal =	 PRL,
  year =	 1998,
}

@inproceedings{Snavely06siggraph,
  author =	 "N. Snavely and S.M. Seitz and R. Szeliski",
  title =	 "Photo Tourism: {E}xploring Photo Collections in
                  3{D}",
  booktitle =	 SIGGRAPH,
  year =	 2006,
  pages =	 "835-846",
  abstract =	 {We present a system for interactively browsing and
                  exploring a large unstructured collection of
                  photographs of a scene using a novel 3D
                  interface. Our system consists of an image-based
                  modeling front end, which automatically computes the
                  viewpoint of each photograph as well as a sparse 3D
                  model of the scene and image to model
                  correspondences. Our photo navigation tool uses
                  imagebased rendering techniques to smoothly
                  transition between photographs, while also enabling
                  full 3D navigation and exploration of the set of
                  images and world geometry, along with auxiliary
                  information such as overhead maps. Our system also
                  makes it easy to construct photo tours of scenic or
                  historic locations, as well as to annotate image
                  details, which are automatically transferred to
                  other relevant images in the collection. We
                  demonstrate our system on several large personal
                  photo collections as well as images gathered from
                  photo sharing Web sites on the Internet.},
}

@inproceedings{Snavely08siggraph,
  author =	 "N. Snavely and R. Garg and S. M. Seitz and
                  R. Szeliski",
  title =	 "{F}inding {P}aths through the {W}orld's {P}hotos",
  booktitle =	 SIGGRAPH,
  year =	 "2008",
}

@InProceedings{Soatto01iccv,
  author =	 "S. Soatto and G. Doretto and Y.N. Wu",
  TITLE =	 {{D}ynamic {T}extures},
  booktitle =	 ICCV,
  PAGES =	 {439-446},
  year =	 2001,
}

@InProceedings{Soatto93cvpr,
  author =	 {S. Soatto and P. Perona and R. Frezza and G. Picci},
  title =	 {Recursive motion and structure estimation with
                  complete error characterization},
  booktitle =	 CVPR,
  pages =	 {428-433},
  year =	 1993,
}

@PhdThesis{Soatto96thesis,
  author =	 {S. Soatto},
  title =	 {A Geometric Framework for Dynamic Vision},
  school =	 {California Institute of Technology},
  year =	 1996,
}

@Article{Soatto97ijcv,
  author =	 {S. Soatto and P. Perona},
  title =	 {Recursive 3-d visual motion estimation using
                  subspace constraints},
  journal =	 IJCV,
  year =	 1997,
  volume =	 22,
  number =	 3,
  pages =	 {235-259},
}

@InProceedings{Sobers2009gnc,
  author =	 {Michael D. Sobers and Girish Chowdhary and Eric N. Johnson},
  title =	 {Indoor Navigation for Unmanned Aerial Vehicles},
  booktitle =	 GNC,
  year =	 2009,
}

@Misc{Sokal96,
  author =	 "A.D. Sokal",
  title =	 "Monte {C}arlo Methods in Statistical Mechanics:
                  Foundations and New Algorithms",
  year =	 1996,
}

@InProceedings{Sola07vslam,
  author =	 {J. Sola},
  fullauthor =	 {Joan Sola},
  title =	 {Multi-camera {VSLAM}: from former information losses
                  to self-calibration},
  booktitle =	 {IROS visual SLAM workshop},
  location =	 {San Diego},
  month =	 {Oct},
  year =	 2007,
  abstract =	 {Visual SLAM is, in recent years, a very active
                  research area, the result of activities in the
                  convergence of the robotics and computer vision
                  communities. We present an overview of techniques,
                  from classical filtering to bundle adjustment
                  solutions, for both monocular and stereo (or
                  multicamera) systems, and emphasize that classical
                  SLAM solutions have been discarding precious sensory
                  information. In particular, the ability of vision to
                  sense objects at infinity should be exploited at its
                  maximum because it is precisely these remote objects
                  that will provide long-term, stable angular
                  references (in the way a compass would
                  do). Monocular SLAM systems have already solved this
                  issue, but stereo and multicamera systems have
                  not. We propose in these cases to use monocular SLAM
                  algorithms using fusion to incorporate all the
                  information. Numerous advantages like
                  desynchronization of the sensors firing, the
                  possibility of using several unequal cameras, or
                  selfcalibration, will naturally arise. We develop a
                  particular method for extrinsically decalibrated
                  stereo systems to illustrate the proposed ideas. We
                  evaluate the method with a real indoor experiment,
                  and highlight and discuss both its assets and
                  drawbacks.},
}

@Article{Sola08tro,
  fullauthor =   {Joan Sola and Andre Monin and Michel Devy and Teresa Vidal-Calleja},
  author =       {J. Sola and A. Monin and M. Devy and T. Vidal-Calleja},
  title =        {Fusing Monocular Information in Multicamera {SLAM}},
  journal =      TRO,
  volume =       24,
  number =       5,
  month =        {Oct},
  year =         2008,
  pages =        {958-968},
}

@Article{Song03pami,
  author =	 {Y. Song and L. Goncalves and P. Perona},
  title =	 {Unsupervised learning of human motion},
  journal =	 PAMI,
  volume =	 25,
  number =	 7,
  month =	 {July},
  year =	 2003,
  pages =	 {814-827},
}

@article{Sosic91sigart,
  author =	 {R. Sosic and J. Gu},
  fullauthor =	 {Rok Sosic and Jun Gu},
  title =	 {3,000,000 Queens in less than one minute},
  journal =	 {SIGART Bull.},
  volume =	 2,
  number =	 2,
  year =	 1991,
  issn =	 {0163-5719},
  pages =	 {22--24},
  doi =		 {http://doi.acm.org/10.1145/122319.122325},
  publisher =	 {ACM Press},
  address =	 {New York, NY, USA},
}

@article{Spetsakis91,
  AUTHOR =	 "Spetsakis, M. and Aloimonos, Y.",
  TITLE =	 "A Multi-frame Approach to Visual Motion Perception",
  JOURNAL =	 IJCV,
  VOLUME =	 6,
  YEAR =	 1991,
  NUMBER =	 3,
  MONTH =	 "August",
  PAGES =	 "245-255"
}

@InProceedings{Spielman04stoc,
  author =	 {D.A. Spielman and S. Teng},
  fullauthor =	 {Daniel A. Spielman and Shang-Hua Teng},
  title =	 {Nearly-Linear Time Algorithms for Graph
                  Partitioning, Graph Sparsification, and Solving
                  Linear Systems},
  booktitle =	 STOC,
  pages =	 {81--90},
  year =	 2004,
}

@incollection {Sprague04nips,
  author =	 "N. Sprague and D. Ballard",
  fullauthor =	 "Nathan Sprague and Dana Ballard",
  title =	 "Eye Movements for Reward Maximization",
  booktitle =	 "Advances in Neural Information Processing Systems
                  16",
  editor =	 "Sebastian Thrun and Lawrence Saul and Bernhard
                  {Sch\"{o}lkopf}",
  publisher =	 "MIT Press",
  address =	 "Cambridge, MA",
  year =	 2004,
  abstract =	 {Recent eye tracking studies in natural tasks suggest
                  that there is a tight link between eye movements and
                  goal directed motor actions. However, most existing
                  models of human eye movements provide a bottom up
                  account that relates visual attention to attributes
                  of the visual scene. The purpose of this paper is to
                  introduce a new model of human eye movements that
                  directly ties eye movements to the ongoing demands
                  of behavior. The basic idea is that eye movements
                  serve to reduce uncertainty about environmental
                  variables that are task relevant. A value is
                  assigned to an eye movement by estimating the
                  expected cost of the uncertainty that will result if
                  the movement is not made. If there are several
                  candidate eye movements, the one with the highest
                  expected value is chosen. The model is illustrated
                  using a humanoid graphic figure that navigates on a
                  sidewalk in a virtual urban environment. Simulations
                  show our protocol is superior to a simple round
                  robin scheduling mechanism.},
  quotes =	 {Our sidewalk navigation model has three behaviors,
                  sidewalk following, obstacle avoidance, and litter
                  collection.},
  r-Hayhoe05tics ={The three hierarchical levels are illustrated in
                  the ?alter?humanoid simulation conducted by
                  \citet{Sprague04nips}. In this simulation the
                  direction of gaze is entirely controlled by rewards
                  that are learned en route.},
  c-dellaert =	 {RL simulation, SAB-like, what's to learn?},
}

@PhdThesis{Sprague04thesis,
  author =	 {Nathan Sprague},
  title =	 {Learning to Coordinate Visual Behaviors},
  school =	 {University of Rochester Computer Science Department},
  year =	 {2004},
  quotes =	 {The most striking feature of the eye-track record is
                  the fact that a large percentage of fixations could
                  be definitively associated with one of a just a few
                  functions: finding objects, manipulating objects, or
                  checking the state of some variable. These data
                  present a compelling picture of how vision is used
                  by humans. The visual system does not passively pass
                  information along to be processed as some later
                  stage. Rather, the eyes are constantly seeking out
                  precisely the information that is needed for tight
                  closed loop control of behavior.},
  c-dellaert =	 {RL simulation, SAB-like, what's to learn?},
}

@InProceedings{Srinivas90,
  author =	 {C. Srinivas and M.D. Srinath},
  title =	 {A stochastic model-based approach for simultaneous
                  restoration of multiple miss-registered images},
  booktitle =	 SPIE,
  pages =	 {1416-1427},
  year =	 1990,
  volume =	 1360,
}

@Article{Srinivasan09ram,
  author =	 {Mandyam V. Srinivasan and Saul Thurrowgood and Dean Soccol},
  title =	 {Competent Vision and Navigation Systems},
  journal = 	 {{IEEE Robotics and Automation Magazine}},
  year = 	 2009,
  volume =	 16,
  number =	 3,
  pages =	 {59-71},
  added-by =	 {richard},
}

@InProceedings{Stachniss04iros,
  author =	 {Stachniss, C. and Haehnel, D. and Burgard, W.},
  title =	 {Exploration with Active Loop-Closing for {FastSLAM}},
  booktitle =	 IROS,
  year =	 2004
}

@InProceedings{Stachniss05rss,
  TITLE =	 {Information Gain-based Exploration Using
                  Rao-Blackwellized Particle Filters},
  AUTHOR =	 {Stachniss, C. and Grisetti, G. and Burgard, W.},
  BOOKTITLE =	 RSS,
  YEAR =	 2005,
  pages =	 {65--72}
}

@inproceedings{Stamos00,
  author =	 {Stamos, I. and Allen, P.},
  title =	 {3-D Model Construction Using Range and Image Data},
  booktitle =	 CVPR,
  year =	 2000,
}

@inproceedings{Stamos00icra,
  author =	 {Stamos, I. and Allen, P.},
  title =	 {Integration of Range and Image Sensing for
                  Photorealistic 3D Modelling},
  booktitle =	 ICRA,
  year =	 2000,
}

@inproceedings{Stamos01,
  author =	 {Stamos, I. and Allen, P.},
  title =	 {Automatic registration of 2D with 3D imagery in
                  urban environments},
  booktitle =	 ICCV,
  year =	 2001,
}

@inproceedings{Stamos02,
  author =	 {Stamos, I. and Allen, P.},
  title =	 {Geometry and Texture Recovery of Scenes of Large
                  Scale},
  booktitle =	 {Computer Vision and Image Understanding},
  year =	 2002,
}

@inproceedings{Stamos03,
  author =	 {Stamos, I. and Leordenau, M.},
  title =	 {Automated Feature-Based Range Registration of Urban
                  Scenes of Large Scale},
  booktitle =	 CVPR,
  year =	 2003,
}

@inproceedings{Stamos04,
  author =	 {Stamos, I. and Leordeanu, M.},
  title =	 {Efficient Model Creation of Large Structures based
                  on Range Segmentation},
  booktitle =	 {3D Data Processing Visualization and Transmission},
  year =	 2004,
}

@inproceedings{Stamos06,
  author =	 {Stamos, I. and Yu, G. and Wolberg, G. and Zokai, S.},
  title =	 {3D Modeling Using Planar Segments and Mesh Elements},
  booktitle =	 {3D Data Processing Visualization and Transmission},
  year =	 2006,
}

@article{Starink95,
  AUTHOR =	 "Starink, J.P.P. and Backer, E.",
  TITLE =	 "Finding Point Correspondences Using Simulated
                  Annealing",
  JOURNAL =	 PR,
  VOLUME =	 28,
  YEAR =	 1995,
  NUMBER =	 2,
  MONTH =	 "February",
  PAGES =	 "231-240"
}

@Article{Stark89,
  author =	 {H.~Stark and P.~Oskoui},
  title =	 {High-Resolution Image Recovery from Image-Plane
                  Arrays, Using Convex Projections},
  journal =	 josaa,
  year =	 1989,
  volume =	 6,
  pages =	 {1715--1726}
}

@InProceedings{Starner95fg,
  author =	 "T. Starner and A. Pentland",
  title =	 "Visual recognition of american sign language using
                  hidden {M}arkov models",
  booktitle =	 "International Workshop on Automatic Face and Gesture
                  Recognition",
  pages =	 "189--194",
  year =	 1995,
}

@InProceedings{Starner98pami,
  author =	 "T. Starner and J. Weaver and A. Pentland",
  title =	 "Real-Time American Sign Language Recognition Using
                  Desk and Wearable Computer Based Video",
  booktitle =	 PAMI,
  pages =	 "1371--1375",
  year =	 1998,
}

@InProceedings{Stasse06iros,
  author =	 {O. Stasse and A.J. Davison and R. Sellaouti and
                  K. Yokoi},
  fullauthor =	 {Olivier Stasse and Andrew J. Davison and Ramzi
                  Sellaouti and Kazuhito Yokoi},
  title =	 {Real-time {3D SLAM} for Humanoid Robot considering
                  Pattern Generator Information},
  booktitle =	 IROS,
  location =	 {Beijing, China},
  month =	 {Oct},
  year =	 2006,
  abstract =	 {Humanoid robotics and SLAM (Simultaneous
                  Localisation and Mapping) are certainly two of the
                  most significant themes of the current worldwide
                  robotics research effort, bu tthe two fields have up
                  until now largely run independent parallel paths,
                  despite the obvious benefit to be gained in joining
                  the two. The next major step forward in humanoid
                  robotics will be increased autonomy, and the ability
                  of a robot to create its own world map on the fly
                  will be a significant enabling
                  technology. Meanwhile, SLAM techniques have found
                  most success with robot platforms and sensor
                  configurations which are outside of the humanoid
                  domain. Humanoid robots move with high linear and
                  angular accelarations in full 3D, and normally only
                  vision is available as an outward-looking
                  sensor. Building on recently published work on
                  monocular SLAM using vision, and on pattern
                  generation, we show that real-time SLAM for a
                  humanoid can indeed be achieved. Using HRP-2, we
                  present results in which a sparse 3D map of visual
                  landmarks is acquired on the fly using a single
                  camera and deonstrated loop closing and drift-free
                  3D motion estimation within a typical cluttered
                  indoor environment. This is achieved by tightly
                  coupling the pattern generator, the robot odometry
                  and inertial sensing to aid visual mapping within a
                  standard EKF framework. To our knowledge this is the
                  first implementation of real-time 3D SLAM for a
                  humanoid robot able to demonstrate loop closing.},
  c-kaess =	 {Uses Davison03iccv for the first visual SLAM on a
                  humanoid. Uses trinocular stereo and a gyro, and
                  shows loop closing. Uses "planning information from
                  the robot's pattern generator for walking motions"
                  as observation input to the EKF.},
}

@Article{Stauder99multimedia,
  author =	 {J. Stauder and R. Mech and J. Ostermann},
  title =	 {Detection of Moving Cast Shadows for Object
                  Segmentation},
  journal =	 {IEEE Transactions of Multimedia},
  year =	 1999,
  volume =	 1,
  number =	 1,
  pages =	 {65-76},
  month =	 {March},
  c-houdan =	 {Complete framework that uses edge detection and
                  frame difference to detect shadows, especially
                  penumbra shadow. But the computation load is high.},
}

@Article{Stauffer00pami,
  author =	 {C. Stauffer and W.E.L. Grimson},
  title =	 {{Learning Patterns of Activity Using Real-Time
                  Tracking}},
  journal =	 PAMI,
  year =	 2000,
  volume =	 22,
  number =	 8,
  pages =	 {747-757},
}

@InProceedings{Stauffer03cvpr,
  author =	 {C. Stauffer and K. Tieu},
  fullauthor =	 {Chris Stauffer and Kinh Tieu},
  title =	 {Automated multi-camera planar tracking
                  correspondence modeling},
  booktitle =	 CVPR,
  year =	 2003,
}

@InProceedings{Stauffer99cvpr,
  author =	 {C. Stauffer and W.E.L. Grimson},
  title =	 {Adaptive Background Mixture Models for Real-time
                  Tracking},
  booktitle =	 CVPR,
  pages =	 {246-252},
  year =	 1999,
  volume =	 2,
  abstract =	 { A common method for real-time segmentation of
                  moving regions in image sequences involves back-
                  ground subtraction, or thresholding the error
                  between an estimate of the image without moving
                  objects and the current image. The numerous
                  approaches to this problem differ in the type of
                  background model used and the procedure used to
                  update the model. This paper discusses modeling each
                  pixel as a mixture of Gaussians and using an on-line
                  approximation to update the model. The Gaussian
                  distributions of the adaptive mixture model are then
                  evaluated to determine which are most likely to
                  result from a background process. Each pixel is
                  classified based on whether the Gaussian
                  distribution which represents it most effectively is
                  considered part of the background model. This
                  results in a stable, real-time outdoor tracker which
                  reliably deals with lighting changes, repetitive
                  motions from clutter, and long-term scene
                  changes. This system has been run almost
                  continuously for 16 months, 24 hours a day, through
                  rain and snow.},
  c-houdan =	 {classic paper on mixture Gaussian models for
                  background subtraction, the K models include both
                  foreground and background},
}

@inproceedings{Steedly03iccv,
  author =	 "D. Steedly and I. Essa and F. Dellaert",
  title =	 "Spectral Partitioning for Structure From Motion",
  booktitle =	 "{ICCV}",
  year =	 "2003"
}

@Book{Stengel86,
  author =	 "R. F Stengel",
  title =	 "Optimal Control and Estimation",
  publisher =	 "Dover Publications Inc.",
  year =	 1986,
  address =	 "New York",
}

@InProceedings{Stenger03a,
  author =	 {Stenger, B. and Thayananthan, A. and Torr,
                  P. H. S. and Cipolla, R.},
  title =	 {Filtering Using a Tree-Based Estimator},
  booktitle =	 {Proc. 9th International Conference on Computer
                  Vision},
  pages =	 {1063--1070},
  year =	 2003,
  volume =	 {II},
  address =	 {Nice, France},
  month =	 {October}
}

@inproceedings{Stentz94icra,
  author =	 {Anthony Stentz},
  title =	 {Optimal and Efficient Path Planning for
                  Partially-Known Environments},
  booktitle =	 ICRA,
  pages =	 {3310--3317},
  month =	 {May},
  year =	 {1994},
  volume =	 {4},
}

@InProceedings{Stentz97,
  title =	 {Best Information Planning for Unknown, Uncertain and
                  Chaning Domains},
  author =	 {A. Stentz},
  booktitle =	 {Proc. AAAI-97 Workshop on On-Line-Search},
  year =	 1997,
}

@Article{Stewart00cse,
  author =	 {Stewart, G.W.},
  title =	 {The decompositional approach to matrix computation},
  pages =	 {50--59},
  journal =	 {Computing in Science \& Engineering},
  volume =	 2,
  number =	 1,
  month =	 {Jan.-Feb.},
  year =	 2000,
  note =	 {Special issue on the Top 10 Algorithms in {Science}
                  \& {Engineering}},
}

@INPROCEEDINGS{Stewart03uia,
  AUTHOR =	 "B. Stewart and J. Ko and D. Fox and K. Konolige",
  TITLE =	 "The Revisiting Problem in Mobile Robot Map Building:
                  A Hierarchical {Bayesian} Approach",
  crossref =	 {_UAI03},
  PAGES =	 "551--558",
  r-Thrun03isrr ={If two robots discover similar maps, are they
                  actually in the same environment, or are these two
                  different parts of the environment that look alike?
                  Clearly, this question is trivially answered if the
                  robots start at the same location. If their initial
                  location is unknown it creates a challenging data
                  association problem. This problem was addressed is a
                  recent paper [this]: the idea here is that robots
                  continuously attempt to localize themselves in each
                  other's maps using particle filters. While this is a
                  highly promising approach, it is computationally
                  somewhat expensive, due to the high costs of running
                  K2 particle filters for K robots.},
}

@InProceedings{Stiny72ifip,
  author =	 {G. Stiny and J. Gips},
  title =	 {Shape Grammars and the Generative Specification of
                  Painting and Sculpture},
  booktitle =	 {Proceedings of IFIP Congress 71},
  pages =	 {1460-1465},
  year =	 1972,
  publisher =	 {North-Holland},
}

@Book{Stiny75,
  author =	 {G. Stiny},
  title =	 {Pictorial and Formal Aspects of Shape and Shape
                  Grammars},
  publisher =	 {Basel: Birkhauser},
  year =	 1975,
}

@Article{Stiny77,
  author =	 {G. Stiny},
  title =	 {Ice-ray: A Note on the Generation of Chinese Lattice
                  Designs},
  journal =	 {Environment and Planning B: Planning and Design},
  year =	 1977,
  volume =	 4,
  pages =	 {89-98 },
}

@Article{Stiny78,
  author =	 {G. Stiny and W. J. Mitchell},
  title =	 {The {P}alladian grammar},
  journal =	 {Environment and Planning B},
  year =	 1978,
  volume =	 5,
  pages =	 {5-18},
}

@Article{Stiny80,
  author =	 {G. Stiny},
  title =	 {Introduction to shape and shape grammars},
  journal =	 {Environment and Planning B: Planning and Design},
  year =	 1980,
  volume =	 7,
  pages =	 {343-351 },
}

@Article{Stiny92,
  author =	 {G. Stiny},
  title =	 {Weights},
  journal =	 {Environment and Planning B: Planning and Design},
  year =	 1992,
  volume =	 19,
  pages =	 {413-430 },
}

@PhdThesis{Stolcke94,
  author =	 {Stolcke, A.},
  title =	 {Bayesian Learning of Probabilistic Language Models},
  school =	 {University of California, Berkeley},
  year =	 1994,
}

@Book{Stollnitz96,
  author =	 {E.J. Stollnitz and T.D. DeRose and D.H. Salesin},
  title =	 {Wavelets for computer graphics: theory and
                  applications},
  publisher =	 {Morgan Kaufmann},
  year =	 1996,
}

@Book{Stone99,
  author =	 {L. D. Stone and C. A. Barlow and T. L. Corwin},
  title =	 {Bayesian Multiple Target Tracking},
  publisher =	 {Artech House},
  address =	 {Boston},
  year =	 1999,
}

@Article{Storvik94,
  author =	 {Geir Storvik},
  title =	 {A {B}ayesian Approach to Dynamic Contours through
                  Stochastic Sampling and Simulated Annealing},
  journal =	 PAMI,
  year =	 1994,
  volume =	 16,
  number =	 10,
  pages =	 {976-986},
}


@Article{Stouffs97,
  author =	 {R. Stouffs and R. Krishnamurti},
  title =	 {Sorts: A Concept for Representational Flexibility},
  journal =	 {CAAD Futures},
  year =	 1997,
}

@InProceedings{Stoytchev05,
  author =	 {A. Stoytchev},
  title =	 {Behavior-Grounded Representation of Tool
                  Affordances},
  booktitle =	 ICRA,
  year =	 2005,
  address =	 {Barcelona, Spain},
  month =	 {April 18-22}
}

@Article{Straforini92,
  author =	 {M. Straforini and C. Coelho and M. Campini and
                  V. Torre},
  title =	 {The recovery and understanding of a line drawing
                  from indoor scenes},
  journal =	 PAMI,
  year =	 1992,
  volume =	 14,
  month =	 {February},
  pages =	 {298-303},
}

@Book{Strang86,
  author =	 {Gilbert Strang},
  title =	 {Introduction to Applied Mathematics},
  publisher =	 {Wellesley-Cambridge Press},
  year =	 1986,
  address =	 {Wellesley, MA},
}

@Book{Strang88,
  author =	 {Gilbert Strang},
  title =	 {Linear Algebra and Its Applications, 3rd Edition},
  publisher =	 {Harcourt},
  year =	 1988,
  address =	 {Orland, FL},
}

@InProceedings{Strecha04cvpr,
  author =	 {C. Strecha and R. Fransens and L. Van Gool},
  title =	 {Wide-baseline Stereo from Multiple Views: a
                  Probabilistic Account},
  booktitle =	 CVPR,
  year =	 2004,
  pages =	 {552-559},
  volume =	 2,
}

@InProceedings{Strecha04cvpr,
  author =	 {C. Strecha and R. Fransens and L. Van Gool},
  title =	 {Wide-baseline Stereo from Multiple Views: a
                  Probabilistic Account},
  booktitle =	 CVPR,
  year =	 2004,
  pages =	 {552-559},
  volume =	 2,
}

@InProceedings{Streit94,
  author =	 {R. Streit and T. Luginbuhl},
  title =	 {Maximum likelihood method for probabilistic
                  multi-hypothesis tracking},
  booktitle =	 {Proc. SPIE, Vol. 2335},
  pages =	 {394-405},
  year =	 1994,
  month =	 {April},
}

@inproceedings{Stroupe03icra,
  author =	 "Ashley Stroupe and Tucker Balch",
  title =	 "Behavior-Based Mapping and Tracking with Multi-Robot
                  Teams Using Probabilistic Techniques",
  year =	 2003,
  note =	 "Submitted to ICRA 2003",
}

@article{Sudderth04,
  author =	 {E. B. Sudderth and M. J. Wainwright and
                  A. S. Willsky},
  title =	 {Embedded trees: {E}stimation of {G}aussian
                  {P}rocesses on graphs with cycles},
  journal =	 {IEEE Transactions on Signal Processing},
  year =	 2004,
  volume =	 52,
  number =	 11,
  pages =	 {3136--3150},
}

@inproceedings{Sudderth06cvpr,
  author =	 {E. Sudderth and A. Torralba and W. Freeman and
                  A. S. Willsky},
  title =	 {Depth from Familiar Objects: A Hierarchical Model
                  for 3D Scenes},
  booktitle =	 CVPR,
  year =	 2006,
}

@Article{Suganathan95,
  author =	 "P.N. Suganathan and E.K. Teoh and D.P. Nital",
  title =	 "Pattern recognition by graph matching using {P}otts
                  {MFT} networks",
  journal =	 PR,
  year =	 1995,
  volume =	 28,
  pages =	 "997-1009",
}

@Article{Sugihara88,
  author =	 {K. Sugihara},
  title =	 {Some location problems for robot navigation using a
                  single camera},
  journal =	 CVIU,
  year =	 1988,
  volume =	 42,
  number =	 1,
  pages =	 {112-129},
  month =	 {April},
}

@Article{Sukkarieh03ijrr,
  Author =	 {S. Sukkarieh and E. Nettleton and J-H. Kim and
                  M. Ridley and A. Goktogan and H.F. Durrant-Whyte},
  title =	 {The ANSER project: Data fusion across multiple
                  uninhabited air vehicles},
  journal =	 IJRR,
  year =	 2003,
  volume =	 22,
  number =	 {7/8},
  pages =	 {505-540},
  abstract =	 {The objective of the autonomous navigation and
                  sensing experiment research (ANSER) project is to
                  demonstrate decentralized data fusion (DDF) and
                  simultaneous localization and map building (SLAM)
                  across multiple uninhabited air vehicles (UAVs). To
                  achieve this objective, the project specifies the
                  development of four UAVs, where each UAV houses up
                  to two terrain sensors and an INS/GPS navigation
                  system. The terrain sensors include a scanning
                  radar, laser/vision and standard vision system. The
                  DDF concept has to be shown to be effective both on
                  a single UAV and on multiple UAVs. The proof of the
                  concept will lie in the ability of the DDF structure
                  to conduct multi-target tracking problems as well as
                  SLAM. To obtain this goal, a number of subgoals are
                  required, most of which have never been attempted
                  before on a research level. The objective of this
                  paper is to present these goals as an overview of
                  the ANSER project along with some simulated and
                  real-time results.},
  c-Makarenko04fusion ={Decentralized Data Fusion (DDF) was applied to
                  tracking ground targets using four purpose-built
                  fixed-wing Unmanned Aerial Vehicles}
}

@TechReport{Sukthankar92,
  author =	 "Rahul Sukthankar",
  title =	 "{RACCOON}: A Real-Time Autonomous Car Chaser
                  Operating Optimally at Night",
  institution =	 "Robotics Institute, Carnegie Mellon",
  year =	 1992,
  number =	 "CMU-RI-TR-92-13",
}

@techreport{Sun05tr,
  author =	 {J. Sun and J. M. Rehg and A. Bobick},
  fullauthor =	 {Jie Sun and James M. Rehg and Aaron Bobick},
  title =	 {Learning for Ground Robot Navigation with Autonomous
                  Data Collection},
  number =	 {GIT-GVU-05-29},
  institution =	 {Georgia Institute of Technology},
  address =	 {Atlanta, USA},
  year =	 2005,
}

@InProceedings{Surmann04iav,
  fullauthor =	 {Hartmut Surmann and Andreas Nuechter and Kai
                  Lingemann and Joachim Hertzberg},
  author =	 {H. Surmann and A. Nuechter and K. Lingemann and
                  J. Hertzberg},
  title =	 {{6D} {SLAM} - Preliminary Report on Closing the Loop
                  in six Dimensions},
  booktitle =	 {The 5th Symposium on Intelligent Autonomous
                  Vehicles},
  year =	 2004,
}

@Book{Sutton98book,
  fullauthor =	 {Richard S. Sutton and Andrew G. Barto},
  author =	 {R.S. Sutton and A.G. Barto},
  title =	 {Reinforcement Learning: An Introduction},
  publisher =	 MIT,
  year =	 1998,
  html =
                  {http://www-anw.cs.umass.edu/~rich/book/the-book.html},
}

@Article{Svoboda05presence,
  author =	 {T. Svoboda and D. Martinec and T. Pajdla},
  title =	 {A Convenient Multi-Camera Self-Calibration for
                  Virtual Enviroments},
  journal =	 {PRESENCE: Teleoperators and Virtual Enviroments},
  year =	 2005,
  volume =	 14,
  number =	 4,
}

@InProceedings{Swain90,
  author =	 "M.J. Swain and D.H. Ballard",
  fullauthor =	 "Michael J. Swain and Dana H. Ballard",
  title =	 "Indexing Via Color Histograms",
  booktitle =	 ICCV,
  pages =	 "390-393",
  year =	 1990,
}

@Article{Swendsen87,
  author =	 {R.H.Swendsen and J.S.Wang},
  title =	 {Nonuniversal critical dynamics in {Monte Carlo}
                  simulations},
  journal =	 {Physics Review Letters},
  year =	 1987,
  volume =	 58,
  number =	 2,
  pages =	 {86-88},
}

@inproceedings{Szeliski85,
  author =	 "R. Szeliski and G. Hinton",
  title =	 "Solving Random-Dot Stereograms Using the Heat
                  Equation",
  booktitle =	 CVPR,
  pages =	 "284--288",
  year =	 1985
}

@inproceedings{Szeliski88,
  author =	 "R. Szeliski",
  title =	 "Estimating Motion From Sparse Range Data Without
                  Correspondence",
  booktitle =	 ICCV,
  pages =	 "207--216",
  year =	 1988
}

@Book{Szeliski89,
  author =	 {R. Szeliski},
  title =	 {Bayesian modeling of uncertainty in low-level
                  vision},
  publisher =	 {Kluwer Academic Publishers},
  year =	 1989,
}

@TechReport{Szeliski91,
  author =	 "R. Szeliski and D. Tonnesen",
  title =	 "Surface Modeling with Oriented Particle Systems",
  institution =	 "Digital Equipment Corporation, Cambridge Research
                  Lab",
  year =	 1991,
  number =	 "CRL 91/14",
}

@article{Szeliski92,
  author =	 {R. Szeliski and D. Tonnesen},
  title =	 {Surface Modeling with Oriented Particle Systems},
  journal =	 {Computer Graphics (SIGGRAPH'92)},
  volume =	 26,
  number =	 2,
  pages =	 {185--194},
  month =	 {July},
  year =	 1992,
}

@TechReport{Szeliski93,
  author =	 {R. Szeliski and S.B. Kang},
  title =	 {Recovering {3D} Shape and Motion from Image Streams
                  using Non-Linear Least Squares},
  institution =	 {DEC Cambridge Research Lab},
  number =	 {CRL 93/3},
  year =	 1993,
  c-dellaert =	 {Non-linear minimization instead of EKF,
                  ie. smoothing. Basically a precursor of all
                  bundle-adjustment. Not applied to robotics.},
}

@TechReport{Szeliski93,
  author =	 "R. Szeliski and S.B. Kang",
  title =	 "Recovering {3D} shape and motion from image streams
                  using non-linear least squares",
  institution =	 "DEC Cambridge Research Lab",
  year =	 1993,
  number =	 "CRL 93/3",
}

@TechReport{Szeliski94,
  author =	 {Szeliski, R.},
  title =	 {Image Mosaicing for tele-Reality Applications},
  institution =	 {DEC Cambridge Research Lab},
  year =	 1994,
  month =	 {May},
}

@inproceedings  {Szeliski94b,
  key =		 "Szeliski",
  author =	 "Szeliski, R. and Coughlan, J.",
  fullauthor =	 "R. Szeliski and J. Coughlan",
  title =	 "Hierarchical Spline-Based Image Registration",
  booktitle =	 CVPR,
  publisher =	 "IEEE Computer Society",
  address =	 "Seattle, Washington",
  month =	 "June",
  year =	 1994,
  pages =	 "194-201",
  keywords =	 "motion estimation, spline-based, hierarchical basis
                  splines",
  bibdate =	 "Thu Oct 14 12:30:02 EDT 1993"
}

@Article{Szeliski94vcir,
  author =	 {R. Szeliski and S.B. Kang},
  title =	 {Recovering {3D} shape and motion from image streams
                  using nonlinear least squares},
  journal =	 {Journal of Visual Communication and Image
                  Representation},
  year =	 1994,
  volume =	 5,
  number =	 1,
  month =	 {March},
}

@TechReport{Szeliski95,
  author =	 "R. Szeliski and S.B. Kang",
  title =	 "A Parallel Feature Tracker for Extended Image
                  Sequences",
  institution =	 "DEC Cambridge Research Lab",
  year =	 1995,
  number =	 "CRL 95/2",
}

@article        {Szeliski96,
  key =		 "Szeliski",
  author =	 "Szeliski, R.",
  fullauthor =	 "R. Szeliski",
  title =	 "Video Mosaics for Virtual Environments",
  journal =	 "IEEE Computer Graphics and Applications",
  month =	 "March",
  year =	 1996,
  pages =	 "22-30",
  keywords =	 "image compositing, image registration, tele-reality",
  bibdate =	 "Mon Feb 6 10:39:17 EST 1995"
}

@Article        {Szeliski97siggraph,
  author =	 "Szeliski, R. and Shum, H.-Y.",
  fullauthor =	 "R. Szeliski and Heung-Yeung Shum",
  title =	 "Creating full view panoramic image mosaics and
                  texture-mapped models",
  journal =	 "Computer Graphics (SIGGRAPH'97)",
  publisher =	 "ACM SIGGRAPH",
  address =	 "Proc. SIGGRAPH'97 (Los Angeles)",
  month =	 "August",
  year =	 1997,
  pages =	 "251-258",
  keywords =	 "panoramic image mosaics, texture map extraction",
  bibdate =	 "Mon 04/07/1997 11:32a"
}

@TechReport{Szeliski97tr,
  author =	 {Szeliski, R. and Golland, P.},
  fullauthor =	 {Szeliski, Richard and Golland, Polina},
  title =	 {Stereo Matching with Transparency and Matting},
  institution =	 {Microsoft Research},
  year =	 1997,
}

@InProceedings{Tan94,
  author =	 "Tan, N.T. and G.D. Sullivan and K.D. Baker",
  title =	 "Fast Vehicle Localization and Recognition Without
                  Line Extraction and Matching",
  volume =	 1,
  pages =	 "85-94",
  booktitle =	 BMVC,
  year =	 1994,
}

@InProceedings{Tanahashi02accv,
  author =	 {H. Tanahashi and C. Wang and Y. Niwa and
                  K. Yamamoto},
  title =	 {Generation of Spherical Image Using {3D} Information
                  Obtained from Stereo Omni-directional System
                  ({SOS})},
  booktitle =	 ACCV,
  pages =	 {574-579},
  year =	 2002,
  month =	 {Jan},
}

@InProceedings{Tang02iros,
  author =	 {L. Tang and Yuta, S.},
  title =	 {Indoor navigation for mobile robots using memorized
                  omni-directional images and robot's motion},
  booktitle =	 IROS,
  pages =	 {269 - 274},
  year =	 2002,
  volume =	 1,
}

@Article{Tang92smc,
  author =	 {Y. Tang and C. G. Lee},
  title =	 {A geometric feature relation graph formulation for
                  consistent sensor fusion},
  journal =	 SMC,
  year =	 1992,
  volume =	 22,
  pages =	 {115--129},
  month =	 {January/February},
}

@Article{Tanner81it,
  author =	 {Tanner, R.},
  title =	 {A recursive approach to low complexity codes},
  journal =	 IT,
  year =	 1981,
  volume =	 27,
  number =	 5,
  pages =	 {533--547},
  month =	 {Spetember},
  quotes =	 {To define the new code, all of the nodes of one
                  class are associated with digits of the code; all
                  the nodes of the other are associated with a subcode
                  whose length is the same as the degree of the node.},
  r-Aji00it =	 {Gallager's work \cite{Gallager62it} attracted little
                  attention for 20 years, but in 1981 Tanner
                  \cite{Tanner81it}, realizing the importance of
                  Gallager's work, made an important generalization of
                  low-density parity-check codes, introduced the
                  "Tanner graph" viewpoint, and recast Gallager's
                  algorithm in explicit message-passing form.},
  r-Kschischang01it ={Genealogically, factor graphs are a
                  straightforward generalization of the "Tanner
                  graphs" of Wiberg \cite{Wiberg96thesis}. Tanner
                  \cite{Tanner81it} introduced bipartite graphs to
                  describe families of codes which are generalizations
                  of the low-density parity-check (LDPC) codes of
                  Gallager \cite{Gallager62it}, and also described the
                  sum-product algorithm in this setting.},
  c-dellaert =	 {Origin of tanner graphs/factor graphs.},
}

@Book{Tanner96,
  author =	 {M.A. Tanner},
  title =	 {Tools for Statistical Inference},
  publisher =	 {Springer Verlag},
  ADDRESS =	 {New York},
  NOTE =	 {Third Edition},
  year =	 1996,
}

@InProceedings{Tao00,
  author =	 {Hai Tao and Harpreet S. Sawhney},
  title =	 {Global matching criterion and color segmentation
                  based stereo},
  booktitle =	 {Proc. Workshop on the Application of Computer Vision
                  (WACV2000)},
  pages =	 {246-253},
  year =	 2000,
}

@InProceedings{Tao00cvpr,
  author =	 {H. Tao and H. S. Sawhney and R. Kumar},
  fullauthor =	 {Hai Tao and Harpreet S. Sawhney and Rakesh Kumar},
  title =	 {{Dynamic Layer Representation with Applications to
                  Tracking}},
  booktitle =	 CVPR,
  volume =	 2,
  pages =	 {134-141},
  year =	 2000,
  c-sangmin =	 {The authors present a framework to identify dynamic
                  layers within a video. Their application is to track
                  cars in pre-defined parametric forms
                  (elipses,rectangles) on the highway taped from the
                  airborne camera (with moving bg). They solve
                  tracking problem and appearance learning problem
                  together. The posterior in their problem is the
                  joint distribution on (pixel ownership
                  w.r.t. different layers) ,motion, shape, and
                  apperance over time. In their filtering step, they
                  deterministically update motion & shape parameters
                  using optimization AND build PDFs on pixel
                  ownerships and appearance pixel values with other
                  variables fixed. This filtering step is, in summary,
                  a generalized EM where each variables are updated
                  with others fixed in an iterative fashion. In
                  addition, the background motion is estimated
                  deterministically using searching procedure under
                  plannar motion assumption. One limitation with their
                  approach is that the step of computing the
                  pixel-ownership (masking) is rather limited to
                  certain simple shapes since their algorithm is not
                  very general, as pointed out by Jojic01cvpr. And
                  another limitation is that once the targets are lost
                  during the deterministic filtering steps, it can
                  hardly be recovered.. as they do not maintain
                  multiple hypothesis.}
}

@Article{Tao02,
  author =	 {H. Tao and H. S. Sawhney and R. Kumar},
  title =	 {Object tracking with Bayesian estimation of dynamic
                  layer representations},
  journal =	 PAMI,
  pages =	 {75--89},
  volume =	 {24},
  number =	 {1},
  year =	 {2002},
}

@InProceedings{Tapus04,
  author =	 {Tapus, A. and Tomatis, N. and Siegwart, R.},
  year =	 2004,
  title =	 {Topological Global Localization and Mapping with
                  Fingerprint and Uncertainty},
  booktitle =	 {Proceedings of the International Symposium on
                  Experimental Robotics},
}

@Inproceedings{Tapus05,
  author =	 {A. Tapus and S. Vasudevan and R. Siegwart},
  fullauthor =	 {Adriana Tapus and Shrihari Vasudevan and Roland
                  Siegwart},
  title =	 {Towards a Multilevel Cognitive Probabilistic
                  Representation of Space},
  booktitle =	 {Proceedings of the {I}nternational {C}onference on
                  {H}uman {V}ision and {E}lectronic {I}maging},
  year =	 2005,
}

@PhdThesis{Tapus05thesis,
  author =	 {A. Tapus},
  title =	 "{Topological SLAM - Simultaneous Localization and
                  Mapping with Fingerprints of Places}",
  school =	 {Swiss Federal Institute of Technology Lausanne
                  (EPFL)},
  year =	 2005,
  c-ananth =	 {Similarly, Tapus [Tapus05thesis] proposes the use of
                  POMDPs for disambiguation. The distinguishing
                  features of this work is however, the use of
                  ``fingerprints of places'' that incorporate various
                  different features such as edges, lines, and color
                  histograms, and help in resolving ambiguity to a
                  significant extent.},
}

@Article{Tardos02ijrr,
  author =	 {J.D. Tards and J. Neira and P.M. Newman and
                  J.J. Leonard},
  title =	 {Robust Mapping and Localization in Indoor
                  Environments using Sonar Data},
  journal =	 IJRR,
  volume =	 21,
  number =	 4,
  pages =	 {311-330},
  year =	 2002,
  r-Castellanos07ras ={In [11] Tardos et al. proposed a map
                  building technique in which, instead of building one
                  global map from the beginning of the exploration
                  task, a sequence of local maps of limited size is
                  built, and later joined together, to obtain the
                  global map. Here we show that, not only is map
                  joining computationally more ecient than
                  building one global map from the beginning, as is it
                  shown in [11], but it also allows to attain better
                  consistency in the stochastic map.},
  c-Alireza =	 {They have three main contributions in this paper,
                  among which is a map joining technique that allows
                  the system to build a sequence of independent
                  stochastic maps and joing them in an optimal
                  fashion. Usage of local maps and then joining them
                  is useful for Robot Relocation (Kidnapped Robot,
                  since the robot will start building a local map even
                  though it doesn't know where it is at the
                  beginning), multirobot map building and local map
                  sequencing. Usage of local maps, not only improves
                  the efficiency of solving the SLAM problem, but also
                  decreases the harms of linearization, since locally
                  linearization is not as bad as linearizing the
                  global state.},
  c-dellaert =	 {Create a series of small, local maps to reduce
                  computational complexity. Shown in
                  \cite{Castellanos07ras} to also be beneficial in
                  terms of reducing consistency problems with regards
                  to linearization errors. Also mention multi-robot
                  mapping as an application.},
}

@InProceedings{Tariq04ismar,
  author =	 {S. Tariq and F. Dellaert},
  title =	 {A Multi-Camera 6-{DOF} Pose Tracker},
  booktitle =	 ISMAR,
  pages =	 {296-297},
  year =	 2004,
}

@Book{Tarjan83book,
  author =	 {R.E. Tarjan},
  title =	 {Data Structures and Network Algorithms},
  publisher =	 {SIAM},
  year =	 1983,
  address =	 {Philadelphia},
}

@Article{Tarjan84siam,
  author =	 {R.E. Tarjan and M. Yannakakis},
  title =	 {Simple linear-time algorithms to test chordality of
                  graphs, test acyclicity of hypergraphs and
                  selectively reduce acyclic hypergraphs},
  journal =	 {SIAM J. Comput.},
  year =	 1984,
  volume =	 13,
  number =	 3,
  pages =	 {566--579},
  r-Blair93chapter ={Of the many ways to represent a chordal graph, a
                  particularly useful and compact representation is
                  provided by clique trees \cite{Liu89siam,
                  Tarjan84siam}. ... In a set of unpublished lecture
                  notes, Tarjan introduced a simpler algorithm known
                  as the minimum cardinality search (MCS)
                  algorithm. \cite{Tarjan84siam} described MCS
                  algorithms for both chordal graphs and acyclic
                  hypergraphs. The MCS algorithm for chordal graphs
                  orders the vertices in reverse order beginning with
                  an arbitrary vertex v \in V for which it sets a(v) =
                  n. At each step the algorithm selects as the next
                  vertex to label an unlabeled vertex adjacent to the
                  largest number of labeled vertices, with ties broken
                  arbitrarily. We refer the reader to
                  \cite{Tarjan84siam} for details on how to implement
                  the algorithm to run in O(n + e) time. ... Theorem:
                  Every maximum cardinality search ordering of a
                  chordal graph G is a perfect elimination ordering. },
  r-Kask05ai =	 {Many of the important properties of tree-based
                  processing were discussed and proved within the
                  database community \cite{Beeri83jacm,this}.},
  c-dellaert =	 {maximum cardinality search},
}

@Article{Tarr89,
  author =	 "M Tarr and S Pinker",
  title =	 "Mental rotation and orientation-dependence in shape
                  recognition",
  journal =	 "Cognitive Psychology",
  year =	 "1989",
  volume =	 "21",
  pages =	 "233-282",
}

@InProceedings{Tavakkoli05isvc,
  author =	 {A. Tavakkoli and M. Nicolescu and G. Bebis},
  title =	 {Automatic Robust Background Modeling Using
                  Multivariate Non-parametric Kernel Density
                  Estimation for Visual Surveillance},
  booktitle =	 {International Symposium of Advances in Visual
                  Computing},
  pages =	 {363-370},
  year =	 2005,
  abstract =	 {The final goal for many visual surveillance systems
                  is automatic understanding of events in a
                  site. Higher level processing on video data requires
                  certain lower level vision tasks to be
                  performed. One of these tasks is the segmentation of
                  video data into regions that correspond to objects
                  in the scene. Issues such as automation, noise
                  robustness, adaptation, and accuracy of the model
                  must be addressed. Current background modeling
                  techniques use heuristics to build a representation
                  of the background, while it would be desirable to
                  obtain the background model automatically. In order
                  to increase the accuracy of modeling it needs to
                  adapt to different parts of the same scene and
                  finally the model has to be robust to noise. The
                  building block of the model representation used in
                  this paper is multivariate non-parametric kernel
                  density estimation which builds a statistical model
                  for the background of the video scene based on the
                  probability density function of its pixels. A post
                  processing step is applied to the background model
                  to achieve the spatial consistency of the foreground
                  objects. },
  c-houdan =	 {It is not a good paper, has no much new compared to
                  Elgammal00eccv},
}

@InProceedings{Taylor03iccv,
  author =	 {C. J. Taylor},
  title =	 {Surface Reconstruction from Feature Based Stereo},
  booktitle =	 ICCV,
  pages =	 {184},
  year =	 2003,
}

@InProceedings{Taylor06dsc,
  author =	 {C. J. Taylor and B. Shirmohammadi},
  fullauthor =	 {Camillo J. Taylor and Babak Shirmohammadi},
  title =	 {Self Localizing Smart Camera Networks and their
                  Applications to 3D Modeling},
  booktitle =	 {Workshop on Distributed Smart Cameras (DSC)},
  year =	 2006,
  month =	 "October",
}

@InProceedings{Taylor91,
  author =	 {C. J. Taylor and D. J. Kriegman and P. Anandan},
  title =	 {Structure and motion in two dimensions from multiple
                  images: A least squares approach},
  booktitle =	 {IEEE Workshop on Visual Motion},
  pages =	 {242--248},
  year =	 1991,
  address =	 {Princeton, New Jersey},
  month =	 {October},
  publisher =	 {IEEE Computer Society Press},
}

@TechReport{Taylor94TR,
  author =	 "C.J. Taylor and D.J. Kriegman",
  title =	 "Minimization on the {L}ie group {SO(3)} and related
                  manifolds",
  number =	 9405,
  institution =	 "Yale University",
  year =	 1994,
  month =	 {April},
  address =	 {New Haven, CT}
}

@InCollection{Taylor95,
  author =	 {C. Taylor and D. Kriegman},
  title =	 {Algorithms for vision-based exploration},
  booktitle =	 {The Algorithmic foundations of robotics},
  publisher =	 {A.K. Peters},
  year =	 1995,
  editor =	 {K. Goldberg and D. halperin and J. Latombe and
                  R. Wilson},
  address =	 {Boston, MA},
}

@article{Taylor95pami,
  AUTHOR =	 "Taylor, C.J. and Kriegman, D.J.",
  TITLE =	 "Structure and Motion from Line Segments in Multiple
                  Images",
  JOURNAL =	 PAMI,
  VOLUME =	 17,
  YEAR =	 1995,
  NUMBER =	 11,
  MONTH =	 "November",
  PAGES =	 "1021-1032"
}

@inproceedings{Taylor96eccv,
  author =	 "C.J. Taylor and P.E. Debevec and J. Malik",
  fullauthor =	 "Camillo J. Taylor and Paul E. Debevec and Jitendra
                  Malik",
  title =	 "Reconstructing Polyhedral Models of Architectural
                  Scenes from Photographs",
  booktitle =	 ECCV,
  pages =	 "659-668",
  year =	 1996,
  url =		 "citeseer.nj.nec.com/taylor96reconstructing.html"
}

@article{Teh06jasa,
  author =	 "Y. W. Teh and M. I. Jordan and M. J. Beal and
                  D. M. Blei",
  title =	 "Hierarchical Dirichlet processes",
  journal =	 JASA,
  volume =	 101,
  pages =	 {1566-1581},
  year =	 2006,
}

@InProceedings{Tekalp92,
  author =	 {A.M. Tekalp and M.K. Ozkan and M.I. Sezan},
  title =	 {High-resolution image reconstruction from
                  lower-resolution image sequences and space varying
                  image restoration},
  booktitle =	 ICASSP,
  pages =	 {169-172},
  year =	 1992,
  volume =	 3,
}

@InProceedings{Teller01cvpr,
  author =	 {S. Teller and M. Antone and Z. Bodnar and M. Bosse
                  and S. Coorg and M. Jethwa and and N. Master},
  fullauthor =	 {Seth Teller and Matthew Antone and Zachary Bodnar
                  and Michael Bosse and Satyan Coorg and Manish Jethwa
                  and and Neel Master},
  title =	 {Calibrated, Registered Images of an Extended Urban
                  Area},
  booktitle =	 CVPR,
  year =	 2001,
}

@inproceedings{Teller98iuw,
  author =	 "S. Teller",
  title =	 "Automated urban model acquisition: Project rationale
                  and status",
  booktitle =	 "Proc. of the Image Understanding Workshop",
  pages =	 "455-462",
  address =	 "Monterey, CA",
  year =	 1998,
  url =		 "citeseer.nj.nec.com/teller98automated.html"
}

@Article{Tenenbaum00nc,
  author =	 {J. B. Tenenbaum and W. T. Freeman},
  title =	 {Seperating style and content with bilinear models},
  journal =	 "Neural Computing",
  year =	 2000,
  volume =	 12,
  number =	 6,
  pages =	 {1247-1283},
}

@article{Tenenbaum00science,
  title =	 "A Global Geometric Framework for Nonlinear
                  Dimensionality Reduction",
  author =	 {J. B. Tenenbaum and V. de Silva and J. C. Langford},
  journal =	 {Science},
  volume =	 {290 (5500)},
  pages =	 {2319--2323},
  year =	 2000,
}

@Book{Terras99,
  author =	 {A. Terras},
  fullauthor =	 {Audrey Terras},
  title =	 {Fourier Analysis on Finite Groups and Applications},
  publisher =	 {Cambridge University Press},
  year =	 1999,
  volume =	 43,
  series =	 {London Mathematical Society Student Texts},
}

@Article{Terzopoulos86,
  author =	 {D. Terzopoulos},
  title =	 {Image Analysis using Multigrid Relaxation Methods},
  journal =	 PAMI,
  year =	 1986,
  volume =	 8,
  number =	 2,
  pages =	 {129-139},
  month =	 {March},
}

@Article{Terzopoulos91pami,
  author =	 "D. Terzopoulos and D. Metaxes",
  title =	 "Dynamic {3D} Models with Local and Global
                  Deformations: Deformable Superquadrics",
  journal =	 PAMI,
  year =	 1991,
  volume =	 61,
  number =	 1,
}

@article{Terzopoulos91pami,
  title =	 {{Dynamic 3 D models with local and global
                  deformations: deformable superquadrics}},
  author =	 {Terzopoulos, D. and Metaxas, D.},
  journal =	 PAMI,
  volume =	 13,
  number =	 7,
  pages =	 {703--714},
  year =	 1991
}

@InCollection{Terzopoulos92,
  author =	 "D. Terzopoulos and R. Szeliski",
  crossref =	 "Blake92",
  pages =	 "3-20",
  title =	 "Tracking with {K}alman Snakes",
}

@InProceedings{Thiel92,
  author =	 "E. Thiel and A. Montanvert",
  title =	 "Chamfer Masks: Discrete Distance Functions,
                  Geometrical Properties and Optimization",
  pages =	 "244-247",
  booktitle =	 PR,
  year =	 1992,
  month =	 "August",
}

@InProceedings{Thomanek92,
  author =	 "F. Thomanek and D. Dickmanns",
  title =	 "Obstacle Detection, Tracking and State Estimation
                  for Autonomous Road Vehicle Guidance",
  pages =	 1399,
  booktitle =	 ICRA,
  year =	 1992,
  address =	 "Raleigh, NC",
  month =	 "July",
}

@article{Thomanek96,
  author =	 "Frank Thomanek",
  title =	 "Visuelle Erkennung und Zustandsschtzung von
                  mehreren Straenfahrzeugen zur autonomen
                  Fahrzeugfhrung",
  publisher =	 "VDI Verlag",
  year =	 1996,
  volume =	 12,
  number =	 272,
  journal =	 "Fortshritt-Berichte VDI",
  address =	 "Dsseldorf",
}

@article{Thomason75,
  author =	 "M.G. Thomason",
  title =	 "Stochastic SDTS for correction of errors in
                  context-free languages",
  journal =	 {IEEE Trans. Comp.},
  volume =	 24,
  pages =	 "1211-1216",
  year =	 1975,
}

@InProceedings{Thorpe97,
  author =	 "Chuck Thorpe",
  address =	 "Grenoble, France",
  title =	 "Mixed Traffic and Automated Highways",
  booktitle =	 IROS,
  volume =	 2,
  year =	 1997,
  month =	 "September"
}

@INPROCEEDINGS{Thrun00a,
  AUTHOR =	 {Thrun, S. and Burgard, W. and Fox, D.},
  TITLE =	 {A Real-Time Algorithm for Mobile Robot Mapping With
                  Applications to Multi-Robot and {3D} Mapping},
  YEAR =	 2000,
  BOOKTITLE =	 ICRA,
  PUBLISHER =	 {IEEE},
  ADDRESS =	 {San Francisco, CA},
  abstract =	 {We present an incremental method for concurrent
                  mapping and localization for mobile robots equipped
                  with 2D laser range finders. The approach uses a
                  fast implementation of scan-matching for mapping,
                  paired with a sample-based probabilistic method for
                  localization. Compact 3D maps are generated using a
                  multi-resolution approach adopted from the computer
                  graphics literature, fed by data from a dual laser
                  system. Our approach builds 3D maps of large, cyclic
                  environments in real-time. It is remarkably
                  robust. Experimental results illustrate that
                  accurate maps of large, cyclic environments can be
                  generated even in the absence of any odometric
                  data.},
  r-Thrun03isrr ={A number of papers addresses the problem under the
                  constraint that the initial pose of all robots
                  relative to each other is known approximately.},
  c-dellaert =	 {Best Conference Paper Award, is paper with
                  transversal SICKs, uses particle filters.},
}

@Article{Thrun00ijrr,
  author =	 "S. Thrun and M. Beetz and M. Bennewitz and
                  W. Burgard and A.B. Creemers and F. Dellaert and
                  D. Fox and D. Haehnel and C. Rosenberg and N. Roy
                  and J. Schulte and D. Schulz",
  fullauthor =	 "Sebastian Thrun and M. Beetz and Maren Bennewitz and
                  Wolfram Burgard and A.B. Creemers and Frank Dellaert
                  and Dieter Fox and Dirk Haehnel and Chuck Rosenberg
                  and Nicholas Roy and Jamieson Schulte and Dirk
                  Schulz",
  title =	 "Probabilistic Algorithms and the Interactive Museum
                  Tour-Guide Robot Minerva",
  journal =	 "International Journal of Robotics Research",
  month =	 "November",
  year =	 2000,
  volume =	 19,
  number =	 11,
  pages =	 "972-999",
}

@article{Thrun01ai,
  author =	 "S. Thrun and D. Fox and W. Burgard and F. Dellaert",
  title =	 "Robust {M}onte {C}arlo Localization for Mobile
                  Robots",
  YEAR =	 2000,
  JOURNAL =	 {Artificial Intelligence},
  VOLUME =	 128,
  NUMBER =	 {1-2},
  PAGES =	 {99--141}
}

@Article{Thrun01ijrr,
  author =	 "S. Thrun",
  TITLE =	 "A Probabilistic Online Mapping Algorithm for Teams
                  of Mobile Robots",
  journal =	 IJRR,
  volume =	 20,
  number =	 5,
  pages =	 {335--363},
  year =	 2001,
  abstract =	 {We present an efficient probabilistic algorithm for
                  the concurrent mapping and localization problem that
                  arises in mobile robotics. The algorithm addresses
                  the problem in which a team of robots builds a map
                  online, while simultaneously accommodating errors in
                  their odometry. At the core of the algorithm is a
                  technique that combines fast maximum likelihood map
                  growing with a Monte Carlo localizer that uses
                  particle representations. The combination of both
                  yields an online algorithm that can cope with large
                  odometric errors typically found when mapping
                  environments with cycles. The algorithm can be
                  implemented distributedly on multiple robot
                  platforms, enabling a team of robots to
                  cooperatively generate a single map of their
                  environment. Finally, an extension is described for
                  acquiring three-dimensional maps, which capture the
                  structure and visual appearance of indoor
                  environments in 3D.},
  r-Fox06ieee =	 {If the initial locations of the robots are known,
                  map merging is a rather straightforward extension of
                  single robot mapping},
  c-dellaert =	 {Journal version of Thrun00a},
}

@article{Thrun01online,
  author =	 "S. Thrun",
  title =	 "An online mapping algorithm for teams of mobile
                  robots",
  journal =	 "Int. J. Robotics Research",
  month =	 "May",
  volume =	 20,
  number =	 5,
  pages =	 "335-363",
  year =	 2001,
}

@InCollection{Thrun01smc,
  author =	 {S. Thrun and D. Fox and F. Dellaert and W. Burgard},
  title =	 {Particle filters for Mobile Robot Localization},
  booktitle =	 {Sequential {M}onte {C}arlo Methods in Practice},
  publisher =	 {Springer-Verlag},
  year =	 2001,
  editor =	 {Arnaud Doucet and Nando de Freitas and Neil Gordon},
  address =	 {New York},
  month =	 {January},
}



@INCOLLECTION{Thrun02a,
  author =	 {S. Thrun},
  fullauthor =	 {Sebastian Thrun},
  title =	 {Robotic mapping: a survey},
  booktitle =	 {Exploring artificial intelligence in the new
                  millennium},
  year =	 2003,
  pages =	 {1--35},
  publisher =	 {Morgan Kaufmann, Inc.},
}

@INPROCEEDINGS{Thrun03isrr,
  AUTHOR =	 {S. Thrun and Y. Liu},
  TITLE =	 {Multi-Robot {SLAM} With Sparse Extended Information
                  Filters},
  YEAR =	 2003,
  BOOKTITLE =	 {Proceedings of the 11th International Symposium of
                  Robotics Research (ISRR'03)},
  publisher =	 {Springer},
  address =	 {Sienna, Italy},
  abstract =	 {We present an algorithm for the multi-robot
                  simultaneous localization and mapping (SLAM)
                  problem. Our algorithm enables teams of robots to
                  build joint maps, even if their relative starting
                  locations are unknown and landmarks are
                  ambiguous-which is presently an open problem in
                  robotics. It achieves this capability through a
                  sparse information filter technique, which
                  represents maps and robot poses by Gaussian Markov
                  random fields. The alignment of local maps into a
                  single global maps is achieved by a tree-based
                  algorithm for searching similar-looking local
                  landmark configurations, paired with a hill climbing
                  algorithm that maximizes the overall likelihood by
                  search in the space of correspondences. We report
                  favorable results obtained with a real-world
                  benchmark data set.},
  c-kaess =	 {describes an extension of SEIF to multiple robots
                  with unknown relative initial poses. Makes use of
                  additivity and locality to allow decentralized,
                  multi-robot mapping. Candidates for map fusion are
                  identified by comparing landmarks based on relative
                  distances and angles to close neighbors, that are
                  stored in an SR(?)-tree. Starting with a candidate
                  match, correspondences are added and deleted by
                  recursive search through the space of data
                  associations, guided by a likelihood that
                  incorporates negative information (if there are two
                  landmarks, both robots should see both of them and
                  not just one).},
}

@Article{Thrun04ijrr,
  author =	 {Thrun, S. and Liu, Y. and Koller, D. and Ng,
                  A.Y. and Ghahramani, Z. and Durrant-Whyte, H.},
  title =	 {Simultaneous Localization and Mapping With Sparse
                  Extended Information Filters},
  journal =	 IJRR,
  volume =	 23,
  number =	 {7-8},
  pages =	 {693-716},
  year =	 {2004},
  abstract =	 {This paper describes a scalable algorithm for the
                  simultaneous mapping and localization (SLAM)
                  problem. SLAM is the problem of acquiring a map of a
                  static environment with a mobile robot. The vast
                  majority of SLAM algorithms are based on the
                  extended Kalman filter (EKF). This paper advocates
                  an algorithm that relies on the dual of the EKF, the
                  extended information filter (EIF). We show that when
                  represented in the information form, map posteriors
                  are dominated by a small number of links that tie
                  together nearby features in the map. This insight is
                  developed into a sparse variant of the EIF, called
                  the sparse extended information filters
                  (SEIF). SEIFs represent maps by graphical networks
                  of features that are locally interconnected, where
                  links represent relative information between pairs
                  of nearby features, as well as information about the
                  robot? pose relative to the map. We show that all
                  essential update equations in SEIFs can be executed
                  in constant time, irrespective of the size of the
                  map. We also provide empirical results obtained for
                  a benchmark data set collected in an outdoor
                  environment, and using a multi-robot mapping
                  simulation.},
  r-Wang05isrr = {However, Eustice et al. [Eustice05iros] demonstrated
                  that the process of sparsification proposed in
                  [this] leads to inconsistent estimates.},
}

@Article{Thrun04ijrr,
  AUTHOR =	 {Thrun, S. and Liu, Y. and Koller, D. and Ng,
                  A.Y. and Ghahramani, Z. and Durrant-Whyte, H.},
  TITLE =	 {Simultaneous Localization and Mapping With Sparse
                  Extended Information Filters},
  YEAR =	 2004,
  volume =	 23,
  number =	 {7-8},
  pages =	 {693-716},
  journal =	 IJRR,
}

@ARTICLE{Thrun04tra,
  AUTHOR =	 {Thrun, S. and Martin, C. and Liu, Y. and H\"{a}hnel,
                  D. and Emery-Montemerlo, R. and Chakrabarti, D. and
                  Burgard, W.},
  TITLE =	 {A Real-Time Expectation Maximization Algorithm for
                  Acquiring Multi-Planar Maps of Indoor Environments
                  with Mobile Robots},
  JOURNAL =	 TRA,
  YEAR =	 2004,
  pages =	 {433-443},
  volume =	 20,
  number =	 3,
  month =	 {June},
}

@Book{Thrun05book,
  author =	 {S. Thrun and W. Burgard and D. Fox},
  fullauthor =	 {Sebastian Thrun, Wolfram Burgard and Dieter Fox},
  title =	 {Probabilistic Robotics},
  publisher =	 MIT,
  year =	 2005,
}

@article{Thrun06,
  author =	 {S. Thrun and M. Montemerlo and et al.},
  title =	 {Stanley, the robot that won the {DARPA} Grand
                  Challenge},
  journal =	 {Journal of {F}ield {R}obotics},
  year =	 2006,
  note =	 "In press"
}

@InProceedings{Thrun96aaai,
  author =	 {S. Thrun and A. Br\"{u}cken},
  title =	 "Integrating Topological And Metric Maps For Mobile
                  Robot Navigation",
  crossref =	 {_AAAI96},
  Abstract =	 {Research on mobile robot navigation has produced two
                  major paradigms for mapping indoor environments:
                  grid-based and topological. While grid-based methods
                  produce accurate metric maps, their complexity often
                  prohibits efficient planning and problem solving in
                  large-scale indoor environments. Topological maps,
                  on the other hand, can be used much more
                  efficiently, yet accurate and consistent topological
                  maps are considerably difficult to learn in
                  large-scale environments. This paper describes an
                  approach that integrates both paradigms: grid-based
                  and topological. Grid-based maps are learned using
                  artificial neural networks and Bayesian
                  integration. Topological maps are generated on top
                  of the grid-based maps, by partitioning the latter
                  into coherent regions. By combining both
                  paradigms?rid-based and topological? the approach
                  presented here gains the best of both worlds:
                  accuracy/consistency and efficiency. The paper gives
                  results for autonomously operating a mobile robot
                  equipped with sonar sensors in populated multi-room
                  environments.},
  quotes =	 {Topological maps are built on top of the grid-based
                  maps. The key idea is simple but very effective: The
                  free-space of a grid-based map is partitioned into a
                  small number of regions, separated by critical
                  lines. Critical lines correspond to narrow passages
                  such as doorways. The partitionedmap is then mapped
                  into a isomorphic graph. .. A large series of
                  experiments showed that in a map of moderate size,
                  the efficiency of planning can be increased by three
                  to four orders of magnitude, while the loss in
                  performance is negligible.},
  c-dellaert =	 {Grid-based mapping with sonar, then partition into
                  regions for planning.},
}

@TechReport{Thrun97,
  author =	 {S. Thrun and D. Fox and W. Burgard},
  title =	 {A probabilistic approach to concurrent mapping and
                  localization for mobile robots},
  institution =	 {Carnegie Mellon},
  year =	 1997,
  number =	 {CMU-CS-97-183},
  month =	 {October},
}

@InProceedings{Thrun98aaai,
  author =	 "S. Thrun and S. Gutmann and D. Fox and W. Burgard
                  and B.J. Kuipers",
  title =	 "Integrating Topological And Metric Maps For Mobile
                  Robot Navigation: A Statistical Approach",
  crossref =	 {_AAAI98},
  pages =	 "989-995",
  abstract =	 {The problem of concurrent mapping and localization
                  has received considerable attention in the mobile
                  robotics community. Existing approaches can largely
                  be grouped into two distinct paradigms: topological
                  and metric. This paper proposes a method that
                  integrates both. It poses the mapping problem as a
                  statistical maximum likelihood problem, and devises
                  an efficient algorithm for search in likelihood
                  space. It presents an novel mapping algorithm that
                  integrates two phases: a topological and a metric
                  mapping phase. The topological mapping phase solves
                  a global position alignment problem between
                  potentially indistinguishable, significant
                  places. The subsequent metric mapping phase produces
                  a fine-grained metric map of the environment in
                  floating-point resolution. The approach is
                  demonstrated empirically to scale up to large,
                  cyclic, and highly ambiguous environments.},
  quotes =	 {In the context of mapping, EM iterates two
                  alternating steps: a localization step, in which the
                  robot is localized using a previously computed map,
                  and a mapping step, which computes the most likely
                  map based on the previously pose estimates. .. In
                  the topological mapping step, the robot can only
                  observe whether or not it is at a significant
                  place. .. The robot is not told how many significant
                  places exist in its environment; neither does it
                  know whether or not it visited a significant place
                  more than once. Instead, it guesses the number of
                  nodes as a side-effect of maximizing the map
                  likelihood function.},
  c-dellaert =	 {Should read again, EM-based, forgot the details.},
  c-ananth =	 { Thrun et al. [Thrun98aaai] use the EM algorithm to
                  solve the correspondence problem while building a
                  topological map. The computed correspondence is
                  subsequently used in constructing a metric map.},
}

@ARTICLE{Thrun98ai,
  AUTHOR =	 {S. Thrun},
  YEAR =	 {1998},
  TITLE =	 {Learning Metric-Topological Maps for Indoor Mobile
                  Robot Navigation},
  JOURNAL =	 {Artificial Intelligence},
  VOLUME =	 {99},
  NUMBER =	 {1},
  PAGES =	 {21--71},
  abstract =	 {Autonomous robots must be able to learn and maintain
                  models of their environments. Research on mobile
                  robot navigation has produced two major paradigms
                  for mapping indoor environments: grid-based and
                  topological. While grid-based methods produce
                  accurate metric maps, their complexity often
                  prohibits efficient planning and problem solving in
                  large-scale indoor environments. Topological maps,
                  on the other hand, can be used much more
                  efficiently, yet accurate and consistent topological
                  maps are often difficult to learn and maintain in
                  large-scale environments, particularly if momentary
                  sensor data is highly ambiguous. This paper
                  describes an approach that integrates both
                  paradigms: grid-based and topological. Grid-based
                  maps are learned using artificial neural networks
                  and naive Bayesian integration. Topological maps are
                  generated on top of the grid-based maps, by
                  partitioning the latter into coherent regions. By
                  combining both paradigms, the approach presented
                  here gains advantages from both worlds:
                  accuracy/consistency and efficiency. The paper gives
                  results for autonomous exploration, mapping and
                  operation of a mobile robot in populated multi-room
                  environments.},
  c-dellaert =	 {Journal version of \citet{Thrun96aaai}},
  c-ananth =	 {Thrun [Thrun98ai] first computes a metric map using
                  value iteration and uses thresholding and Voronoi
                  diagrams to extract the topology from this map.}
}

@Article{Thrun98c,
  author =	 {S. Thrun and D. Fox and W. Burgard},
  title =	 {A probabilistic approach to concurrent mapping and
                  localization for mobile robots},
  journal =	 ML,
  year =	 1998,
  volume =	 31,
  pages =	 {29--53},
  abstract =	 {This paper addresses the problem of building
                  large-scale geometric maps of indoor environments
                  with mobile robots. It poses the map building
                  problem as a constrained, probabilistic
                  maximumlikelihood estimation problem. It then
                  devises a practical algorithm for generating the
                  most likely map from data, along with the most
                  likely path taken by the robot. Experimental results
                  in cyclic environments of size up to 80 by 25 meter
                  illustrate the appropriateness of the approach.},
  c-kaess =	 {Probabilitic SLAM, a new solution to the then EKF
                  dominated field [DurrantWhyte06ram]},
}

@INPROCEEDINGS{Thrun98e,
  AUTHOR =	 {S. Thrun and D. Fox and W. Burgard},
  YEAR =	 1998,
  TITLE =	 {Probabilistic Mapping of an Environment by a Mobile
                  Robot},
  BOOKTITLE =	 ICRA,
}

@ARTICLE{Thrun98ml,
  AUTHOR =	 {Thrun, S.},
  TITLE =	 {Bayesian Landmark Learning for Mobile Robot
                  Localization},
  JOURNAL =	 ML,
  YEAR =	 1998,
  volume =	 33,
  number =	 1,
  abstract =	 {To operate successfully in indoor environments,
                  mobile robots must be able to localize
                  themselves. Most current localization algorithms
                  lack flexibility, autonomy, and often optimality,
                  since they rely on a human to determine what aspects
                  of the sensor data to use in localization (e.g.,
                  what landmarks to use). This paper describes a
                  learning algorithm, called BaLL, that enables mobile
                  robots to learn what features/landmarks are best
                  suited for localization, and also to train
                  artificial neural networks for extracting them from
                  the sensor data. A rigorous Bayesian analysis of
                  probabilistic localization is presented, which
                  produces a rational argument for evaluating
                  features, for selecting them optimally, and for
                  training the networks that approximate the optimal
                  solution. In a systematic experimental study, BaLL
                  outperforms two other recent approaches to mobile
                  robot localization.},
  quotes =	 {As shown by our empirical comparison, enabling a
                  robot to extract its own features (and learning its
                  own landmarks) has a noticeable impact on the
                  quality of the results.},
  c-dellaert =	 {has famous door example for Markov localization. NN
                  trains on features, images? Very abstract paper, not
                  very clear, not many images. Hard to see what was
                  done without slugging through.}
}

@InProceedings{Thrun99fsr,
  author =	 "Sebastian Thrun and M. Bennewitz and Wolfram Burgard
                  and A.B. Cremers and Frank Dellaert and Dieter Fox
                  and D. Haehnel and G. Lakemeyer and Chuck Rosenberg
                  and Nicholas Roy and Jamieson Schulte and D. Schulz
                  and W. Steiner",
  title =	 "Experiences with two deployed interactive tour-guide
                  robots",
  booktitle =	 FSR,
  month =	 "August",
  year =	 "1999",
  url =		 "http://www.ri.cmu.edu/pubs/pub_3203.html"
}

@InProceedings{Thrun99ki,
  author =	 "Sebastian Thrun and M. Bennewitz and Wolfram Burgard
                  and A.B. Cremers and Frank Dellaert and Dieter Fox
                  and D. Haehnel and G. Lakemeyer and Chuck Rosenberg
                  and Nicholas Roy and Jamieson Schulte and D. Schulz
                  and W. Steiner",
  title =	 "MINERVA: A Tour-Guide Robot that Learns",
  booktitle =	 {KI-99: Advances in AI},
  month =	 "September",
  publisher =	 {Springer},
  year =	 1999,
  editor =	 {W. Burgard and T. Christaller and A.B. Cremers},
  pages =	 {14-26},
}

@InProceedings{Tian05cvpr,
  author =	 {Y Tian and M. Lu and A. Hampapur},
  title =	 {Robust and Efficient Foreground Analysis for
                  Real-time Video Surveillance},
  booktitle =	 CVPR,
  year =	 2005,
  abstract =	 {We present a new method to robustly and efficiently
                  analyze foreground when we detect background for a
                  fixed camera view by using mixture of Gaussians
                  models and multiple cues. The background is modeled
                  by three Gaussian mixtures as in the work of
                  Stauffer and Grimson. Then the intensity and texture
                  information are integrated to remove shadows and to
                  enable the algorithm working for quick lighting
                  changes. For foreground analysis, the same Gaussian
                  mixture model is employed to detect the static
                  foreground regions without using any tracking or
                  motion information. Then the whole static regions
                  are pushed back to the background model to avoid a
                  common problem in background subtraction -
                  fragmentation (one object becomes multiple
                  parts). The method was tested on our real time video
                  surveillance system. It is robust and run about 130
                  fps for color images and 150 fps for grayscale
                  images at size 160x120 on a 2GB Pentium IV machine
                  with MMX optimization.},
  c-houdan =	 {A paper discussing foreground analysis: static
                  object detection, foreground fragments reduction,
                  abandoned and removed objects (ghosts) detection},
}

@article{Tierney86,
  author =	 "Tierney, L. and Kadane, J. B.",
  year =	 "1986",
  title =	 "Accurate approximations for posterior moments and
                  marginal distributions",
  journal =	 "Journal of the American Statistical Association",
  volume =	 "81",
  pages =	 "82-86",
}

@InCollection{Tierney96,
  author =	 "L. Tierney",
  title =	 "Introduction to general state-space {M}arkov chain
                  theory",
  crossref =	 "Gilks96",
}

@Article{Tinney67ieee,
  author =	 {Tinney, W.F.; Walker, J.W.;},
  title =	 {Direct solutions of sparse network equations by
                  optimally ordered triangular factorization},
  journal =	 {Proceedings of the IEEE},
  year =	 1967,
  volume =	 55,
  number =	 11,
  pages =	 {1801 - 1809},
  month =	 {November},
  r-Liu85toms =	 {The most widely used general-purpose ordering scheme
                  in sparse matrix computation is the minimum-degree
                  algorithm \cite{Duff82, Eisenstat77, George81book,
                  Tinney67ieee}},
}

@TechReport{Tipping97ppca,
  author =	 {M.E. Tipping and C.M. Bishop},
  fullauthor =	 "Michael E. Tipping and Christopher M. Bishop",
  title =	 {Probabilistic principal component analysis},
  institution =	 {Neural Computing Research Group, Aston University},
  year =	 1997,
  number =	 {NCRG/97/010},
  address =	 {September},
}

@article{Tipping99nc,
  author =	 {M.E. Tipping and C.M. Bishop},
  fullauthor =	 "Michael E. Tipping and Christopher M. Bishop",
  title =	 "Mixtures of Probabilistic Principal Component
                  Analysers",
  journal =	 "Neural Computation",
  volume =	 11,
  number =	 2,
  pages =	 "443-482",
  year =	 1999,
  url =		 "citeseer.nj.nec.com/tipping98mixtures.html"
}

@Article{Tipping99ppca,
  author =	 {M.E. Tipping and C.M. Bishop},
  fullauthor =	 "Michael E. Tipping and Christopher M. Bishop",
  title =	 {Probabilistic principal component analysis},
  year =	 1999,
  journal =	 "Journal of the Royal Statistical Society",
  volume =	 "Series B 61(3)",
  pages =	 "611-622",
}

@InProceedings{Tobler02SMI,
  author =	 {R.F. Tobler, S. Maierhofer and A. Wilkie},
  title =	 {A Multiresolution Mesh Generation Approach for
                  Procedural Definition of Complex Geometry},
  booktitle =	 {Proceedings of the Shape Modeling International
                  2002},
  year =	 2002,
  publisher =	 {IEEE Computer Society},
}

@article{Toet08ergonomics,
  Abstract =	 {Field-of-view (FOV) restrictions are known to affect
                  human behaviour and to degrade performance for a
                  range of different tasks. However, the relationship
                  between human locomotion performance in complex
                  environments and FOV size is currently not fully
                  known. This paper examined the effects of FOV
                  restrictions on the performance of participants
                  manoeuvring through an obstacle course with
                  horizontal and vertical barriers. All FOV
                  restrictions tested (the horizontal FOV was either
                  30? 75?or 120? while the vertical FOV was always 48?
                  significantly reduced performance compared to the
                  unrestricted condition. Both the time and the number
                  of footsteps needed to traverse the entire obstacle
                  course increased with a decreasing FOV size. The
                  relationship between FOV restriction and manoeuvring
                  performance that was determined can be used to
                  formulate requirements for FOV restricting devices
                  that are deployed to perform time-limited human
                  locomotion tasks in complex structured environments,
                  such},
  Author =	 {Toet, A. and Jansen, S. E. M. and Delleman, N. J.},
  Journal =	 {Ergonomics},
  Number =	 3,
  Pages =	 {385--394},
  Title =	 {Effects of field-of-view restriction on manoeuvring
                  in a 3-D environment.},
  Volume =	 51,
  Year =	 2008,
  c-dellaert =	 {Abstract seems to suggest that peripheral vision is
                  crucial to navigation. How much of it is related to
                  optic flow determination of heading is not known},
}

@InCollection{Toledo99dimacs,
  author =	 {S. Toledo},
  fullauthor =	 {Sivan Toledo},
  editor =	 {J.M. Abello and J.S. Vitter},
  fulleditor =	 {James M. Abello and Jeffrey Scott Vitter},
  booktitle =	 {External Memory Algorithms},
  title =	 {A survey of out-of-core algorithms in numerical
                  linear algebra},
  publisher =	 {American Mathematical Society},
  year =	 1999,
  series =	 {DIMACS Series in Discrete Mathematics and
                  Theoretical Computer Science},
  pages =	 {161-179},
}

@InCollection{Tolman51,
  author =	 {E. C. Tolman},
  title =	 "{Cognitive Maps in Rats and Man}",
  booktitle =	 {Behavior and Psychological Man},
  publisher =	 {University of California Press},
  year =	 1951,
  c-ananth =	 {Historically, topological mapping is descended from
                  the theory of cognitive maps proposed as a means of
                  spatial representation in cognitive science
                  [Tolman51].}
}

@InProceedings{Tom94,
  author =	 {Brian C. Tom and Aggelos K. Katsaggelos},
  title =	 {Reconstruction of a High Resolution Image from
                  Multiple Degraded Mis-Registered Low Resolution
                  Images},
  booktitle =	 SPIE,
  volume =	 2308,
  pages =	 {971-981},
  year =	 1994,
}

@InProceedings{Tom94b,
  author =	 {Brian C. Tom and Aggelos K. Katsaggelos},
  title =	 {Reconstruction of a High Resolution Image from
                  Registration and Restoration of Low Resolution
                  Images},
  booktitle =	 ICIP,
  volume =	 3,
  pages =	 {553-557},
  year =	 1994,
}

@InProceedings{Tom95,
  author =	 {Brian C. Tom and Aggelos K. Katsaggelos},
  title =	 {Reconstruction of a High Resolution Image by
                  Simultaneous Registration, Restoration, and
                  Interpolation of Low Resolution Images},
  booktitle =	 ICIP,
  pages =	 {539-542},
  year =	 1995,
  volume =	 2,
}

@PhdThesis{Tom95b,
  author =	 {Brian C. Tom},
  title =	 {Reconstruction of a High Resolution Image from
                  Multiple, Degraded Low Resolution Images},
  school =	 {Northwestern University},
  year =	 1995,
}

@InProceedings{Tom96,
  author =	 {Brian C. Tom and Aggelos K. Katsaggelos},
  title =	 {Resolution Enhancement in Color Video},
  booktitle =	 {EUSIPCO 96},
  pages =	 {145-148},
  year =	 1996,
  volume =	 1,
}

@Article{Tomasi92,
  author =	 "C. Tomasi and T. Kanade",
  title =	 "Shape and motion from image streams under
                  orthography: a factorization method",
  journal =	 IJCV,
  year =	 1992,
  volume =	 9,
  number =	 2,
  pages =	 "137-154",
  month =	 "Nov.",
}

@inproceedings{Tomatis01,
  author =	 "N. Tomatis and I. Nourbakhsh and R. Siegwart",
  title =	 "Simultaneous localization and map-building: a global
                  topological model with local metric maps",
  booktitle =	 IROS,
  year =	 2001,
}

@inproceedings{Tomatis02,
  author =	 "N. Tomatis and I. Nourbakhsh and R. Siegwart",
  title =	 "Hybrid Simultaneous Localization and Map Building:
                  Closing the Loop with Multi-Hypotheses Tracking",
  booktitle =	 ICRA,
  pages =	 {2749-2754},
  year =	 2002,
  c-ananth =	 {An approach that is closer to our ideal in the sense
                  of maintaining a multi-hypothesis space over
                  correspondences, is given by Tomatis et
                  al. [Tomatis02] and also uses POMDPs to solve the
                  correspondence problem. However, while in their case
                  a multi-hypothesis space is maintained, it is used
                  only to detect the points where the probability mass
                  splits into two. Also, like a lot of others, this
                  work uses specific qualities of the indoor
                  environment such as doors and corridor junctions,
                  and hence is not generally applicable to any
                  environment.},
}

@InProceedings{Tombre96,
  author =	 {K. Tombre},
  title =	 {Structural and Syntactic Methods in Line Drawing
                  Analysis : To What Extent Do They Work ?},
  booktitle =	 {SSPR},
  year =	 1996,
  pages =	 {310-321},
}

@InProceedings{Tomono05icra,
  author =	 {M. Tomono},
  fullauthor =	 {Masahiro Tomono},
  title =	 {3-{D} Localization and Mapping Using a Single Camera
                  Based on Structure-from-Motion with Automatic
                  Baseline Selection},
  booktitle =	 ICRA,
  location =	 {Barcelona, Spain},
  month =	 {Apr},
  year =	 2005,
  abstract =	 {This paper presents a system of 3-D simultaneous
                  localization and mapping (SLAM) using monocular
                  vision based on the structure-from-motion scheme. An
                  crucial issue in applying structure-from-motion to
                  SLAM is that accuracy depends heavily on the
                  baseline distance. We address this problem by
                  selecting an appropriate baseline based on criteria
                  for the tradeoff between the baseline distance and
                  the number of feature points visible in the
                  images. Experimental results show that full 3-D
                  sparse maps with camera trajectory were built from
                  images captured with a handy camera.},
  c-kaess =	 {Off-line processing of pictures from hand-held
                  camera, no other sensors. Uses minimum baseline for
                  stability, unnecessary frames automatically
                  identified. Results of short sequences without
                  loops},
}

@InProceedings{Tomono07icra,
  author =	 {M. Tomono},
  fullauthor =	 {Masahiro Tomono},
  title =	 {Monocular {SLAM} using a {R}ao-{B}lackwellised
                  particle filter with exhaustive pose space search},
  booktitle =	 ICRA,
  location =	 {Rome, Italy},
  pages =	 {2421-2426},
  month =	 {Apr},
  year =	 2007,
  abstract =	 {This paper presents a method of 3-D SLAM using a
                  single camera. We utilize a Rao-Blackwellised
                  particle filter (RBPF) to deal with a large number
                  of landmarks. A difficulty in monocular SLAM is
                  robustness to outliers and noise, which may cause
                  false estimates especially under short baseline
                  conditions. We propose an exhaustive pose-space
                  search that finds all the plausible hypotheses
                  efficiently using epipolar geometry. The obtained
                  pose hypotheses are refined by the RBPF. Simulations
                  and experiments show that the proposed method
                  successfully performed 3-D SLAM with a small number
                  of particles.},
}

@Article{Ton89,
  author =	 {J. Ton and A.K. Jain},
  title =	 {Registering Landsat Images Using Point Pattern
                  Matching},
  journal =	 {IEEE Transactions on Geoscience and Remote Sensing},
  year =	 1989,
  volume =	 27,
  number =	 5,
  pages =	 {642-651},
}

@Unpublished{Topp04,
  author =	 {E. A. Topp},
  title =	 {Design study: A control system for a mobile service
                  robot},
  year =	 2004,
}

@InProceedings{Topp06iros,
  author =	 {E.A. Topp and H. H\"{u}ttenrauch and
                  H.I. Christensen},
  title =	 {Topological Modelling for Human Augmented Mapping},
  booktitle =	 IROS,
  year =	 2006,
  address =	 {Beijing, China},
  month =	 {October},
  abstract =	 {Service robots designed for domestic settings need
                  to navigate in an environment that they have to
                  share with their users. Thus, they have to be able
                  to report their current state and whereabouts in a
                  way that is comprehensible for the user. Pure metric
                  maps do not usually correspond to the understanding
                  of the environment a user would provide. Thus, the
                  robotic map needs to be integrated with the human
                  representation. This paper describes our framework
                  of Human Augmented Mapping that allows us to achieve
                  this integration.We propose further a method to
                  specify and represent regions that relate to a user?
                  view on the environment. We assume an interactive
                  setup for the specification of regions and show the
                  applicability of our method in terms of
                  distinctiveness for space segmentation and in terms
                  of localisation purposes.},
  quotes =	 {A central question is here how to partition the map
                  derived from sensory data into regions that
                  correspond to areas considered relevant by
                  users. .. We consider two types of events that can
                  trigger the system to segment the environment in the
                  internal representation. One is to receive external
                  input that annotates a certain spatial entity with a
                  label (e.g, ?.. this is Elin? office...?. The other
                  type of event is the data driven detection of a ?ew
                  area?},
  c-dellaert =	 {HAM :-) Emphasis on communication. Robot listens to
                  user or detects it is in new area. Has lots of
                  references that are not explored yet.}
}

@InProceedings{Topp06iros2,
  author =	 {E.A. Topp and H. H\"{u}ttenrauch and
                  H.I. Christensen and K.S. Eklundh},
  title =	 {Bringing Together Human and Robotic Environment
                  Representations - A Pilot Study},
  booktitle =	 IROS,
  year =	 2006,
  address =	 {Beijing, China},
  month =	 {October},
  abstract =	 {Human interaction with a service robot requires a
                  shared representation of the environment for spoken
                  dialogue and task specification where names used for
                  particular locations are depending on personal
                  preferences. A question is how such human oriented
                  models can be tied to the geometric robotic models
                  needed for precise localisation and navigation. We
                  assume that this integration can be based on the
                  information potential users give to a service robot
                  about its working environment. We further believe
                  that this information is best given in an
                  interactive setting (a "guided tour") in this
                  particular environment. This paper presents a pilot
                  study that investigates how humans present a
                  familiar environment to a mobile robot. The study is
                  set up within our concept of Human Augmented
                  Mapping, for which we assume an initial "guided
                  tour" scenario to teach a robot its
                  environment. Results from this pilot study are used
                  to validate a proposed generic environment model for
                  a service robot.},
  quotes =	 {We model the environment by using a hierarchy of
                  graphs. The main concepts we incorporate so far are
                  locations (or places) and regions.},
  c-dellaert =	 {Hierarchy on top of HAM?}
}

@inproceedings{Tordoff02,
  author =	 "Tordoff, B. and Murray, D.W.",
  title =	 "Guided sampling and consensus for motion estimation",
  pages =	 "82-96",
  booktitle =	 "Proc 7th European Conf on Computer Vision",
  volume =	 1,
  year =	 2002
}

@article{Tordoff05,
  author =	 {Ben Tordoff and David W Murray},
  title =	 {Guided-MLESAC: faster image transform estimation by
                  using matching priors},
  journal =	 {Transactions of PAMI},
  volume =	 27,
  number =	 10,
  pages =	 {1523--1535},
  year =	 2005,
}

@inproceedings{Torr00b,
  author =	 "Torr, P. H. S. and Davidson, C.",
  title =	 "IMPSAC: A synthesis of importance sampling and
                  random sample consensus to effect multi-scale image
                  matching for small and wide baselines",
  pages =	 "819-833",
  booktitle =	 "ECCV2000",
  volume =	 1,
  url =		 "http://research.microsoft.com/~philtorr/",
  year =	 2000
}

@article{Torr00cviu,
  author =	 {P.H.S. Torr and A. Zisserman},
  title =	 {{MLESAC}: A New Robust Estimator with Application to
                  Estimating Image Geometry},
  journal =	 CVIU,
  year =	 2000,
  volume =	 78,
  number =	 1,
  pages =	 {138--156},
}

@article{Torr01pami,
  author =	 {P.H.S. Torr, R. Szeliski and P. Anandan},
  title =	 {An integrated Bayesian approach to layer extraction
                  from image sequences},
  journal =	 PAMI,
  volume =	 23,
  number =	 3,
  pages =	 {297-303},
  month =	 {March},
  year =	 2001,
  keywords =	 {layers, stereo, video analysis},
  c-sangmin =	 {use of layered approach within Bayesian framework
                  for stereo reconstruction and introduce Bayesian
                  version of RANSAC},
}

@article{Torr02ijcv,
  author =	 {P.H.S. Torr},
  title =	 {Bayesian Model Estimation and Selection for Epipolar
                  Geometry and Generic Manifold Fitting},
  journal =	 IJCV,
  volume =	 50,
  number =	 1,
  pages =	 {27--45},
  year =	 2002,
}

@InProceedings{Torr03ais,
  author =	 {P.H.S. Torr},
  title =	 {Solving Markov Random Fields using Semi Definite
                  Programming},
  booktitle =	 {Ninth International Workshop on Artificial
                  Intelligence and Statistics},
  year =	 2003,
}

@article{Torr03pami,
  AUTHOR =	 "P.H.S. Torr and C. Davidson",
  TITLE =	 "IMPSAC: Synthesis of Importance Sampling and Random
                  Sample Consensus",
  JOURNAL =	 PAMI,
  VOLUME =	 25,
  YEAR =	 2003,
  NUMBER =	 3,
  MONTH =	 "March",
  PAGES =	 "354-364"
}

@InProceedings{Torr06cvpr,
  author =	 {P. Kumar and P.H.S. Torr and A. Zisserman},
  title =	 {Solving Markov Random Fields Using Second Order Cone
                  Programming},
  booktitle =	 CVPR,
  year =	 2006,
}

@InProceedings{Torr93,
  author =	 "P.H.S. Torr and D. Murray",
  title =	 "Outlier Detection and Motion Segmentation",
  booktitle =	 "Proceedings SPIE Sensor Fusion Conference",
  pages =	 "432-443",
  year =	 1993
}

@inproceedings{Torr95,
  AUTHOR =	 "Torr, P.H.S.",
  TITLE =	 "Motion Segmentation and Outlier Detection",
  BOOKTITLE =	 "Ph. D.",
  YEAR =	 1995
}

@inproceedings{Torr97,
  author =	 "Torr, P.H.S. ",
  title =	 "An Assessment of Information Criteria for Motion
                  Model Selection",
  pages =	 "47--53",
  booktitle =	 CVPR,
  year =	 1997
}

@article{Torr97b,
  author =	 "P.H.S. Torr and D. Murray",
  title =	 "The development and comparison of robust methods for
                  estimating the fundamental matrix",
  journal =	 IJCV,
  volume =	 24,
  number =	 3,
  pages =	 "271--300",
  year =	 1997,
}

@InProceedings{Torr98,
  author =	 "P. Torr and A. Zisserman",
  title =	 "Robust computation and parametrization of multiple
                  view relations",
  pages =	 "485-491",
  booktitle =	 ICCV,
  year =	 1998,
}

@inproceedings{Torr98b,
  author =	 "Torr, P. and Fitzgibbon, A. and Zisserman, A.",
  title =	 "Maintaining Multiple Motion Model Hypotheses Over
                  Many Views to Recover Matching and Structure",
  booktitle =	 ICCV,
  year =	 1998,
  pages =	 "485--491",
  url =
                  "http://imogen.robots.ox.ac.uk:20000/~vgg/vggpapers/Torr98a.ps.gz"
}

@inproceedings{Torr99,
  author =	 "P.H.S. Torr and R. Szeliski and P. Anandan",
  title =	 "An integrated {Bayesian} approach to layer
                  extraction from image sequences",
  booktitle =	 ICCV,
  year =	 1999,
  pages =	 "983-990",
}

@techreport{Torr99tr,
  author =	 "P.H.S. Torr, A. Zisserman",
  title =	 "MLESAC: A New Robust Estimator with Application to
                  Estimating Image Geometry",
  number =	 "MSR-TR-99-60",
  institution =	 {MSR},
  year =	 2000,
}

@inproceedings{Torr99va,
  author =	 {P.~H.~S.~Torr and A.~Zisserman},
  title =	 {Feature Based Methods for Structure and Motion
                  Estimation},
  pages =	 {278--294},
  booktitle =	 {Vision Algorithms: Theory and Practice},
  editor =	 {B. Triggs and A. Zisserman and R. Szeliski},
  publisher =	 {Springer-Verlag},
  series =	 {LNCS},
  number =	 1883,
  address =	 {Corfu, Greece},
  month =	 sep,
  year =	 1999
}

@inproceedings{Torralba03,
  title =	 {Context-based vision system for place and object
                  recognition},
  author =	 {A. Torralba and K. P. Murphy and W. T. Freeman and
                  M. A. Rubin},
  booktitle =	 ICCV,
  volume =	 1,
  pages =	 {273--280},
  year =	 2003,
}

@inproceedings{Torralba04cvpr,
  title =	 {Sharing features: efficient boosting procedures for
                  multiclass object detection},
  author =	 {A. Torralba and K. P. Murphy and W. T. Freeman},
  booktitle =	 CVPR,
  pages =	 {762-769},
  year =	 2004,
}

@inproceedings{Torralba08pami,
  Title =	 {80 million tiny images: a large dataset for
                  non-parametric object and scene recognition},
  author =	 {A. Torralba and R. Fergus and W. T. Freeman},
  booktitle =	 PAMI,
  volume =	 30,
  number =	 11,
  pages =	 {1958-1970},
  year =	 2008,
}

@InProceedings{Torre01,
  author =	 {F. Torre and M. J. Black},
  title =	 {Robust principal component analysis for computer
                  vision},
  booktitle =	 ICCV,
  pages =	 {362-369},
  year =	 2001,
}

@inproceedings{Toyama01iccv,
  author =	 "Kentaro Toyama and Andrew Blake",
  title =	 "Probabilistic Tracking in a Metric Space",
  booktitle =	 CVPR,
  year =	 2001,
}

@InProceedings{Toyama99iccv,
  author =	 {K. Toyama and J. Krumm and B. Brumitt and B. Meyers},
  title =	 {Wallflower: Principles and Practice of Background
                  Maintenance},
  booktitle =	 ICCV,
  year =	 1999,
  abstract =	 {Background maintenance is a frequent element of
                  video surveillance systems. We develop Wallflower, a
                  three-component system for background maintenance:
                  the pixel-level component performs Wiener filtering
                  to make probabilistic predictions of the expected
                  background; the region-level component fills in
                  homogeneous regions of foreground objects; and the
                  frame-level component detects sudden, global changes
                  in the image and swaps in better approximations of
                  the background. We compare our system with 8 other
                  background subtraction algorithms. Wallflower is
                  shown to outperform previous algorithms by handling
                  a greater set of the difficult situations that can
                  occur. Finally, we analyze the experimental results
                  and propose normative principles for background
                  maintenance.},
  r-Javed02motion ={ Toyama et. al. propose a three tiered algorithm
                  to deal with the background subtraction problem. The
                  algorithm uses only color information at the pixel
                  level. The region level deals with the background
                  object relocation problem. Global illumination
                  changes are handled at the frame level. This
                  algorithm is able to handle sudden changes in
                  illumination only if the model describing the scene
                  after the illumination changes is known a priori.},
  c-houdan =	 {It's the first work using hierarchical approach for
                  background segmentation. The pixel-level uses a
                  linear predictor "Wiener filter"},
}

@Article{Tran00,
  author =	 {Tran, T.V. and Letowski, T. and Abouchacra, K.S.},
  year =	 {2000},
  title =	 {Evaluation of acoustic beacon characteristics for
                  navigation tasks},
  journal =	 {Ergonomics},
  volume =	 {43},
  number =	 {6},
  pages =	 {807-827}
}

@InProceedings{Tran07nips,
  author = {D. Tran and D. A. Forsyth},
  title = {Configuration estimates improve pedestrian finding},
  booktitle = NIPS,
  year = {2007}
}

@INPROCEEDINGS{Treibitz06cvpr,
  title =	 {Instant 3Descatter},
  author =	 {Treibitz, T. and Schechner, Y.Y.},
  booktitle =	 {Computer Vision and Pattern Recognition, 2006 IEEE
                  Computer Society Conference on},
  year =	 2006,
  volume =	 2,
  pages =	 { 1861-1868},
}

@Inproceedings{Triebel05,
  author =	 {Triebel, R. and Burgard, W. and Dellaert, F.},
  title =	 { Using Hierarchical EM to Extract Planes from {3D}
                  Range Scans},
  booktitle =	 ICRA,
  year =	 2005,
}

@inproceedings{Triggs96,
  AUTHOR =	 "Triggs, B.",
  TITLE =	 "Factorization Methods for Projective Structure and
                  Motion",
  BOOKTITLE =	 CVPR,
  YEAR =	 1996,
  PAGES =	 "845-851"
}

@InProceedings{Triggs97cvpr,
  author =	 "B. Triggs",
  title =	 "Autocalibration and the Absolute Quadric",
  booktitle =	 CVPR,
  year =	 1997,
  url =		 "citeseer.nj.nec.com/triggs97autocalibration.html"
}

@InProceedings{Triggs99,
  author =	 {B. Triggs and P. McLauchlan and R. Hartley and
                  A. Fitzgibbon},
  title =	 {Bundle Adjustment -- A Modern Synthesis},
  booktitle =	 {Vision Algorithms: Theory and Practice},
  editor =	 {Triggs, W. and Zisserman, A. and Szeliski, R.},
  publisher =	 {Springer Verlag},
  series =	 {LNCS},
  pages =	 {298--375},
  location =	 {Corfu, Greece},
  month =	 {Sep},
  year =	 1999,
  abstract =	 {This paper is a survey of the theory and methods of
                  photogrammetric bundle adjustment, aimed at
                  potential implementors in the computer vision
                  community. Bundle adjustment is the problem of
                  refining a visual reconstruction to produce jointly
                  optimal structure and viewing parameter
                  estimates. Topics covered include: the choice of
                  cost function and robustness; numerical optimization
                  including sparse Newton methods, linearly convergent
                  approximations, updating and recursive methods;
                  gauge (datum) invariance; and quality control. The
                  theory is developed for general robust cost
                  functions rather than restricting attention to
                  traditional nonlinear least squares.},
  c-kaess =	 {Seminal work, very important! All details of how to
                  implement bundle adjustment correctly, overview of
                  all kinds of numerical optimization methods for
                  solving, also incremental, furthermore error
                  modelling, preconditioning, gauge freedom,
                  historical overview, matrix decompositions.},
}

@misc{Trimble,
  author =	 {Trimble Navigation Limited},
  title =	 {{GPS} {T}utorial {W}eb site},
  url =		 {http://www.trimble.com/gps/}
}

@inproceedings{Truyen08nips,
  author =	 {Tran The Truyen and Dinh Q. Phung and Hung H. Bui
                  and Svetha Venkatesh},
  booktitle =	 NIPS,
  title =	 {Hierarchical Semi-Markov Conditional Random Fields
                  for Recursive Sequential Data},
  year =	 {2008},
  keywords =	 {hierarchical, crf, behavior recognition},
  c-sangmin =	 {They used hierarchical Markov chain with finish
                  variables, used by Murphy and Paskin. The overall
                  learning of H-CRF is quite impressive given that
                  there can be a huge number of parameters. In terms
                  of experimental results, the results are good. But,
                  the models have only two and three layers where the
                  number of states are quite small (total number of
                  meta states would be less than 20). For problems
                  with large number of states at every hierarchy, it
                  is not clear what is the computational complexity
                  w.r.t. the number of states, maybe the the quadratic
                  w.r.t. the total number of concatenated meta
                  states. The more severe aspect is that the inference
                  complexity is O(T^3). Basically, for long sequences,
                  the algorithm would face severe computational
                  challenge. This complexity is also related to Bui's
                  AAAI paper on HHMM with general hierarchy. Maybe
                  there would be a room to improve the efficiency.},
}

@inproceedings{Truyen08nips,
  Author =	 {Tran The Truyen and Dinh Q. Phung and Hung H. Bui
                  and Svetha Venkatesh},
  Booktitle =	 NIPS,
  Title =	 {Hierarchical Semi-Markov Conditional Random Fields
                  for Recursive Sequential Data},
  Year =	 {2008},
  Keywords =	 {hierarchical, crf, behavior recognition},
  c-sangmin =	 {They used hierarchical Markov chain with finish
                  variables, used by Murphy and Paskin. The overall
                  learning of H-CRF is quite impressive given that
                  there can be a huge number of parameters. In terms
                  of experimental results, the results are good. But,
                  the models have only two and three layers where the
                  number of states are quite small (total number of
                  meta states would be less than 20). For problems
                  with large number of states at every hierarchy, it
                  is not clear what is the computational complexity
                  w.r.t. the number of states, maybe the the quadratic
                  w.r.t. the total number of concatenated meta
                  states. The more severe aspect is that the inference
                  complexity is O(T^3). Basically, for long sequences,
                  the algorithm would face severe computational
                  challenge. This complexity is also related to Bui's
                  AAAI paper on HHMM with general hierarchy. Maybe
                  there would be a room to improve the efficiency.},
}

@article{Tsai79,
  AUTHOR =	 {W.H. Tsai and K.S. Fu},
  TITLE =	 {Error-correcting isomorphisms of attributed
                  relational graphs for pattern analysis},
  JOURNAL =	 SMC,
  VOLUME =	 9,
  YEAR =	 1979,
  PAGES =	 {757-768 },
}

@article{Tsai84,
  AUTHOR =	 "Tsai, R.Y. and Huang, T.S.",
  TITLE =	 "Uniqueness and Estimation of Three-Dimensional
                  Motion Parameters of Rigid Objects with Curved
                  Surfaces",
  JOURNAL =	 PAMI,
  VOLUME =	 6,
  YEAR =	 1984,
  NUMBER =	 1,
  MONTH =	 "January",
  PAGES =	 "13-27"
}

@Article{Tsamardinos03ai,
  author =	 {I. Tsamardinos and M. E. Pollack},
  title =	 {Efficient Solution Techniques for Disjunctive
                  Temporal Reasoning Problems},
  journal =	 {Artificial Intelligence},
  year =	 2003,
  volume =	 151,
  number =	 {1-2},
  pages =	 {43-90},
}

@InProceedings{Tsubouchi87,
  author =	 {T. Tsubouchi and S. Yuta},
  title =	 {Map-assisted vision system of mobile robots for
                  reckoning in a building environment},
  booktitle =	 ICRA,
  year =	 1987,
  pages =	 {1978-1984},
}

@InProceedings{Tu01iccv,
  author =	 {Zhuowen Tu and Song-Chun Zhu and Heung-Yeung Shum},
  title =	 {Image Segmentation by Data Driven Markov Chain Monte
                  Carlo},
  booktitle =	 ICCV,
  year =	 2001,
}

@InProceedings{Tu03iccv,
  author =	 {Zhuowen Tu and Xiangrong Chen and Alan L. Yuille and
                  Song-Chun Zhu},
  title =	 {Image Parsing: Unifying Segmentation, Detection and
                  Recognition},
  booktitle =	 ICCV,
  pages =	 {18-25},
  year =	 2003,
}

@Article{Tu03pami,
  author =	 {Z.W. Tu and S.C. Zhu},
  title =	 {Image Segmentation by Data-Driven {M}arkov Chain
                  {M}onte {C}arlo},
  journal =	 PAMI,
  year =	 2002,
  volume =	 24,
  number =	 5,
  pages =	 {657-673},
}

@InProceedings{Tu06bsc,
  author =	 {R. Tu and Y. Mao and J. Zhao},
  fullauthor =	 {Ronghui Tu and Yongyi Mao and Jiying Zhao},
  title =	 {Towards a Unified Solution for
                  Constraint-Satisfaction Problems: A
                  Survey-Propagation Approach Based on Normal
                  Realizations},
  booktitle =	 {23rd Biennial Symposium on Communications},
  pages =	 {252--255},
  year =	 2006,
  month =	 {June},
  quotes =	 {Generalizing the work of \citet{Maneva05soda}, in
                  this paper, we introduce a generic combinatorial
                  framework for arbitrary constraint satisfaction
                  problems. ... Based on normal realizations, we then
                  introduce a new class of algorithms, which we call
                  the MR algorithms, for solving arbitrary constraint
                  satisfaction problems. The existing survey
                  propagation algorithm and its generalization appear
                  to be a special case of the MR family. },
  c-dellaert =	 {MR=marginalization-restriction (MR) algorithm},
}

@InProceedings{Tu94siggraph,
  author =	 {X. Tu and D. Terzopoulos},
  fullauthor =	 {Xiaoyuan Tu and Demetri Terzopoulos},
  title =	 {{Artificial Fishes: Physics, Locomotion, Perception,
                  Behavior}},
  booktitle =	 SIGGRAPH,
  pages =	 {43-50},
  year =	 1994,
}

@InProceedings{Tucakov97icss,
  author =	 {V. Tucakov and M. Sahota and D. Murray and
                  A. Mackworth and J. Little and S. Kingdon and
                  C.Jennings and R. Barman},
  title =	 {Spinoza: A Stereoscopic Visually Guided Mobile
                  Robot},
  booktitle =	 {Proc. of Hawaii Intl. Conf. on Systems Sciences},
  location =	 {Hawaii, USA},
  pages =	 {188-197},
  volume =	 5,
  month =	 {Jan},
  year =	 1997,
  abstract =	 {Our mobile robot, Spinoza, embodies a sophisticated
                  real-time vision system for the control of a mobile
                  robot in a dynamic environment. The complexity of
                  our robot architecture arises from the wide variety
                  of tasks that need to be performed and the resulting
                  challenge of coordinating multiple distributed,
                  concurrent processes on a diverse range of processor
                  architectures, including transputers, digital signal
                  processors and a workstation host. The system
                  handles the sensing, reasoning and action components
                  of a robot, distributed over these architectures,
                  and responds to unpredictable events in an unknown
                  dynamic environment. Spinoza relies heavily on its
                  capability to perform real-time vision processing in
                  order to perform task such as mapping, navigation,
                  exploration, tracking and simple manipulation.},
}

@Article{Turing48,
  author =	 {Turing, A. M.},
  title =	 {Rounding-off errors in matrix processes},
  journal =	 {Quart. J. Mech. Appl. Math.},
  year =	 1948,
  volume =	 1,
  pages =	 {287--308},
  r-MathSciNet = {This condensed paper consists of two parts: a
                  discussion of methods for solving linear algebraic
                  equations and a discussion of the errors to be
                  expected. In the first part the author states that
                  methods of approximation are more laborious than
                  direct ones. Concerning the direct methods he shows
                  that most of them are applications of the
                  decomposition of the matrix $A$ into the product
                  $LDU$, where $L$ and $U$ are triangular matrices
                  with diagonal elements 1 and having elements not
                  equal to zero below or above the diagonal,
                  respectively, and $D$ is a diagonal matrix. He
                  proves that the decomposition is
                  unique. Applications of this are Gauss's elimination
                  method with the Jordan variant which the author
                  considers the best method for inverting $A$,
                  Choleski's method, Morris's escalator process and
                  Schmidt's orthogonalization. For each of these
                  methods the author measures the work of computation
                  by counting the number of multiplications and
                  recordings. },
}

@InProceedings{Turk87,
  author =	 {M.A. Turk and D.G. Morgenthaler and K. Gremban and
                  M. Marra},
  title =	 {Video road following for the autonomous land
                  vehicle},
  booktitle =	 ICRA,
  pages =	 {273-280},
  year =	 1987,
  month =	 {March},
}

@article{Turk91,
  AUTHOR =	 "Turk, M. and Pentland, A.P.",
  TITLE =	 "Eigenfaces for Recognition",
  JOURNAL =	 "Cognitive Neuroscience",
  VOLUME =	 3,
  YEAR =	 1991,
  NUMBER =	 1,
  PAGES =	 "71-96"
}

@inproceedings{Turk91b,
  AUTHOR =	 "Turk, M. and Pentland, A.P.",
  TITLE =	 "Face Recognition Using Eigenfaces",
  BOOKTITLE =	 CVPR,
  YEAR =	 1991,
  PAGES =	 "586-591"
}

@inproceedings{Tuytelaars00,
  author =	 {T. Tuytelaars and L. {Van Gool}},
  title =	 {Matching Widely Separated Views based on Affinely
                  Invariant Neighbourhoods},
  booktitle =	 BMVC,
  pages =	 {412-422},
  year =	 2000,
}

@InProceedings{Tuytelaars00bmvc,
  author =	 {T. Tuytelaars and L. {Van Gool}},
  title =	 {Wide baseline stereo based on local, affinely
                  invariant regions},
  booktitle =	 BMVC,
  pages =	 {412-422},
  year =	 2000,
}

@inproceedings{Tuytelaars98icip,
  author =	 "T. Tuytelaars and M. Proesmans and L. Van Gool",
  title =	 "The Cascaded Hough Transforms",
  pages =	 "736--739",
  booktitle =	 "ICIP",
  year =	 1998,
}

@InProceedings{Tuytelaars99icra,
  author =	 {T. Tuytelaars and L. {Van Gool} and L. Dhaene and
                  R. Koch},
  title =	 {Matching Affinely Invariant Regions for Visual
                  Servoing},
  booktitle =	 ICRA,
  year =	 1999,
}

@InProceedings{Tweed02,
  author =	 {D. Tweed and A. Calway.},
  title =	 {Tracking Many Objects Using Subordinate
                  {Condensation}},
  booktitle =	 BMVC,
  year =	 2002,
}

@Article{Uhlmann91,
  author =	 {J. K. Uhlmann},
  title =	 {Metric trees},
  journal =	 {Applied Mathematics Letters},
  year =	 1991,
  volume =	 4,
  number =	 5,
}

@inproceedings{Uhlmann97spie,
  author =	 "J. K. Uhlmann and S. J. Julier and M. Csorba",
  title =	 "Nondivergent simultaneous map building and
                  localisation using covariance intersection",
  booktitle =	 "The Proceedings of AeroSense: The 11th International
                  Symposium on Aerospace/Defense Sensing, Simulation
                  and Controls, Orlando, Florida",
  note =	 "Navigation and Control Technologies for Unmanned
                  Systems II",
  publisher =	 "SPIE",
  year =	 1997
}

@Book{Ullman79,
  author =	 "S. Ullman",
  title =	 "The interpretation of visual motion",
  publisher =	 MIT,
  year =	 1979,
}

@Book{Ullman80book,
  author =	 {J.D. Ullman},
  title =	 {Principles of Database Systems},
  publisher =	 {Computer Science Press},
  year =	 1980,
  address =	 {Potomac, Md.},
  r-Fagin82tods ={Relational database design theory, as in
                  \cite{Ullman80book}, for example, requires us to
                  write down our assumptions regarding the real world
                  in terms of functional dependencies and multivalued
                  dependencies.}
}

@article{Ullman84cognition,
  title =	 {Visual routines.},
  author =	 {Ullman, S.},
  fullauthor =	 {Ullman, Shimon},
  journal =	 {Cognition},
  volume =	 18,
  month =	 {Dec},
  year =	 1984,
  pages =	 {97--159},
  abstract =	 {This paper examines the processing of visual
                  information beyond the creation of the early
                  represcntations. A fundamental requirement at this
                  level is the capacity to establish visually abstract
                  shape properties and spatial relations. This
                  capacity plays a major role in object recognition,
                  visually guided manipulation, and more abstract
                  visual thinking. For the human visual system, the
                  perception of spatial properties and relations that
                  are complex from a computational standpoint,
                  nevertheless often appears immediate and
                  effortless. This apparent immediateness and ease of
                  perceiving spatial relations is, however,
                  deceiving. It conceals in fact a complex array of
                  processes highly specialized for the task. The
                  proficiency of the human system in analyzing spalial
                  information far surpasses the capacities of current
                  artificial systems. The study of the computations
                  that underlie this competence may therefore lead to
                  the development of new more efficient processors for
                  the spatial analysis of visual information. It is
                  suggested that the perception of spatial relations
                  is achieved by the application to the base
                  representations of visual routines that are composed
                  of sequences of elemental operations. Routines for
                  different properties and relations share elemental
                  operations. Using a fixed set of basic operations,
                  the visual system can assemble different routines to
                  extract an unbounded variety of shape properties and
                  spatial relations. At a more detailed level, a
                  number of plausible basic operations are suggested,
                  based primarily on their potential usefulness, and
                  supported in part by empirical evidence. The
                  operations discussed include shifting of the
                  processing focus, indexing to an odd-man-out
                  location, bounded activation, boundary tracing, and
                  marking. The problem of assembling such elemental
                  operations into meaningful visual routines is
                  discussed briefly.},
  summary =	 {Examines the processing of visual information beyond
                  the creation of early base representations. It is
                  suggested that a fundamental requirement is the
                  capacity to establish visually abstract shape
                  properties and spatial relations. This capacity
                  plays a major role in object recognition, visually
                  guided manipulation, and more abstract visual
                  thinking. For the human visual system, the
                  perception of spatial properties and complex
                  relations often appears deceptively immediate and
                  effortless. The proficiency of the system in
                  analyzing spatial information far surpasses the
                  capacities of current artificial systems. Study of
                  the computations that underlie this competence may
                  lead to the development of more efficient methods
                  for the spatial analysis of visual information. The
                  perception of abstract shape properties and spatial
                  relations raises difficulties with major
                  implications for the overall processing of visual
                  information. It is argued that the computation of
                  spatial relations divides the analysis of visual
                  information into 2 main stages: the bottom-up
                  creation of certain representations of the visible
                  environment and the application of visual routines,
                  composed of elemental operations, to the
                  representations constructed in the 1st stage.},
  r-Hayhoe00vc = {The idea of visual routines was first introduced by
                  \citet{Ullman84cognition}, to describe the
                  perception of spatial relationships, such as the
                  apparently effortless perceptual process of judging
                  whether a point is inside a closed curve. The
                  essential property of a routine was that it
                  instantiated a procedure as opposed to requiring a
                  specialized detector of some kind. For example,
                  seeing if two points are on the same contour can be
                  done using an operation such as tracing the
                  contour. A procedure such as this can cope with a
                  large variety of spatial relations and do so in a
                  computationally efficient manner?wo of Ullman?
                  requirements for a routine. Ullman proposed a set of
                  basic operations used in assembling routines, such
                  as a shift of the processing focus, as might occur
                  when fixation or attention is directed to a
                  location. Another basic operation was to ?ark?an
                  environmental location, as might occur when the
                  information at that location is required in a
                  subsequent operation.},
  c-dellaert =	 {Long and old, nevertheless seminal, should read
                  attentively one day.},
}

@Book{Ullman96book,
  author =	 "S. Ullman",
  title =	 "High-Level Vision: Object recognition and visual
                  cognition",
  publisher =	 MIT,
  year =	 1996,
}

@Article{Ullmann76,
  author =	 {J.R. Ullmann},
  title =	 {An Algorithm for Subgraph Isomorphism},
  journal =	 {Journal of the ACM},
  year =	 1976,
  volume =	 23,
  pages =	 {31-42},
}

@InProceedings{Ulrich00aaai,
  author =	 {I. Ulrich and I. Nourbakhsh},
  fullauthor =	 {Iwan Ulrich and Illah Nourbakhsh},
  title =	 {Appearance-Based Obstacle Detection with Monocular
                  Color Vision},
  crossref =	 {_AAAI00},
  pages =	 {866-871}
}

@inproceedings{Ulrich00icra,
  author =	 {I. Ulrich and I. Nourbakhsh},
  fullauthor =	 {Iwan Ulrich and Illah Nourbakhsh},
  title =	 "Appearance-Based Place Recognition for Topological
                  Localization",
  booktitle =	 ICRA,
  month =	 "April",
  year =	 2000,
  volume =	 2,
  pages =	 "1023 - 1029",
  abstract =	 {This paper presents a new appearance-based place
                  recognition system for topological localization. The
                  method uses a panoramic vision system to sense the
                  environment. Color images are classified in
                  real-time based on nearest-neighbor learning, image
                  histogram matching, and a simple voting scheme. The
                  system has been evaluated with eight cross-sequence
                  tests in four unmodified environments, three indoors
                  and one outdoors. In all eight cases, the system
                  successfully tracked the mobile robot's
                  position. The system correctly classified between
                  87\% and 98\% of the input color images. For the
                  remaining images, the system was either momentarily
                  confused or uncertain, but never classified an image
                  incorrectly},
  r-Goedeme04jrs ={\citet{Ulrich00icra} created a method for
                  appearance-based place recognition for topological
                  localization. Their similarity measure, analog to
                  ours, is based on histogram matching. A serious
                  drawback of their system is that it does not extract
                  the topological structure itself, this has to be
                  done manually.},
  c-dellaert =	 {Has some related work that I have not gone through
                  yet.}
}

@Article{Ulrich01,
  author =	 {Iwan Ulrich and Johann Borenstein},
  title =	 {The GuideCane -- Applying Mobile Robot Technologies
                  to Assist the Visually Impaired},
  journal =	 {IEEE Transactions on Systems, Man, and Cybernetics,
                  -- Part A: Systems and Humans},
  year =	 {2001},
  volume =	 {31},
  number =	 {2},
  pages =	 {131-136},
  month =	 {March},
}

@Article{Umeyama88,
  author =	 {S. Umeyama},
  title =	 {An eigendecomposition approach to weighted graph
                  matching problems},
  journal =	 PAMI,
  year =	 1988,
  volume =	 10,
  number =	 5,
  pages =	 {695 -703},
  month =	 {September},
}

@Article{Umeyama91,
  author =	 {S. Umeyama},
  title =	 {Least-squares estimation of transformation
                  parameters between two point patterns},
  journal =	 PAMI,
  year =	 1991,
  volume =	 13,
  number =	 4,
  pages =	 {376 -380},
  month =	 {April},
}

@Article{Umeyama93,
  author =	 {S. Umeyama},
  title =	 {Parameterized point pattern matching and its
                  application to recognition of object families},
  journal =	 PAMI,
  year =	 1993,
  volume =	 15,
  number =	 2,
  pages =	 {136 -144},
  month =	 {February},
}

@Article{Unser91,
  author =	 {M.~Unser and A.~Aldroubi and M.~Eden},
  title =	 {Fast {B}-Splines Transforms for Continuous Image
                  Representation and Interpolation},
  journal =	 pami,
  year =	 1991,
  volume =	 13,
  number =	 3,
  pages =	 {277--285}
}

@InProceedings{Upcroft06cdc,
  author =	 {B. Upcroft and B. Douillard and M. Ridley and
                  H. Durrant-Whyte},
  title =	 {Non-{G}aussian state estimation in an outdoor
                  decentralised sensor network},
  booktitle =	 CDC,
  year =	 2006,
}

@InProceedings{Upcroft06iser,
  Author =	 {Upcroft, B. and Ridley, M.F. and Ong, L. and
                  Douillard, B. and Kaupp, T. and Kumar, S. and
                  Bailey, T.A. and Ramos, F.T. and Makarenko, A. and
                  Brooks, A. and Sukkarieh, S. and Durrant-Whyte,
                  H.F. },
  title =	 {Multi-level State Estimation in an Outdoor
                  Decentralised Sensor Network},
  booktitle =	 ISER,
  year =	 2006,
  month =	 {June},
  abstract =	 {Decentralised estimation of heterogeneous sensors is
                  performed on an outdoor network. Attributes such as
                  position, appearance, and identity represented by
                  non-Gaussian distributions are used in in the fusion
                  process. It is shown here that real-time
                  decentralised data fusion of non-Gaussian estimates
                  can be used to build rich environmental maps. Human
                  operators are also used as additional sensors in the
                  network to complement robotic information.},
  c-dellaert =	 {One ground, one air vehicle, two
                  operators. Operators also provide info.},
  quotes =	 {At the geometric level, non-Gaussian Bayesian
                  estimation was used for fusing bearing-only position
                  observations from monocular vision sensors. We also
                  use an approximate node-node fusion algorithm [self]
                  using Gaussian mixture models (GMMs) and a variant
                  of the Covariance Intersect algorithm
                  [Julier97acc]. This algorithm provides consistent
                  estimates in practice but like Ihler and
                  Rosencrantz's work, there is no guarantee of a
                  convergent solution. All local node information was
                  then transmitted to neighbouring platforms. The net
                  result was that each platform locally maintained a
                  complete map (or belief) of all features observed by
                  all nodes in the network.}
}

@Article{Ur92,
  author =	 {H.~Ur and D.~Gross},
  title =	 {Improved Resolution from Subpixel Shifted Pictures},
  journal =	 GMIP,
  year =	 1992,
  volume =	 54,
  number =	 2,
  month =	 {March},
  pages =	 {181--186}
}

@InProceedings{Urmson02iros,
  author =	 {C. Urmson and M. B. Dias and R. Simmons},
  title =	 {Stereo Vision Based Navigation for Sun-Synchronous
                  Exploration},
  booktitle =	 IROS,
  year =	 2002,
  pages =	 {805-810},
}

@Article{Uyttendaele04,
  author =	 {M. Uyttendaele and A. Criminisi and S.B. Kang and
                  S. Winder and R. Szeliski and R. Hartley},
  fullauthor =	 {Matthew Uyttendaele and Antonio Criminisi and Sing
                  Bing Kang and Simon Winder and Richard Szeliski and
                  Richard Hartley},
  title =	 {Image-Based Interactive Exploration of Real-World
                  Environments},
  journal =	 {IEEE Computer Graphics and Applications},
  year =	 2004,
  volume =	 24,
  number =	 3,
  pages =	 {52-63},
  month =	 {May/June},
}

@inproceedings{Valgren06iros,
  title =	 {Incremental Topological Mapping Using
                  Omnidirectional Vision},
  author =	 {C. Valgren and A. Lilienthal and Tom Duckett},
  booktitle =	 IROS,
  year =	 2006,
  abstract =	 {This paper presents an algorithm that builds
                  topological maps, using omnidirectional vision as
                  the only sensor modality. Local features are
                  extracted from images obtained in sequence, and are
                  used both to cluster the images into nodes and to
                  detect links between the nodes. The algorithm is
                  incremental, reducing the computational requirements
                  of the corresponding batch algorithm. Experimental
                  results in a complex, indoor environment show that
                  the algorithm produces topologically correct maps,
                  closing loops without suffering from perceptual
                  aliasing or false links. Robustness to lighting
                  variations was further demonstrated by building
                  correct maps from combined multiple datasets
                  collected over a period of 2 months.},
  c-ananth =	 {Many existing algorithms use low-level
                  characteristics specific to particular sensing
                  modalities such as obstacle distances from laser
                  scanners to characterize landmarks. These methods
                  cannot be retargeted to other sensors. An instance
                  is Valgren and Duckett [Valgren06iros] perform
                  topological mapping using an omnidirectional camera
                  and model places using SIFT histograms. Ambiguity is
                  solved using maximum likelihood matching of SIFT
                  features, done by computing an affinity matrix of
                  the images, and thus involves binding decisions at
                  each step.}
}

@Article{Valiant1979,
  title =	 {The Complexity of Computing the Permanent},
  author =	 {L. G. Valiant},
  pages =	 {189--201},
  journal =	 tcs,
  year =	 1979,
  month =	 apr,
  volume =	 8,
  number =	 2,
  source =	 {http://theory.lcs.mit.edu/~dmjones/hbp/tcs/tcs.bib}
}

@InProceedings{VanDerMerwe01icassp,
  fullauthor =	 {Rudolph van der Merwe and Eric A. Wan},
  author =	 {R.v.d. Merwe and E.A. Wan},
  title =	 {The square-root Unscented {K}alman filter for state
                  and parameter estimation},
  booktitle =	 ICASSP,
  pages =	 {3461--3464},
  volumn =	 6,
  location =	 {Salt Lake City, Utah},
  year =	 2001,
}

@Article{VanderVorst00cse,
  author =	 {{van der Vorst}, H.A.},
  title =	 {Krylov subspace iteration},
  pages =	 {32--37},
  crossref =	 {_CSE00Jan},
  journal =	 {Computing in Science \& Engineering},
  volume =	 2,
  number =	 1,
  month =	 {Jan.-Feb.},
  year =	 2000,
  note =	 {Special issue on the Top 10 Algorithms in {Science}
                  \& {Engineering}},
}

@InProceedings{Vasconcelos98nips,
  author =	 {N. Vasconcelos and A. Lippman},
  title =	 {Learning Mixture Hierarchies},
  booktitle =	 {NIPS},
  year =	 1998,
}

@Article{Vaseghi95,
  author =	 {S. V. Vaseghi},
  title =	 {State duration modeling in hidden {M}arkov models},
  journal =	 {IEEE Trans. Information Theory},
  year =	 1995,
  volume =	 41,
  pages =	 {31-41},
}

@InProceedings{Vassallo98,
  author =	 {R. F. Vassallo and H. J. Schneebeli and
                  J. Santos-Victor},
  title =	 {Visual navigation: combining visual servoing and
                  appearance based methods},
  booktitle =	 {Int. Symposium on Intelligent Robotic Systems},
  year =	 1996,
  month =	 {july},
}

@inproceedings{Vasudevan06iros,
  author =	 {Vasudevan, S. and Gachter, S. and Berger, M. and
                  Siegwart, R.},
  title =	 {Cognitive Maps for Mobile Robots: An Object based
                  Approach},
  year =	 2006,
  booktitle =	 {Proceedings of the {IROS} Workshop From Sensors to
                  Human Spatial Concepts ({FS2HSC} 2006)},
  abstract =	 {Robots are rapidly evolving from factory workhorses
                  to robot-companions. The future of robots, as our
                  companions, is highly dependent on their abilities
                  to understand, interpret and represent the
                  environment in an efficient and consistent fashion,
                  in a way that is comprehensible to humans. This
                  paper is oriented in this direction. It suggests a
                  hierarchical probabilistic representation of space
                  that is based on objects. A global topological
                  representation of places with object graphs serving
                  as local maps is suggested. Experiments on place
                  classification and place recognition are also
                  reported in order to demonstrate the applicability
                  of such a representation in the context of
                  understanding space and thereby performing spatial
                  cognition. Further, relevant results from user
                  studies validating the proposed representation are
                  also reported. Thus the theme of the work is
                  representation for spatial cognition.},
}

@article{Vasudevan07ras,
  author =	 {Vasudevan, S. and Gachter, S. and Berger, M. and
                  Siegwart, R.},
  fullauthor =	 {Shrihari Vasudevan and Stefan G\"achter and Viet
                  Nguyen and Roland Siegwart},
  title =	 {Cognitive Maps for Mobile Robots --- An Object based
                  Approach},
  year =	 {2007},
  journal =	 RAS,
  volume =	 {55},
  number =	 {5},
  month =	 {May},
  pages =	 {359--371}
}

@inproceedings{Vedaldi05iccv,
  Author =	 {A. Vedaldi and H. Jin and P. Favaro and S. Soatto},
  Title =	 {KALMANSAC: Robust Filtering by Consensus},
  Booktitle =	 ICCV,
  Pages =	 {633--640},
  Year =	 2005
}

@inproceedings{Vedaldi06cvpr,
  Author =	 {A. Vedaldi and S. Soatto},
  Title =	 {Local Features, All Grown Up},
  Booktitle =	 CVPR,
  Pages =	 {1753--1760},
  Year =	 2006
}

@INPROCEEDINGS{Vedaldi07cvpr,
  title =	 {Moving Forward in Structure From Motion},
  author =	 {Vedaldi, A. and Guidi, G. and Soatto, S.},
  booktitle =	 {Computer Vision and Pattern Recognition, 2007. CVPR
                  '07. IEEE Conference on},
  year =	 2007,
  month =	 {June},
  pages =	 {1-7},
  keywords =	 {image motion analysis, image reconstruction, least
                  squares approximations, navigationautonomous
                  navigation applications, error landscape, forward
                  motion, images, instantaneous least-squares
                  reprojection error, local minima, scene
                  reconstructed depth, singularities,
                  structure-from-motion},
}

@Article{Vedula05TOG,
  author =	 {Sundar Vedula and Simon Baker and Takeo Kanade},
  title =	 {Image-Based Spatio-Temporal Modeling and View
                  Interpolation of Dynamic Events},
  journal =	 {ACM Transactions on Graphics},
  month =	 {April},
  year =	 2005,
  volume =	 24,
  number =	 2,
  pages =	 {240 - 261},
}

@InProceedings{Veeck04iros,
  author =	 {Veeck, M. and Burgard, W.},
  title =	 {Learning Polyline Maps from Range Scan Data Acquired
                  with Mobile Robots},
  booktitle =	 IROS,
  year =	 2004,
  abstract =	 {Geometric representations of the environment play an
                  important role in mobile robotics as they support
                  various tasks such as motion control and accurate
                  localization. Popular approaches to represent the
                  geometric features of an environment are occupancy
                  grids or line models. Whereas occupancy grids
                  require a huge amount of memory and therefore do not
                  scale well with the size of the environment, line
                  models are unable to correctly represent corners or
                  connections between objects. In this paper we
                  present an algorithm that learns sets of polylines
                  from laser range scans. Starting with an initial set
                  of polylines generated from the range scans it
                  iteratively optimizes these polylines using the
                  Bayesian Information Criterion. During the
                  optimization process our algorithm utilizes
                  information about the angles between line segments
                  extracted from the original range scans. We present
                  experiments illustrating that our algorithm is able
                  to learn accurate and highly compact polyline maps
                  from laser range data obtained with mobile robots.},
}

@Article{Veeraraghavan08pami,
  author =	 {A. Veeraraghavan and R. Chellappa and M. Srinivasan},
  title =	 {Shape-and-Behavior Encoded Tracking of Bee Dance},
  journal =	 PAMI,
  month =	 {March},
  year =	 2008,
  volume =	 30,
  number =	 3,
  pages =	 {463 -- 476},
  c-sangmin =	 {In general, quite simplistic approach towards the
                  honey bee dance recognition problem where they
                  closed the loop between the tracking and behavior
                  recognition. The approaches, while simple, looks
                  very practical, highly engineered towards the
                  problem although it may deliver some general
                  framework to some extent. One nice part is to
                  measure the auto-regressive model correlation length
                  through thorough result analysis. It looks quite
                  principled, and should be used in my work
                  afterwards, in case I would need to measure the
                  effective corrleated length. The experimental
                  results,, miss labeling results though while they
                  claim that the waggle detection is excellent,, not
                  very convincing in Sangmin's opinion since
                  qualitative results tend to deliver more information
                  for the labeling tasks due to the possible over
                  segementations. },
}

@InProceedings{Veloso06hri,
  author =       {Manuela M. Veloso and Paul E. Rybski and Felix von Hundelshausen},
  title =        {FOCUS: A Generalized Method for Object Discovery for Robots taht Observe and Interact with Humans},
  booktitle =    HRI,
  year =         2006,
  added-by =     {Alex},
}

@InProceedings{Vermaak02,
  author =	 {J. Vermaak and P. Perez and M. Gangnet and A. Blake},
  title =	 {Towards Improved Observation Models for Visual
                  Tracking: Selective Adaptation},
  booktitle =	 ECCV,
  pages =	 {645-660},
  year =	 2002,
}

@InProceedings{Vermaak03,
  author =	 {J. Vermaak and N. Lawrence and P. Perez},
  title =	 {Variational Inference for Visual Tracking},
  booktitle =	 CVPR,
  year =	 2003,
  pages =	 {773--780},
}

@InProceedings{Vermaak03b,
  author =	 {J. Vermaak and S. J. Godsill and A. Doucet},
  title =	 {Radial Basis Function Regression Using
                  Trans-Dimensional Sequential Monte Carlo},
  booktitle =	 {Proceedings of the 12th IEEE Workshop on Statistical
                  Signal Processing},
  pages =	 {525-528},
  year =	 2003
}

@InProceedings{Vermaak03c,
  author =	 {J. Vermaak and A. Doucet and P. Perez},
  title =	 {Maintaining Multi-Modality through Mixture Tracking},
  booktitle =	 ICCV,
  year =	 2003,
}

@article{Vermaak04a,
  Author =	 {Vermaak, J. and Godsill, S. and Perez, P.},
  Title =	 {Monte {C}arlo filtering for multi-target tracking
                  and data association},
  Journal =	 AES,
  Year =	 2004
}

@InProceedings{Vetter98,
  author =	 {T. Vetter and V. Blanz},
  title =	 {Coloured {3D} Face Models from Single Images: An
                  Example Based Approach},
  booktitle =	 ECCV,
  year =	 1998,
  pages =	 {499--513},
}

@Inproceedings{Vicci99,
  author =	 "L. Vicci and S. Brumback and K. Keller and G. Welch
                  and G. Bishop and D. Colucci",
  title =	 "The {H}iball tracker: High-performance widearea
                  tracking for virtual and augmented environments",
  booktitle =	 "Proceedings of the ACM Symposium on Virtual Reality
                  Software and Technology",
  publisher =	 "Addison-Wesley",
  pages =	 "1--11",
  year =	 1999
}

@Inproceedings{Vidal02cdc,
  author =	 "R. Vidal and A. Chiuso and S. Soatto",
  title =	 "Observability and identifiability of jump linear
                  systems",
  booktitle =	 CDC,
  year =	 2002,
  volume =	 4,
  pages =	 "3614-3619",
}

@article{Vidal06ijcv,
  title =	 {{Two-View Multibody Structure from Motion}},
  author =	 {Vidal, R. and Ma, Y. and Soatto, S. and Sastry, S.},
  journal =	 IJCV,
  volume =	 68,
  number =	 1,
  pages =	 {7--25},
  year =	 2006,
  publisher =	 {Springer}
}

@InProceedings{Viejo07iros,
  author =	 {D. Viejo and M. Cazorla},
  title =	 {3D plane-based egomotion for SLAM on semi-structured
                  environment},
  booktitle =	 IROS,
  year =	 {2007}
}

@InProceedings{Viejo07iros,
  author = {D. Viejo and M. Cazorla},
  title = {3D plane-based egomotion for SLAM on semi-structured environment},
  booktitle = IROS,
  year = {2007}
}

@InProceedings{Viola01,
  author =	 {P. Viola and M. Jones},
  title =	 {Rapid object detection using a boosted cascade of
                  simple features},
  booktitle =	 CVPR,
  year =	 2001,
}

@article{Viola02ijcv,
  author =	 {Paul Viola and Michael Jones},
  title =	 {Robust Real-time Object Detection},
  journal =	 {International Journal of Computer Vision - to
                  appear},
  year =	 2002,
  url =		 {citeseer.nj.nec.com/viola01robust.html}
}

@Book{VonNeumann44,
  author =	 {{von Neumann}, John and Morgenstern, Oskar},
  fullauthor =	 {{von Neumann}, John and Morgenstern, Oskar},
  title =	 {Theory of Games and Economic Behavior},
  publisher =	 {Princeton University Press},
  year =	 1944,
}

@InProceedings{Vorst08iros,
  author =	 {P. Vorst and S. Schneegans and B. Yang and A. Zell},
  title =	 {Self-Localization with RFID Snapshots in Densley
                  Tagged Environments},
  booktitle =	 IROS,
  year =	 {2008}
}

@InProceedings{Vorst08iros,
  author = {P. Vorst and S. Schneegans and B. Yang and A. Zell},
  title = {Self-Localization with RFID Snapshots in Densley Tagged Environments},
  booktitle = IROS,
  year = {2008}
}

@article{Vu02wscg,
  author =	 "V-T. Vu, F. Bremond and M. Thonnat",
  fullauthor =	 "Van-Thinh Vu, Francois Bremond and Monique Thonnat",
  title =	 "Human behaviour visualisation and simulation for
                  automatic video understanding",
  journal =	 "Journal of WSCG",
  pages =	 {1388-1399},
  volume =	 10,
  number =	 {1-3},
  year =	 2002,
}

@article{Vujovic97,
  author =	 "N. Vujovic and D. Brzakovic",
  title =	 "Establishing the correspondence between control
                  points in pairs of mammographic images",
  journal =	 IP,
  pages =	 "1388-1399",
  volume =	 6,
  number =	 10,
  year =	 1997,
}

@inproceedings{Wagner07cvww,
  author =	 {Daniel Wagner and Dieter Schmalsteig},
  title =	 {ARToolKitPlus for pose tracking on mobile devices},
  booktitle =	 {Computer Vision Winter Workshop},
  year =	 {2007},
  c-alireza =	 {They present ARToolKitPlus in this paper, a
                  successor to popular ARToolKit pose tracking
                  library. Fiducial markers are widely used today for
                  different augmented reality applications. The
                  ARToolKitPlus searches for rectangular markers in
                  the images and uses basic computer vision techniques
                  to efficiently find the four corners of the
                  markers. Knowing the location of four points on a
                  planar surface is enough to use homography and find
                  the relative pose of the marker with respect to the
                  camera. ARToolKitPlus provides the capability of
                  syntheisizing hundreds of Id-based fiducial markers
                  and efficiently tracking them. }
}

@InProceedings{Wagner07cvww,
  author =	 {Daniel Wagner and Dieter Schmalsteig},
  title =	 {ARToolKitPlus for pose tracking on mobile devices},
  booktitle =	 {cvww},
  year =	 {2007},
  alireza =	 {They present ARToolKitPlus in this paper, a
                  successor to popular ARToolKit pose tracking
                  library. Fiducial markers are widely used today for
                  different augmented reality applications. The
                  ARToolKitPlus searches for rectangular markers in
                  the images and uses basic computer vision techniques
                  to efficiently find the four corners of the
                  markers. Knowing the location of four points on a
                  planar surface is enough to use homography and find
                  the relative pose of the marker with respect to the
                  camera. ARToolKitPlus provides the capability of
                  syntheisizing hundreds of Id-based fiducial markers
                  and efficiently tracking them. }
}

@InProceedings{Wahlgren05,
  author =	 {C. Wahlgren and T. Duckett},
  title =	 {Topological Mapping for Mobile Robots using
                  Omnidirectional Vision (extended abstract)},
  booktitle =	 {Proceedings of the Third Swedish Workshop on
                  Autonomous Robotics},
  year =	 2005,
}

@techreport{Wainwright03tr,
  Author =	 {M. J. Wainwright and M. I. Jordan},
  Title =	 {Semidefinite Relaxations for Approximate Inference
                  on Graphs with Cycles},
  Institution =	 {EECS Department, University of California, Berkeley},
  Year =	 2003,
  URL =
                  {http://www.eecs.berkeley.edu/Pubs/TechRpts/2003/5347.html},
  Number =	 {UCB/CSD-03-1226},
}

@article{Wainwright99vr,
  author =	 "M. Wainwright",
  title =	 "Visual adaptation as optimal information
                  transmission",
  journal =	 "Vision Research",
  volume =	 39,
  pages =	 {3960--3974},
  year =	 1999,
  abstract =	 {We propose that visual adaptation in orientation,
                  spatial frequency, and motion can be understood from
                  the perspective of optimal information
                  transmission. The essence of the proposal is that
                  neural response properties at the system level
                  should be adjusted to the changing statistics of the
                  input so as to maximize information transmission. We
                  show that this principle accounts for several
                  well-documented psychophysical phenomena, including
                  the tilt aftereffect, change in contrast sensitivity
                  and post-adaptation changes in orientation
                  discrimination. Adaptation can also be considered on
                  a longer time scale, in the context of tailoring
                  response properties to natural scene
                  statistics. From the anisotropic distribution of
                  power in natural scenes, the proposal also predicts
                  differences in the contrast sensitivity function
                  across spatial frequency and orientation, including
                  the oblique effect.},
}

@InProceedings{Walker00icad,
  author =	 {Walker, B. N. and Kramer, G. and Lane, D. M.},
  year =	 {2000},
  title =	 {Psychophysical scaling of sonification mappings},
  booktitle =	 {Proceedings of the Sixth International Conference on
                  Auditory Display, Atlanta, GA (2-5 April)},
}

@InProceedings{Walker00icad,
  author =	 {Walker, B. N. and Kramer, G. and Lane, D. M.},
  year =	 2000,
  title =	 {Psychophysical scaling of sonification mappings},
  booktitle =	 {Proceedings of the Sixth International Conference on
                  Auditory Display, Atlanta, GA (2-5 April)},
}

@InProceedings{Walker01icad,
  author =	 {Walker, B. N. and Lane, D. M.},
  year =	 2001,
  title =	 {Psychophysical scaling of sonification mappings: A
                  comparison of sighted and visually impaired
                  listeners},
  booktitle =	 {Proceedings of the Seventh International Conference
                  on Auditory Display, Espoo, Finland (28 July - 01
                  August)},
  pages =	 {90-94},
}


@Article{Walker06hf,
  author =	 {Walker, B. N. and Lindsay, J.},
  title =	 {Navigation performance with a virtual auditory
                  display: Effects of beacon sound, capture radius,
                  and practice},
  journal =	 {Human Factors},
  year =	 2006,
  volume =	 48,
  number =	 2,
  pages =	 {265- 278},
}

@InProceedings{Walker96icad,
  author =	 {Walker, B. N. and Kramer, G.},
  year =	 1996,
  title =	 {Mappings and metaphors in auditory displays: An
                  experimental assessment},
  booktitle =	 {Proceedings of the Third International Conference on
                  Auditory Display, Palo Alto, CA (4-6 November)},
}

@InProceedings{WalkerKramer96aes,
  author =	 {Walker, B. N. and Kramer, G.},
  year =	 1996,
  title =	 {Human factors and the acoustic ecology:
                  Considerations for multimedia audio design},
  booktitle =	 {Proceedings of the Audio Engineering Society 101st
                  Convention, Los Angeles, CA (8-11 November)},
}

@PhdThesis{Walter72thesis,
  author =	 {J.R. Walter},
  title =	 {Representations of rigid cycle graphs},
  School =	 {Wayne State University},
  year =	 1972,
  r-Blair93chapter ={The notion of clique trees was introduced
                  independently by Buneman \cite{Buneman74dm},
                  Gavril\cite{Gavril74jct}, and Walter
                  \cite{Walter72thesis}},
  r-Heggernes06dm ={Chordal graphs are exactly the intersection graphs
                  of subtrees of a tree
                  \cite{Buneman74dm,Gavril74jct,Walter72thesis}: A
                  graph G is chordal if and only if there exists a
                  tree T whose vertex set is the set of maximal
                  cliques of G and that satisfies the following
                  property: for every vertex v in G, the set of
                  maximal cliques containing v induces a connected
                  subtree of T. Such a tree is called a clique tree,
                  and it can be computed in linear time
                  \cite{Blair93chapter}.},
}

@Misc{Waltz06,
  author =	 {David L. Waltz},
  title =	 {Gene Freuder and the Roots of Constraint
                  Computation},
  howpublished = {Web},
  month =	 {January},
  year =	 {2006},
  c-dellaert =	 {Idea of assigning labels to folds goes back to (the)
                  David Huffman. Arc consistency can solve scene
                  labeling.}
}

@Article{Wang02,
  author =	 {X. Wang and S. Challa and R. Evans},
  title =	 {Gating techniques for maneuvering target tracking in
                  clutter},
  journal =	 AES,
  year =	 2002,
  volume =	 38,
  number =	 3,
  pages =	 {1087- 1097},
}

@InProceedings{Wang05fsr,
  author =	 {Z. Wang and S. Huang and G. Dissanayake},
  title =	 {Implementation issues and experimental evaluation of
                  {D-SLAM}},
  booktitle =	 FSR,
  location =	 {Port Douglas, Australia},
  month =	 {Jul},
  year =	 2005,
  abstract =	 {D-SLAM algorithm first described in [1] allows SLAM
                  to be decoupled into solving a non-linear static
                  estimation problem for mapping and a
                  three-dimensional estimation problem for
                  localization. This paper presents a new version of
                  the D-SLAM algorithm that uses an absolute map
                  instead of a relative map as presented in [1]. One
                  of the significant advantages of D-SLAM algorithm is
                  its O(N) computational cost where N is the total
                  number of features (landmarks). The theoretical
                  foundations of D-SLAM together with implementation
                  issues including data association, state recovery,
                  and computational complexity are addressed in
                  detail. Evaluation of the D-SLAM algorithm is
                  provided using both real experimental data and
                  simulations.},
  r-Wang05isrr = {The landmark locations are maintained using either a
                  compact relative map [Wang05iros] or an absolute
                  Cartesian map [this]. The new formulation retains
                  the significant advantage of being able to improve
                  the location estimates of all the landmarks from one
                  local observation, yet results in an exactly sparse
                  information matrix with the number of nonzero
                  elements related to the range of the sensor on board
                  the robot. The main assumption in [Wang05iros]
                  [this] is that the robot can observe at least two
                  previously seen landmarks in each observation.},
}

@InProceedings{Wang05fsr,
  author =	 {Z. Wang and S. Huang and G. Dissanayake},
  title =	 {Implementation issues and experimental evaluation of
                  {D-SLAM}},
  booktitle =	 FSR,
  location =	 {Port Douglas, Australia},
  month =	 {Jul},
  year =	 {2005},
}

@InProceedings{Wang05iros,
  author =	 {Z. Wang and S. Huang and G. Dissanayake},
  title =	 {Decoupling Localization and Mapping in {SLAM} Using
                  Compact Relative Maps},
  booktitle =	 IROS,
  location =	 {Edmonton, Canada},
  month =	 {Aug},
  year =	 2005,
  abstract =	 {In this paper, we propose a new algorithm for SLAM
                  that makes use of a state vector consisting of
                  quantities that describes the relative locations
                  among features. In contrast to previous relative map
                  strategies, the new state vector is compact and
                  always consists of 2n-3 elements (in a 2-D
                  environment) where n is the number of features in
                  the map. It is also shown that the information from
                  observations can be transformed and grouped into two
                  parts: first one containing the information about
                  the map and the second one containing the
                  information about the robot location relative to the
                  features in the map. Therefore the SLAM can be
                  decoupled into two processes where mapping uses the
                  first part of the transformed observation vector and
                  localization becomes a 3-dimensional estimation
                  problem. It is also shown that the information
                  matrix of the map is exactly sparse, resulting in
                  potential computational savings when an information
                  filter is used for mapping. The new decoupled SLAM
                  algorithm is called D-SLAM and is illustrated using
                  simulation. },
  r-Wang05isrr = {The landmark locations are maintained using either a
                  compact relative map [this] or an absolute Cartesian
                  map [Wang05fsr]. The new formulation retains the
                  significant advantage of being able to improve the
                  location estimates of all the landmarks from one
                  local observation, yet results in an exactly sparse
                  information matrix with the number of nonzero
                  elements related to the range of the sensor on board
                  the robot. The main assumption in [this] [Wang05fsr]
                  is that the robot can observe at least two
                  previously seen landmarks in each observation.},
}

@InProceedings{Wang05iros,
  author =	 {Z. Wang and S. Huang and G. Dissanayake},
  title =	 {Decoupling Localization and Mapping in {SLAM} Using
                  Compact Relative Maps},
  booktitle =	 IROS,
  location =	 {Edmonton, Canada},
  month =	 {Aug},
  year =	 {2005},
}

@InProceedings{Wang05isrr,
  author =	 {Z. Wang and S. Huang and G. Dissanayake},
  title =	 {{DSLAM}: Decoupled Localization and Mapping for
                  Autonomous Robots},
  booktitle =	 {International Symposium of Robotics Research (ISRR
                  05)},
  month =	 {Oct},
  year =	 2005,
  abstract =	 {The main contribution of this paper is the
                  reformulation of the simultaneous localization and
                  mapping (SLAM) problem for mobile robots such that
                  the mapping and localization can be treated as two
                  concurrent yet separated processes: DSLAM (decoupled
                  SLAM). It is shown that SLAM can be decoupled into
                  solving a nonlinear static estimation problem for
                  mapping and a lowdimensional dynamic estimation
                  problem for localization. The mapping problem can be
                  solved using an Extended Information Filter where
                  the information matrix is shown to be exactly
                  sparse. A significant saving in the computational
                  effort can be achieved for large scale problems by
                  exploiting the special properties of sparse
                  matrices. An important feature of DSLAM is that the
                  correlation among landmarks are still kept and it is
                  demonstrated that the uncertainty of the map
                  landmarks monotonically decrease. The algorithm is
                  illustrated through computer simulations and
                  experiments.},
  quotes =	 {The main assumption in [Wang05iros] [Wang05fsr] is
                  that the robot can observe at least two previously
                  seen landmarks in each observation. This paper
                  provides a strategy to relax the above assumption by
                  merging a set of observations to construct
                  admissible measurements. An improved localization
                  process based on a local SLAM is also presented.},
  c-kaess =	 {D-SLAM converts measurements into relative
                  measurements between two landmarks, so that the
                  robot location can be omitted from the state
                  vector. The resulting information matrix is exactly
                  sparse (but not necessarily banddiagonal as in the
                  example in Figure 4c!). Updates are constant time,
                  but recovering the state vector requires solving a
                  sparse linear equation. Given a good initial guess
                  from the previous estimation this can be done in
                  linear time, for example by preconditioned CG.},
}

@InProceedings{Wang06_3dpvt,
  author =	 {W. Zhang and J. Kosecka},
  title =	 {Image Based Localization in Urban Environments},
  booktitle =	 PVT,
  year =	 {2006},
  month =	 {May},
  abstract =	 {In this paper we present a prototype system for
                  image based localization in urban
                  environments. Given a database of views of city
                  street scenes tagged by GPS locations, the system
                  computes the GPS location of a novel query view. We
                  first use a wide-baseline matching technique based
                  on SIFT features to select the closest views in the
                  database. Often due to a large change of viewpoint
                  and presence of repetitive structures, a large
                  percentage of matches (> 50\%) are not correct
                  correspondences. The subsequent motion estimation
                  between the query view and the reference view, is
                  then handled by a novel and efficient robust
                  estimation technique capable of dealing with large
                  percentage of outliers. This stage is also
                  accompanied by a model selection step among the
                  fundamental matrix and the homography. Once the
                  motion between the closest reference views is
                  estimated, the location of the query view is then
                  obtained by triangulation of translation
                  directions. Approximate solutions for cases when
                  triangulation cannot be obtained reliably are also
                  described. The presented system is tested on the
                  dataset used in ICCV 2005 Computer Vision Contest
                  and is shown to have higher accuracy than previous
                  reported results.},
  c-dellaert =	 {modified WB matching with more matches, novel motion
                  estimation, SIFT keypoints, voting scheme for
                  location recognition, }
}

@inproceedings{Wang06cvpr,
  author =	 {S. Wang, A. Quattoni, L. Morency, D. Demirdjian and
                  T. Darrell},
  title =	 {Hidden Conditional Random Fields for Gesture
                  Recognition},
  booktitle =	 CVPR,
  year =	 {2006},
  keywords =	 {behavior recognition, gesture recognition, crf,
                  hidden},
  c-sangmin =	 {They develop hidden CRF model for gesture
                  recognition. They claim that (I agree) hidden
                  structures are well shared between different
                  gestures through joint discriminative
                  learning. Their experimental results against HMMs
                  and CRFs look fairly convincing for their specific
                  tasks and provides illustrative examples of
                  structured hidden structures. Nontheless, the
                  limitation is that they provide segmented examples
                  for classification. Hence, the problem is
                  essentially simpler than continous recognition. },
}

@InProceedings{Wang06eccv,
  author =	 {X. Wang, K. Tieu and E. Grimson},
  fullauthor =	 {Xiaogang Wang, Kinh Tieu and Eric Grimson},
  title =	 {{Learning Semantic Scene Models by Trajectory
                  Analysis}},
  booktitle =	 ECCV,
  volume =	 3,
  pages =	 {110--123},
  year =	 2006,
  keywords =	 {trajectory clustering, surveillence, tracking},
  c-sangmin =	 {use Stauffer tracker to obtain tracking data from
                  wide area. then, cluster the paths based on
                  hand-crafted distance metrics. The advantage of the
                  distance metric is that it can cluster data with
                  incomplete tracking(over-segmented data).The
                  clusters divide the paths between cars and
                  pedestrians as they incorporate object features as
                  well.The concepts of birth and sink are good terms.}
}

@PhdThesis{Wang07thesis,
  author =	 {Z. Wang},
  fullauthor =	 {Zhan Wang},
  title =	 {Exactly Sparse Information Filters for Simultaneous
                  Localization and Mapping},
  year =	 2007,
  school =	 {The University of Technology, Sydney},
}

@article{Wang83,
  author =	 "C.Y. Wang and H. Sun H. and S. Yada and
                  A. Rosenfeld",
  title =	 "Some Experiments in Relaxation Image Matching Using
                  Corner Features",
  journal =	 PR,
  volume =	 16,
  number =	 2,
  pages =	 "167-182",
  year =	 1983
}

@Article{Wang94ip,
  author =	 {J.Y.A. Wang and E. H. Adelson},
  title =	 {Representing moving images with layers},
  journal =	 IP,
  month =	 {September},
  year =	 1994,
  volume =	 3,
  number =	 5,
  pages =	 {625--638},
  c-sangmin =	 {seminal paper which introduced layered
                  representation},
  keywords =	 {layers, video analysis},
}

@InProceedings{Watkins06aiaa,
  author =	 {A. Watkins and J. Kehoe and R. Lind},
  title =	 {SLAM for Flight Through Urban Environments using
                  Dimensionality Reduction},
  booktitle =	 {Proceedings of the AIAA Guidance, Navigation, and
                  Control Conference},
  year =	 {2006},
  added_by =	 {Alireza},
}

@InProceedings{Watkins06aiaa,
  author = {A. Watkins and J. Kehoe and R. Lind},
  title = {SLAM for Flight Through Urban Environments using Dimensionality Reduction},
  booktitle = {Proceedings of the AIAA Guidance, Navigation, and Control Conference},
  year = {2006},
  added_by = {Alireza}
}

@inproceedings{Weber00eccv,
  author =	 "Markus Weber and Max Welling and Pietro Perona",
  title =	 "Unsupervised Learning of Models for Recognition",
  booktitle =	 ECCV,
  pages =	 "18-32",
  year =	 2000,
  url =		 "citeseer.nj.nec.com/weber00unsupervised.html"
}

@InProceedings{Weber95,
  author =	 "J. Weber and D. Koller and Q.-T. Luong and J. Malik",
  title =	 "An integrated stereo-based approach to automatic
                  vehicle guidance",
  booktitle =	 ICCV,
  year =	 1995,
  address =	 "Boston",
  month =	 "June",
}

@Article{Wehner96jeb,
  author =	 {R\"udiger Wehner and Barbara Michel and Per Antonsen},
  title =	 {Visual Navigation in Insects:  Coupling of Egocentric and Geocentric Information},
  journal =	 {The Journal of Experimental Biology},
  year =	 1996,
  volume =	 199,
  pages =	 {129-140},
  publisher =	 {The Company of Biologists Limited},
  added-by =	 {richard},
}

@inproceedings{Wei00siggraph,
  author =	 "Li-Yi Wei and Marc Levoy",
  title =	 "Fast Texture Synthesis Using Tree-Structured Vector
                  Quantization",
  booktitle =	 SIGGRAPH,
  editor =	 "Kurt Akeley",
  pages =	 "479--488",
  year =	 2000,
  url =		 "citeseer.nj.nec.com/wei00fast.html"
}

@inproceedings{Weiss99nips,
  author =	 {Yair Weiss and William T. Freeman},
  title =	 {Correctness of Belief Propagation in {Gaussian}
                  Graphical Models of Arbitrary Topology.},
  booktitle =	 NIPS,
  year =	 1999,
  pages =	 {673-679},
  ee =		 {http://nips.djvuzone.org/djvu/nips12/0673.djvu},
  bibsource =	 {DBLP, http://dblp.uni-trier.de}
}

@article{Welch97scaat,
  author =	 "G. Welch and G. Bishop",
  title =	 "{SCAAT}: Incremental Tracking with Incomplete
                  Information",
  journal =	 "Computer Graphics",
  volume =	 31,
  number =	 "{Annual Conference Series}",
  pages =	 "333--344",
  year =	 1997,
  url =		 "citeseer.ist.psu.edu/welch97scaat.html"
}

@Article{Weld99,
  author =	 "D.S. Weld",
  title =	 "Recent Advances in AI Planning",
  journal =	 "AI Magazine",
  year =	 1999,
  volume =	 20,
  number =	 2,
  pages =	 "93-123",
}

@InProceedings{Welling03,
  author =	 {M. Welling and G. E. Hinton S. Osindero},
  title =	 {Learning Sparse Topographic Representations with
                  Products of Student-t Distributions},
  booktitle =	 NIPS,
  year =	 2003
}

@InProceedings{Wellington2004,
  author =	 {C. Wellington and A. Stentz},
  title =	 {Online Adaptive Rough-Terrain Navigation in
                  Vegetation},
  booktitle =	 ICRA,
  year =	 2004,
}

@InProceedings{Wellington2005,
  author =	 {C. Wellington and A. Courville and A. Stentz},
  title =	 {Interacting Markov Random Fields for Simultaneous
                  Terrain Modeling and Obstacle Detection},
  booktitle =	 RSS,
  pages =	 {},
  year =	 {2005},
  month =	 {},
  address =	 {},
}

@article{Wells97,
  author =	 "W. Wells",
  title =	 "Statistical approaches to feature-based object
                  recognition",
  journal =	 IJCV,
  year =	 1997,
  volume =	 21,
  number =	 "1/2",
  pages =	 "63--98",
}

@InProceedings{Wen03,
  author =	 {Z.Wen and Z.Liu and T.S.Huang},
  title =	 {Face Relighting with Radiance Environment Maps},
  booktitle =	 CVPR,
  year =	 2003,
}

@article{Weng89,
  author =	 {J. Weng and T. Huang and N. Ahuja},
  title =	 {Motion and structure from two perspective views:
                  algorithms, error analysis and error estimation},
  journal =	 PAMI,
  volume =	 11,
  number =	 5,
  pages =	 {451--476},
  year =	 1989,
}

@article{Weng93,
  author =	 "J. Weng and N. Ahuja and T. Huang",
  title =	 "Optimal motion and structure estimation",
  journal =	 PAMI,
  volume =	 15,
  pages =	 {864--884},
  month =	 {September},
  year =	 1993
}

@InProceedings{Wenger03egr,
  author =	 "A.Wenger and T. Hawkins and P. Debevec",
  title =	 "Optimizing Color Matching in Lighting Reproduction
                  System for Complex Subject and Illuminant Spectra",
  booktitle =	 "Eurographics Symposium on Rendering",
  year =	 2003,
}

@inproceedings{Wenger2005,
  author =	 {A.Wenger and A.Gardner and C.Tchou and J.Unger and
                  T.Hawkins and P.Debevec},
  title =	 {Performance relighting and reflectance
                  transformation with time-multiplexed illumination},
  booktitle =	 SIGGRAPH,
  year =	 2005,
  pages =	 {756--764},
}

@inproceedings{Werner02bmvc,
  author =	 "Werner, T. and Zisserman, A.",
  title =	 "Model Selection for Automated Architectural
                  Reconstruction from Multiple Views",
  booktitle =	 BMVC,
  year =	 2002
}

@inproceedings{Werner02eccv,
  author =	 "Werner, T. and Zisserman, A.",
  title =	 "New Techniques for Automated Architecture
                  Reconstruction from Photographs",
  booktitle =	 ECCV,
  year =	 2002,
  publisher =	 "Springer-Verlag",
}

@InProceedings{Werner95,
  author =	 "S Werner and A Buchwieser and E D Dickmanns",
  title =	 "Real-time simulation of visual machine perception
                  for helicopter flight assistance",
  booktitle =	 SPIE,
  volume =	 2463,
  year =	 1995,
  month =	 "April",
  pages =	 "93-101",
}

@InProceedings{Wettergreen97,
  author =	 {D. Wettergreen and H. Thomas and M. Bualat},
  title =	 {Initial Results from Vision-based Control of the
                  {A}mes {M}arsokhod {R}over},
  year =	 1997,
  booktitle =	 IROS,
}

@inproceedings{Wiberg95ett,
  author =	 {N. Wiberg and H.-A. Loeliger and R. K\"{o}tter},
  title =	 {Codes and iterative decoding on general graphs},
  booktitle =	 {Euro. Trans. Telecomm.},
  pages =	 {513--525},
  year =	 1995,
  volume =	 6,
  month =	 {Sept./Oct.},
  r-Forney01it = {Wiberg et al. pcitet{Wiberg95ett,Wiberg96thesis}
                  rediscovered Tanner's work and ex- tended it to
                  include state variables, a step whose importance can
                  hardly be overstated.},
}

@PhdThesis{Wiberg96thesis,
  author =	 "N. Wiberg",
  title =	 "Codes and Decoding on General Graphs",
  school =	 {Linkoping University, Sweden},
  year =	 1996,
  abstract =	 {Iterative decoding techniques have become a viable
                  alternative for constructing high performance coding
                  systems. In particular, the recent success of turbo
                  codes indicates that performance close to the
                  Shannon limit may be achieved. In this thesis, it is
                  showed that many iterative decoding algorithms are
                  special cases of two generic algorithms, the min-sum
                  and sum-product algorithms, which also include
                  non-iterative algorithms such as Viterbi decod-
                  ing. The min-sum and sum-product algorithms are
                  developed and presented as generalized trellis
                  algorithms, where the time axis of the trellis is
                  replaced by an arbitrary graph, the "Tanner
                  graph". With cycle-free Tanner graphs, the resulting
                  decoding algorithms (e.g., Viterbi decoding) are
                  maximum-likelihood but suffer from an exponentially
                  increasing com- plexity. Iterative decoding occurs
                  when the Tanner graph has cycles (e.g., turbo
                  codes); the resulting algorithms are in general
                  suboptimal, but significant complexity reductions
                  are possible compared to the cycle-free
                  case. Several performance estimates for iterative
                  decod- ing are developed, including a generalization
                  of the union bound used with Viterbi decoding and a
                  characterization of errors that are uncorrectable
                  after infinitely many decoding itera-tions.},
  r-Kschischang01it ={Genealogically, factor graphs are a
                  straightforward generalization of the "Tanner
                  graphs" of Wiberg \cite{Wiberg96thesis}. Tanner
                  \cite{Tanner81it} introduced bipartite graphs to
                  describe families of codes which are generalizations
                  of the low-density parity-check (LDPC) codes of
                  Gallager \cite{Gallager62it}, and also described the
                  sum-product algorithm in this setting. ... Wiberg
                  introduced "hidden" (latent) state variables and
                  also suggested applications beyond coding.},
  r-Forney01it = {Wiberg et al. pcitet{Wiberg95ett,Wiberg96thesis}
                  rediscovered Tanner's work and extended it to
                  include state variables, a step whose importance can
                  hardly be overstated.},
}

@Article{Wilburn05TOG,
  author =	 {B. Wilburn and N. Joshi and V. Vaish and
                  E.-V. Talvala and E. Antunez and A. Barth and
                  A.Adams and M.Horowitz and M.levoy},
  title =	 {High Performance Imaging Using Large Camera Arrays},
  journal =	 {ACM Transactions on Graphics},
  year =	 {2005},
  volume =	 {24},
  number =	 {3},
  pages =	 {765 - 776},
}

@InProceedings{Wilczkowiak01iccv,
  author =	 {M. Wilczkowiak and E. Boyer and P. Sturm},
  title =	 {Camera Calibration and {3D} Reconstruction from
                  Single Images Using Parallelepipeds},
  booktitle =	 ICCV,
  pages =	 {142-148},
  year =	 2001,
  month =	 {July},
}

@InProceedings{Wilczkowiak02eccv,
  author =	 {M. Wilczkowiak and E. Boyer and P. Sturm},
  fullauthor =	 {Marta Wilczkowiak and Edmond Boyer and Peter Sturm},
  title =	 {{3D} Modeling Using Geometric Constraints: A
                  Parallelepiped Based Approach},
  booktitle =	 ECCV,
  pages =	 {221--237},
  year =	 2002,
  month =	 {May}
}

@inproceedings{Wilczkowiak03iccv,
  title =	 {Scene Modeling Based on Constraint System
                  Decomposition Techniques},
  author =	 {M. Wilczkowiak and G. Trombettoni and C. Jermann and
                  P. Sturm and E. Boyer},
  fullauthor =	 {Marta Wilczkowiak and Gilles Trombettoni and
                  Christophe Jermann and Peter Sturm and Edmond Boyer},
  pages =	 {1004--1010},
  booktitle =	 ICCV,
  address =	 {Nice, France},
  year =	 2003
}

@article{Wilkie03jov,
  author =	 {Wilkie, R. M. and Wann, J. P.},
  year =	 2003,
  title =	 {Eye-movements aid the control of locomotion},
  journal =	 {J. Vision},
  volume =	 3,
  number =	 11,
  pages =	 {677--684},
  abstract =	 {Eye-movements have long been considered a problem
                  when trying to understand the visual control of
                  locomotion. They transform the retinal image from a
                  simple expanding pattern of moving texture elements
                  (pure optic flow), into a complex combination of
                  translation and rotation components (retinal
                  flow). In this article we investigate whether there
                  are measurable advantages to having an active free
                  gaze, over a static gaze or tracking gaze, when
                  steering along a winding path. We also examine
                  patterns of free gaze behavior to determine
                  preferred gaze strategies during active
                  locomotion. Participants were asked to steer along a
                  computer-simulated textured roadway with free gaze,
                  fixed gaze, or gaze tracking the center of the
                  roadway. Deviation of position from the center of
                  the road was recorded along with their point of
                  gaze. It was found that visually tracking the middle
                  of the road produced smaller steering errors than
                  for fixed gaze. Participants performed best at the
                  steering task when allowed to sample naturally from
                  the road ahead with free gaze. There was some
                  variation in the gaze strategies used, but sampling
                  was predominantly of areas proximal to the center of
                  the road. These results diverge from traditional
                  models of flow analysis.},
  quotes =	 {With our simple robot traveling in a straight line
                  the current direction of motion is specified by the
                  FoE, so in principle it can be made to steer by
                  ensuring that the FoE always lies in the required
                  direction. .. Owls have large eyes, which are highly
                  sensitive to environmental motion, and are fixed in
                  their sockets. .. Nearly all animals with good
                  vision can move their eyes, and in most cases a
                  mobile gaze is an essential feature of visual data
                  acquisition. It is impossible for humans to maintain
                  gaze fixed in the direction of travel without using
                  a stationary visual target, or paralyzing the
                  extra-ocular muscles to the eyes. .. It has been
                  proposed that the rotation introduced into retinal
                  flow by eye-movements can actually simplify the
                  steering task (Kim & Turvey, 1999; Wann & Swapp,
                  2000). .. In this paper we present an experiment
                  where we attempt to determine how gaze influences
                  and informs steering behavior. .. The [results]
                  confirm an advantage for free gaze over gaze
                  fixation in a steering task.},
  c-dellaert =	 {Nice robot analogy. Arguments for fixing gaze are
                  that the retinal field is not influenced by eye
                  rotation, but it seems that humans do better if
                  their eyes can gaze freely. Both \cite{Land94nature}
                  and \citet{Kim99ep} are possible, no information on
                  that here.},
}


@misc{Will99,
  author =	 "Todd Will",
  title =	 "Introduction to the Singular Value Decomposition",
  year =	 "1999",
  url =		 "http://www.uwlax.edu/faculty/will/svd/index.html",
}

@InProceedings{Willett99,
  author =	 {Willett, P. and Yanhua Ruan and Streit, R.},
  title =	 {Making the probabilistic multi-hyptohesis tracker
                  the tracker of choice},
  booktitle =	 {Proceedings 1999 IEEE Aerospace Conference},
  pages =	 {387 -399},
  year =	 1999,
  volume =	 4,
}

@InProceedings{Williams00isr,
  author =	 {Williams, S.B. and Newman, P. and Dissanayake,
                  M. and Rosenblatt, J. and Durrant-Whyte H.},
  title =	 {A decoupled, distributed {AUV} control architecture},
  booktitle =	 {31st Intl. Sym. on Robotics},
  pages =	 {246-251},
  year =	 2000,
  volume =	 1,
  address =	 {Montreal},
  month =	 {May},
  abstract =	 {Current work on undersea vehicles at the Australian
                  Centre for Field Robotics concentrates on the
                  development of terrain-aided navigation techniques,
                  sensor fusion and vehicle control architectures for
                  real-time platform control. Accurate position and
                  attitude estimation and control methods use
                  information from scanning sonar to complement a
                  limited vehicle dynamic model and unobservable
                  environmental disturbances. In this paper we present
                  the vehicle control architecture currently running
                  on the Oberon submersible. This architecture is
                  based on the Distributed Architecture for Mobile
                  Navigation. We use a distributed, decoupled control
                  paradigm to facilitate the tuning of individual
                  control modes. A number of behaviours have been
                  created to direct the motion of the vehicle. We show
                  that when coupled with a low-level terrain-aided
                  navigation scheme, effective control of the vehicle
                  can be achieved.},
  c-dellaert =	 {Rosenblatt's DAMN applied to Autonomous Underwater
                  Vehicles}
}

@PhdThesis{Williams01thesis,
  author =	 {S.B. Williams},
  title =	 {Efficient Solutions to Autonomous Mapping and
                  Navigation Problems},
  school =	 {The University of Sydney},
  year =	 2001,
  r-Bailey06ram ={The original notion of relative submaps was
                  introduced by Chong and Kleeman. This was further
                  developed by Williams \cite{Williams01thesis} in the
                  form of the constrained relative submap filter
                  (CRSF). However, CRSF does not exhibit global-level
                  convergence without forfeiting the decoupled submap
                  structure.}
}

@InProceedings{Williams02,
  author =	 "S.B. Williams and G. Dissanayake and
                  H. Durrant-Whyte",
  title =	 "An efficient approach to the simultaneous
                  localisation and mapping problem",
  booktitle =	 ICRA,
  year =	 2002,
  pages =	 "406-411",
  c-Alireza =	 "They use a method which they call Constrained Local
                  Submap Filter(CLSF), in which they build local maps
                  independently of the global map, and since they are
                  independent, there is no need to update the global
                  covariance matrix. The local maps are fused to the
                  global map every few frames periodically by applying
                  the constraints between the landmarks seen in both
                  the local and global map. The first robot pose is
                  set as the origin of the local map. They have some
                  approximations, so the final result is not equal to
                  full optimization but they have good experimental
                  results."
}

@InProceedings{Williams02icra,
  author =	 "S.B. Williams and G. Dissanayake and
                  H. Durrant-Whyte",
  title =	 "Towards multi-vehicle simultaneous localisation and
                  mapping",
  booktitle =	 ICRA,
  year =	 2002,
  r-Fox06ieee =	 {If the initial locations of the robots are known,
                  map merging is a rather straightforward extension of
                  single robot mapping},
  abstract =	 {This paper presents a novel approach to the
                  multi-vehicle Simultaneous Localisation and Mapping
                  (SLAM) problem that exploits the manner in which
                  observations are fused into the global map of the
                  environment to manage the computatidnal complexity
                  of the algorithm and improve the data association
                  process. Rather than incorporating every observation
                  directly into the global map of the environment, the
                  Constrained Local Submap Filter (CLSF) relies on
                  creating an independent, local submap of the
                  features in the immediate vicinity of the
                  vehicle. This local submap is then periodically
                  fused into the global map of the environment. This
                  representation has been shown to reduce the
                  computational complexity of maintaining the global
                  map estimates as well as improving the data
                  association process. This paper examines the
                  prospect of applying the CLSF algorithm to the
                  multi-vehicle SLAM problem.}
}

@InProceedings{Williams06nips,
  Author =	 {C.K.I. Williams and J. Quinn and N. McIntosh},
  Title =	 {{F}actorial {S}witching {K}alman filters for
                  condition {M}onitoring in {N}eonatal {I}ntensive
                  {C}are},
  BookTitle =	 NIPS,
  fullauthor =	 {Christopher K.I. Williams and John Quinn and Neil
                  McIntosh},
  year =	 {2006}
}

@InProceedings{Williams07iccv,
  author =	 {B. Williams and G. Klein and I. Reid},
  fullauthor =	 {Brian Williams and Georg Klein and Ian Reid},
  title =	 {Real-Time {SLAM} Relocalisation},
  booktitle =	 ICCV,
  location =	 {Rio de Janeiro, Brazil},
  month =	 {Oct},
  year =	 2007,
  abstract =	 {Monocular SLAM has the potential to turn inexpensive
                  cameras into powerful pose sensors for applications
                  such as robotics and augmented reality. However,
                  current implementations lack the robustness required
                  to be useful outside laboratory conditions: blur,
                  sudden motion and occlusion all cause tracking to
                  fail and corrupt the map. Here we present a system
                  which automatically detects and recovers from
                  tracking failure while preserving map integrity. By
                  extending recent advances in keypoint recognition
                  the system can quickly resume tracking ?i.e. within
                  a single frame time of 33ms ?using any of the
                  features previously stored in the map. Extensive
                  tests show that the system can reliably generate
                  maps for long sequences even in the presence of
                  frequent tracking failure.},
  c-kaess =	 {Presents relocalization for Davison's SceneLab
                  monocular SLAM system, in order to survive sequences
                  with low number of features or motion blur without
                  corrupting the map. Mainly interesting in the
                  absence of IMU/odometry, as no prediction is
                  possible except for some very general motion
                  constraints. Uses FAST corner detector and joint
                  compatibility test. Extends Williams07icra. Feature
                  recognition is based on a modification of randomized
                  tree-based work by Lepetit, that avoids offline
                  learning, and reduced the complexity employing
                  randomized lists. Runs successfully for one hour
                  with a small number of features (70) restricted by
                  the underlying EKF-based SLAM technique. 30Hz on
                  Core 2 Duo 2.7GHz plus using GPU. Relocalization
                  part seems to have linear growth with the number of
                  classifier matches.},
}

@inproceedings{Williams07iccv,
  author =	 {Williams, B. and Klein, G. and Reid, I.},
  title =	 {Real-time SLAM relocalisation},
  booktitle =	 ICCV,
  abstract =	 {Monocular SLAM has the potential to turn inexpensive
                  cameras into powerful pose sensors for applications
                  such as robotics and augmented reality. However,
                  current implementations lack the robustness required
                  to be useful outside laboratory conditions: blur,
                  sudden motion and occlusion all cause tracking to
                  fail and corrupt the map. Here we present a system
                  which automatically detects and recovers from
                  tracking failure while preserving map integrity. By
                  extending recent advances in keypoint recognition
                  the system can quickly resume tracking -- i.e.\
                  within a single frame time of 33ms -- using any of
                  the features previously stored in the map. Extensive
                  tests show that the system can reliably generate
                  maps for long sequences even in the presence of
                  frequent tracking failure. },
  year =	 {2007},
  added-by =	 {Jinhan Lee, Changhyun Choi},
  url =
                  {link:Williams07ICCV.pdf|worksite:/Papers/Williams07ICCV.pdf},
}

@InProceedings{Williams07icra,
  author =	 {B. Williams and P. Smith and I. Reid},
  fullauthor =	 {Brian Williams and Paul Smith and Ian Reid},
  title =	 {Automatic Relocalisation for a Single-Camera
                  Simultaneous Localisation and Mapping System},
  booktitle =	 ICRA,
  location =	 {Rome, Italy},
  month =	 {Apr},
  year =	 2007,
  abstract =	 {We describe a fast method to relocalise a monocular
                  visual SLAM (Simultaneous Localisation and Mapping)
                  system after tracking failure. The monocular SLAM
                  system stores the 3D locations of visual landmarks,
                  together with a local image patch. When the system
                  becomes lost, candidate matches are obtained using
                  correlation, then the pose of the camera is solved
                  via an efficient implementation of RANSAC using a
                  three-point-pose algorithm. We demonstrate the
                  usefulness of this method within visual SLAM: (i) we
                  show tracking can reliably resume after tracking
                  failure due to occlusions, motion blur or unmodelled
                  rapid motions; (ii) we show how the method can be
                  used as an adjunct for a proposal distribution in a
                  particle filter framework; (iii) during successful
                  tracking we use idle cycles to test if the current
                  map overlaps with a previouslybuilt map, and we
                  provide a solution to aligning the two maps by
                  splicing the camera trajectories in a consistent and
                  optimal way.},
  r-Williams07iccv ={This paper builds on our previos work [this]. The
                  main improvement here is the feature recognition
                  which is now faster, more invariant and supports
                  on-line learning.},
  c-kaess =	 {See Williams07iccv},
}

@INPROCEEDINGS{Williams08oceans,
  title =	 {AUV-assisted surveying of relic reef sites},
  author =	 {Williams, S.B. and Pizarro, O. and Johnson-Roberson,
                  M. and Mahon, I. and Webster, J. and Beaman, R. and
                  Bridge, T.},
crossref =	 {_Oceans08Kobe},
  pages =	 {1-7},
  abstract =	 {This paper describes the autonomous underwater
                  vehicle (AUV) Sirius and presents its participation
                  in a scientific expedition to survey drowned reefs
                  along the shelf edge of the Great Barrier Reef (GBR)
                  in Queensland, Australia. The primary function of
                  the AUV was to provide geo-referenced,
                  high-resolution optical imagery to facilitate
                  validation of seabed habitat characterisation based
                  on acoustic data. We describe the AUV capabilities
                  and its operation in the context of the cruise
                  objectives to document these relic reef sites. The
                  data processing pipeline involved in generating
                  SLAM-based navigation and large scale 3D
                  visualizations of survey data is briefly
                  described. We also present preliminary results
                  illustrating the type of data products possible with
                  our system and how these complement data gathered by
                  other ship-borne instruments on the cruise.},
  c-dellaert =	 {Large-distance SLAM to do loop-closing on very long
                  trajectories, create 3D reconstruction by building a
                  mesh from sparse stereo features on a frame-to-frame
                  basis, then use graphics techniques to generate a
                  watertight mesh. Similar to Nicosevici08oceans},
  c_viorela=	{},
}

@Article{Williams97,
  author =	 "M.L. Williams and R.C. Wilson and E.R. Hancock",
  title =	 "Multiple graph matching with {B}ayesian inference",
  journal =	 PRL,
  year =	 1997,
  volume =	 18,
  pages =	 "1275-1281",
}

@article{Williams97stochastic,
  author =	 "Lance R. Williams and David W. Jacobs",
  title =	 "Stochastic Completion Fields: A Neural Model of
                  Illusory Contour Shape and Salience",
  journal =	 "Neural Computation",
  volume =	 9,
  number =	 4,
  pages =	 "837-858",
  year =	 1997,
  url =		 "citeseer.nj.nec.com/williams95stochastic.html"
}

@InProceedings{Wilson07iswc,
  author =	 {J. Wilson and B. N. Walker and J. Lindsay and
                  C. Cambias and F. Dellaert},
  fullauthor =	 {Jeff Wilson and Bruce N. Walker and Jeffrey Lindsay
                  and Craig Cambias and Frank Dellaert},
  title =	 {{SWAN: System for Wearable Audio Navigation}},
  booktitle =	 ISWC,
  year =	 2007,
}

@InCollection{Wilson93,
  author =	 "William W Wilson",
  title =	 "Visual Servo Control of Robots using Kalman Filter
                  Estimates of Robot Pose Realtive to Work-pieces",
  booktitle =	 "Visual Servoing",
  publisher =	 "World Scientific",
  year =	 1993,
  editor =	 "Koichi Hashimoto",
}

@Article{Wilson96,
  author =	 "W.J. Wilson and C.C.w. Hulls and G.S. Bell",
  title =	 "Relative end-effector control using {C}artesian
                  position based visual servoing",
  journal =	 TRA,
  year =	 1996,
  volume =	 12,
  number =	 5,
  pages =	 "684-696",
  month =	 "October",
}

@article{Wilson99pami,
  author =	 "A. D. Wilson and A. F. Bobick",
  fullauthor =	 "Andrew D. Wilson and Aaron F. Bobick",
  title =	 "Parametric {H}idden {M}arkov {M}odels for {G}esture
                  {R}ecognition",
  journal =	 PAMI,
  volume =	 21,
  number =	 9,
  pages =	 "884-900",
  year =	 1999,
  url =		 "citeseer.nj.nec.com/wilson99parametric.html"
}


@Book{Winkler95,
  author =	 {G. Winkler},
  title =	 {Image analysis, random fields and dynamic {M}onte
                  {C}arlo methods},
  publisher =	 springer,
  year =	 1995,
}

@PhdThesis{Winn03,
  author =	 {John Winn},
  title =	 {Variational Message Passing and its Applications},
  school =	 {University of Cambridge},
  year =	 2003,
}

@InProceedings{Winters00omni,
  author =	 {Winters, N. and Gaspar, J. and Lacey, G. and
                  Santos-Victor, J.},
  title =	 {Omni-directional vision for robot navigation},
  booktitle =	 {IEEE Workshop on Omnidirectional Vision},
  pages =	 {21-28},
  year =	 2000,
}

@Article{Witkin81,
  author =	 "A.P. Witkin",
  title =	 "Recovering Surface Shape and Orientation from
                  Texture",
  journal =	 AI,
  year =	 1981,
  volume =	 17,
  pages =	 "17-45",
}

@Book{Wolberg90,
  author =	 {G.~Wolberg},
  title =	 {Digital Image Warping},
  publisher =	 {IEEE Computer Society Press},
  year =	 1990,
  address =	 {Los Alamitos, CA}
}

@Article{Wolf05,
  author =	 {Wolf, J. and Burgard, W. and Burkhardt, H.},
  title =	 {Robust Vision-based Localization by Combining an
                  Image Retrieval System with Monte Carlo
                  Localization},
  journal =	 {IEEE Transactions on Robotics},
  year =	 2005,
  volume =	 21,
  number =	 2,
  pages =	 {208-216}
}

@Article{Wolf05ar,
  author =	 {Denis F. Wolf and Gaurav S. Sukhatme},
  title =	 {Mobile Robot Simultaneous Localization and Mapping
                  in Dynamic Environments},
  journal =	 AR,
  month =	 {July},
  year =	 2005,
  volume =	 19,
  number =	 1,
  pages =	 {53-65},
  c-sangmin =	 {they use two layer representation, one for static,
                  and another for dynamic},
}

@inproceedings{Wonka00,
  title =	 "Visibility Preprocessing with Occluder Fusion for
                  Urban Walkthroughs",
  author =	 "Peter Wonka and Michael Wimmer and Dieter
                  Schmalstieg",
  year =	 2000,
  pages =	 "71--82",
  editor =	 "Bernard Proche and Holly Rushmeier",
  isbn =	 "3-211-83535-0",
  booktitle =	 "Rendering Techniques 2000 (Proceedings of the
                  Eurographics Workshop on Rendering 2000)",
  month =	 jun,
  location =	 "held in Brno, Czech Republic, June 26-28, 2000",
  organization = "Eurographics",
  publisher =	 "Springer-Verlag Wien New York",
  keywords =	 "Visibility determination, image-based rendering.,
                  occluder occlusion, occluder fusion, urban
                  environments, walkthrough, real-time graphics,
                  shadow algorithms, occlusion culling",
  URL =
                  "http://www.cg.tuwien.ac.at/research/publications/2000/wonka-2000-VisP",
}

@InProceedings{Wonka03,
  author =	 {P. Wonka},
  fullauthor =	 {Peter Wonka},
  title =	 {Instant Architecture},
  booktitle =	 SIGGRAPH,
  year =	 2003,
}

@INPROCEEDINGS{Woock07ivs,
  title =	 {Odometry-Based Structure from Motion},
  author =	 {Woock, P. and Pagel, F. and Grinberg, M. and
                  Willersinn, D.},
  booktitle =	 {Intelligent Vehicles Symposium, 2007 IEEE},
  year =	 2007,
  month =	 {June},
  pages =	 {1112-1117},
  keywords =	 {automobiles, driver information systems, image
                  sensorscamera motion, monocular camera, odometry
                  data, steering angle measurements,
                  structure-from-motion approach, yaw rate
                  measurements},
}

@Article{Woodham80,
  author =	 "Woodham, R. J.",
  title =	 "Photometric Method for Determining Surface
                  Orientation from Multiple Images",
  journal =	 "Optical Engineering",
  volume =	 19,
  number =	 1,
  pages =	 {139--144},
  year =	 1980,
}

@article{Woodham94,
  author =	 {R. J. Woodham},
  journal =	 {J. Opt. Soc. Am. A},
  number =	 11,
  pages =	 3050,
  title =	 {Gradient and curvature from photometric-stereo
                  method including local confidence estimation},
  volume =	 11,
  year =	 1994,
}

@Article{Wren97pami,
  author =	 {C.R. Wren and A. Azarbayejani and T. Darrell and
                  A. Paul Pentland},
  title =	 {Pfinder: Real-Time Tracking of the Human Body},
  journal =	 PAMI,
  year =	 1997,
  volume =	 19,
  number =	 7,
  pages =	 {780-785},
  abstract =	 {Pfinder is a real-time system for tracking people
                  and interpreting their behavior. It runs at 10Hz on
                  a standard SGI Indy computer, and has performed
                  reliably on thousands of people in many different
                  physical locations. The system uses a multiclass
                  statistical model of color and shape to obtain a 2D
                  representation of head and hands in a wide range of
                  viewing conditions. Pfinder has been successfully
                  used in a wide range of applications including
                  wireless interfaces, video databases, and
                  low-bandwidth coding.},
  c-houdan =	 {use single Gaussian distribution to model
                  background, need an initialization process that no
                  foreground object is in the scene}
}

@InProceedings{Wu03cvpr,
  fullauthor =	 {Ying Wu and Gang Hua and Ting Yu},
  title =	 {Switching Observation Models for Contour Tracking in
                  Clutter},
  booktitle =	 CVPR,
  year =	 2003,
  pages =	 {295--304},
}

@InProceedings{Wu08gnc,
  author=	 {Allen D. Wu and Eric N. Johnson},
  title=	 {Methods for Localization and Mapping Using Vision and Inertial Sensors},
  booktitle =	 GNC,
  year =	 2008,
  added-by =	 {richard},
}

@article{Wu89,
  AUTHOR =	 "Wu, J.J. and Rink, R.E. and Caelli, T.M. and
                  Gourishankar, V.G.",
  TITLE =	 "Recovery Of The 3-D Location And Motion Of A Rigid
                  Object Through Camera Image (An Extended {K}alman
                  Filter Approach)",
  JOURNAL =	 IJCV,
  VOLUME =	 2,
  year =	 1989,
  PAGES =	 "373-394"
}

@InProceedings{WuRehg03,
  author =	 {J.~Wu and J.~M. Rehg and M.~Mullin},
  title =	 {Learning a Rare Event Detection Cascade by Direct
                  Feature Selection},
  booktitle =	 NIPS,
  year =	 2003,
  month =	 {December},
}

@InProceedings{Xie03icme,
  author =	 {L. Xie, S.-F. Chang, A. Divakaran and H. Sun},
  title =	 {{Unsupervised Discovery of Multilevel Statistical
                  Video Structures Using Hierarchical Hidden Markov
                  Models}},
  booktitle =	 ICME,
  volume =	 3,
  pages =	 {29--32},
  year =	 2003,
  c-sangmin =	 {use H-HMM to learn break/play categories in soccer
                  video, tested unsupervised learning, results not
                  very convincing},
}

@Article{Xie04prl,
  author =	 {L. Xie, P. Xu, S.-F. Chang, A. Divakaran and H. Sun},
  title =	 {{Structure Analysis of Soccer Video with Domain
                  Knowledge and Hidden Markov Models}},
  booktitle =	 PRL,
  month =	 {May},
  year =	 2004,
  volume =	 25,
  number =	 7,
  pages =	 {767--775},
  c-sangmin =	 {use H-HMM to learn break/play categories in soccer
                  video},
}

@InProceedings{Xing02nips,
  title =	 "Distance Metric Learning, with application to
                  Clustering with side-information",
  author =	 {E.P. Xing and A.Y. Ng and M.I. Jordan and
                  S. Russell},
  booktitle =	 NIPS,
  year =	 2002,
  pages =	 {521-528}
}

@InProceedings{Xing04,
  title =	 "Bayesian Haplotype Inference via the Dirichlet
                  Process",
  author =	 {E. Xing and R. Sharan and M. Jordan},
  booktitle =	 {International Conference on Machine Learning},
  year =	 2004,
  pages =	 {879-886}
}

@InProceedings{Xiong98,
  author =	 {Y. Xiong and K. Turkowski},
  title =	 {Registration, calibration and Blending in Creating
                  High-Quality Panoramas},
  booktitle =	 WACV,
  pages =	 {69-75},
  year =	 1998,
}

@Article{Xu05csvt,
  author =	 {D. Xu and J. Liu and X. Li and Zh. Liu and X. Tang},
  title =	 {Insignificant Shadow Detection for Video
                  Segmentation},
  journal =	 {IEEE Transaction on Circuits and Systems for Video
                  Technology},
  year =	 2005,
  volume =	 15,
  number =	 8,
  pages =	 {1058-1064},
  month =	 {August},
  abstract =	 {To prevent moving cast shadows from being
                  misunderstood as part of moving objects in change
                  detection based video segmentation, this paper
                  proposes a novel approach to the cast shadow
                  detection based on the edge and region information
                  in multiple frames. First, an initial change
                  detection mask containing moving objects and cast
                  shadows is obtained. Then a Canny edge map is
                  generated. After that, the shadow region is detected
                  and removed through multiframe integration, edge
                  matching, and region growing. Finally, a post
                  processing procedure is used to eliminate noise and
                  tune the boundaries of the objects. Our approach can
                  be used for video segmentation in indoor
                  environment. The experimental results demonstrate
                  its good performance.},
  c-houdan =	 {Use gradient info: insignificant shadow won't have
                  strong edges. Use multiple frames to distinguish
                  moving edge (foreground) from static edges
                  (background)},
}

@InProceedings{Xu05motion,
  author =	 {W. Xu and Y. Zhou and Y. Gong and H. Tao},
  title =	 {Background Modeling Using Time Dependent Markov
                  Random Field With Image Pyramid},
  booktitle =	 {Workshop on Motion and Video Computing},
  year =	 {2005},
  abstract =	 {Background modeling is important for video
                  surveillance. In the paper, we present a novel
                  background modeling algorithm based on probabilistic
                  graphic model and Gibbs Sampling. The background is
                  modeled at different resolution level by image
                  pyramids. We develop a time dependent pyramidal
                  Markov Random Field (MRF) to represent the state of
                  foreground/background at each pixel in the
                  pyramid. Both spatial and temporal constraints in
                  the foreground labeling process are considered using
                  three kinds of links in the MRF. The probability of
                  adding/deleting a foreground object is calculated by
                  online learning algorithm and is used as prior
                  information in computing foreground label. We use
                  Gibbs Sampling to solve the MRF under the framework
                  of Maximum A Posterior (MAP). Experimental result
                  shows that this real-time algorithm is able to
                  segment the foreground object accurately from videos
                  with clutter in the scene.},
  c-houdan =	 {This MRF-based background modeling outperforms MOG
                  method in segmentation results, but the author
                  didn't mention computing speed for real-time
                  tracking},
}

@Article{Xu95,
  author =	 {L. Xu and A. Yuille},
  title =	 {Robust principal component analysis by
                  self-organizing rules based on statstical physics
                  approach},
  journal =	 {IEEE Trans. Neural Networks},
  year =	 1995,
  volume =	 6,
  number =	 1,
  pages =	 {131-143},
}

@InProceedings{Xuan07icml,
  Author =	 {Xiang Xuan and Kevin Murphy},
  Booktitle =	 ICML,
  Keywords =	 {change detection, timeseries},
  Title =	 {Modeling changing dependency structure in
                  multivariate time series },
  Year =	 {2007},
  c-sangmin =	 {honey bee},
}

@Article{Xue92,
  author =	 {K.~Xue and A.~Winans and E.~Walowit},
  title =	 {An Edge-Restricted Spatial Interpolation Algorithm},
  journal =	 {J. of Electrical Imaging},
  year =	 1992,
  volume =	 1,
  number =	 2,
  pages =	 {152--161}
}

@InProceedings{Yagi91icra,
  author =	 {Yagi, Y. and Kawato, S. and Tsuji, S.},
  title =	 {Collision avoidance using omnidirectional image
                  sensor ({COPIS})},
  booktitle =	 ICRA,
  pages =	 {910-915},
  year =	 1991,
  volume =	 1,
}

@Article{Yagi94tra,
  author =	 {Yagi, Y. and Kawato, S. and Tsuji, S.},
  title =	 {Real-time omnidirectional image sensor ({COPIS}) for
                  vision-guided navigation},
  journal =	 TRA,
  year =	 1994,
  volume =	 10,
  number =	 1,
  pages =	 {11-22},
  month =	 {Feb},
}

@Article{Yagi95tra,
  author =	 {Yagi, Y. and Nishizawa, Y. and Yachida, M.},
  title =	 {Map-based Navigation for a Mobile Robot with
                  Omnidirectional Image Sensor {COPIS}},
  journal =	 TRA,
  volume =	 11,
  number =	 5,
  pages =	 {634-648},
  month =	 {Oct},
  year =	 1995,
  r-Dailey06icarcv ={Yachida? system [this] took a similar approach
                  [kaess: to Kriegman89tra] but used a single
                  omnidirectional vision sensor and accumulation of
                  measurements over time, rather than stereo, to
                  determine the positions of vertical line
                  landmarks. },
}

@Article{Yagi95tra,
  author =	 {Yagi, Y. and Nishizawa, Y. and Yachida, M.},
  title =	 {Map-based navigation for a mobile robot with
                  omnidirectional image sensor {COPIS}},
  journal =	 TRA,
  year =	 1995,
  volume =	 11,
  number =	 5,
  pages =	 {634 - 648},
  month =	 {Oct},
}

@Article{Yamamoto05warsi,
  title =	 {Optical sensing for robot perception and
                  localization},
  author =	 {Yamamoto, Y. and Pirjanian, P. and Munich, M. and
                  DiBernardo, E. and Goncalves, L. and Ostrowski,
                  J. and Karlsson, N.},
  journal =	 {IEEE Workshop on Advanced Robotics and its Social
                  Impacts},
  keywords =	 {NorthStar},
  year =	 {2005},
  month =	 {June},
  pages =	 {14--17},
  doi =		 {10.1109/ARSO.2005.1511612},
}

@Article{Yamamoto05warsi,
  title =	 {Optical sensing for robot perception and
                  localization},
  author =	 {Yamamoto, Y. and Pirjanian, P. and Munich, M. and
                  DiBernardo, E. and Goncalves, L. and Ostrowski,
                  J. and Karlsson, N.},
  journal =	 {IEEE Workshop on Advanced Robotics and its Social
                  Impacts},
  keywords =	 {NorthStar},
  year =	 {2005},
  month =	 {June},
  pages =	 {14--17},
  doi =		 {10.1109/ARSO.2005.1511612},
}

@inproceedings{Yamato92,
  author =	 {J. Yamato, J. Ohya and K. Ishii},
  title =	 {Recognizing Human Action in Time-sequential images
                  Using Hidden {Markov} Model},
  booktitle =	 CVPR,
  year =	 1992,
  pages =	 {379-385},
}

@Article{Yamauchi96smc,
  author =	 {B. Yamauchi and R. Beer},
  title =	 {Spatial Learning for Navigation in Dynamic
                  Environments},
  journal =	 {IEEE Transactions on Systems, Man, and
                  Cybernetics-Part B, Special Issue on Learning
                  Autonomous Robots},
  year =	 1996,
  volume =	 26,
  pages =	 {496-505},
  c-ananth =	 {Yamauchi et al. [Yamauchi96smc][Yamauchi97jrs] use a
                  reactive controller in conjunction with an Adaptive
                  Place Network that detects and identifies special
                  places in the environment. These locations are
                  subsequently placed in a network denoting spatial
                  adjacency.},
}

@Article{Yamauchi97jrs,
  author =	 {B. Yamauchi and P. Langley},
  fullauthor =	 {Brian Yamauchi and Pat Langley},
  title =	 {Place Recognition in Dynamic Environments},
  journal =	 {Journal of Robotic Systems},
  year =	 1997,
  volume =	 14,
  number =	 2,
  pages =	 {107-120},
  month =	 {February},
  note =	 {Special Issue on Mobile Robots},
  c-ananth =	 {Yamauchi et al. [Yamauchi96smc][Yamauchi97jrs] use a
                  reactive controller in conjunction with an Adaptive
                  Place Network that detects and identifies special
                  places in the environment. These locations are
                  subsequently placed in a network denoting spatial
                  adjacency.},
}

@InProceedings{Yan02,
  author =	 "Y. Li and T. Wang and H. Shum",
  title =	 "Motion {T}exture: A {T}wo-{L}evel {S}tatistical
                  {M}odel for {C}haracter {M}otion {S}ynthesis",
  booktitle =	 "SIGGRAPH",
  year =	 2002,
}

@Article{Yang02,
  author =	 { M. Yang and D. Kriegman and N. Ahuja },
  title =	 {Detecting Faces in Images: A Survey},
  journal =	 PAMI,
  year =	 2002,
  volume =	 24,
  number =	 1,
  month =	 "January",
  pages =	 {34-58},
}

@Article{Yang97,
  author =	 {Z. Yang and B. Rannala},
  title =	 {Bayesian Phylogenetic Inference Using {DNA}
                  Sequences: A {M}arkov Chain {M}onte {C}arlo Method},
  journal =	 {Molecular Biology and Evolution},
  year =	 1997,
  volume =	 14,
  pages =	 {717-724}
}

@Article{Yannakakis81siam,
  author =	 {M. Yannakakis},
  title =	 {Computing the minimum fill-in is {NP-complete}},
  journal =	 {SIAM J. Algebraic Discrete Methods},
  year =	 1981,
  volume =	 2,
  r-Heggernes06dm ={both the minimum triangulation and the treewidth
                  problems are NP-hard \cite{Arnborg87siam,
                  Yannakakis81siam}.},
}

@book{Yarbus67book,
  author =	 {Yarbus, A.},
  year =	 1967,
  title =	 {Eye Movements and Vision},
  publisher =	 {Plenum Press},
  r-Ballard91ai ={The first systematic study of saccadic eye movements
                  in the context of behavior was done by
                  \citet{Yarbus67book}},
  r-Hayhoe05tics ={Over 50 years ago a Russian scientist, Alfred
                  Yarbus, was able to capture the movements of the eye
                  by attaching a mirror system to the
                  eyeball. Although he was not the first to measure
                  eye movements, his work most clearly called
                  attention to their intrinsically cognitive
                  nature. Nowadays most vision scientists are familiar
                  with his traces of a subject examining Repin's
                  painting: "They Did Not Expect Him" and the very
                  different gaze patterns elicited by different
                  instructions to the subject \cite{Yarbus67book}. The
                  significance of this finding was that it revealed in
                  a particularly compelling way that ?eeing?is
                  inextricably linked to the observer? cognitive
                  goals.},
  c-dellaert =	 {Don't have book},
}

@InProceedings{Yata00icra,
  author =	 {Yata, T. and Ohya, A. and Yuta, S.},
  title =	 {Fusion of omni-directional sonar and
                  omni-directional vision for environment recognition
                  of mobile robots},
  booktitle =	 ICRA,
  pages =	 {3925 - 3930},
  year =	 {2000},
  volume =	 {4},
}

@InProceedings{Yatziv04,
  author =	 {Liron Yatziv and Guillermo Sapiro and Marc Levoy},
  title =	 {Lightfield completion},
  booktitle =	 ICIP,
  year =	 2004,
  volume =	 3,
  pages =	 {1787-1790},
}

@inproceedings{Yedidia00nips,
  author =	 "J.S. Yedidia and W.T. Freeman and Y.Weiss",
  fullauthor =	 "Jonathan S. Yedidia and William T. Freeman and Yair
                  Weiss",
  title =	 "Generalized Belief Propagation",
  booktitle =	 NIPS,
  pages =	 "689-695",
  year =	 2000,
}

@TechReport{Yedidia02,
  author =	 "J.S. Yedidia and W.T. Freeman and Y.Weiss",
  fullauthor =	 "Jonathan S. Yedidia and William T. Freeman and Yair
                  Weiss",
  title =	 {Understanding Belief Propagation and its
                  Generalizations},
  institution =	 {Mitsubishi Electric Research Laboratories},
  year =	 2002,
  number =	 {TR-2001-22},
  month =	 {January},
}

@inproceedings{Yeh04cvpr,
  Abstract =	 {We describe an approach to recognizing location from
                  mobile devices using image-based Web search. We
                  demonstrate the usefulness of common image search
                  metrics applied on images captured with a
                  camera-equipped mobile device to find matching
                  images on the World Wide Web or other
                  general-purpose databases. Searching the entire Web
                  can be computationally overwhelming, so we devise a
                  hybrid image-and-keyword searching technique. First,
                  image-search is performed over images and links to
                  their source Web pages in a database that indexes
                  only a small fraction of the Web. Then, relevant
                  keywords on these Web pages are automatically
                  identified and submitted to an existing text-based
                  search engine (e.g. Google) that indexes a much
                  larger portion of the Web. Finally, the resulting
                  image set is filtered to retain images close to the
                  original query. It is thus possible to efficiently
                  search hundreds of millions of images that are not
                  only textually related but also visually
                  relevant. We demonstrate our approach on an
                  application allowing users to browse Web pages
                  matching the image of a nearby location.},
  Author =	 {Yeh, T. and Tollmar, K. and Darrell, T.},
  booktitle =	 CVPR,
  Pages =	 {76--81},
  Title =	 {Searching the Web with mobile images for location
                  recognition},
  Volume =	 2,
  Year =	 2004,
  r-wang06_3dpvt ={ In [8] the authors described an approach to
                  recognizing location from mobile devices using
                  image-based Web search utilizing a hybrid color
                  histogram and keyword search technique. However
                  global color histograms are not very discriminative
                  since images with similar color distributions but
                  different content are often present.}
}

@Article{Yen56,
  author =	 {L.J. Yen},
  title =	 {On nonuniform sampling of bandwidth limited signals},
  journal =	 {IRE Trans. Circuits Syst.},
  year =	 1956,
  volume =	 {3},
  pages =	 {251-257},
}

@InProceedings{Yezzi01,
  author =	 {A.J. Yezzi and S.Soatto},
  title =	 {Stereoscopic segmentation},
  booktitle =	 ICCV,
  pages =	 {59-66},
  volume =	 1,
  year =	 2001,
  url =		 {citeseer.nj.nec.com/yezzi01stereoscopic.html},
}

@inproceedings{Yianilos93soda,
  author =	 "P.N. Yianilos",
  title =	 "Data Structures and Algorithms for Nearest Neighbor
                  Search in General Metric Spaces",
  booktitle =	 "{SODA}: {ACM}-{SIAM} Symposium on Discrete
                  Algorithms",
  year =	 1993,
  url =		 "citeseer.nj.nec.com/yianilos93data.html"
}

@inproceedings{Yin05aaai,
  author =	 {Yin, J. and Shen, D. and Yang, Q. and Li, Z. N.},
  booktitle =	 AAAI,
  keywords =	 {plan recognition, segmentation, slds},
  title =	 {Activity Recognition through Goal-Based
                  Segmentation},
  Year =	 {2005},
  c-sangmin =	 { This is a relatively a nice work. The one issue
                  they mat not be addressing is the sharing of LDSs,
                  which would be generally advocated as a good idea
                  when the number of goals increases, and also does
                  the support for the scalable systems and for
                  debugging purposes. In particular, there may be some
                  questions possible. Can we require less number of
                  training samples by sharing LDSs? Maybe so, since a
                  lot of the sub-segments are being shared for sure,
                  in particular, in the navigation application in this
                  paper. },
}

@inproceedings{Yin2005aaai,
  Author =	 {Yin, J. and Shen, D. and Yang, Q. and Li, Z. N.},
  Title =	 {Activity Recognition through Goal-Based
                  Segmentation},
  Booktitle =	 AAAI,
  Year =	 {2005},
  Keywords =	 {plan recognition, segmentation, slds},
  c-sangmin =	 { This is a relatively a nice work. The one issue
                  they mat not be addressing is the sharing of LDSs,
                  which would be generally advocated as a good idea
                  when the number of goals increases, and also does
                  the support for the scalable systems and for
                  debugging purposes. In particular, there may be some
                  questions possible. Can we require less number of
                  training samples by sharing LDSs? Maybe so, since a
                  lot of the sub-segments are being shared for sure,
                  in particular, in the navigation application in this
                  paper. },
}

@InProceedings{Yokakohiji00,
  author =	 {Y. Yokakohiji},
  title =	 {Accurate Image Overlay on Video See-Through {HMDs}
                  Using Vision and Accelerometers},
  booktitle =	 {IEEE VR},
  pages =	 {247-254},
  year =	 2000
}

@Article{Youla78,
  author =	 {D.C. Youla},
  title =	 {Generalized image restoration by the method of
                  alternating orthogonal projections},
  journal =	 {IEEE Trans. Circuits Syst.},
  year =	 1978,
  volume =	 {CAS-25},
  pages =	 {694-702},
}

@InProceedings{Yu05,
  author =	 {T. Yu and Y. Wu},
  title =	 {Collaborative Tracking of Multiple Targets},
  booktitle =	 CVPR,
  year =	 2004,
}

@inproceedings{Yu2002kdd,
  author =	 "H. Yu and J. Han and K.C. Chang",
  title =	 "{PEBL}:Positive-example based learning for Web page
                  classification using {SVM}",
  booktitle =	 KDD,
  year =	 2002,
  pages =	 {239-248},
}

@inproceedings{Yu2003ijcai,
  author =	 "H. Yu",
  title =	 "{SVMC}:Single Class Classification With Support
                  Vector Machines",
  booktitle =	 IJCAI,
  year =	 2003,
}

@InProceedings{Yu98siggraph,
  author =	 {Y. Yu and J. Malik},
  title =	 {Recovering photometric properties of architectural
                  scenes from photographs},
  booktitle =	 SIGGRAPH,
  pages =	 {207-217},
  year =	 1998,
}

@InProceedings{Yu99,
  author =	 {Y.Yu and P.Debevec and J.Malik and T.Hawkins},
  title =	 {Inverse global illumination: Recovering reflectance
                  models of real Surface Modeling with Oriented
                  Particle Systems},
  booktitle =	 {Computer Graphics (SIGGRAPH 99)},
  pages =	 {215-224},
  year =	 1999,
}

@InProceedings{Yu99,
  author =	 {Y.Yu and P.Debevec and J.Malik and T.Hawkins},
  title =	 {Inverse global illumination: Recovering reflectance
                  models of real Surface Modeling with Oriented
                  Particle Systems},
  booktitle =	 {Computer Graphics (SIGGRAPH 99)},
  pages =	 {215-224},
  year =	 1999,
}

@inproceedings{Yuan04eccv,
  author =	 "L. Yuan, F. Wen, C. Liu and H-Y. Shum",
  fullauthor =	 "Lu Yuan and Fang Wen and Ce Liu and Heung-Yeung
                  Shum",
  title =	 "Synthesizing Dynamic Texture with Closed-Loop Linear
                  Dynamic System",
  booktitle =	 ECCV,
  year =	 2004,
}


@Article{Yuen05tro,
  author =	 {David C. K. Yuen and Bruce A. MacDonald},
  title =	 {Vision-Based Localization Algortihm Based on
                  Landmark Matching, Triangulation, Reconstruction,
                  and Comparison},
  journal =	 {IEEE Transactions on Robotics},
  year =	 2005,
  volume =	 21,
  number =	 2,
  pages =	 {217-226}
}

@Article{Yuille91,
  author =	 {A. Yuille and D. Geiger and H. Bulthoff},
  title =	 {Stereo, Mean Field Theory and Psychophysics},
  journal =	 {Network: Computation in Neural Systems},
  year =	 1991,
  volume =	 2,
  pages =	 {423-442},
}

@Article{Yuille92,
  author =	 "A. L. Yuille and P. W. Hallinan and D. S. Cohen",
  journal =	 IJCV,
  number =	 2,
  pages =	 "99-111",
  title =	 "Feature Extraction from Faces Using Deformable
                  Templates",
  volume =	 8,
  year =	 1992,
}

@Article{ Yuille99ijcv,
  author =	 "A. Yuille and D. Snow and R. Epstein and
                  P. Belhumeur",
  title =	 "Determining Generative Models of Objects Under
                  Varying Illumination: Shape and Albedo from Multiple
                  Images Using SVD and Integrability",
  journal =	 IJCV,
  volume =	 35,
  number =	 3,
  pages =	 {203--222},
  year =	 1999,
}

@TechReport{Zach02tr,
  author =	 {C. Zach and K. Karner and J. Bauer and A. Klaus and
                  K. Schindler},
  title =	 {Modeling and Visualizing the Cultural Heritage Data
                  Set of {Graz}},
  institution =	 {Research Center for Virtual Reality and
                  Visualization (VRVis)},
  year =	 2002,
  number =	 {2002-041},
}

@InProceedings{Zach08cvpr,
  author =	 {C. Zach and A. Irschara and H Bischof},
  title =	 {What Can Missing Correspondences Tell Us About {3D}
                  Structure and Motion},
  booktitle =	 CVPR,
  year =	 2008,
}

@article{Zeger88bio,
  AUTHOR =	 "S.L. Zeger and K-Y. Liang and P.S. Albert",
  fullauthor =	 "Scott L. Zeger and kung-Yee Liang and Paul
                  S. Albert",
  TITLE =	 "Models for Longitudinal Data : A Generalized
                  Estimating Equation Approach",
  JOURNAL =	 "Biometrics",
  VOLUME =	 44,
  YEAR =	 1988,
  NUMBER =	 4,
  MONTH =	 "Dec",
  PAGES =	 "1049-1060",
}


@Article{ZelnikManor06pami,
  fullauthor =	 "L. Zelnik-Manor and M. Irani",
  fullauthor =	 "Lihi Zelnik-Manor and Michal Irani",
  journal =	 PAMI,
  volume =	 28,
  number =	 9,
  pages =	 "1530-1535",
  title =	 {{Statistical Analysis of Dynamic Actions}},
  year =	 2006,
}

@TechReport{Zhang01tr,
  author =	 {Z. Zhang and Y. Shan},
  fullauthor =	 {Zhengyou Zhang and Ying Shan},
  title =	 {Incremental Motion Estimation Through Local Bundle
                  Adjustment},
  institution =	 {Microsoft Research},
  number =	 {MSR-TR-01-54},
  month =	 {May},
  year =	 2001,
  abstract =	 {We propose a new incremental motion estimation
                  algorithm to deal with long image sequences. It
                  applies to a sliding window of triplets of images,
                  but unlike previous approaches, which rely on point
                  matches across three or more views, we also use
                  those points shared only by two views. This is
                  important because matches between two views are more
                  common than those across more views. The problem is
                  formulated as a series of local bundle adjustments
                  in such a way that the estimated camera motions in
                  the whole sequence are consistent with each
                  other. Two implementations are described. The first
                  is an exact one, which, based on the observation of
                  the sparse structure of the adjustment network,
                  embeds the optimization of 3D structure parameters
                  within the optimization of the camera pose
                  parameters. This optimization embedding considerably
                  reduces the minimization complexity. The second is a
                  mathematical procedure which transforms the original
                  problem involving both 3D structure and pose
                  parameters into a much smaller one, a minimization
                  over just the camera? pose parameters. This leads to
                  an even higher computational gain. Because we make
                  full use of local image information, our technique
                  is more accurate than previous incremental
                  techniques, and is very close to, and considerably
                  faster than, global bundle adjustment. Experiments
                  with both synthetic and real data have been
                  conducted to compare the proposed technique with
                  other techniques, and have shown our technique to be
                  clearly superior.},
  c-kaess =	 {Zhang03icip seems to be the peer reviewed version},
}

@Inproceedings{Zhang03cvpr,
  title =	 {{Spacetime stereo: shape recovery for dynamic
                  scenes}},
  author =	 {Zhang, L. and Curless, B. and Seitz, SM},
  crossref =	 {_CVPR03},
  volume =	 2,
}

@InProceedings{Zhang04icrb,
  author =	 {P. Zhang and E. E. Milios and J. Gu},
  title =	 {Underwater Robot Localization using Artificial
                  Visual Landmarks},
  booktitle =	 {Proc. IEEE Int. Conf. Robot. Biomimetics},
  year =	 {2004},
  added-by =	 {Alireza}
}

@InProceedings{Zhang04icrb,
  author = {P. Zhang and E. E. Milios and J. Gu},
  title = {Underwater Robot Localization using Artificial Visual Landmarks},
  booktitle = {Proc. IEEE Int. Conf. Robot. Biomimetics},
  year = {2004},
  added-by = {Alireza}
}

@article{Zhang04siggraph,
  author =	 {L. Zhang and N. Snavely and B. Curless and
                  S. M. Seitz},
  title =	 {Spacetime faces: high resolution capture for
                  modeling and animation},
  journal =	 "SIGGRAPH",
  year =	 2004,
}


@InProceedings{Zhang91,
  author =	 {Z. Zhang and O.D. Faugeras},
  title =	 {Tracking {3D} line segments: new developments},
  booktitle =	 {Proc. Int. Conf. Advanced Robotics},
  year =	 1991,
}

@article{Zhang92,
  AUTHOR =	 "Zhang, Z. and Faugeras, O.D.",
  TITLE =	 "Three-Dimensional Motion Computation and Object
                  Segmentation in a Long Sequence of Stereo Frames",
  JOURNAL =	 IJCV,
  VOLUME =	 7,
  YEAR =	 1992,
  NUMBER =	 3,
  MONTH =	 "April",
  PAGES =	 "211-241"
}

@Book{Zhang92book,
  author =	 {Z. Zhang and O. Faugeras},
  title =	 {{3D} Dynamic Scene Analysis},
  publisher =	 {Springer-Verlag},
  year =	 1992,
}

@InProceedings{Zhang94canai,
  author =	 {N.L. Zhang and D. Poole},
  title =	 {A simple approach to {Bayesian} network
                  computations},
  booktitle =	 {Proc. of the 10th Canadian Conf. on AI},
  year =	 1994,
  address =	 {Banff, Alberta, Canada},
  month =	 {May},
  r-Mao04uai =	 {Elimination algorithm /citep{Zhang94canai} on a BN.},
}

@article{Zhang94ijcv,
  author =	 {Z. Zhang},
  title =	 {Iterative point matching for registration of
                  free-form surfaces},
  journal =	 IJCV,
  volume =	 13,
  number =	 2,
  year =	 1994,
  pages =	 "119-152",
}

@InCollection{Zhang96,
  author =	 {Jun Zhang and Aggelos Katsaggelos},
  title =	 {Image Recovery Using the {EM} Algorithm},
  booktitle =	 {DSP Handbook},
  publisher =	 {CRC Press/IEEE Press},
  year =	 1996,
}

@article{Zhang98,
  AUTHOR =	 "Zhang, Z.Y.",
  TITLE =	 "Determining The Epipolar Geometry And Its
                  Uncertainty - A Review",
  JOURNAL =	 IJCV,
  VOLUME =	 27,
  YEAR =	 1998,
  NUMBER =	 " 2",
  MONTH =	 "March",
  PAGES =	 "161-195"
}

@inproceedings{Zhang99iccv,
  author =	 {Zhengyou Zhang},
  title =	 {Flexible Camera Calibration by Viewing a Plane from
                  Unknown Orientations},
  booktitle =	 ICCV,
  year =	 {1999}
}

@InProceedings{Zhang99iccv,
  author =	 {Zhengyou Zhang},
  title =	 {Flexible Camera Calibration by Viewing a Plane from
                  Unknown Orientations},
  booktitle =	 {International Conference on Computer Vision},
  year =	 {1999}
}

@Article{ZhangMFT92,
  author =	 {Jun Zhang},
  title =	 {The Mean Field Theory in {EM} Procedures for
                  {M}arkov random fields},
  journal =	 SP,
  year =	 1992,
  volume =	 40,
  number =	 10,
  pages =	 {2570-2583},
  month =	 {October},
}

@InProceedings{Zhao00,
  author =	 {L. Zhao and C. Thorpe},
  title =	 {Recursive Context Reasoning for Human Detection and
                  Part Identification},
  booktitle =	 {IEEE Workshop on Human Modeling, Analysis, and
                  Synthesis},
  year =	 2000,
  address =	 {Hilton Head, SC},
}

@article{Zhao03ieee,
  Author =	 {Feng Zhao and Jie Liu and Juan Liu and Guibas,
                  L. and Reich, J.},
  Journal =	 {Proceedings of the IEEE},
  Number =	 8,
  Pages =	 {1199--1209},
  Title =	 {Collaborative signal and information processing: an
                  information-directed approach},
  Ty =		 {JOUR},
  Volume =	 91,
  Year =	 2003,
  Abstract =	 {This paper describes information-based approaches to
                  processing and organizing spatially distributed,
                  multimodal sensor data in a sensor
                  network. Energy-constrained networked sensing
                  systems must rely on collaborative signal and
                  information processing (CSIP) to dynamically
                  allocate resources, maintain multiple sensing foci,
                  and attend to new stimuli of interest, all based on
                  task requirements and resource constraints. Target
                  tracking is an essential capability for sensor
                  networks and is used as a canonical problem for
                  studying information organization problems in
                  CSIP. After formulating a CSIP tracking problem in a
                  distributed constrained optimization framework, the
                  paper describes information-driven sensor query and
                  other techniques for tracking individual targets as
                  well as combinatorial tracking problems such as
                  counting targets. Results from simulations and
                  experimental implementations have demonstrated that
                  these information-based approaches are scalable and
                  make efficient use of scarce sensing and
                  communication resources.},
  quotes =	 {IDSQ [5], [26] formulates the tracking problem as a
                  more general distributed constrained optimization
                  that maximizes information gain of sensors while
                  minimizing communication and resource usage.}
}

@InProceedings{Zhao04,
  author =	 {T. Zhao and R. Nevatia},
  title =	 {Tracking Multiple Humans in Crowded Environment},
  booktitle =	 CVPR,
  year =	 2004,
}

@InProceedings{Zheng88icpr,
  author =	 {J.Y. Zheng and M. Asada and S. Tsuji},
  title =	 {Color-based panoramic representation of outdoor
                  environment for a mobile robot},
  booktitle =	 ICPR,
  pages =	 {801-803},
  year =	 1988,
  volume =	 2,
}

@InProceedings{Zheng90icpr,
  author =	 {J.Y. Zheng and S. Tsuji},
  title =	 {Panoramic representation of scenes for route
                  understanding},
  booktitle =	 ICPR,
  pages =	 {161-167},
  year =	 1990,
  volume =	 1,
}

@article{Zheng92ijcv,
  author =	 {J.Y. Zheng and S. Tsuji},
  fullauthor =	 {Jiang Yu Zheng and Saburo Tsuji},
  title =	 {Panoramic representation for route recognition by a
                  mobile robot},
  journal =	 IJCV,
  volume =	 9,
  number =	 1,
  year =	 1992,
  issn =	 {0920-5691},
  pages =	 {55--76},
  publisher =	 {Kluwer Academic Publishers},
  address =	 {Hingham, MA, USA},
}

@Article{Zhou93,
  author =	 {Zhou, B. and Bose, N.K.},
  title =	 {Multitarget tracking in clutter: fast algorithms for
                  data association},
  journal =	 AES,
  year =	 1993,
  volume =	 29,
  number =	 2,
  pages =	 {352-363},
}


@Article{Zhou95,
  author =	 {Zhou, B. and Bose, N.K.},
  title =	 {An efficient algorithm for data association in
                  multitarget tracking},
  journal =	 AES,
  year =	 1995,
  volume =	 31,
  number =	 1,
  pages =	 {458 -468},
}

@InProceedings{Zhu00,
  author =	 {S.C.Zhu and R.Zhang and Z.Tu},
  title =	 {Integrating Bottom-Up/Top-Down for Object
                  Recognition by Data Driven Markov Chain Monte Carlo},
  booktitle =	 CVPR,
  year =	 2000,
}

@Article{Zhu04ram,
  author =	 {Z.Zhu and Karuppiah, D.R. and Riseman, E.M. and
                  Hanson, A.R.},
  title =	 {Keeping smart, omnidirectional eyes on you [Adaptive
                  panoramic stereovision]},
  journal =	 {Robotics \& Automation Magazine},
  year =	 2004,
  volume =	 11,
  number =	 4,
  pages =	 {69-78},
  month =	 {Dec},
  note =	 {Special Issue on Panoramic Robotics},
}

@InProceedings{Zhu07iccv2,
  author =	 {Z. Zhu and T. Oskiper and S. Samarasekera and
                  R. Kumar and H.S. Sawhney},
  fullauthor =	 {Zhiwei Zhu and Taragay Oskiper and Supun
                  Samarasekera and Rakesh Kumar and Harpreet
                  S. Sawhney},
  title =	 {Ten-fold Improvement in Visual Odometry Using
                  Landmark Matching},
  booktitle =	 ICCV,
  location =	 {Rio de Janeiro, Brazil},
  month =	 {Oct},
  year =	 2007,
  abstract =	 {Our goal is to create a visual odometry system for
                  robots and wearable systems such that localization
                  accuracies of centimeters can be obtained for
                  hundreds of meters of distance traveled. Existing
                  systems have achieved approximately a 1\% to 5\%
                  localization error rate whereas our proposed system
                  achieves close to 0.1\% error rate, a ten-fold
                  reduction. Traditional visual odometry systems drift
                  over time as the frame-to-frame errors
                  accumulate. In this paper, we propose to improve
                  visual odometry using visual landmarks in the
                  scene. First, a dynamic local landmark tracking
                  technique is proposed to track a set of local
                  landmarks across image frames and select an optimal
                  set of tracked local landmarks for pose
                  computation. As a result, the error associated with
                  each pose computation is minimized to reduce the
                  drift significantly. Second, a global landmark based
                  drift correction technique is proposed to recognize
                  previously visited locations and use them to correct
                  drift accumulated during motion. At each visited
                  location along the route, a set of distinctive
                  visual landmarks is automatically extracted and
                  inserted into a landmark database dynamically. We
                  integrate the landmark based approach into a
                  navigation system with 2 stereo pairs and a low-cost
                  Inertial Measurement Unit (IMU) for increased
                  robustness. We demonstrate that a real-time visual
                  odometry system using local and global landmarks can
                  precisely locate a user within 1 meter over 1000
                  meters in unknown indoor/outdoor environments with
                  challenging situations such as climbing stairs,
                  opening doors, moving foreground objects etc..},
}


@InProceedings{Zhu98,
  author =	 "S.C. Zhu",
  title =	 "Stochastic computation of medial axis in {M}arkov
                  random fields",
  pages =	 "72--80",
  booktitle =	 CVPR,
  year =	 1998,
}

@Article{Zhu99,
  author =	 "S.C. Zhu",
  title =	 "Stochastic Jump-Diffusion process for computing
                  Medial Axes in {M}arkov Random Fields ",
  journal =	 PAMI,
  year =	 1999,
  volume =	 21,
  number =	 11,
  month =	 "November",
}

@InProceedings{Zielke92,
  author =	 "T. Zielke and M. Brauckmann and W. von Seelen",
  title =	 "Intensity and Edge--Based Symmetry Detection Applied
                  to Car--Following",
  pages =	 "865--873",
  ISBN =	 "3-540-55426-2",
  editor =	 "Giulio Sandini",
  booktitle =	 ECCV,
  month =	 "May",
  series =	 "LNCS",
  volume =	 588,
  publisher =	 "Springer",
  address =	 "Berlin, Germany",
  year =	 1992,
}

@Article{Zitnick04siggraph,
  author =	 {C.Zitnick and S.B.Kang and M.Uyttendaele and
                  S.Winder and R.Szeliski},
  title =	 {High-Quality Video View Interpolation Using a
                  Layered Representation},
  journal =	 {ACM Transactions on Graphics},
  year =	 2004,
  volume =	 23,
  number =	 3,
  pages =	 {600-608},
}

@Article{Zivkovic07ras,
  Author =	 {Z. Zivkovic and O. Booij and B. Kr\"{o}se},
  Title =	 {From images to rooms},
  Journal =	 ras,
  Volume =	 55,
  Number =	 5,
  Pages =	 {411--418},
  address =	 {Amsterdam, The Netherlands, The Netherlands},
  doi =		 {http://dx.doi.org/10.1016/j.robot.2006.12.005},
  fullauthor =	 {Zoran Zivkovic and Olaf Booij and Ben Kr\"{o}se},
  issn =	 {0921-8890},
  publisher =	 {North-Holland Publishing Co.},
  year =	 2007,
  note =	 {Data set url: \tt
                  http://staff.science.uva.nl/\~{}zivkovic/FS2HSC/dataset.html}
}

@InProceedings{Zlot02icra,
  author =	 "R. Zlot and A. Stentz and M.B. Dias and S Thayer",
  fullauthor =	 "Robert Zlot and Anthony Stentz and M. Bernardine
                  Dias and Scott Thayer",
  title =	 "Multi-Robot Exploration Controlled by a Market
                  Economy",
  booktitle =	 ICRA,
  month =	 "May",
  year =	 2002,
}

@InProceedings{Zoeter03icann,
  author =	 {O. Zoeter and T. Heskes},
  fullauthor =	 {Onno Zoeter and Tom Heskes},
  title =	 {Multi-scale switching linear dynamical systems},
  booktitle =	 {Proceedings ICANN/ICONIP},
  year =	 2003,
}

@Article{Zoeter03pami,
  author =	 {O. Zoeter and T. Heskes},
  fullauthor =	 {Onno Zoeter and Tom Heskes},
  title =	 {Hierarchical visualization of time-series data using
                  switching linear dynamical systems},
  journal =	 PAMI,
  year =	 2003,
  volume =	 25,
  number =	 10,
  pages =	 {1202-1215},
  month =	 {October},
}

@Article{Zweig99,
  author =	 {G. Zweig and S. Russell},
  fullauthor =	 {Geoffrey Zweig and Stuart Russell},
  title =	 {Probabilistic modeling with Bayesian networks for
                  automatic speech recognition},
  journal =	 {Australian Journal of Intelligent Information
                  Processing Systems},
  year =	 1999,
  volume =	 5,
  number =	 4,
  pages =	 {253-260},
}

@Proceedings{_AAAI00,
  Year =	 2000,
  Title =	 {Proc. $17^{th}$ AAAI National Conference on AI},
  Booktitle =	 {Proc. $17^{th}$ AAAI National Conference on AI},
  address =	 {Austin, TX},
  _publisher =	 {AAAI Press},
}

@Proceedings{_AAAI02,
  Year =	 2002,
  Title =	 {Proc. $19^{th}$ AAAI National Conference on AI},
  Booktitle =	 {Proc. $19^{th}$ AAAI National Conference on AI},
  address =	 {Edmonton, Alberta, Canada},
  _publisher =	 {AAAI Press},
}

@Proceedings{_AAAI04,
  Year =	 2004,
  Title =	 {Proc. $21^{th}$ AAAI National Conference on AI},
  Booktitle =	 {Proc. $21^{th}$ AAAI National Conference on AI},
  Address =	 {San Jose, CA},
  _publisher =	 {AAAI Press},
}

@Proceedings{_AAAI05,
  Year =	 2005,
  Title =	 {Proc. $22^{nd}$ AAAI National Conference on AI},
  Booktitle =	 {Proc. $22^{nd}$ AAAI National Conference on AI},
  address =	 {Pittsburgh, PA},
  _publisher =	 {AAAI Press},
}

@Proceedings{_AAAI82,
  Year =	 1982,
  Title =	 {Proc. First AAAI National Conference on AI},
  Booktitle =	 {Proc. First AAAI National Conference on AI},
  _publisher =	 {AAAI Press},
  address =	 {Carnegie Mellon University, Pittsburgh, PA},
}

@Proceedings{_AAAI88,
  Year =	 1988,
  Title =	 {Proc. $5^{th}$ AAAI National Conference on AI},
  Booktitle =	 {Proc. $5^{th}$ AAAI National Conference on AI},
  _publisher =	 {AAAI Press},
  address =	 {St. Paul, MN},
  month =	 {April},
}

@Proceedings{_AAAI92,
  Year =	 1992,
  Title =	 {Proc. $9^{th}$ AAAI National Conference on AI},
  Booktitle =	 {Proc. $9^{th}$ AAAI National Conference on AI},
  _publisher =	 {AAAI Press},
}

@Proceedings{_AAAI96,
  Year =	 1996,
  Title =	 {Proc. $13^{th}$ AAAI National Conference on AI},
  Booktitle =	 {Proc. $13^{th}$ AAAI National Conference on AI},
  _publisher =	 {AAAI Press},
}

@Proceedings{_AAAI98,
  Year =	 1998,
  Title =	 {Proc. $15^{th}$ AAAI National Conference on AI},
  Booktitle =	 {Proc. $15^{th}$ AAAI National Conference on AI},
  _publisher =	 {AAAI Press},
}

@Proceedings{_AAAI99,
  Year =	 1999,
  Title =	 {Proc. $16^{th}$ AAAI National Conference on AI},
  Booktitle =	 {Proc. $16^{th}$ AAAI National Conference on AI},
  _publisher =	 {AAAI Press},
}

@Proceedings{_CVPR00,
  Title =	 CVPR,
  Booktitle =	 CVPR,
  Address =	 {Hilton Head},
  Month =	 {June},
  Year =	 2000,
}

@Proceedings{_CVPR01,
  Title =	 CVPR,
  Booktitle =	 CVPR,
  Month =	 {June},
  Year =	 2001,
  Isbn =	 {1063-6919},
}

@Proceedings{_CVPR03,
  Title =	 CVPR,
  Booktitle =	 CVPR,
  Month =	 {June},
  Year =	 2003,
  Address =	 {San Diego},
}

@Proceedings{_CVPR04,
  Title =	 CVPR,
  Booktitle =	 CVPR,
  Month =	 {June},
  Year =	 2004,
}

@Proceedings{_CVPR05,
  title =	 CVPR,
  booktitle =	 CVPR,
  year =	 2005,
  fulleditor =	 {Cordelia Schmid and Stefano Soatto and Carlo Tomasi},
  editor =	 {C. Schmid and S. Soatto and C. Tomasi},
  month =	 {June},
  organization = {IEEE},
}

@Book{_George93edited,
  title =	 {Graph Theory and Sparse Matrix Computations},
  booktitle =	 {Graph Theory and Sparse Matrix Computations},
  editor =	 {J.A. George and J.R. Gilbert and J.W-H. Liu},
  series =	 {IMA Volumes in Mathematics and its Applications},
  publisher =	 {Springer-Verlag},
  address =	 {New York},
  year =	 1993,
  volume =	 56,
}

@Proceedings{_ICCV99,
  Year =	 1999,
  Title =	 {Proc. $7^{th}$ IEEE Intl. Conf. on Computer Vision},
  Booktitle =	 {Proc. $7^{th}$ IEEE Intl. Conf. on Computer Vision},
  address =	 {Kerkyra, Greece},
}

@Book{_Jordan98book,
  editor =	 {M.I. Jordan},
  title =	 {Learning in Graphical Models},
  publisher =	 {Kluwer Academic Press},
  year =	 1998,
  note =	 {Also published by MIT Press, 1999}
}

@Proceedings{_Oceans05Washington,
  address =	 {Washington, USA},
  title =	 {OCEANS, 2005. Proceedings of MTS/IEEE},
  booktitle =	 {OCEANS 2005. Proceedings of MTS/IEEE},
  year =	 2005,
}

@Proceedings{_Oceans07Aberdeen,
  address =	 {Aberdeen, Scotland},
  title =	 {OCEANS, 2007 - Europe},
  booktitle =	 {OCEANS 2007. Proceedings of IEEE},
  year =	 2007,
}

@Proceedings{_Oceans08Kobe,
  address =	 {Kobe, Japan},
  title =	 {OCEANS, 2008. Proceedings of IEEE},
  booktitle =	 {OCEANS 2008. Proceedings of IEEE},
  year =	 2008,
}

@Proceedings{_Oceans09Bremen,
  Year =	 2009,
  Title =	 {OCEANS 2009. Proceedings of IEEE },
  BookTitle =	 {OCEANS 2009. Proceedings of IEEE},
  address =	 {Bremen, Germany},
  _publisher =	 {IEEE},
  month =	 {May},
}

@Proceedings{_Robocup07,
  booktitle =	 {RoboCup 2007: Robot Soccer World Cup XI},
  title =	 {RoboCup 2007: Robot Soccer World Cup XI},
  series =	 {Lecture Notes In AI},
  editor =	 {U. Visser and F. Ribeiro and T. Ohashi and F. Dellaert},
  year =	 2008,
  publisher =	 {Springer-Verlag},
  month =	 {July},
}

@Proceedings{_UAI00,
  booktitle =	 {Proc. $16^{th}$ Conf. on Uncertainty in AI (UAI)},
  title =	 {Proc. $16^{th}$ Conf. on Uncertainty in AI (UAI)},
  year =	 2000,
  fulleditor =	 {Craig Boutilier and Moises Goldszmidt},
  address =	 {Stanford, CA},
  month =	 {July},
  _publisher =	 {Morgan Kaufmann},
}

@Proceedings{_UAI01,
  booktitle =	 {Proc. $17^{th}$ Conf. on Uncertainty in AI (UAI)},
  title =	 {Proc. $17^{th}$ Conf. on Uncertainty in AI (UAI)},
  year =	 2001,
  fulleditor =	 {Jack Breese and Daphne Koller},
  address =	 {Seattle, WA},
  month =	 {August},
  _publisher =	 {Morgan Kaufmann},
}

@Proceedings{_UAI02,
  booktitle =	 {Proc. $18^{th}$ Conf. on Uncertainty in AI (UAI)},
  title =	 {Proc. $18^{th}$ Conf. on Uncertainty in AI (UAI)},
  year =	 2002,
  fulleditor =	 {Adnan Darwiche, Nir Friedman},
  address =	 {Alberta, Canada},
  month =	 {August},
  _publisher =	 {Morgan Kaufmann},
}

@Proceedings{_UAI03,
  booktitle =	 {Proc. $19^{th}$ Conf. on Uncertainty in AI (UAI)},
  title =	 {Proc. $19^{th}$ Conf. on Uncertainty in AI (UAI)},
  year =	 2003,
  fulleditors =	 {Christopher Meek and Uffe Kjrulff},
  address =	 {Acapulco, Mexico},
  month =	 {August},
  _publisher =	 {Morgan Kaufmann},
}

@Proceedings{_UAI04,
  booktitle =	 {Proc. $20^{th}$ Conf. on Uncertainty in AI (UAI)},
  title =	 {Proc. $20^{th}$ Conf. on Uncertainty in AI (UAI)},
  year =	 2004,
  fulleditors =	 {Max Chickering and Joseph Halpern},
  address =	 {Banff, Canada},
  month =	 {July},
  _publisher =	 {AUAI Press},
}

@Proceedings{_UAI05,
  booktitle =	 {Proc. $21^{th}$ Conf. on Uncertainty in AI (UAI)},
  title =	 {Proc. $21^{th}$ Conf. on Uncertainty in AI (UAI)},
  year =	 2005,
  address =	 {Edinburgh, Scotland},
  month =	 {July},
  _publisher =	 {AUAI Press},
}

@Proceedings{_UAI06,
  booktitle =	 {Proc. $22^{nd}$ Conf. on Uncertainty in AI (UAI)},
  title =	 {Proc. $22^{nd}$ Conf. on Uncertainty in AI (UAI)},
  year =	 2006,
  address =	 {Cambridge, MA},
  month =	 {July},
  _publisher =	 {Morgan Kaufmann},
}

@Proceedings{_UAI90,
  booktitle =	 {Proc. $6^{th}$ Conf. on Uncertainty in AI (UAI)},
  title =	 {Proc. $6^{th}$ Conf. on Uncertainty in AI (UAI)},
  year =	 1990,
  fulleditor =	 {Piero Bonissone and Max Henrion and Laveen Kanal and
                  John Lemmer},
  address =	 {Cambridge, MA},
  month =	 {July},
  _publisher =	 {Elsevier Science},
}

@Proceedings{_UAI94,
  booktitle =	 {Proc. $10^{th}$ Conf. on Uncertainty in AI (UAI)},
  title =	 {Proc. $10^{th}$ Conf. on Uncertainty in AI (UAI)},
  year =	 1994,
  fulleditor =	 {Ramon Lopez de Mantaras and David Poole},
  address =	 {Seattle, WA},
  month =	 {July},
  _publisher =	 {Morgan Kaufmann},
}

@Proceedings{_UAI95,
  booktitle =	 {Proc. $11^{th}$ Conf. on Uncertainty in AI (UAI)},
  title =	 {Proc. $11^{th}$ Conf. on Uncertainty in AI (UAI)},
  year =	 1995,
  fulleditor =	 {Philippe Besnard and Steve Hanks},
  address =	 {Montreal, QU},
  month =	 {July},
  _publisher =	 {Morgan Kaufmann},
}

@Proceedings{_UAI96,
  booktitle =	 {Proc. $12^{th}$ Conf. on Uncertainty in AI (UAI)},
  title =	 {Proc. $12^{th}$ Conf. on Uncertainty in AI (UAI)},
  year =	 1996,
  fulleditor =	 {Eric Horvitz and Finn Jensen},
  address =	 {Portland, OR},
  month =	 {August},
  _publisher =	 {Morgan Kaufmann},
}

@Proceedings{_UAI97,
  booktitle =	 {Proc. $13^{th}$ Conf. on Uncertainty in AI (UAI)},
  title =	 {Proc. $13^{th}$ Conf. on Uncertainty in AI (UAI)},
  year =	 1997,
  fulleditor =	 {Dan Geiger and Prakash Shenoy},
  address =	 {Providence, RI},
  month =	 {August},
  _publisher =	 {Morgan Kaufmann},
}

@Proceedings{_UAI98,
  booktitle =	 {Proc. $14^{th}$ Conf. on Uncertainty in AI (UAI)},
  title =	 {Proc. $14^{th}$ Conf. on Uncertainty in AI (UAI)},
  year =	 1998,
  fulleditor =	 {Gregory Cooper and Serafin Moral},
  address =	 {Madison, WI},
  month =	 {July},
  _publisher =	 {Morgan Kaufmann},
}

@Proceedings{_UAI99,
  booktitle =	 {Proc. $15^{th}$ Conf. on Uncertainty in AI (UAI)},
  title =	 {Proc. $15^{th}$ Conf. on Uncertainty in AI (UAI)},
  year =	 1999,
  fulleditor =	 {Kathryn Laskey and Henri Prade},
  address =	 {Stockholm, Sweden},
  month =	 {July},
  _publisher =	 {Morgan Kaufmann},
}

@proceedings{_WG05,
  fulleditor =	 {Dieter Kratsch},
  booktitle =	 {31st Intl. Workshop on Graph-Theoretic Concepts in
                  Computer Science},
  title =	 {31st Intl. Workshop on Graph-Theoretic Concepts in
                  Computer Science},
  publisher =	 {Springer},
  year =	 2005,
  month =	 {June},
  address =	 {Metz, France},
}

@article{vanVeen98,
  author =	 {van Veen, H and Distler, H. and Braum, S. and
                  Bulthoff, H.},
  title =	 {Navigating through a virtual city: Using virtual
                  reality technology to study human action and
                  perception},
  journal =	 {Future Generation Computer Systems},
  volume =	 14,
  pages =	 {231--242},
  year =	 1998,
  c-annath =	 { Researchers in Cognitive science have , through
                  cognitive simulation, gathered a number of pieces of
                  evidence that suggest the use of representations
                  similar to topological maps in people. These studies
                  have shown that in addition to landmarks and other
                  special markers in environments, procedural
                  information regarding navigation between two
                  specific nodes is also used. Psychological studies
                  have also confirmed these findings [vanVeen98].}
}

@Article{yamamoto05warsi,
  title =	 {Optical sensing for robot perception and
                  localization},
  author =	 {Yamamoto, Y. and Pirjanian, P. and Munich, M. and
                  DiBernardo, E. and Goncalves, L. and Ostrowski,
                  J. and Karlsson, N.},
  journal =	 {IEEE Workshop on Advanced Robotics and its Social
                  Impacts},
  keywords =	 {NorthStar},
  year =	 {2005},
  month =	 {June},
  pages =	 {14--17},
  doi =		 {10.1109/ARSO.2005.1511612},
}

